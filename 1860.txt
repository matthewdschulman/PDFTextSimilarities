Open-World Mission Speciﬁcation for Reactive Robots
Spyros Maniatopoulos, Matthew Blair, Cameron Finucane, and Hadas Kress-Gazit
Abstract— Recent advances have enabled the automatic gen-
eration of correct-by-construction robot controllers from high-
level mission speciﬁcations. However, most current approaches
operate under the closed-world assumption, i.e., only elements
of the world explicitly modeled a priori can be taken into
account during execution. In this paper, we tackle the problem
of specifying and automatically updating the missions of robots
operating in worlds that are open with respect to new elements,
such as new objects and regions of interest. We demonstrate our
approach in a scenario featuring a robotic courier whose world
is open with respect to letters addressed to new recipients.
I. INTRODUCTION
In order for robots to become widely accessible, users
must be able to command them by specifying high-level
behaviors, rather than programming low-level robot con-
trollers. This type of robot control has recently become
possible by applying tools and ideas from formal methods
and hybrid systems to the ﬁeld of robotics. The resulting
methodologies translate high-level tasks to discrete and sub-
sequently low-level continuous controllers in a correct-by-
construction manner [1]–[7]. Reactive approaches, e.g. [2],
[4], [7], account for a dynamic – and possibly adversarial –
environment, and are thus of particular interest.
These approaches operate under the closed-world assump-
tion. The robot only accounts for what was modeled before
execution, and no information can be added autonomously,
i.e. without a human re-specifying the mission. However,
robots have moved from the cloistered assembly line to such
highly unstructured workspaces as the Fukushima Daiichi
nuclear disaster site [8]. In addition, robots are sometimes
asked to incorporate new functions during execution. Ex-
amples include robots that learn on-the-ﬂy [9] or query
online knowledge repositories [10]. Finally, the world may
be open with respect to goals added after the robot has been
deployed, as in the case of urban search and rescue tasks [11],
military scenarios [12], and autonomous space and planetary
exploration missions [13].
Example 1: Consider a robotic courier, i.e., a “mailbot”,
(see Fig. 1) deployed in a school or company building. Its
task is to collect letters and deliver them to the recipients’
ofﬁces. This mission is relatively simple, and yet the robot’s
world is already open w.r.t. letters addressed to recipients
about which the robot does not know.
In order to obtain controllers for open worlds, a number of
challenges have to be overcome. First, the world can be open
This work was supported by NSF CAREER CNS-0953365 and NSF
ExCAPE.
The authors are with the Autonomous Systems Lab, Sibley School of Me-
chanical and Aerospace Engineering, Cornell University, Ithaca, NY 14853,
USA, fsm2296, meb286, cpf37, hadaskgg@cornell.edu
Fig. 1: Our robotic courier: an Aldebaran Nao humanoid robot is
mounted on a Segway-based, mobility and sensing platform.
w.r.t. its spatial components. An aspect of this issue has been
tackled in [14] and [15], where the authors introduced local
resynthesis as a way to account for local topological changes
in the robot’s workspace. Additionally, an approach that
addresses the unreactive equivalent of the same problem ap-
peared in [16]. Furthermore, the aforementioned approaches
deal with changes in the internal structure of the workspace.
We are interested in expanding the workspace upon discovery
of new regions. In addition, we are interested in augmenting
the mission with additional objectives, a situation that may
arise if the robot can discover new regions or objects of
interest. The work in [17] allows the robot’s workspace
to expand, but does not account for the discovery of non-
spatial aspects of the world, such as learning new actions
or responding to unexpected events. Moreover, there is the
the challenge of specifying open-world missions in the
ﬁrst place, since the world is only partially known prior
to execution. Speciﬁcation languages and abstractions have
been developed for similar tasks with both formal [11], [18]
and statistical [19] methods. This paper differs from previous
approaches in its use of correct-by-construction controller
synthesis in an open world, requiring new techniques.
In this paper, we ﬁrst propose open-world abstractions,
which allow us to specify high-level robot behaviors in terms
of elements in the world that are unknown prior to execution.
Furthermore, they allow the speciﬁcation to be updated in
an autonomous fashion, as new elements of interest are
discovered. The new elements include, but are not limited
to, the sensing of new objects and events, and the discovery
of new regions of the workspace, and they may lead to
new mission constraints and/or goals. We show how the
mission speciﬁcation can be systematically and automatically
rewritten on-the-ﬂy, in order to correctly incorporate these
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 4328
new elements of the open world. Finally, our high-level
approach allows the user to control how the new elements
will be accounted for, and when the robot should start
operating according to the updated mission speciﬁcation.
Therefore, our work differs from, and is complementary to,
[14] and [15], which focus on directly revising the robot’s
discrete controller to account for changes in the workspace.
The paper is organized as follows: Section II provides
the necessary background on logic-based reactive mission
planning. Section III formally states the problem we are
addressing. The proposed abstractions, which we will use
to specify tasks over open worlds, are deﬁned in Section IV.
Section V presents our approach to systematically rewriting
the mission speciﬁcation. Simulations of the mailbot scenario
(Example 1), which is revisited throughout the paper, are
provided in Section VI. Finally, our conclusions, as well as
possible research directions, are summarized in Section VII.
II. PRELIMINARIES
A. Controller Synthesis
We present an overview of our reactive controller synthesis
process. We refer the reader to [2] for a detailed presentation.
Discrete Abstraction: First, the robot’s workspace is par-
titioned using a ﬁnite number of cells. The Boolean region
propositions R = fr
1
;r
2
;:::;r
N1
g denote the location
of the robot in the partition, and are thus mutually ex-
clusive. In addition, the robot can perform actions A =
f
1
;
2
;:::;
N2
g, which can involve the use of actuators,
e.g. grasping an object, turning an on-board camera on, or
the activation of memory propositions, e.g. having visited a
region at least once. Region and action propositions together
form the set of robot propositionsY =R[A.
Furthermore, the robot has sensors, whose value, whether
continuous or discrete, is abstracted by the Boolean environ-
ment/sensor propositionsX =fx
1
;x
2
;:::;x
N3
g. The sen-
sor propositions allow the robot to react to its environment.
Linear Temporal Logic: We are interested in missions with
complex requirements, such as surveillance, avoidance, and
response to events. Thus, we use Linear Temporal Logic
(LTL) formulas to specify desired high-level behaviors. LTL
consists of propositions, and Boolean (:;^;_) and tempo-
ral (next,, and until,U) operators. Additional temporal
operators, eventually (

) and always () can be derived.
In our setting, LTL formulas are constructed from atomic
propositions  2 AP = X [Y. The semantics of an
LTL formula ' are deﬁned over an inﬁnite sequence  of
truth assignments to the atomic propositions. Let t2 N be
the position index of . Then, (t) denotes the subset of
propositions  2 AP that are True at position t of the
sequence , and [t] denotes the valuation of a particular
proposition at position t.
Reactive Synthesis: Speciﬁcally, we use the GR(1) frag-
ment of LTL, because its synthesis is tractable [20]. GR(1)
formulas ' have an assume-guarantee structure between the
environment (e) and the robot (system, s):
' = ('
e
)'
s
);'
e
='
e
i
^'
e
t
^'
e
g
;'
s
='
s
i
^'
s
t
^'
s
g
where i denotes initial conditions, t safety assumptions/re-
quirements, andg liveness assumptions/requirements (goals)
for the environment and the robot, respectively.
If the formula ' is realizable, a discrete robot strategyS
is computed by solving a two-player game between the robot
and the environment (adversary) [20]. The strategy, which is
guaranteed to be winning for the robot, is augmented with
simple low-level controllers to form a hybrid controller [2].
B. LTL Mission Planning
The Linear Temporal Logic Mission Planning (LTLMoP)
toolkit [21] is a Python-based, open-source toolkit for
controlling physical and simulated robots using high-level
behavior speciﬁcations.
1
LTLMoP allows users to specify
missions in either pure LTL, natural language via a module
called SLURP [22], or a formal grammar called Struc-
tured English [23]. Structured English is designed to enable
users to intuitively understand behavior speciﬁcations and
this paper will use it for demonstration. Speciﬁcations in
Structured English are parsed using a feature-based context-
free grammar and translated into formulas of LTL for
controller synthesis. LTLMoP provides our framework for
mission speciﬁcation, performs reactive controller synthesis,
and monitors execution of the resulting strategy.
III. PROBLEM STATEMENT
Using the terminology in Section II, we say that the world
is closed if and only if AP , the set of atomic propositions,
is ﬁxed. That is, if the robot encounters a new element in its
world (such as a new object), which was not modeled as a
proposition 2 AP , it will essentially ignore it, even if it
is relevant to the mission.
Three main reasons motivate the need for open-world
mission speciﬁcation and planning. First, in applications such
as autonomous search and rescue scenarios, the mission is
often speciﬁed before the robot has obtained full knowledge
of the world. Second, the robot may have to incorporate
new functions and respond to new events during execution.
Finally, the mission’s set of atomic propositionsAP may be
too large for the user to enumerate a priori.
We begin our formal analysis of the problem by deﬁning
a model of an open world. Let W be a sequence of
sets of atomic propositions,W = AP
0
AP
1
:::AP
k
, where
AP
k+1
6=AP
k
, and k2N.
Also, letD =fd
1
;:::;d
m
;:::;d
M
g represent the abstract
sensors that are responsible for detectingM different classes
of new elements in the open world, where D  X
k

AP
k
;8k. For instance, one sensor d may detect new letters,
whereas another new ofﬁces. The number of new elements
that can be detected is not bounded by M, since each
sensor inD can trigger multiple times over the course of
a mission. In addition, let D be a function that reads the
sensors abstracted byD, and returns a new proposition if
1
http://ltlmop.github.io
4329
the sensors detected an unmodeled element of the world:
D(m;t) =
(
f
mt
g; if d
m
[t] =True
;; if d
m
[t] =False
(1)
where d
m
[t] denotes the value of the binary sensor d
m
at position t of the inﬁnite sequence  (Section II-A), and

mt
62AP
t
. The new proposition
mt
can be either a sensor,
an action, or a region proposition.
Putting everything together, we state the open-world model
that we consider in this paper.
Deﬁnition 1 (Expanding Open World Model): The
sequenceW is an expanding open world model if the set
of atomic propositions AP is updated as follows:
AP
t+1
=AP
t
[
M
[
m=1
D(m;t); (2)
and if AP changes, AP
t+1
is appended toW:
W =
(
WAP
t+1
; if
W
M
m=1
(d
m
[t] =True)
W; otherwise
(3)
As a corollary, if the world is closed, thenW =AP
0
;8t.
We will return to this deﬁnition in Section V, where we
augment the update ofAP
t
with additional new propositions.
Notice the assumptions regardingW that Eq. (2) makes:
Assumption 1:W only models the addition of proposi-
tions. That is, AP
k
 AP
k+1
. In other words, propositions
cannot be removed. Hence,W is dubbed an expanding open
world model.
Assumption 2:W models a world that is open only w.r.t.
new elements of M different types, i.e., those elements that
can be sensed by the sensors d
m
2D, m2f1;:::;Mg.
Assumption 1 is not limiting, since a proposition can be in
AP without being part of the robot’s controller. Furthermore,
the value of a proposition can be restricted by adding safety
requirements to '
e;s
t
, if necessary. The disadvantage of not
removing propositions that are no longer pertinent to the
mission is that the synthesis algorithm [20] will be searching
for a winning strategy over a larger graph, which leads to a
higher computation time. Assumption 2 limits the new events
to which the robot will react, to those that it can sense and
that are relevant to the mission. For instance, the mailbot
(Example 1) should update its mission if it senses a new
recipient, but not if someone tries to hand it a trash bag.
In order to obtain a mission speciﬁcation and a robot
plan that react to unmodeled elements of the world, we
need to address two main problems. First, we should allow
speciﬁcations that include operators outside of LTL, in order
to enable the mission to adapt toW. Then, we need to deﬁne
the speciﬁc mechanism that will allow new propositions
mt
to be incorporated in the mission’s LTL formulas.
The problem of rewriting a speciﬁcation to allow for
adding new propositions is stated below:
Problem 1 (Mission Speciﬁcation Update): Let  be a
speciﬁcation language andP

a parser for it. Augment 
andP

, such that given a mission speciﬁcation written in ,
M
k
=M(AP
k
)2 , a GR(1) formula '[k], and the latest
set of atomic propositions, AP
k+1
AP
k
, the missionM
k
and formula '
k
are automatically updated as follows:
M
k+1
=M(AP
k+1
); (4a)
'[k + 1] =P

(M
k+1
); (4b)
where the initial conditions of the GR(1) formula '[k + 1]
are set such that(t
+
)j ='
e
i
[k+1]^'
s
i
[k+1], where(t
+
)
are the current truth assignments to the atomic propositions
2AP
k+1
right after AP
k
is updated.
These restrictions on'[k +1] should ensure that its initial
conditions are compatible with the current environment and
robot state. The initial valuations of the new propositions
2 AP
k+1
nAP
k
are set according to the sensor readings
and the constraints inM
k+1
. Notice that the speciﬁcation
language  and the parserP

only provide the semantics and
mechanics for updating'[k]. The resulting formula,'[k+1],
depends on the user-deﬁned mission speciﬁcationM.
Given the problem statement above, we ﬁrst augment the
speciﬁcation language  with open world abstractions in
Section IV. These abstractions allow us to specify tasks
without explicitly referring to individual propositions. In
Section V we show how an additional mechanism of 
leverages the expressive power of open world abstractions to
enable the systematic addition of new propositions to AP
k
,
and consequently the rewriting ofM
k
and '[k].
IV. OPEN-WORLD ABSTRACTIONS
A. Groups of Propositions
In order to write meaningful speciﬁcations over proposi-
tions without referring to them explicitly, we borrow notions
of ﬁrst-order logic to augment . First-order logic differs
from propositional logic and LTL by its use of predicates and
quantiﬁcation over entities, of which our approach is only
concerned with quantiﬁcation. Two types of quantiﬁcation
are allowed in ﬁrst-order logic: universal quantiﬁcation using
8 and existential quantiﬁcation using9.
 allows quantiﬁcation over sets of propositions, which
we refer to as groups. This allows users to specify reac-
tive behaviors in terms of groups of propositions instead
of explicitly naming propositions. Quantiﬁcation behaves
identically towards all propositions within a group, therefore
they must all be grammatically interchangeable within a
speciﬁcation. This interchangeability is a property of propo-
sitions of the same type (i.e. sensors, action propositions, or
regions), therefore we further constrain groups to be sets of
propositions that are all of a single type. In summary, a group
G has the following property: GX
t
jGA
t
jGR
t
.
This generalizes the work in [17], which focused only on
groups of region propositions.
B. Group Quantiﬁers
For an expression in  to be quantiﬁed over a group of
propositions, the expression must have both a reference to
the group (e.g. the name of the group) and a quantiﬁer. 
is augmented with three quantiﬁers: ‘any’, ‘all’, and ‘each’.
For quantiﬁcation to be meaningful in a robot’s behavior
4330
the parserP

must be able to translate the semantics of
these ﬁrst-order logic operations into LTL formulas '. In
this section we deﬁne LTL interpretations of quantiﬁcation.
Let  ' be the translation of an expression in  into an
expression containing only LTL operators and quantiﬁed
groups. Using G to denote a group, we can write the quan-
tiﬁcation of groups in  ' as ‘any(G)’, ‘all(G)’, or ‘each(G)’.
We will also use [y=x]  ' to denote the expression that results
from replacing all occurrences of x in  ' with y.
The quantiﬁer ‘any(G)’ in a sentence is translated as the
logical disjunction of every proposition in the groupG. That
is,  ' is translated into: [p=any(G)]  ', where: p =
W
i2G

i
.
The quantiﬁer ‘all(G)’ in a sentence is translated as the
logical conjunction of every proposition in the groupG.  ' is
therefore translated into: [p=all(G)]  ', where: p =
V
i2G

i
.
The quantiﬁer ‘each(G)’ is similar to ‘all(G)’, but acts
with a different semantic scope. ‘each(G)’ denotes that the
entire expression is true for each of the propositions in G
separately. Thus,  ' is translated into:
V
i2G
[
i
=each(G)]  '
Example 2: Consider a scenario where a robot is helping
to manage a hotel. The robot has a group of regions repre-
senting the rooms in the hotel, a group of sensors indicating
whether rooms are occupied, with a proposition for every
room, and actions for cleaning a room, welcoming guests,
and apologizing to guests. Part of the robot’s speciﬁcation
might be expressed in English as: “If some rooms are oc-
cupied but not all rooms are occupied then welcome guests.
If all rooms are occupied then apologize to guests. If none
of the rooms are occupied then go to each room and clean
the room.” Using the quantiﬁers in , this behavior can be
expressed without explicitly naming individual propositions.
C. Proposition Correspondence
One consequence of writing speciﬁcations without indi-
vidual propositions is that relationships between proposi-
tions become more difﬁcult to denote in speciﬁcations. For
instance if a robot were operating in a workspace with
groups of regions that had one-to-one relationships, such as
pick-up and drop-off locations, those relationships cannot be
speciﬁed without explicitly naming individual propositions.
To address this difﬁculty, our new  must allow the deﬁni-
tion of correspondences between propositions in groups. A
correspondence is a mapping from individual propositions
to sets of propositions that contain at most one proposition
from each group deﬁned in the speciﬁcation.  allows users
to deﬁne correspondence either by explicitly mapping atomic
propositions to one another or by mapping one group onto
another. Correspondence is denoted by the function C

:
AP ! 2
AP
, which takes in an atomic proposition and
returns the set of propositions that it has been deﬁned to
correspond to, where 2
AP
denotes the power set ofAP . We
say that a proposition 
i
corresponds to 
j
if and only if

j
2C

(
i
), where i6= j. For deﬁning correspondences
between groups, we deﬁne another correspondence function
C
G
, which operates on groups of propositions. We say that a
groupG
i
corresponds toG
j
, written asG
j
2C
G
(G
i
), where
i6=j if and only if the following two conditions hold:
8
j
2G
j
9!
i
2G
i
:
j
2C

(
i
) (5a)
8
i
2G
i
:C

(
i
)\G
j
6=; (5b)
Where9! denotes unique existence. Note that these condi-
tions necessitate thatjG
i
j =jG
j
j. In the remainder of this
paper we will omit the subscripts onC when its usage is
clear.
Once correspondence has been deﬁned in a speciﬁcation,
 allows the use of a ‘corresponding’ operator to implicitly
refer to the relationship between individual propositions
without explicitly referring to the propositions themselves.
To use our previous notation of  ' andG, the ‘corresponding’
operator can be written as ‘corresponding(G)’. The ‘corre-
sponding’ operator is different from the quantiﬁers described
earlier because its semantics depend on the presence of
another quantiﬁed group in the same sentence. We can
demonstrate this dependency with two English sentences:
“Go to the corresponding rooms” and “Take all of the guests
to their corresponding rooms”. The ﬁrst sentence is unclear
because it is lacking the index of correspondence provided in
the second sentence, namely “all of the guests”. Therefore a
sentence using correspondence has two relevant groups:G
q
,
the quantiﬁed group, andG
c
, the ‘corresponding’ group.G
q
may be paired with any of the available quantiﬁers, but the
interpretation of quantiﬁed sentences using correspondence
always results in conjunction over statements, as occurs with
the ‘each’ quantiﬁer. We can now express the translation of
 ' for a sentence using correspondence as:
^
i2Gq
[
i
=q(G
q
)][C(
i
)\G
c
=corresponding(G
c
)]  '; (6)
where q is any of the available quantiﬁers. Note from
our deﬁnition of correspondence that the set intersection
in (6) results in at most one element. If the intersection is
empty, meaning that a correspondence has not been properly
deﬁned, then the sentence produces a syntax error.
Example 3: Correspondence is useful in a scenario in
which a robot performs an identical task over many sets
of related propositions, such as waiting on tables at a
restaurant. Our speciﬁcation can deﬁne a group of region
propositions representing the tables in the restaurant and a
group of sensor propositions representing the robot being
signalled by speciﬁc tables. We can specify our desired
behavior in English as follows: “Calls correspond to tables.
If you are sensing any calls then go to the corresponding
table.” The abstraction of propositions into groups makes the
speciﬁcation more compact and readable, less error-prone,
and more easily extensible. To specify this behavior over
another pair of call and table propositions, we need only
add the new propositions to their appropriate groups.
V. OPEN-WORLD MISSION SPECIFICATION
This section describes our approach to specifying and
updating robot missions taking place in open worlds. Our
presentation takes the form of requirements on a speciﬁcation
4331
language , such that mission speciﬁcationsM(AP )2 ,
parsed byP

satisfy Eqs. (4a) and (4b). First, we leverage
the expressive power of open-world abstractions to specify
high-level behaviors without referring to individual proposi-
tions  2 AP
k
. Then, we show that the addition of new
propositions to a mission speciﬁcation M
k
= M(AP
k
)
has to follow certain rules, such that correspondence C
G
between groups of propositions is maintained. Finally, we
provide a mechanism that allows the user to explicitly specify
when the updated speciﬁcationM
k+1
=M(AP
k+1
), and
consequently the GR(1) formula '[k + 1] = P

(M
k+1
),
should be synthesized into a revised robot controller.
A. Deﬁning Tasks over Open Worlds
The ﬁrst requirement on speciﬁcationsM
0
=M(AP
0
)2
 is the deﬁnition of groups of propositions G
i
and the
deﬁnition of correspondence,C
G
, between groups of proposi-
tions. Then, tasks that refer to individual propositions2G
i
can be replaced by tasks over G
i
and G
j
2C(G
i
); j6=i.
An advantage of open-world abstractions is the ability to
specify a mission even if the groups contain no propositions
prior to execution, i.e., G
i
= ; inM
0
. In this case, the
groups will be populated on-the-ﬂy as new elements in the
world are discovered (see Section V-B, and Example 5).
Example 4: We revisit Example 1 and make use of the
open world abstractions. For illustrative purposes, we use
Structured English [23] as the speciﬁcation language .
Mission speciﬁcation: (partial) Autonomous Mailbot
1: Group Letters is letter1, letter2
2: Group Offices is office1, office2
3: Letters correspond to Offices
4: If you are sensing any Letter then
go to the corresponding Office
Let G
1
be Letters and G
2
be Offices. Line 3
establishes correspondence fromG
1
toG
2
, i.e.,G
2
2C(G
1
).
We use the notation G
2
2C(G
1
), rather than G
2
=C(G
1
),
because G
1
could potentially correspond to more groups,
e.g.C(G
1
) =fG
2
;G
3
;:::g. Notice how the task in line 4
does not refer to any particular letters or ofﬁces. As already
mentioned, even ifG
1
;G
2
2M
0
were empty, the user would
still be able to specify the mission above.
Let a letter corresponding to a new recipient be sensed by
a sensor d
m
2D, e.g. labeled newLetter. Then, a new
proposition, 
mt
, e.g. labeled letter3, would be added
to AP
t
. There are two requirements for the speciﬁcation
M
k+1
to reﬂect the addition of the new proposition. First,

mt
has to also be added to the groupG
1
. Second, an ofﬁce
proposition,
0
=office3, has to be created, if necessary,
and added toG
2
, in order to re-establish correspondence, i.e.,
G
2
2C(G
1
), where nowG
0
1
=G
1
[f
mt
g,G
0
2
=G
2
[f
0
g.
Then, we would have 
0
2C(
mt
). These two requirements
are generalized in Problem 2, a subset of of Problem 1.
Problem 2 (New Propositions and Correspondence):
Given a mission speciﬁcationM
k
, containing n groups of
propositions, G
M
=fG
1
;G
2
;:::;G
n
g, and a new propo-
sition 
mt
= D(m;t), deﬁne a mechanism for (i) adding

mt
to any number of groupsGG
M
, and for (ii) creating
additional propositions, 
ij
, and adding them to the groups
that each G
i
2G corresponds to, i.e., to
G
C
=
[
Gi2G
C
G
(G
i
)
B. Rewriting the Mission Speciﬁcation
To address Problem 2, we introduce another element to
the speciﬁcation language , the add to Group operator.
Deﬁnition 2 (add to Group): The add to Group operator
takes the new proposition 
mt
= D(m;t), and adds it to
one or more groups of propositions,GG
M
. Furthermore,
it adds additional propositions, 
ij
, to the corresponding
groups, G
C
. That is, (G
0
;G
0
C
) = add to(
mt
;G), where
G
0
=fG
0
i
jG
0
i
=G
i
[f
mt
g;G
i
2Gg;
G
0
C
=

G
j
0


G
j
0
=G
j
[


ij
	
;G
j
2C(G
i
);G
i
2G
	
:
Returning to Example 4, the add to Group operator
would be add to(
mt
;fG
1
g) = (fG
1
g;fG
2
g); where G
1
and G
2
stand for Letters and Offices, respectively.
The equivalent Structured English task would be: if you
are sensing newLetter then add to group
Letters, where newLetter is the label of a sensor
d
m
2 D. The new propositions are named by either a
predeﬁned naming scheme, prompting the human user,
or using information from the low-level sensor that is
abstracted by the proposition d
m
. For example, the new
“letter” proposition could be named after the recipient’s
name, e.g. letter johnDoe, while the “ofﬁce” might
use the address printed on the letter, e.g. Room 155.
Since we are now adding propositions besides those added
by the detection sensors d
m
2D, as a direct result of the
open world, we have to revise Deﬁnition 1 as follows:
Deﬁnition 3 (Expanding Open World Model): Our
modelW =AP
0
AP
1
:::AP
k
is now updated such that the
propositions added in order to maintain correspondence are
also added to the set of atomic propositions. That is,
AP
t+1
=AP
t
[
M
[
m=1
D(m;t)[
M
[
m=1
[
2D(m;t)
C

() (8)
replaces Eq. (2). Eq. (3) remains the same.
Assumption 3: The grounding [24] of new propositions
2 AP
k+1
nAP
k
to the robot’s physical world is obtained
either from the robot’s low-level sensors, which propositions
d2D abstract, or by prompting the human user (Section
VI). Some auxiliary propositions, such as robot memory
propositions, do not require grounding to the physical world.
For instance, in Example 4, a new letter would result
in new propositions letter3 and office3. The sensor
proposition letter3 would be grounded to letters bearing
the new recipient’s name. The information for grounding
office3 to a location on the robot’s workspace can be
inferred from the address on the letter, which the robot can
look up on a map. If the new ofﬁce is not part of the current
map, the robot could prompt the user for its location, and
then incorporate it as a new region proposition.
4332
Fig. 2: Illustration of our approach. For clarity, a single new
proposition m is added to a single group Gm, which has two
corresponding groups, C(Gm). The Tasks part of M
k+1
is
immutable throughout the rewriting and resynthesis processes. That
is, only the contents of groups Gm and C(Gm) change, not the
tasks’ description. Finally,S
0
denotes the revised robot controller.
C. Updating the Controller
The speciﬁcation rewriting described so far has resulted
in mission speciﬁcationM
k+1
that can be parsed to an LTL
speciﬁcation'[k+1], according to Eq. (4b). However, for the
updates to be reﬂected in the robot’s controller,'[k + 1] has
to be passed to the synthesis algorithm in order to extract a
new winning strategy. This process is dubbed “resynthesis”,
and it is based on the work in [17].
Since we want to enable the user to specify when
resynthesis should take place, we associate a robot
proposition, e.g. resynthesize, with it. For example, in
the setting of Example 4, and using Structured English, we
could say: if you are sensing newLetter then
add to group Letters and resynthesize. In
this task, the robot would update its strategy immediately
after detecting a letter for a new recipient. In a search
and rescue setting, it might make more sense for the
robot to ﬁnish executing other, higher priority tasks before
resynthesizing. An excerpt from such a mission could be:
resynthesize if and only if you are not
activating rescueSurvivor and you are
activating resynthesisPending.
The deﬁnition of the add to Group operator and resynthesis
conclude the augmentation of the speciﬁcation language .
Our approach is graphically summarized in Fig. 2.
VI. SIMULATION IN LTLMOP
We implemented the proposed approach to open-world
mission speciﬁcation in LTLMoP (see Section II-B). We
augmented Structured English with open-world abstractions
(groups, quantiﬁers, and correspondences), the add to group
operator, and a resynthesis action.
Example 5: We revisit the mailbot scenario from Exam-
ples 1 and 4, and present the full mission speciﬁcation,M
0
.
The robot’s workspace can be seen in Fig. 3a.
Initially, the robot has no information about speciﬁc let-
ters or their recipients. Therefore, it patrols the regions in
PatrolRooms. If it senses a new letter (see Fig. 3a), it
will add a proposition to the groupLetters. In simulation,
LTLMoP prompts the user for the name of the proposition,
e.g.letter1. Additionally, the add to operator has to add a
proposition to the group Offices, in order to maintain the
correspondence. LTLMoP prompts the user a second time,
and the user inputs one of the region names,r1–r6 (see Fig.
3b). The two user prompts simulate the process of scanning
the letter for the recipient’s name and address, in order to
name and ground the new propositions (see Assumption 3).
Mission speciﬁcation: Autonomous Mailbot
Group declarations:
Group Letters is empty
Group Offices is empty
Group PatrolRooms is mailRoom, hallW, hallN
Correspondence deﬁnitions: (immutable)
Letters correspond to Offices
Mission tasks: (immutable)
If you are sensing any Letters then go to the
corresponding Office
If you are not sensing any Letters then visit
each PatrolRoom
Open–World settings: (immutable)
If you are sensing newLetter then add to
group Letters and resynthesize
After the speciﬁcation is rewritten, the LTL formula '[k]
changes to '[k + 1], according to Eqs. (4a) and (4b). The
change involves adding a new mission goal: the delivery
of letter1 to the corresponding ofﬁce r1. Speciﬁcally,
compared to'
s
g
[k],'
s
g
[k+1] contains the additional liveness
requirement:

(letter1)r1).
After resynthesis (see Fig. 3c), the robot can now sense
letters in two ways. First, it could detect a letter addressed to
the same recipient asletter1. In this case,letter1 will
become True, and the robot will deliver the letter to r1.
Second, it could detect a letter addressed to a new recipient.
In that case, the sensor newLetter will become True,
and the add to group operator will once again cause new
propositions to be added to Letters and Offices.
VII. CONCLUSIONS AND FUTURE WORK
In this paper, we presented an approach to specifying
and updating robot missions that take place in worlds open
with respect to new elements, such as new objects and
regions of interest. During execution, the new elements are
translated into new propositions, which are automatically
incorporated into the mission speciﬁcation. This is possible
via (i) open-world abstractions, which enable us to specify
high-level behaviors without explicitly referring to individual
propositions, and (ii) the add to Group mechanism, which
systematically augments sets of propositions with new ele-
ments. A notable advantage of our approach is that it allows
the user to specify how the new elements will be incorporated
4333
(a) A new letter is detected. The user names the new proposition.
(b) The user grounds the corresponding ofﬁce proposition to r1.
(c) letter1 and r1 were added to Letters and Offices.
Fig. 3: Simulation of Example 5 in LTLMoP.
into the mission, and under which conditions the updates will
be reﬂected in the robot’s controller.
A future research direction is the generalization of our
model in order to also account for the removal of proposi-
tions that are no longer pertinent to the mission. In addition,
our method of translating an updated speciﬁcation to a new
execution strategy is that of global resynthesis. We will
investigate local resynthesis approaches, in the direction of
[14], [15]. The ability to remove propositions, coupled with
the efﬁciency of local resynthesis will allow us to deal with
large-scale open worlds without synthesis becoming a com-
putational bottleneck. Furthermore, we intend to generalize
and formalize the introduction of elements of ﬁrst-order logic
to our speciﬁcation language. On the implementation side,
we are interested in a human-robot dialogue interface that
would allow users to specify new tasks during execution.
REFERENCES
[1] C. Belta, A. Bicchi, M. Egerstedt, E. Frazzoli, E. Klavins, and G. J.
Pappas, “Symbolic planning and control of robot motion: State of the
art and grand challenges,” Robotics and Automation Magazine, vol. 14,
no. 1, pp. 61–70, 2007.
[2] H. Kress-Gazit, G. E. Fainekos, and G. J. Pappas, “Temporal logic
based reactive mission and motion planning,” IEEE Transactions on
Robotics, vol. 25, no. 6, pp. 1370–1381, 2009.
[3] S. Karaman and E. Frazzoli, “Sampling-based motion planning with
deterministic -calculus speciﬁcations,” in CDC, 2009.
[4] T. Wongpiromsarn, U. Topcu, and R. M. Murray, “Receding horizon
control for temporal logic speciﬁcations,” in Proc. of the 13th Int’l
Conf. on Hybrid Systems: Computation and Control, 2010.
[5] L. Bobadilla, O. Sanchez, J. Czarnowski, K. Gossman, and S. LaValle,
“Controlling wild bodies using linear temporal logic,” in RSS, Los
Angeles, CA, USA, June 2011.
[6] A. Bhatia, M. Maly, L. E. Kavraki, and M. Y . Vardi, “Motion planning
with complex goals,” Robotics Automation Magazine, IEEE, vol. 18,
no. 3, pp. 55 –64, sept. 2011.
[7] A. Ulusoy, M. Marrazzo, and C. Belta, “Receding horizon control
in dynamic environments from temporal logic speciﬁcations,” in
Robotics: Science and Systems, 2013.
[8] K. Nagatani, S. Kiribayashi, Y . Okada, S. Tadokoro, T. Nishimura,
T. Yoshida, E. Koyanagi, and Y . Hada, “Redesign of rescue mobile
robot quince,” in Safety, Security, and Rescue Robotics (SSRR), 2011
IEEE International Symposium on, 2011, pp. 13–18.
[9] Y . Jiang, M. Lim, C. Zheng, and A. Saxena, “Learning to place
new objects in a scene,” International Journal of Robotics Research,
vol. 31, no. 9, 2012.
[10] D. Hunziker, M. Gajamohan, M. Waibel, and R. D’Andrea, “Rapyuta:
The RoboEarth cloud engine,” in Proc. IEEE Int. Conf. on Robotics
and Automation (ICRA), Karlsruhe, Germany, 2013, pp. 438–444.
[11] K. Talamadupula, J. Benton, P. Schermerhorn, S. Kambhampati, and
M. Scheutz, “Integrating a closed world planner with an open world
robot: A case study,” AAAI, 2010.
[12] M. Klenk, M. Molineaux, and D. W. Aha, “Goal-driven autonomy for
responding to unexpected events in strategy simulations,” Computa-
tional Intelligence, vol. 29, no. 2, pp. 187–206, 2013.
[13] W. Truszkowski, M. Hinchey, J. Rash, and C. Rouff, “Autonomous and
autonomic systems: a paradigm for future space exploration missions,”
Systems, Man, and Cybernetics, Part C: Applications and Reviews,
IEEE Transactions on, vol. 36, no. 3, pp. 279–291, 2006.
[14] S. C. Livingston, R. M. Murray, and J. W. Burdick, “Backtracking
temporal logic synthesis for uncertain environments,” in IEEE Int’l.
Conf. on Robotics and Automation, 2012.
[15] S. C. Livingston, P. Prabhakar, A. B. Jose, and R. M. Murray,
“Patching task-level robot controllers based on a local -calculus
formula,” in IEEE Int’l. Conf. on Robotics and Automation, 2013.
[16] M. Guo, K. H. Johansson, and D. V . Dimarogonas, “Revising motion
planning under linear temporal logic speciﬁcations in partially known
workspaces,” in IEEE Int’l. Conf. on Robotics and Automation, 2013.
[17] S. Sarid, B. Xu, and H. Kress-Gazit, “Guaranteeing high-level behav-
iors while exploring partially known maps,” in Robotics: Science and
Systems, 2012.
[18] S. Joshi, P. Schermerhorn, R. Khardon, and M. Scheutz, “Abstract
planning for reactive robots,” 2012 IEEE International Conference on
Robotics and Automation, pp. 4379–4384, May 2012.
[19] S. Tellex, T. Kollar, S. Dickerson, M. R. Walter, A. G. Banerjee,
S. Teller, and N. Roy, “Understanding Natural Language Commands
for Robotic Navigation and Mobile Manipulation,” AAAI, 2011.
[20] N. Piterman, A. Pnueli, and Y . Sa’ar, “Synthesis of Reactive(1)
Designs,” in VMCAI, Charleston, SC, January 2006, pp. 364–380.
[21] C. Finucane, G. Jing, and H. Kress-Gazit, “LTLMoP: Experimenting
with language, temporal logic and robot control,” in IEEE/RSJ Int’l.
Conf. on Intelligent Robots and Systems, Oct. 2010, pp. 1988–1993.
[22] V . Raman, C. Lignos, C. Finucane, K. C. T. Lee, M. Marcus, and
H. Kress-Gazit, “Sorry Dave, I’m Afraid I Can’t Do That: Explain-
ing Unachievable Robot Tasks Using Natural Language,” Robotics:
Science and Systems, 2013.
[23] H. Kress-Gazit, G. E. Fainekos, and G. J. Pappas, “Translating
structured english to robot controllers,” Advanced Robotics, vol. 22,
no. 12, pp. 1343–1359, 2008.
[24] S. Coradeschi, A. Loutﬁ, and B. Wrede, “A short review of symbol
grounding in robotic and intelligent systems,” KI, vol. 27, no. 2, pp.
129–136, 2013.
4334
