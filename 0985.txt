Manipulation Strategy Decision and Execution based on
Strategy Proving Operation for Carrying Large and Heavy Objects
Masaki Murooka, Shintaro Noda, Shunichi Nozawa, Yohei Kakiuchi, Kei Okada and Masayuki Inaba
Abstract—In case that a robot carries large and heavy objects
with unknown physical parameters such as mass automatically,
the autonomous decision and execution of the manipulation
strategy are necessary. The method to decide the proper
strategy from the various candidates depending on the object is
a difﬁcult problem and not researched widely. We consider the
operation as the mapping from the physical parameter space to
the object motion space. Based on the concept of mapping, we
deﬁne the strategy proving operation (SPO) for determination
of strategy feasibility. We introduce two examples of SPO
and construct the system for deciding strategy from lifting,
pushing, and pivoting. Executing the strategy in the situation
that physical parameters are not known is also necessary.
We construct the generator and controller for the full-body
manipulation, which can be employed regardless of strategy.
The controller enables the robot to exert adequate force while
keeping balance. We clarify the applicable scope of the proposed
method and show that a life-sized humanoid decides the strategy
and carries various large and heavy objects autonomously
through the experiment.
I. INTRODUCTION
Carrying objects is one of the tasks which robots are ex-
pected to perform in daily life. Especially, the high autonomy
in the motion is necessary for human utility.
One of the difﬁculties of the carrying task is selection of
the feasible strategy from a lot of choice, and the choice of
these strategies depends on the physical parameters of the
target object. For example if the object is heavy, large and
high friction, then pivoting behavior might be appropriate
one, whereas if the object is heavy, large but low friction,
then the robot can push the object as shown in Fig.1. The
problem is that measuring physical parameters of the objects
is very difﬁcult unless the robot manipulates them, however,
the robot requires physical parameters in order to manipulate
the object.
In this paper, we solve the above problem by Manipulation
Strategy Decision (MSD) and Execution (MSE) based on
Strategy Proving Operation (SPO). SPO is the object opera-
tion for determining the feasibility of the strategy based on
mapping between the physical parameter space, the object
motion space, and the strategy list. We construct the system
for carrying objects by integrating MSD and MSE, which
is applicable to general objects, environments, and robots
(Fig.2). The features of this system are following two points:
(i) deciding strategy autonomously and (ii) requiring no
M. Murooka, S. Noda, S. Nozawa, Y. Kakiuchi, K. Okada and M.
Inaba are with Department of Mechano-Infomatics, The University of
Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo 113-8656, Japan murooka at
jsk.t.u-tokyo.ac.jp
physical parameters of the objects. We conﬁrm the effective-
ness of our method in an experiment in which a humanoid
robot carries large furniture autonomously.
Pushing Pivoting
Fig. 1. Objects Manipulation by a Robot.
II. CARRYING LARGE AND HEAVY OBJECTS
WITH A ROBOT
A. Problem Establishment
In this section, we organize the premise and clarify the
deﬁnition of the problem for carrying heavy objects with the
robot.
1) Parameters of Objects, Environment, and Robot: Fig.3
shows the parameters of the three element: Objects (O),
Environment (E), and Robot (R). Let ?
O
, ?
E
, and ?
R
be the parameters of each element. The parameters can be
divided into the kinematic parameters ?
?K
and the physical
parameters ?
?P
. The kinematic parameters represent the
geometrical structure and the physical parameters are related
to the dynamics.
In this paper, we assume ?
OK
and ?
EK
are known. Even
if those are unknown, the robot can generate the model online
from vision data such as images and point clouds[1]. On the
other hand, ?
OP
and ?
EP
are unknown because they are
rarely known in general situation, and difﬁcult to measure.
?
R?
is treated as known.
2) Deﬁnision of Manipulation Strategy: There are var-
ious manipulation methods for heavy objects. Pushing[2],
Pivoting[3], [4], Lifting[5], Holding[6], and Tumbling[7], are
researched and achieved in experiments with real robots.
We deﬁne the manipulation strategy S as this manipulation
method, and express the strategy S with the object’s pose
sequence r(t) for general expression.
S: r(t)=(x(t),y(t),z(t),?(t),?(t),?(t))
T
(t ≥ 0) (1)
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 3425
Fig. 2. Propsed System Conﬁguration
(A) MSD decides the feasible strategy S
i
, and (B) MSE executes S
i
.
Fig. 3. Table of the O,E,R Parameters
Gray cells mean the unknown parameters.
The characters, x,y,z represent the position of COG in
the world coordinate and ?,?,? represent the attitude in
roll, pitch, yaw direction. For generating method of the
manipulation strategy S, it is possible to deﬁne major general
strategy based on heuristics, or generate automatically with
learning algorithm by applying random sequence of external
force and moment on dynamics simulation.
3) Problem: In the following, we solve the problem to
decide and execute the manipulation strategy applicable for
each object.
B. Our Proposed System
The Fig.2 shows the proposed system for carrying the
objects with unknown physical parameter. The system con-
sists of two components: (A) Manipulation Strategy Decision
(MSD) and (B) Manipulation Strategy Execution (MSE). In
(A), the robot decides the proper strategy based on the infor-
mation got by strategy proving operation. Strategy proving
operation are generated by considering mapping between
physical parameter space and strategy list. In (B), the robot
generate the full-body motion from strategy and execute it by
full-body control. The generator and controller, which need
no physical parameters, are common for various strategy. In
the following sections, we introduce (A) in Sec.III, and (B) in
Sec.IV. We perform the veriﬁcation experiments to evaluate
each component in the last of Sec.III and IV respectively,
and the effectiveness of whole system is conﬁrmed in the
experiment with HRP-2 robot in Sec.V.
C. Related Works and Contributions of this Paper
1) The Framework for Strategy Decision: Although a lot
of researches deal with the motion generation and control
for individual strategy, the decision procedure of strategy is
hardly researched. In the research of Nishide et al.[8], the
robot predicts the dynamics by manipulating and learning,
but the strategy decision is not discussed. The researches
on the industrial arm robot are achieving the sophisticated
object manipulations, but the working situation are mostly
unchanged and the strategy switching is not necessary.
The framework of the autonomous decision becomes abso-
lutely necessary for the robots to perform the carrying task in
the general situation. In this research, we propose the general
principle and the simple and heuristic detection methods. We
believe the proposed system has the high comprehensiveness
and this research becomes the base in this research ﬁeld.
2) The Approach to deal with the physical parameters:
Another feature of the proposed method is the point that we
do not deal with the physical parameter directly. The model-
based approach is possible by measuring some physical
parameters such as mass, COG, and friction[9], [10], but
there are following demerits: the system inevitably has the
model error, the procedure becomes complicated, and the
measured parameters are low-accuracy. We do not employ
the learning-based approach[8], because learning for carrying
heavy objects in the real world takes time and is sometimes
dangerous. We believe the heuristic-based approach is more
stable and powerful in practical use if the method has the
enough basis and the generality.
III. MANIPULATION STRATEGY DECISION
A. General Theorem of the Method
In this subsection, we introduce the general principle
justifying the Manipulation Strategy Decision (MSD).
1) The Relation between the Manipulation Strategy and
the Parameter of Objects and Environment: We deﬁne the
symbol of space and list as follows: the parameter space Ω
?
,
the object motion space Ω
M
, and the strategy list L
S
.
Ω
?
= {(?
O
,?
E
) | ?
O
? ?
O
,?
E
? ?
E
} (2)
Ω
M
= {v=(v
x
,v
y
,v
z
,v
?
,v
?
,v
?
)
T
| v ? R
6
} (3)
L
S
= {S
1
,S
2
,S
3
,··· ,S
i
,··· ,S
n
} (4)
The brief operation can be considered as the mapping ? from
Ω
?
to Ω
M
.
?:Ω
?
?? ?(Ω
?
) ? Ω
M
;(?
O
,?
E
) ?? v (5)
The dimension and the range of ?(Ω
?
) are much smaller
than those of Ω
?
, and v is easy to measure compared to
(?
O
,?
E
). It is also easy to classify ?(Ω
?
) by the moving
direction . Fig.4 represents the example of the mapping ?
i
.
3426
Fig. 4. The Relationship between Space (Ω
?
,Ω
M
), List (L
S
), and
Mapping (?,?)
If the object motion signiﬁed byr
i
(t) can be achieved, the
manipulation strategy S
i
is feasible as the following formula.
?? s.t. ?(?
O
,?
E
) ? ?( ˙ r
i
(
ˆ
t)) =? S
i
? FS (t =
ˆ
t) (6)
FS is the set of the feasible strategy for the object and
the environment (?
O
,?
E
). ? is the neighborhood function
independent of (?
O
,?
E
), which is deﬁned heuristically.
? corresponds to the mapping between Ω
M
and L
S
. The
parameter set in which S
i
is feasible can be expressed as
?
?1
(?( ˙ r
i
(
ˆ
t))) using the composite mapping (Fig.4).
2) The Deﬁnition of the Strategy Proving Operation: We
deﬁne the Strategy Proving Operation (SPO) as follows.
SPO : ? s.t.  v
i
? ?(Ω
?
)( v
i
? ?( ˙ r
i
(
ˆ
t))) (7)
 v
i
is the key motion which is easy to prove. It is desirable that
?
?1
( v
i
) approximates ?
?1
(?( ˙ r
i
(
ˆ
t))) because the sufﬁciency
of the SPO result becomes higher. In this paper, we decide
the strategy at the starting point, and let
ˆ
t be 0. SPO can
deal with several key motions at one time in the following
case.
 v
i
, v
j
,···? SPO(Ω
?
) (8)
3) The Construction and Practice Method of the MSD
using SPO: We introduce the method for constructing and
practicing MSD. In the following, i) and ii) are the phase that
constructing the system which are common for any objects
and environment. In iii) and iv), we practice the strategy
decision for each (?
O
,?
E
).
i) Generate L
S
.
ii) Deﬁne  v
i
(? ?( ˙ r
i
(
ˆ
t))) and SPO for each S
i
.
iii) Execute SPO until ﬁnding the feasible strategy.
iv) If the following inequality is satisﬁed, S
i
is feasible.
	SPO(?
O
,?
E
)? v
i
	<?
th
(9)
B. Object Tilt / Slide Detection for the Selection of Pushing
and Pivoting
In the following three subsections, we introduce the ex-
ample of the implementation and the integration of general
SPOs available by the dual-arm robot.
1) Statics Analysis of the Pushed Object: Pushing (?
push
)
is one of the most basic operation. In the following, we
analyze the statics of the pushed object on the ﬂoor. The
object shape is assumed to be rectangular in this case, but
many objects are approximated in this assumption. Setting
variables as shown in left of Fig.5, equilibrium equations of
forces and moments are as follows:
f
hx
= f (10)
f
hz
+n = mg (11)
cmg = lf
hz
+hf
hx
+pn (12)
The object starts to move in the following two conditions:
eq.(13) is the condition of tilt and eq.(14) is that of slide.
p ≤ 0 ?? f
hx
≥
cmg ?lf
hz
h
(13)
f>?n ?? f
hx
>?(mg ?f
hz
) (14)
Therefore, the movement of the pushed object (?
push
(Ω
?
))
is classiﬁed into ”tilt”, ”slide”, and ”still” (Fig.6 left).
Fig. 5. Establishment of Variables
Left ﬁgure: Variables for statics analysis of a pushed object
Right ﬁgure: Variables for kinematic analysis of a tilted object
Fig. 6. The Movement of the Pushed Object
Left ﬁgure: The classiﬁcation of the pushed object movement
Settings of the variables are as follows:
f
hz
=0,l=1.0,c=0.5,m=10,u=1.0,g=9.8
Right ﬁgure: The threshold of the Object Tilt / Slide Detection
Setting of the variable is as follows: h=0.5
2) Strategy and Key Motion: We set the strategy S
i
and
key motion v
i
as Table.I . Eq.(15) is derived from the statics
analysis. From eq.(15), the operation ?
push
is SPO, which
determines the feasibility of S
push
and S
pivot
. We call this
SPO the Object Tilt / Slide Detection.
 v
push
, v
pivot
? ?
push
(Ω
?
) (15)
3) Procedure of the Object Tilt / Slide Detection: The
purpose of the Object Tilt / Slide Detection is the deter-
3427
TABLE I
KEY MOTION FOR THE OBJECT TILT/SLIDE DETECTION
i (name) push pivot
S
i
S
push
S
pivot
 v
i
(˙ x
th
,?,0,0,0,?)
T
(˙ x
th
,?,0,0,
˙
?
th
,?)
T
(? : ”don’t care”) (˙ x
th
>?
th
) (˙ x
th
,
˙
?
th
>?
th
)
TABLE II
KEY MOTION FOR THE OBJECT LEAVING FLOOR DETECTION
i (name) lift
S
i
S
lift
 v
i
(?,?, ˙ z
th
,0,0,0)
T
(? : ”don’t care”) (˙ z
th
>?
th
)
The following is satisﬁed for each strategy:  v
i
? ?( ˙ r
i
(0))
˙ y and ˙ ? are ? in S
push
and S
pivot
because they do not affect the ˙ x and
˙
?.
Also, ˙ x and ˙ y are ? in S
lift
.
mination that the object motion is ”tilt” ( v
pivot
) or ”slide”
( v
push
). Although there are a lots of determination methods,
we propose the following procedure in this paper.
1) Apply the impedance control to the both hands.
2) Reach for the grasping point of the object.
3) Push the object forward quasi-statically.
4) Continue to push while x
h
<x
h,th
and ?
h
<?
h,th
.
5) x
h
>x
h,th
? ”slide”; ?
h
>?
h,th
? ”tilt”;
otherwise ? ”still” or ”error”
x
h
and ?
h
are x position and pitch angle of the hands. The
string th in the index means threshold.
We assume that the hands keep from slipping because
of grabbing and adaptation. By applying the impedance
control[11], the motion of the hands becomes adaptive to the
object position and posture (Fig.7). Therefore, we consider
the position and posture of the hands approximate those of
the object as eq.(16), and determine as 5) in the procedure.
˙ x
h
≈ ˙ x,
˙
?
h
≈
˙
? (16)
The visual recognition of the large object is difﬁcult
because the object is close to the robot and covers the ﬁeld
of view. Therefore, we used the kinematic information of the
hands in this case.
Fig. 7. Schematic View of Object Manipulation by Robot in Tilt / Slide
Detection
When pushing a sliding object, hands remain horizontal (left ﬁgure), but
when pushing a tilting object, hands rotate downward (right ﬁgure).
4) Calculation of Tilt / Slide Detection Threshold: The
threshold x
h,th
,?
h,th
should be changed depending on the
height of the grasping point h because the assumed relation
between x
h
and ?
h
changes during object tilting. As shown
in right of Fig.5, d and ? are deﬁned by
d =

l
2
+h
2
,? = arctan
h
l
(17)
Supposing that ?
h
is small enough, x
h
is given by
x
h
= dcos??dcos(?+?
h
)
= d(cos??cos?cos?
h
+sin?sin?
h
)
=d?
h
sin?
= ?
h
h (18)
Using the constant margins x
h,mrg
(> 0) and ?
h,mrg
(> 0),
the threshold is deﬁned as follows.
x
h,th
= x
h
?x
h,mrg
,?
h,th
= ?
h
??
h,mrg
(19)
When ?
h,th
is set to be constant, x
h,th
is derived as follows
from eq.(18) (Fig.6 right).
x
h,th
=(?
h,th
+?
h,mrg
)h?x
h,mrg
(20)
C. Object Leaving Floor Detection for the Selection of
Lifting
In this subsection, we propose another SPO.
1) Statics Analysis of the Lifted Object: Lifting (?
lift
)is
also basic operation. The object which is added the upward
force f
z
is lifted if the eq.(21) is satisﬁed. Otherwise the
object keeps still.
f
z
>mg (21)
2) Strategy and Key Motion: We set the strategy S
i
and
key motion  v
i
as Table.II . From eq.(22), ?
lift
is SPO for
S
lift
. We call this SPO the Object Leaving Floor Detection.
 v
lift
? ?
lift
(Ω
?
) (22)
3) Procedure of the Object Leaving Floor Detection: The
Object Leaving Floor Detection determines ”lifted” ( v
lift
)in
the following procedure:
1) Reach for the grasping point of the object.
2) Add the upward force f
z
quasi-statically until the sat-
uration of the reaction force is detected or f
z
exceeds
the threshold f
z,th
.
3) the saturation is detected ? ”lifted”;
otherwise ? ”still” or ”error”
f
z,th
is the threshold, which is the max force that the robot
can exert. When the robot increases f
z
, the reaction force
that the hands receive saturates at the time when the object
starts to leave the ﬂoor[12]. In the case that the saturation is
not detected within f
z,th
, the robot can not add the required
force to lift the object. The saturation of the reaction force
is detected by determining whether the difference of the
reaction force which the humanoid robot measures becomes
lower.
4) Calculation of Leaving Floor Detection Threshold: We
calculate the hand contact force threshold from the torque
limit as follows. Eq.(23) is the dynamics condition for the
limbs of the robot.
(J
T
f ??
0
)
i
≤ (?
max
)
i
for all joints (23)
3428
J, ?
0
and ?
max
are Jacobian of the arm, torque vector of
arm joints during f = 0, and maximum limit torque vector.
f is the contact force of the hand. Let s and r be the norm
and the unit direction vector of f.
f = sr (	r	=1) (24)
From eq.(23), the maximum of the contact force is calculated
as follows:
s ≤ min
i

(?
max
+?
0
)
i
(J
T
r)
i

(25)
D. The Construction and the Experiment of MSD by Inte-
grating SPO
In this subsection, we construct the system for Manipu-
lation Strategy Decision by integrating Object Tilt / Slide
Detection and Object Leaving Floor Detection. By the ex-
periment in which a humanoid robot decides the strategy
for carrying the various types of objects, we conﬁrm the
effectiveness of the constructed system.
1) The Priority Order of the Strategy: The priority order
of the strategy can be considered by operability based on
r
i
. In this system, we give the heuristic priority which is
applicable to many situations based on the experience. In
general, when the object is light, S
lift
has higher operability
than graspless manipulation[13] such as S
push
and S
pivot
.
If the object is heavy, S
push
is more stable and faster than
S
pivot
, and therefore S
push
takes precedence over S
pivot
.
Therefore, we decide the priority order as following: S
lift
,
S
push
, S
pivot
.
2) The Planning of the Grasping Point when Switching
the Strategy: The effective grasping point (GP) is different
depending on the strategy. For example, from Fig.6, we can
say that pushing becomes more stable as the GP becomes
lower, and the required force for tilting becomes smaller as
the GP becomes higher. When lifting, the GP close to the
COG is more stable. We approximate the center of the shape
as the COG because COG (? ?
OP
) is unknown. In this
system, ?
OK
includes the candidates of GPs, and the robot
selects the most effective GP when the strategy is decided.
Fig. 8. System Flow of the Manipulation Strategy Decision
Determine the feasibility of lifting, pushing, and pivoting based on object
leaving ﬂoor detection and object tilt / slide detection
3) The Construction and the Experiment of MSD: We
constructed the system integrating Object Tilt / Slide De-
tection and Object Leaving Floor Detection, which decides
the strategy from lifting, pushing, and pivoting (Fig.8).
We carried out the experiment in which the life-sized
humanoid HRP-2 decides strategy for 10 objects by this
system. We assigned the variables as follows: x
h,mrg
=
25[mm],?
h,mrg
=0.025[rad], ?
h,th
=0.175[rad], f
z,th
=
20[N] and x
h,th
is calculated by eq.(20). Hand force is
measured by 6-axis wrist force sensor, and the hand pose
is calculated by the value of the IMU sensor attached to the
root link and the encoder of each joint.
First, a small cardboard box and a garbage box were
determined as ”lifted” by Object Leaving Floor Detection
(Fig.9). For a garbage box, the saturation of the reaction
force was detected at the point that f
z
was 5.18[N] for one
hand, which is approximately equal with the value calculated
from the object mass (Fig.10). The other 8 objects were
determined as ”still”. Second, the robot determined 4 objects
as ”slide”, and the other 4 objects as ”tilt” by Object Tilt
/ Slide Detection (Fig.9). Fig.11 shows x
h
and ?
h
during
the detection. This decision of strategy agrees with intuitive
handling by human. We conﬁrm the strategy is achieved by
the execution system introduced in the next section through
the experiment in Sec.V.
Garbage box (3.7Kg)
Drawer with casters
(26.4Kg)
Small cardboard box
(0.9Kg)
Desktop PC case
(20.0Kg)
Drawer with casters
(26.4Kg)
Large cardboard box
(5.5Kg)
Caster chair (11.0Kg) Stepladder (14.3Kg) Cupboard (20.2Kg)
Fig. 9. Manipulation Strategy Decision by a Humanoid
The robot grabbed the object from the both sides and executed the detection.
Top 3 ﬁgures: Object Leaving Floor Detection.
Bottom 6 ﬁgures: Object Tilt / Slide Detection.
E. Applicable Scope of MSD
We clarify the scope of the proposed method for MSD.
This section is mainly divided into two parts: the general
theorem (III-A) and the implemented system (III-B,III-C,III-
D).
1) The General Theorem: The general theorem is dis-
cussed on the basis of basic assumption of kinematics and
3429
Fig. 13. System Flow of the Controller for the Strategy Motion
Left ﬁgure: The whole controller
Right ﬁgure: The detail of the modiﬁer
The procedure of full-body balancing is shown in Fig.13
right. ZMP modiﬁcation calculates the modiﬁed ZMP by
eq.(28)[14].
x
zmp
=
Mx
g
g ?Mz
g
¨ x
g
+

l/r
{z
h
f
trg
h,x
?x
h
f
trg
h,z
+?
trg
h,y
}
Mg ?

l/r
f
trg
h,z
(28)
Preview control[15] derives the target COG, and then re-
solved momentum control[16] calculates the modiﬁed pos-
ture ?
mdf
all
. The robot can exert f
trg
while keeping balance
by ?
mdf
all
.
3) The Estimator: f
trg
is estimated by sensor feedback
in the estimator. We update f
trg
periodically by eq.(29) to
decrease the operational direction component of the force
error.
f
trg,j+1
= f
trg,j
+K
u
(f
msr,j
?f
trg,j
,r
j
) r
j
(29)
K
u
is a feedback gain, and r
j
is the unit vector representing
the operational direction. The index, j, means the number
of cycles. By this update, the proper f
trg
is calculated
automatically depending on the ?
OP
and ?
EP
, and follow-
up performance of the object manipulation is improved.
The estimator also detects the error of the object motion.
Based on the assumption that the hands keep from slipping,
the estimated object motion ˆ r can be calculated from the
actual hand pose. By comparing ˆ r with target motion ˆ r
i
(t),
the robot can detect the motion error such as collision with
obstacles. The separation of the hands from the object also
can be detected from f
msr
.
4) The Veriﬁcation Experiment: In order to conﬁrm the
effectiveness of the control system, we conducted the experi-
ment in which the life-sized humanoid HRP-2 tilts the objects
(Fig.14). Table.III is the result of the target and actual angle
of tilting. The actual angle was measured by recognizing the
checkerboard attached to the object using the vision sensor.
The follow-up performance of tilting the heavy cupboard was
improved by updating f
trg
. Fig.15 shows that the force error
becomes small by update.
Cupboard Cardboard box
Fig. 14. Veriﬁcation Experiment of Full-body Control System by Tilting
the Object
TABLE III
OBJECT TILT ANGLE BY TILTING MANIPULATION
Cupboard Cardboard box
(20.2Kg) (3.7Kg)
Target tilt angle [deg] 7.00 7.00
Actual tilt angle 1.71 6.29
(without estimator) [deg] (error 5.29) (error 0.71)
Actual tilt angle 5.25 6.72
(with estimator) [deg] (error 1.75) (error 0.28)
-2
 0
 2
 4
 6
 8
 10
 12
 0 1 2 3 4 5 6 7 8 9 10
force [N]
Time[s]
measured force
target force
-25
-20
-15
-10
-5
 0
 5
 10
 0 1 2 3 4 5 6 7 8 9 10
force [N]
Time[s]
measured force
target force
x-axis force of right hand y-axis force of right hand
Fig. 15. The Hand Contact Force during Tilting the Object
V. EXPERIMENT ON CARRYING FURNITURE
Using HRP-2[17], we performed the experiment on car-
rying the furniture, switching the manipulation strategy de-
pending on the object autonomously by the integrated system
of MSD and MSE. HRP-2 carried 10 objects, which are
dealt with in the experiment of Sec.III-D. The objects have
different physical parameters, which are unknown, but the
robot achieved to estimate the required information directly
for deciding and executing the strategy. Fig.16 shows that the
robot carried the garbage box, the drawer with casters, and
the cupboard by lifting, pushing, and pivoting respectively.
Furthermore, we conﬁrmed MSE enabled to execute the
strategy motion robustly by the error detector and the force
updater in the controller. (Fig.16(13)-(16)).
VI. CONCLUSIONS
In this paper, we proposed the method for deciding and
executing the manipulation strategy of the objects with un-
known physical parameters. Considering the operation as the
mapping from the physical parameter space to the object mo-
tion space, we deﬁned the strategy proving operation (SPO).
By implementing SPO, we constructed the system deciding
the feasibility of lifting, pushing, and pivoting. For executing
the strategy, we constructed the generator and controller
which various strategy can share, and enabled the robot to
3431
(1) (2) (3) (4)
(5) (6) (7) (8)
(9) (10) (11) (12)
(13) (14) (15) (16)
Fig. 16. Snapshots of the Experiment in which HRP-2 Carries Furniture.
The robot decides the manipulation strategy autonomously based on the
feasibility.
(1)-(3): Carry a garbage box (200mm x 310mm x 540mm, 3.7Kg) by
lifting.
(4)-(6): Carry a drawer with caster (600mm x 390mm x 610mm, 26.4Kg,
low friction) by pushing.
(7)-(12): Carry a cupboard (353mm x 586mm x 1816mm, 20.2Kg, high
friction) by pivoting.
(13),(14): Detect the error of object motion by human interference or
collision with obstacles.
(15),(16): Add a 8Kg weight (within the red circle) to the 20Kg cupboard.
Target hand force is updated depending on the object weight automatically.
manipulate objects with unknown physical parameters. The
feature of these system components is the point that required
information is estimated directly, and the physical parameters
are treated implicitly. We conﬁrmed the effectiveness of each
component and whole system through experiments. The life-
sized humanoid robot decided and executed the strategy for
carrying large furniture automatically. We can use this system
in wide scope of objects, environments, and robots.
REFERENCES
[1] Yohei Kakiuchi, Ryohei Ueda, Kazuya Kobayashi, Kei Okada,
Masayuki Inaba. Working with Movable Obstacles Using On-line
Environment Perception Reconstruction Using Active Sensing and
Color Range Sensor. In Proceedings of the 2010 IEEE/RSJ Interna-
tional Conference on Intelligent Robots and Systems, pp. 1969–1701,
October 2010.
[2] Shunichi Nozawa, Yohei Kakiuchi, Kei Okada, and Masayuki Inaba.
Controlling the planar motion of a heavy object by pushing with a
humanoid robot using dual-arm force control. In Proceedings of The
2012 IEEE International Conference on Robotics and Automation, pp.
1428–1435, 5 2012.
[3] Eiichi Yoshida, Mathieu Poirier, Jean-Paul Laumond, Oussama Ka-
noun, Florent Lamiraux, Rachid Alami and Kazuhito Yokoi. Whole-
body motion planning for pivoting based manipulation by humanoids.
In Proceedings of The 2008 IEEE International Conference on
Robotics and Automation, pp. 1712–1717, 2008.
[4] Eiichi Yoshida, Mathieu Poirier, Jean-Paul Laumond, Oussama Ka-
noun, Florent Lamiraux, Rachid Alami and Kazuhito Yokoi. Pivoting
based manipulation by a humanoid robot. Autonomous Robots, Vol. 28,
No. 1, pp. 77–88, 2010.
[5] Kensuke Harada, Shuuji Kajita, Hajime Saito, Mitsuharu Morisawa,
Fumio Kanehiro, Kiyoshi Fujiwara, Kenji Kaneko, and Hirohisa
Hirukawa. A Humanoid Robot Carrying a Heavy Object. In
Proceedings of The 2005 IEEE International Conference on Robotics
and Automation, pp. 1724 – 1729, April, 2005.
[6] Ohmura Yoshiyuki and Kuniyoshi Yasuo. Humanoid robot which
can lift a 30kg box by whole body contact and tactile feedback.
In Proceedings of the 2007 IEEE/RSJ International Conference on
Intelligent Robots and Systems, pp. 1136–1141, October 2007.
[7] Naoyuki Sawasaki, Masayuki Inaba, and Hirochika Inoue. Tumbling
Objects Using a Multi-Fingered Robot. In Proceedings of the 20th
International Symposium on Industrial Robots and Robot Exhibition,
1989.
[8] Shun Nishide, Tetsuya Ogata, Jun Tani, Kazunori Komatani, and
Hiroshi G. Okuno. Predicting object dynamics from visual images
through active sensing experiences. Advanced Robotics, Vol. 22, No. 5,
pp. 527–546, 2008.
[9] Yong Yu, Kenro Fukuda, and Showzow Tsujio. Estimation of mass
and center of gravity of graspless unknown object based on gravity
equi-effect planes. In Proceedings of the 1998 IEEE/RSJ International
Conference on Intelligent Robots and Systems, Vol. 3, pp. 1497–1502,
October 1998.
[10] Yoshikawa Tsuneo, and Kurisu Masamitsu . Indentiﬁcation of the
center of friction from pushing an object by a mobile robot . In Pro-
ceedings of the 1991 IEEE/RSJ International Conference on Intelligent
Robots and Systems, November 1991.
[11] Shunichi Nozawa, Iori Kumagai, Yohei Kakiuchi, Kei Okada, and
Masayuki Inaba. Humanoid full-body controller adapting constraints
in structured objects through updating task-level reference force.
In Proceedings of the 2012 IEEE/RSJ International Conference on
Intelligent Robots and Systems, pp. 3417–3424, 10 2012.
[12] Shunichi Nozawa, Ryohei Ueda, Yohei Kakiuchi, Kei Okada, and
Masayuki Inaba. Sensor-based integration of full-body object ma-
nipulation based on strategy selection in a life-sized humanoid robot.
Journal of Robotics and Mechatronics, Vol. 23, No. 2, pp. 239–248,
(2011).
[13] Y. Aiyama, M. Inaba, and H. Inoue. Pivoting: A new method of
graspless manipulation of object by robot ﬁngers. In Proceedings of
the 1993 IEEE/RSJ International Conference on Intelligent Robots and
Systems, pp. 136–143, 1993.
[14] K. Harada, S. Kajita, K.Kaneko, and H.Hirukawa. Zmp analysis
for arm/leg coordination. In Proceedings of the 2003 IEEE/RSJ
International Conference on Intelligent Robots and Systems, pp. 75–
81, (2003).
[15] Shuuji Kajita, Fumio Kanehiro, Kenji Kaneko, Kiyoshi Fujiwara,
Kensuke Harada, Kazuhito Yokoi, and Hirohisa Hirukawa. Biped
walking pattern generation by using preview control of zero-moment
point. In Proceedings of The 2003 IEEE International Conference on
Robotics and Automation, pp. 1620–1626, Sep (2003).
[16] S.Kajita, F.Kanehiro, K.Kaneko, K.Fujiwara, K.Harada, K.Yokoi, and
andH.Hirukawa. Resolved Momentum Control:Humanoid Motion
Planning based on the Linear and Angular Momentum. In Proceedings
of the 2003 IEEE/RSJ International Conference on Intelligent Robots
and Systems, pp. 1644–1650, October, 2003.
[17] Kei Okada, Takashi Ogura, Atsushi Haneda, Junya Fujimoto, Fabien
Gravot, and Masayuki Inaba:. Humanoid Motion Generation System
on HRP2-JSK for Daily Life Environment. In International Confer-
ence on Mechatronics and Automation, pp. 1772 – 1777, July, (2005).
3432
