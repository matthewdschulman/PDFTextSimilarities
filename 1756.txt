Interactive Bayesian Identiﬁcation of Kinematic Mechanisms
Patrick R. Barrag´ an and Leslie Pack Kaelbling and Tom´ as Lozano-P´ erez
Abstract— This paper addresses the problem of identifying
mechanisms based on data gathered while interacting with
them. We present a decision-theoretic formulation of this
problem, using Bayesian ﬁltering techniques to maintain a
distributional estimate of the mechanism type and parameters.
In order to reduce the amount of interaction required to arrive
at a conﬁdent identiﬁcation, we select actions explicitly to
reduce entropy in the current estimate. We demonstrate the
approach on a domain with four primitive and two composite
mechanisms. The results show that this approach can correctly
identify complex mechanisms including mechanisms which are
difﬁcult to model analytically. The results also show that
entropy-based action selection can signiﬁcantly decrease the
number of actions required to gather the same information.
I. INTRODUCTION
Consider a household robot that can move and grasp. It
arrives in a new house and must quickly learn to interact
with a variety of kinematic mechanisms: cupboard doors
that rotate about hinges on the left or right or that slide
sideways; drawers that pull out; security latches on the front
door; faucet handles that rotate or slide along multiple axes.
We would expect the robot already to know about a general
class of such mechanisms, possibly articulated in terms of
one degree-of-freedom primitives and ways in which they
can be combined. Then, faced with a new object, we would
like it to be able to grasp and attempt to move it, possibly
receiving information from several modalities, including joint
torques and positions, tactile feedback, and visual tracking of
parts of the object. In this process, the robot should quickly
be able to discover the type of mechanism it is interacting
with, as well as its parameters, such as hinge location, radius
of rotation, etc.
In this paper, we present a decision-theoretic formulation
of this problem, using Bayesian ﬁltering techniques to main-
tain a distributional estimate of the mechanism type and
parameters. In order to reduce the amount of interaction
required to arrive at a conﬁdent identiﬁcation, we select
actions explicitly to reduce entropy in the current estimate.
If the ultimate goal of the robot is to open a cupboard door
or to cause water to come out of faucet, then this problem
is appropriately formulated as a partially-observable Markov
decision process (POMDP) [1]. Such a formulation would
This work was supported in part by the NSF under Grant No. 1117325.
Any opinions, ﬁndings, and conclusions or recommendations expressed in
this material are those of the author(s) and do not necessarily reﬂect the
views of the National Science Foundation. We also gratefully acknowledge
support from ONR MURI grant N00014-09-1-1051, from AFOSR grant
FA2386-?10-?1-?4135 and from the Singapore Ministry of Education under
a grant to the Singapore-MIT International Design Center.
Computer Science and Artiﬁcial Intelligence Laboratory,
Massachusetts Institute of Technology, Cambridge, MA 02139 USA
barragan@mit.edu, tlp@mit.edu, lpk@mit.edu
Fig. 1. Willow Garage PR2 robot manipulating revolute model
support optimal action exploration in service of achieving
the goal. Solution of POMDPs can be computationally very
difﬁcult, so in this work, we focus on the goal of identifying
the mechanism and use a greedy action-selection method.
We apply this framework in a simple experimental domain
with four primitive and two composite mechanisms and
demonstrate in simulation that it can use position information
to perform effectively and that information-driven action
selection offers signiﬁcant advantages. We have conducted
experiments on a PR2 robot, using active exploration and
position information to discriminate among the mechanisms.
II. RELATED WORK
There has been substantial previous work on kinematic
identiﬁcation.
Katz et al. [2] showed accurate identiﬁcation of kinematic
joint types (e.g. revolute, prismatic) using vision-based track-
ing of features on a mechanism as it is actuated. After track-
ing the motion of features on the object, feature clusters are
formed based on their relative motion. The relative motion
between clusters indicates the type of joint connecting the
links of the mechanism. They consider revolute and prismatic
joints between each cluster by providing models of the trans-
forms between features on separate bodies. Katz et al. [3] use
action selection methods based on relational reinforcement
learning. They show that using this action selection method
can signiﬁcantly reduce the number of actions required to
correctly identify the kinematic relationships in the structure.
Their results demonstrate robust joint identiﬁcation using
guided action selection.
Jain and Kemp [4] use Equilibrium Point Control (EPC) to
actuate some simple mechanisms. A new equilibrium point at
each step is calculated to keep a manipulator hook attached
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 2013
to the handle of the mechanism; the equilibrium point then
becomes the next commanded position. The resulting end
effector position is used to estimate the kinematics of the
mechanism, which is assumed to be either a revolute or a
prismatic joint, lying in a plane parallel to the ﬂoor. In later
work, Jain and Kemp [5] show a data-driven approach to
identifying speciﬁc doors, identifying door types, and detect-
ing manipulation events such as locked doors or collisions
between doors and other objects. By collecting training data,
including forces and positions, while opening various types
of doors, their system can correctly identify information of
interest when encountering a new door instance.
St¨ urm et al. [6] also developed a sophisticated approach to
kinematic identiﬁcation from multiple information sources.
They calculated a maximum-likelihood estimate of the pa-
rameters and probabilities over models for the joint. This
work was restricted to four models for joints: rigid, revolute,
prismatic, and Gaussian process, which is a data-driven
model for any joint that could not be explained by the
other three. The Bayesian Information Criterion was used
to select the best model, trading off goodness of ﬁt with
model complexity. Three types of observations were used
in the work. Much of the work used ﬁducial markers for
tracking the individual links of the kinematic bodies. By
analyzing the relative motion of the markers (much like Katz
et al.), they were able to correctly identify joint types. They
also used vision-based marker-less tracking in some of their
experiments. Finally, in conjunction with Jain and Kemp [7],
they integrated gripper positioning while operating a mech-
anism. The controller always attempted to make a useful
move for the current most likely model. Their system allowed
a robot to successfully operate multiple mechanism types.
Their approach does not use the action to help predict the
joint type but instead relies on the data measured as actions
are taken. This useful approach is employed successfully in
other works (Ruhr et al. [8] and Becker et al. [9]).
Our work differs in objective and approach from this
earlier work. We use a Bayes ﬁlter to identify the type of
the mechanism without segmenting out or identifying the
individual joints. Also, our fundamental approach does not
require visual information. It can use any combination of
information sources but is demonstrated in this paper using
position information. In our work, we expand the range of
possible mechanisms that can be identiﬁed and manipulated
with only gripper-position feedback. In particular, we also
consider ”serial” mechanisms, such as latches, that behave
differently in different parts of their conﬁguration spaces. As
implied in the name, these latches have a ﬁxed constraint that
their handles can be placed in to restrict their motion. These
mechanisms also include unilateral constraints which can be
difﬁcult to model analytically. We also choose actions (using
entropy-based action selection) to gather information quickly
about the type of mechanism instead of directly attempting
to control the mechanism as if it were of the most likely type.
This exploratory action selection also allows the system to
start with no information about how to move, even initially,
and to discover appropriate motions through trial and error.
III. PROBLEM FORMULATION
We formulate the mechanism as a discrete-state, Input-
Output Hidden Markov Model (IOHMM), in which the
hidden states are the states of the mechanisms, inputs are
actions taken by the robot, and outputs are the sensed data.
A. Model speciﬁcation
The state of a kinematic system is a tuple S =hm;;xi,
where:
 m is the type of the mechanism. The type speciﬁes
a particular class of the object. These types need not
simply be serial linkages. In general, a model class
could describe a wide range of possible objects (e.g.
soft bodies or systems of objects). In this work, we
will focus on kinematic mechanisms. These objects
can have any number of degrees of freedom, including
“sequential” mechanisms, such as latches, in which
some degrees of freedom may only be accessible when
others are in a speciﬁc range of conﬁgurations. In this
work, we will enumerate a ﬁnite set of types in advance.
  is a vector of parameters of the mechanism. Objects
of a given typem will be characterized by a ﬁnite set of
(typically continuous) parameters. Examples would be
the position of the pivot and radius of a revolute joint
or axis speciﬁcations of a prismatic joint.
 x is a vector of variables that specify a particular current
conﬁguration of the mechanism. Examples would be the
current angle of a revolute joint or Cartesian position
of a free mechanism.
For the purposes of identifying a mechanism, the state
space will consist of a set of hm;;xi tuples, with the
dimensionalities of andx depending on the particular type
m.
The action space A might include any set of primitive
actions a robot could take to get information about or change
the state of the mechanism it is interacting with, including
looking at it from different viewpoints, pushing, pulling, etc.
The only requirements on the space of actions are:
 Any action may be attempted on any mechanism type
with any parameter and variable values.
 All actions always terminate in ﬁnite time.
The observation spaceO might include inputs from any of
the robot’s sensors, including vision, tactile, force, position,
and vibration sensors.
Once the spaces are deﬁned, we must characterize their
relationships. The transition model describes the effects of
actions on the state of the system as a conditional probability
distribution over values of the state at time t+1 given the
state at time t and the action executed at time t. This is
a discrete-time model that assumes each primitive action is
run to completion. We can factor the transition model into
two components: the probability that the mechanism type or
parameters change (for example, because the robot breaks
a constraint on the mechanism, or because the mechanism
becomes jammed) and the probability that the variables
2014
change, given the mechanism type and parameters.
Pr(s
t+1
js
t
;a
t
) = Pr(m
t+1
;
t+1
;x
t+1
jm
t
;
t
;x
t
;a
t
)
= Pr(m
t+1
;
t+1
jm
t
;
t
;x
t
;a
t
)
 Pr(x
t+1
jm
t+1
;
t+1
;x
t
;a
t
)
The characterization of type and parameter change,
Pr(m
t+1
;
t+1
jm
t
;
t
;x
t
;a
t
) ;
might be written by hand or learned from very long-term
interactions. We expect that, for now, it will be sufﬁcient
to use a distribution that keeps m and  at their previous
values with high probability and offers a near uniform change
to other values. The normal operation of the mechanism is
characterized by
Pr(x
t+1
jm
t+1
;
t+1
;x
t
;a
t
) ;
which is a model of how the variables of a mechanism of
typem with parameters change in response to actions of the
robot. Such models may be described analytically, through
the use of forward simulation or with data-driven approaches.
The observation model speciﬁes a distribution over ele-
ments of O, given the current state and previous action:
Pr(o
t+1
jm
t+1
;
t+1
;x
t+1
;a
t
) :
Exactly how this model is to be speciﬁed depends on the
sensors involved. Note thato can be a vector of observations
from different sensing modalities.
B. Bayesian inference
We will focus on the problem of identifying the type and
parameters of the mechanism that the robot is interacting
with. Having made such an identiﬁcation, the robot would
then be able to plan to manipulate the mechanism to achieve
multiple goals within the operating space of the mechanism,
such as opening or closing a door.
Given a sequence of actions, a
0:T 1
= a
0
;:::;a
T 1
,
and observations made as a result of those actions, o
1:T
=
o
1
;:::;o
T
, as well as a distribution characterizing the a pri-
ori belief in the different elements of the state space, Pr(s
0
),
we are interested in computing the posterior distribution over
types and parameters, which is obtained by marginalizing out
the variables at time T .
Pr(m
T
;
T
ja
0:T 1
;o
1:T
) =
X
x
T
Pr(m
T
;
T
;x
T
ja
0:T 1
;o
1:T
)
=
X
x
T
Pr(s
T
ja
0:T 1
;o
1:T
)
This expression can be further seen as a marginalization over
the states of the mechanism from times 0 through T 1:
X
x
T
X
s
0:T 1
Pr(s
0:T
ja
0:T 1
;o
1:T
)
Then, we can use Bayes’ rule and the conditional indepen-
dence relationships in a IOHMM to write
Pr(m
T
;
T
ja
0:T 1
;o
1:T
)/
X
x
T
X
s
0:T 1
Pr(s
0
)
T 1
Y
t=0
Pr(o
t+1
js
t+1
;a
t
)Pr(s
t+1
js
t
;a
t
)
Depending on particular representational choices, this quan-
tity can typically be computed efﬁciently using dynamic
programming or recursive ﬁltering.
IV. ACTIVE EXPLORATION
Random or arbitrary selection of actions is rarely efﬁcient,
in the sense that it may require a long sequence of actions
to effectively determine the type and parameters of the
mechanism the robot is interacting with. We can articulate
the goal of identifying the mechanism as desiring that the
conditional entropy,
H(m
T
;
T
ja
0:T 1
;o
1:T
) ;
be below some desired value. The entropy of a random
variable is a measure of its disorder or lack of information;
in the discrete case, it is
H(X) = 
X
x
Pr(x)log
2
Pr(x) :
We might have an additional implicit goal that the robot
not change the type or parameters of the mechanism; this
would prevent the robot from ripping the door off its hinges
in order to reduce it to an easily identiﬁable free body.
Finding an optimal strategy for selecting observations to
reduce overall entropy is as difﬁcult as solving a POMDP. For
efﬁciency reasons, we will pursue a myopic action-selection
strategy. Given a belief state b, which is a probability
distribution over the state of the mechanism at timeT given
all previous actions and observations, the objective is to
select the action that, in expectation over observations it may
generate, will result in the belief state b
0
with the lowest
entropy. That is:
a

T
= min
a
E
ojb;a
H(s
T+1
ja
0:T 1
;o
1:T
;a;o) :
Depending on the sizes of the spaces, this can be difﬁcult
to calculate analytically; we describe a sampling method in
section V.
In problems that are submodular, this greedy strategy can
be shown to be within a constant factor of optimal [10].
For a problem to be submodular, it must be that taking a
particular action a
1
is never more informative after taking
another action a
2
than it would have been before taking a
2
.
Unfortunately, that is not the case in our domain: attempting
to rotate a latch may only be informative after it has
been translated into a conﬁguration in which the rotational
freedom is available.
Even though it is not even boundedly suboptimal, we will
ﬁnd empirically that greedy action selection is a signiﬁcant
improvement over a random approach.
2015
V. EXPERIMENTAL DOMAIN AND
IMPLEMENTATION
We have applied this general approach to the relatively
simple example problem of discriminating among 6 different
types of mechanisms using position feedback resulting from
manipulation of each mechanism at a designated handle. The
mechanisms all operate in a plane, although this is not a
fundamental limitation of the approach. The experimental
results were generated using a simulated robot. Preliminary
experiments using a Willow Garage PR2 robot have shown
successful diagnosis of instances of several mechanism types.
a) States: The mechanism types include a completely
free body, a rigidly ﬁxed body, a 1-DOF revolute joint, a 1-
DOF prismatic joint, and two sequential 2-DOF latch mech-
anisms. The ﬁrst latch is a composite mechanism comprised
of a revolute joint followed by a prismatic joint. However, as
implied by the name, the latch is more than simply a com-
posite mechanism because a ﬁxed rigid body exists in which
the end of the prismatic joint can be placed. This constraint
causes this model to exhibit different behaviors in different
parts of its conﬁguration space. Similarly, the second latch is
comprised of a prismatic joint followed by another prismatic
joint perpendicular to the ﬁrst. This mechanism also has a
ﬁxed rigid body to restrict its motion in certain parts of the
mechanism’s conﬁguration space. Furthermore, the prismatic
joints in these models have displacement limits along their
axes. These components make these simulated models a
somewhat realistic representation of a mechanism that may
exist in the real world.
Table I shows the types, parameters, and variables that
make up the state space. Fig. 2 shows the deﬁnition of
each model, its parameters, and its variables. The rotated
“U” shaped boxes around the handles (represented by the
large dot in each diagram) of the latch mechanisms remain
ﬁxed in space even while the mechanism moves to different
conﬁgurations. For the prismatic mechanism, the dashed line
representing the axis is meant to indicate that the handle
can move freely along this axis. This free motion along the
axis of the prismatic model is distinctly different from the
constrained motion that the prismatic joints exhibit in the
two latch models. A dashed axis line is absent from these
diagrams to indicate the existence of these limits.
b) Actions: In this work, we will restrict our attention
to physical interactions in which we assume the robot is
grasping the mechanism non-rigidly (using some sort of a
caging grasp, for example). We assume that the robot will
work within a ﬁnite workspace. Furthermore, we assume
that the robot, while moving the handle of a particular
mechanism, will have no probability of generating a state
in which the handle exists outside of the workspace (e.g. the
robot will not throw a free body out of its reach). Actions
consist of commands to move the hand to target points
in the horizontal plane. The commands are executed by a
proportional-derivative (PD) controller for a ﬁxed amount
of time. The time-out is such that, if no obstacles are
encountered, then any target point in the robot’s workspace
m  x
Free x;y location
Fixed xpos;ypos location
Revolute x
pivot
;y
pivot
location, r radius 2[0;2] angle
Prismatic x
axis
;y
axis
;
axis
axis deﬁnition  displacement
Latch 1 x
pivot
;y
pivot
;r;
latch
;
latch
;
Latch 2 x
axis
;y
axis
;
axis
;
1
latch
;
2
latch

1
;
2
TABLE I
SPACE OF POSSIBLE MECHANISM STATES
can be reached. However, the robot may not reach the target
point if the mechanism in its current state constrains the
motion. We have veriﬁed in our pilot tests with the PR2 that
the compliance in the robot controller and the mechanisms
are such that these incomplete motions do not generate large
enough motions to damage the mechanisms. When the action
terminates, the gripper is commanded to its current position
with the effect of “relaxing” the robot. The possible actions
allowed for the robot are a discrete set of target points within
its workspace.
c) Observations: In this simple domain, we use the
robot’s proprioception, in the form of the observed x;y
position of the object’s handle (the same position as the
robot’s end effector) as the observation. In simulation of the
true mechanism, to generate an observation, we add Gaussian
noise to the simulated transitions to mimic transition and
observation noise of a real system. The relationship between
the commanded position and the resulting position yields
information about the underlying mechanism.
A. Transition and observation models
For many idealized situations, writing down transition
and observation models analytically is possible by using
ideal physics models to describe the nominal next state
and observation and adding Gaussian noise. However, once
collisions and friction are involved, generating analytical
models becomes much more difﬁcult. Our approach in this
work is to use the Bullet Physics Library (http://www.
bulletphysics.org) to construct approximate models
of the mechanisms, and then use those models to simulate
the effects of actions and to model the observations. The use
of simulation allows signiﬁcant ﬂexibility in terms of the
possible object classes that can be modeled.
The transition and observation models used in the esti-
mator have Gaussian noise around nominal next states and
observations. In order to compensate for possible modeling
errors and to better demonstrate the effects of the action-
selection strategies, we use a signiﬁcantly higher variance in
the observation model than would be expected in the real
robot.
A consequence of using a simulation rather than an
analytical model is that we do not have the ability to
integrate effectively over states and observations; in our
implementation we have to rely on samples drawn from the
simulation.
B. Implementation
We use a discrete representation of the state space, which
makes the belief state a multinomial distribution. The mecha-
2016
x
y
x
y
x
pos  
,y
pos
x
pivot  
,y
pivot
x
axis  
,y
axis
?
axis  
x
pivot  
,y
pivot
?
latch  
r

r
?
latch  
x
axis  
,y
axis
?
axis  
?
1
latch  
?
2
latch  
?

?
?
2
?
1
?

?
Free Fixed Revolute Prismatic Latch  1 Latch  2
Fig. 2. Diagrams of the each of the 6 models considered. Fixed parameters are shown in red while variables are shown in blue. The large dot represents
each mechanisms handle.
m 
Free
Fixed 0.0, 0.0
Revolute 0.3, 0.3, 0:3
p
2
Prismatic -0.16, -0.16, /4
Latch 1 -0.2, 0.0, 0.1, 0.0, 0.1
Latch 2 -0.1, -0.1, 0.0, 0.1, 0.1
TABLE II
EXPERIMENTAL PARAMETER VALUES FOR MECHANISM TYPES
nism types are discrete, and each mechanism type has its own
set of parameters and variables, the spaces of which are uni-
formly discretized, so that a “state” in the discrete space cor-
responds to a multi-dimensional “box” in parameter-variable
space. An alternative strategy is to represent a continuous
conditional distribution of the parameters and variables for
each mechanism type. These conditional distributions are not
uni-modal or otherwise easily characterized parametrically,
and so the only plausible alternative representation would be
as a set of samples. We letS be the set of discrete states;
s =hm;(
lo
;
hi
);(x
lo
;x
hi
)i2S ;
and let
^ s =hm;(
hi
 
lo
)=2;(x
hi
 x
lo
)=2i
be a canonical state value, with the values for parameters
and variables chosen in the centers of their ranges.
For the following experiments, we restrict our state space
to one parameter set for each of the 6 model types consid-
ered. However, adding another set of parameters for a model
type is no different than adding a single parameter set for a
new model type. Thus, the approach is capable of using a
state space with many parameter sets for each model type,
although the state-space size grows as the product of the
number of parameter and variable values for each type. Each
model-parameter pair has a discrete set of variable values
which span the robot’s workspace. The speciﬁc parameter
values used for each model are given in Table II.
When the world is initialized, the robot assumes that its
gripper’s current position is (0,0) in its workspace which is
box around its gripper in the plane in Cartesian space (x,y).
The robot then performs actions relative to this position.
Therefore, for any model-parameter pair to be considered
with non-zero probability, the pair must have the Cartesian
position (0,0) as an achievable pose relative to the robot’s
gripper. When simulating the “real” world, a true mechanism
was chosen from among the possible mechanism types con-
sidered. Any observation from this true mechanism received
added Gaussian noise. The initial variable values of each true
mechanism were chosen such that the handle would begin at
(0,0) as required.
The two critical computations in the system are the belief-
state update and action selection.
The belief update takes a belief state from the previous
time step, an action, and an observation, and computes an
approximate new belief state.
BELIEFUPDATE(b, a, o):
1 b
0
= ZEROS(b)
2 for s2S
3 r = SIMTRANS(^ s;a)
4 for s
0
2S
5 b
0
[s
0
] =b
0
[s
0
]+N(^ s
0
;r;
trans
)
6 for s2S
7 z = SIMOBS(^ s;a)
8 b
0
[s] =b
0
[s]N(z;o;
obs
)
9 return NORMALIZE(b
0
)
Lines 2–5 compute the transition update. Given a discrete
state s, we ﬁnd the canonical continuous state, ^ s, and then
ﬁnd the nominal next continuous state, r by invoking the
simulated transition model SIMTRANS. Now, we assign a
transition probability froms to each discretes
0
in proportion
to a Gaussian density with variance 
2
obs
, evaluated on the
distance betweenr and ^ s
0
, which is the canonical continuous
value of state s
0
. At the end of this update, b
0
is an unnor-
malized multinomial distribution over the discrete states and
represents the effects of taking action a. Lines 6–8 compute
the observation update. Given a canonical continuous state
^ s and action a, we invoke the simulator SIMOBS to ﬁnd
the nominal observation z. Then, we scale the posterior
belief ins,b
0
[s] by the Gaussian likelihood of making actual
observation o when expecting observation z, with variance

2
obs
. Finally, we divide through by the sum of the values in
b
0
and return a multinomial distribution.
The action selection procedure uses sampling to estimate
the expected entropy resulting from taking each possible
action, and returns the minimizing action.
2017
SELECTACTION(b, k):
1 totalH[a] = 0 for all a2A
2 for a2A
3 for i2 1::k
4 sb
5 r GAUSSIAN(simTrans(^ s;a);
trans
)
6 o GAUSSIAN(SIMOBS(r;a);
obs
)
7 b
0
= BELIEFUPDATE(b;a;o)
8 totalH[a] = totalH[a]+H(b
0
)
9 return ARGMIN
a
(totalH)
For each action, we draw k sampled observations and com-
pute the average entropy of the resulting belief states. Then
we return the action that minimizes that average entropy.
Lines 4–6 generate a sample observation by: sampling a
discrete states fromb, then sampling a continuous resulting
state r from a Gaussian centered on the nominal dynamics
model applied to canonical continuous state ^ s and action a,
then sampling an observationo from a Gaussian centered on
the nominal observation for continuous state r.
VI. RESULTS
Experimental results were obtained in simulation. The
state space incorporated an instance of each mechanism
type in many possible conﬁgurations. The ﬁlter utilized
simulations in its transition step. A separate simulation with
added Gaussian noise on the order of the noise levels
seen from position measurements from the PR2 ( 1 [cm]
standard deviation) was used to simulate the true mechanism.
The observation covariance matrix used in the multivariate
Gaussians in the observation model represented noise above
this level.
Each of the 6 mechanism types was used as the true model.
The latching mechanisms were initialized in their latched
position. For a given experiment on a given mechanism,
the robot took 10 actions, and the ﬁlter’s belief state over
the mechanism and parameters was recorded (after summing
over all possible variable values for a given model-parameter
pair). This experiment will be referred to as a trial. Each trial
was repeated 10 times, and the results were averaged.
A. Single Trial
Considering a single trial on a particular mechanism
can clearly illustrate the process of entropy-based action
selection. Fig. 3 shows the results from a trial with the true
mechanism of type Latch 2 with the parameters given in
Table II for that mechanism. A model instance is a particular
pair of model type and parameter set which completely
deﬁne the behavior of the mechanism. In meters in Cartesian
space in the plane denoted (x,y), the ﬁrst three actions
chosen during this trial were (0.12,-0.12), (0.12,0.12), and
(-0.12,0.12).
The ﬁrst action caused increased belief in the Latch 2
model instance (the same type and parameters as the true
mechanism), the Revolute model instance, and the Free
model instance. These three models are the only models
which could come close to the position achieved by the true
Fig. 3. Single trial for instance of the Latch 2 model type using entropy-
based action selection.
mechanism. Concretely, the true mechanism can almost reach
the commanded position because the handle can slide out
of the latching constraint and move within a short distance
of the commanded point. The instances of the Free and
Revolute models can also come near this position. However,
the Fixed model instance cannot move. The Prismatic model
instance moves along an axis that does not come near to
the commanded point. Finally, the Latch 1 model instance is
restricted by its latching constraint and also cannot move.
The second action chosen further increases the belief that
the true mechanism is either the Free or Latch 2 model
instances. However, the Revolute instance’s probability de-
creases sharply because the commanded move takes the
true mechanism’s position within the radius of the Revolute
instance.
The third action distinguishes between the last two in-
stances that have high probabilities. Although the true mech-
anism can exist in a conﬁguration state near the commanded
target point, the mechanism begins in a position such that the
action causes it to collide with the ﬁxed latching constraint
rigid body. If the true mechanism was the Free instance,
the handle should move completely to the commanded
point. Because the robot cannot reach the commanded point,
the observation obtained drastically drops the belief in the
Free instance leaving only the Latch 2 instance with high
probability. The following actions further solidify the belief
in the Latch 2 instance and thus correctly identiﬁes the true
mechanism.
This example shows an important result. Considering the
previous conﬁguration of the mechanism, the system can
choose an action for high information gain that may not
have been a useful action in other possible conﬁgurations
of the mechanisms considered. This is an illustration of the
usefulness of belief state entropy-based action selection. By
choosing actions carefully, the system is able to distinguish
the true model from the other possibilities with relative few
actions compared to random exploration.
2018
(a) Free - Random (b) Fixed - Random (c) Revolute - Random
(d) Free - Entropy (e) Fixed - Entropy (f) Revolute - Entropy
Fig. 4. Filter convergence and random vs. entropy-based action selection from Free, Fixed, and Revolute models.
(a) Prismatic - Random (b) Latch 1 - Random (c) Latch 2 - Random
(d) Prismatic - Entropy (e) Latch 1 - Entropy (f) Latch 2 - Entropy
Fig. 5. Filter convergence and random vs. entropy-based action selection from Prismatic, Latch 1, and Latch 2 models.
2019
B. Full Trials
Fig. 4 and Fig. 5 show two main results. The top row
of each ﬁgure shows the averaged experimental results for
random action selection while the bottom row shows the
results for entropy-based action selection. In nearly all cases
(for each mechanism and each type of action selection),
the true model-parameter set became much more likely
than the other possibilities after less than 10 actions and,
in most cases, after only a few. Moreover, the speed of
convergence is signiﬁcantly improved by the entropy-based
action selection. In these experiments, entropy-based action
selection requires between half and two-thirds of the number
of actions required by random action selection to reach the
same conﬁdence level.
Using physics simulations, the ﬁlter was able to robustly
predict the two different latch mechanisms. These mecha-
nisms can experience collisions with the ﬁxed part of the
latch. Second, the latches themselves are built with limits
to make them realistic models of latches found in the real
world. For example, Latch 1 can only be extended to a certain
distance even outside of the locking constraint. These limits
are a type of unilateral constraint which can be hard to model
analytically. However, the use of simulations can more easily
model many complex real world systems.
Of the 120 experiments ran, a single experiment utilizing
random action selection misclassiﬁed the mechanism. In this
experiment, the true Latch 1 model was misclassiﬁed as the
ﬁxed mechanism after 10 actions because no selected action
moved the handle out of the latch’s constraint. After 10
actions, the models had nearly-identical probability, but the
ﬁxed mechanism was slightly favored due to discretization
error. This result emphasizes the beneﬁt of entropy-based
action selection as it would have purposefully chosen actions
to disambiguate between the two models in this scenario.
These simulation results do not test variations in the pa-
rameter values of the model types. Many different instances
of each model type could be added to the state space allowing
the ﬁlter to decide within a model type which parameter set
is more likely. However, the state-space size scales as the
product of the number of variable and parameter values,
summed over types. The ﬁlter update time grows as the
square of the state-space size. Action selection requires a
ﬁlter update for each sample of the belief state for each action
considered. Thus, with a sufﬁciently large state space, this
method becomes computationally intractable.
Initial experiments have been conducted on the Willow
Garage PR2 robot. The results suggest that the robot is able
to distinguish between instances of several of the models.
The corresponding video (http://lis.csail.mit.
edu/movies/ICRA14_1756_VI_fi.mp4) shows ex-
amples of these successful trials. While the real world
experiments are very promising, they can fail due to factors
that are not present in the simulations. For example, out-of-
plane displacements can cause the mechanism to bind. In the
future, some combination of more realistic simulations and
more robust execution is called for.
VII. CONCLUSION
Manipulation can be an extremely useful information-
gathering tool. Robots attempting to act robustly in new
environments can use many sensor modalities to identify
the objects around them. This paper presents an approach
to identifying mechanisms based on manipulation data. The
approach uses a Bayesian ﬁlter to estimate the probability of
different model types, their parameters, and their variables.
The ﬁlter utilizes simulations in its transition model to allow
for complex mechanisms which may be hard to model
or could require large amounts of data to represent. Our
approach correctly distinguishes the mechanism types used
including two latching mechanisms which exhibit different
constraints in different parts of their conﬁguration spaces.
Moreover, action selection based on decreasing belief-state
entropy is utilized and shown to signiﬁcantly decrease the
number of required actions to gather the same information.
This approach attempts to choose actions which will most
distinguish model-parameter pairs from others and thus ex-
plicitly attempts to gather useful information.
Our desire is to extend this work to include a larger variety
of complex models and to integrate multiple sensor modal-
ities. To effectively increase the model space, we may need
to experiment with a more adaptive discretization method.
The current approach becomes computationally intractable
for large state spaces due to the exponential growth is number
of discrete states. We plan to move to a hybrid state represen-
tation that leaves some dimensions continuous; this should
drastically increase the speed of our ﬁlter update. Ultimately,
we wish to learn transition and observation models from
experience, so that novel mechanisms can be explored and
understood by the robot.
REFERENCES
[1] R. D. Smallwood and E. J. Sondik, “The optimal control of partially
observable Markov processes over a ﬁnite horizon,” Operations Re-
search, vol. 21, pp. 1071–1088, 1973.
[2] D. Katz and O. Brock, “Manipulating articulated objects with inter-
active perception,” in ICRA, 2008.
[3] D. Katz, Y . Pyuro, and O. Brock, “Learning to manipulate articulated
objects in unstructured environments using a grounded relational
representation,” in Proceedings of Robotics: Science and Systems IV,
Zurich, Switzerland, June 2008, pp. 254–261.
[4] A. Jain and C. C. Kemp, “Pulling open doors and drawers: Coordi-
nating an omni-directional base and a compliant arm with equilibrium
point control,” in ICRA, 2010.
[5] ——, “Improving robot manipulation with data-driven object-centric
models of everyday forces,” Autonomous Robots, pp. 1–17, 2012.
[6] J. Sturm, C. Stachniss, and W. Burgard, “A probabilistic framework
for learning kinematic models of articulated objects,” J. Artif. Intell.
Res. (JAIR), vol. 41, pp. 477–526, 2011.
[7] J. Sturm, A. Jain, C. Stachniss, C. C. Kemp, and W. Burgard,
“Operating articulated objects based on experience,” in IROS, 2010.
[8] T. Ruhr, J. Sturm, D. Pangercic, M. Beetz, and D. Cremers, “A
generalized framework for opening doors and drawers in kitchen
environments,” in Robotics and Automation (ICRA), 2012 IEEE In-
ternational Conference on. IEEE, 2012, pp. 3852–3858.
[9] J. Becker, C. Bersch, D. Pangercic, B. Pitzer, T. R¨ uhr, B. Sankaran,
J. Sturm, C. Stachniss, M. Beetz, and W. Burgard, “The pr2 workshop-
mobile manipulation of kitchen containers,” in IROS workshop on
results, challenges and lessons learned in advancing robots with a
common platform, 2011.
[10] A. Krause and C. Guestrin, “Near-optimal observation selection using
submodular functions,” in AAAI, 2007, pp. 1650–1654.
2020
