Symmetry Cooperative Object Transportation by Multiple Humanoid
Robots
Meng-Hung Wu, Atsushi Konno, Shuhei Ogawa, Shunsuke Komizunai
Abstract— This research aims to create a framework of
transporting an object by multiple humanoid robots. In this
work, a symmetric hybrid position/force control is adapted to
two humanoid robots. The reference object position and attitude
are given by an operator online, and the two humanoid robots
generate its whole body motion to follow the reference object
position properly. The result of proposed method is veriﬁed
with a dynamics simulation.
I. INTRODUCTION
Among all types of robots, humanoid robots have the
potential to handle multiple tasks and walk on uneven terrain,
like human beings. Hence, it is considered that humanoid
robots might be possible to work instead of humans at
dangerous zones such as plant facilities.
However, there is a limitation of actuator output, so
the humanoid robots are unable to perform dexterously
and effectively as human beings. Although robots could be
enforced by attaching more powerful motors, the output of
motors is proportional to the size and weight of motors and
there is a load capacity limit in robots meanwhile. Therefore,
multiple humanoid robots working cooperatively will be a
solution to exploit the capability of robots, and which enables
robots to carry a heavy object, or bend a tough object
together.
The style of cooperation of multiple robots can be classi-
ﬁed into two types generally:
(I) Leader-follower type: one robot recognizes its po-
sition, makes moving plan itself or is operated
directly by a human operator, which is called leader
robot. Then the other robots, which are called
follower robots, just follow the leader robot [1].
(II) Symmetry type: there is no apparent leader robot,
and a central controller controls all the robot in the
same time [2]. The central controller requires all
information of the controlled robots.
In type (I), the force-controlled follower robots follow
the position-controlled leader robot. The impedance of the
follower robots has to be small to strictly follow the motion
of the leader robot. Hence disturbance from environments
may seriously affect on the stability of the robots. Moreover,
the follower robot starts planning after the leader robot moves
as illustrated in Fig. 1 (a). This time-lag may cause low
M.H. Wu, A. Konno, S. Ogawa, and S. Komizunai are with
Division of System Science and Informatics, Graduate School
of Information Science and Technology, Hokkaido University,
Kita 14, Nishi 9, Kita-ku, Sapporo, Hokkaido, 060-0814, Japan.
{wu, ogawa}@scc.ist.hokudai.ac.jp, {konno,
komizunai}@ssi.ist.hokudai.ac.jp
Leader Follower
Planning Waiting Moving Planning
Stopping
Moving
F F
Leader Follower Leader Follower
(a)Leader-follower type
Robot A Robot B
Planning Planning
Command
Moving Moving
Stopping Stopping
Robot A Robot B Robot A Robot B
(b) Symmetry type
Fig. 1. Conceptual difference of the two types of cooperation
responsibility and an unexpected falling down. In type (II),
the reference object position is equally used for controlling
the robots by a central controller. Furthermore, the two robots
synchronously move and stop as illustrated in Fig. 1 (b).
This synchronously movement achieves high responsibility
and robustness in carrying an object.
For those reasons, the symmetry type is studied in this
research for cooperation between two humanoid robots.
Uchiyama and Dauchez proposed a central control law
for controlling two robot arms without distinguishing master
and slave [2]. But the redundancy of internal force is un-
considered if there are more than two arms. This control
law is extended to ﬁt controlling of four robot arms in
this research. There are some ongoing researches about
cooperation transportation by robots [1][3], but most of
them focus on wheeled robots. However, a humanoid robot
uses discrete foot placement while moving which makes
it more difﬁcult to accelerate or decelerate suddenly. Also,
internal force between the robots may result in falling down
because the stability margin (e.g. margin of zero moment
point from the fringe of the support polygon) of a moving
humanoid robot maybe not always big enough. Also there
is a research studies in cooperative object transportation
between a humanoid robot and a human [4]. But it turns
out that the human adjusts himself to ﬁt the humanoid
robot’s movement. As a result, to achieve cooperative object
transportation by humanoid robots is more difﬁcult than by
wheeled robots, and has not been realized yet.
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 European Union 3446
d1
d2
d3
d4
x-y plane
d1 d2
d3 d4
Robot1 Foot
Robot2 Foot
Center of the object
d3
d4
d1 d2
Current robot1 Foot
Current robot2 Foot
Refference robot1 Foot
Refference robot2 Foot
Object moves
Fig. 2. Scheme of this framework
This research aims to create a framework of cooperative
object transportation for humanoid robots. The scheme of the
framework is shown in Fig. 2. At ﬁrst, each robot records
the relative displacement from the center of the grasped
object to their foot position in x-y plane (d1–d4). The relative
displacement is set as constant, and the reference footprint
position is calculated with this constants from the object
position. Next, an operator gives a reference velocity of the
grasped object. The object reference position is calculated by
integrating the reference velocity, and the robot arms move
the object to follow the reference trajectory. The reference
footprint positions are continuously calculated while the
object is moving. When the error between the current and
reference footprint position exceeds a speciﬁed threshold the
robots start to walk. After a few walks, the robots will stop
if the error is under the threshold. The center of the grasped
object is always controlled by hybrid position/force control
law in order to keep the previously speciﬁed internal force
between the two robots while moving.
II. WORKSPACE VECTORS DESCRIBING COORDINATED
TASKS
In this research, the extended hybrid position/force con-
troller is derived based on the kinematics and the statics
of the four arms. In this section, the kinematic and static
equations are derived using the task vectors proposed in [2],
which involves generalized forces, velocities and positions.
∑
o
O
o
x
o
y
o
z
o
∑
a
O
a
x
a
y
a
z
a
o
F
b1
o
F
b2
o
F
b3
o
F
b4
o
N
b4
o
N
b3
o
N
b2
o
N
b1
o
l
h3
o
l
h4
o
l
h2
o
l
h1
O
h3
O
h2
O
h1
O
h4
∑
h3
∑
h4
∑
h1
∑
h2
Fig. 3. A quad-arm manipulator holding a single object
Let us consider four arms holding an object as shown in
Fig. 3. å
o
, å
hi
and å
a
represent the base frame, hand frame
of arm i, and the object frame, respectively. The object frame
is ﬁxed to the object. The virtual sticks
o
l
hi
(i = 1? 4)
are determined at the moment the robots hold the object as
vectors from O
i
to O
a
. The virtual sticks is ﬁxed to the hand
frame å
hi
. Let h1 and h2 be two arms of one robot, while
h3 and h4 be two arms of the other one. The deformation
of the object and the slippage of the hands on object are
assumed to be very small in this research, i.e. the relative
position between the object center and the grasping points
are constants. And in practical use, the relative position and
posture information of the two robots can be computed from
their joint angle information.
A. Workspace Force Vectors
The force/moment vectors
o
f
bi
at the tips of the four virtual
sticks are denoted as
o
f
bi
=

o
F
T
bi
o
N
T
bi

T
, (1)
where
o
F
bi
? 3?1 is force vector, and
o
N
bi
? 3?1 is moment
vector. The resultant force and moment vectors
o
f
a
at the
object are given by
o
f
a
=

o
F
T
a
o
N
T
a

T
= W
o
q
b
,
W?

I
6
I
6
I
6
I
6

,
o
q
b
?

o
f
T
b1
o
f
T
b2
o
f
T
b3
o
f
T
b4

T
, (2)
where I
n
represents the n? n unit matrix. The matrix W
maps the 24–dimensional vector
o
q
b
into the 6–dimensional
vector
o
f
a
. The rank of W is 6, therefore the null space
of W is 18–dimension. i.e. the outer force/moment acts on
the object is 6–dimension, and the internal force/moment
, which is independent from the movement of the object,
is 18–dimension. Since the null space is 18–dimension, we
can make 18–dimensional vector space corresponding to the
null space by choosing a proper vector set of 18–dimension,
3447
which is orthogonal to each other. The vector space is chosen
as:
V=
?
?
?
?
I
6
I
6
O
6
I
6
?I
6
O
6
?I
6
O
6
I
6
?I
6
O
6
?I
6
?
?
?
?
, (3)
where O
n
represents the n?n zero matrix. Then we deﬁne a
18–dimensional vector
o
f
n
, which belongs to this null space,
and when
o
f
a
is given the general solution of (2) becomes
as follows:
o
q
b
= W
† o
f
a
+ V
o
f
n
, (4)
where W
†
is the pseudo-inverse matrix of W. The workspace
force/moment vector
o
h is deﬁned as:
o
h=

o
f
T
a
o
f
T
n

. (5)
(4) is rewritten using
o
h as follows:
o
q
b
= U
o
h (6)
where U =

W
†
V

. As a result,
o
h could be computed
when
o
q
b
is given as follows:
o
h= U
?1 o
q
b
(7)
here,
U
?1
=
?
?
?
?
I
6
I
6
I
6
I
6
1
4
I
6
1
4
I
6
?
1
4
I
6
?
1
4
I
6
1
2
I
6
?
1
2
I
6
O
6
O
6
O
6
O
6
1
2
I
6
?
1
2
I
6
?
?
?
?
. (8)
The 18–dimensional vector
o
f
n
includes 3 sets of internal
force/moment vectors and it is represented as follows:
o
f
n
?
?
?
o
f
r
o
f
c1
o
f
c2
?
?
. (9)
Solution of (9) is given as follows:
o
f
a
=
o
f
b1
+
o
f
b2
+
o
f
b3
+
o
f
b4
, (10)
o
f
r
=
1
4
o
f
b1
+
1
4
o
f
b2
?
1
4
o
f
b3
?
1
4
o
f
b4
, (11)
o
f
c1
=
1
2
o
f
b1
?
1
2
o
f
b2
, (12)
o
f
c2
=
1
2
o
f
b3
?
1
2
o
f
b4
. (13)
The parameters of (11)–(13) depend on the chosen orthog-
onal vector sets V. All of the vectors
o
f
r
,
o
f
c1
, and
o
f
c2
represent internal forces generated at the grasped object, and
they can be controlled by giving the reference values for
them. In the case of cooperation between two robots,
o
f
r
corresponds to the internal force generated by the two robots,
while
o
f
c1
and
o
f
c2
correspond to internal forces generated
between two arms of each robot.
B. Workspace Velocity and Position Vectors
If the virtual work done by
o
q
b
balances with the work
done by
o
h, the absolute velocity (
o
s
a
) and the relative
velocity (
o
Ds
r
,
o
Ds
c1
,
o
Ds
c2
) can be derived as:
o
s
a
=
1
4
o
s
b1
+
1
4
o
s
b2
+
1
4
o
s
b3
+
1
4
o
s
b4
, (14)
o
Ds
r
=
o
s
b1
+
o
s
b2
?
o
s
b3
?
o
s
b4
, (15)
o
Ds
c1
=
o
s
b1
?
o
s
b2
, (16)
o
Ds
c2
=
o
s
b3
?
o
s
b4
. (17)
According to [2], the workspace position can be derived as
follows:
o
p
a
=
1
4
o
p
b1
+
1
4
o
p
b2
+
1
4
o
p
b3
+
1
4
o
p
b4
, (18)
o
Dp
r
=
o
p
b1
+
o
p
b2
?
o
p
b3
?
o
p
b4
, (19)
o
Dp
c1
=
o
p
b1
?
o
p
b2
, (20)
o
Dp
c2
=
o
p
b3
?
o
p
b4
. (21)
The task vectors of generalized forces, generalized veloc-
ities, generalized position are deﬁned as
h=

o
f
a
a
f
r
a
f
c1
a
f
c2

, (22)
u=

o
s
a
a
Ds
r
a
Ds
c1
a
Ds
c2

, (23)
z=

o
p
a
a
Dp
r
a
Dp
c1
a
Dp
c2

, (24)
respectively. The sufﬁx a represents that the vector is deﬁned
with respect to the object frame å
a
.
Finally, we deﬁne a Jacobian matrix J
quad
, which maps
all joint velocities of the two robots s to the generalized
velocities is deﬁned as:
u= J
quad
s . (25)
The relationship between the joint torque L of the two robots
and the generalized forces is given by:
L= J
T
quad
h . (26)
III. WALKING PATTERN GENERATION
A ﬂow chart of walking planning is shown in Fig. 4. The
two robots generate their own reference zero moment point
(ZMP) and reference center of mass (CoM) trajectory, and
hence the walking plan of two robots are independent. At
ﬁrst, the robots are in waiting condition. If the error between
the reference footprint position and current position exceeds
the previously speciﬁed threshold, the robot starts to take its
ﬁrst step. The error includes position error e
p
and attitude
error in yaw direction e
A
, which are deﬁned as:
e
p
=k d
re f
? d
cur
k , (27)
e
A
=k y
re f
? y
cur
k , (28)
where d
re f
is the reference foot position, d
cur
is the current
foot position, y
re f
is the reference yaw angle of the foot, and
y
cur
is the current yaw angle of the foot, respectively. e
p
and
e
A
are both checked in left and right foot. After the ﬁrst step,
3448
start
waiting
does error go over ?
walk for one step
does error go over ?
no
yes
yes
no
Fig. 4. Flow chart of walking planning
initial zmp 
Fig. 5. The reference ZMP trajectory
the error will be checked again and the robot decides if it
should stop or take a next step. Finally, the robot will stop
walking when the error is under the threshold in which the
arms can move the object to the desired position without
stepping. The reference footprint position is calculated to
meet the initial relative position from the object center to
the footprint position as shown in Fig. 2. Once the reference
footprint position is decided, the reference ZMP trajectory
can be calculated by interpolating the discrete footprint
positions (Fig. 5).
Then the reference trajectory of CoM that corresponds
desired ZMP can be computed by applying the preview
control of ZMP [5].
IV. CONTROL LAW OF THE WHOLE SYSTEM
The control law of the whole system consist of position
control and force control.
A. Position Control–Whole Body Kinematics
Cooperation between the robots A and B is considered
in this system, in which each robot has 32 degrees of free-
dom (DOF). The control variables in this system are: CoM
position p
CoM
AB
, waist link attitude R
waist
AB
, the position and
attitude of the swinging foot pR
swingLeg
AB
, the generalized
object position z, and the arm angles q
elbow
AB
(deﬁned in
[6]) of two robots, respectively. The whole system kinematics
object
support leg
support leg
robot A
robot B
Fig. 6. The joint path for calculating J
quad
equation is given as follows:
?
?
?
?
?
?
˙ p
CoM
AB
˙
R
waist
AB
˙ p
˙
R
swingFoot
AB
˙ z
˙
q
elbow
AB
?
?
?
?
?
?
=
?
?
?
?
?
?
diag(J
CoM
A
,J
CoM
B
)
diag(J
waist
A
,J
waist
B
)
diag(J
swingFoot
A
,J
swingFoot
B
)
J
quad
diag(J
elbow
A
,J
elbow
B
)
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
˙
q
A
1
.
.
.
˙
q
A
32
˙
q
B
1
.
.
.
˙
q
B
32
?
?
?
?
?
?
?
?
?
?
,
(29)
where J
CoM
is the CoM Jacobian matrix, J
waist
is the Jaco-
bian matrix form supporting leg to waist link, J
swingFoot
is the
Jacobian matrix of swing foot, J
elbow
is the Jacobian matrix
of arm angles, respectively. z and J
quad
are deﬁned in chapter
II, and ˙ z can be approximated by u (i. e. ˙ z≈ u). The joint path
for calculating J
quad
is shown in Fig. 6. The f oot
i
˙ x ˙ y
˙
q
(i= A,B)
is the vector from base frame å
o
to supporting leg, and
the supporting leg switches to each other after every step.
The reference trajectory of CoM and swinging foot can be
calculated in the way described in chapter III. The reference
attitude of the waist link is given so that the upper body
maintains the upright posture, and the reference yaw angle
is calculated as the mean-value of the supporting foot and
swing foot. The reference object position
o
p
a
is given by an
operator online. Since relative movement between the tips of
the four virtual sticks may cause internal force, the reference
o
Dp
r
,
o
Dp
c1
, and
o
Dp
c2
are set to zero vectors. The reference
arm angles q
elbow
AB
are set to the same arm angles in initial
posture for ﬁxing it. (29) is rewrote as:
˙ p
all
= J
all
s . (30)
The whole reference joint angles of the two robots q
re f
can be computed by solving inverse kinematic of (30) when
reference p
re f
all
is given. The iterative procedure is as follows:
• step1: k = 0, q(k)= q
cur
.
• step2: p
all
(k)= FK(q(k)).
• step3: if (p
re f
all
?p
all
(k))< e, q
re f
= q(k), iteration ends.
• step4: q(k+ 1)= q(k)+ J
†
all
(p
re f
all
? p
all
(k))
• step5: k = k+ 1, go to step2.
3449
-40
-20
 0
 20
 40
 60
 80
 100
 120
 140
 1 2 3 4 5 6 7 8 9 10
Force [N]
Time [s]
Without force control
With force control
-40
-20
 0
 20
 40
 60
 80
 100
 120
 140
 1 2 3 4 5 6 7 8 9 10
Force [N]
Time [s]
Without force control
With force control
-40
-20
 0
 20
 40
 60
 80
 100
 120
 140
 1 2 3 4 5 6 7 8 9 10
Force [N]
Time [s]
Without force control
With force control
(a) x direction (b) y direction (c) z direction
-50
-40
-30
-20
-10
 0
 10
 20
 30
 1 2 3 4 5 6 7 8 9 10
Torque [N*m]
Time [s]
Without force control
With force control
-50
-40
-30
-20
-10
 0
 10
 20
 30
 1 2 3 4 5 6 7 8 9 10
Torque [N*m]
Time [s]
Without force control
With force control
-50
-40
-30
-20
-10
 0
 10
 20
 30
 1 2 3 4 5 6 7 8 9 10
Torque [N*m]
Time [s]
Without force control
With force control
(d) roll direction (e) pitch direction (f) yaw direction
Fig. 10. Internal force of six axis
(a) 0 [s] (b) 7 [s]
(a) 14 [s] (b) 21 [s]
(a) 28 [s] (b) 35 [s]
Fig. 11. The motion of online operation
REFERENCES
[1] Y . Hirata, T. Sawada, Z. Wang and K. Kosuge, “Leader-Follwer Type
Motion Control Algorithm of Multiple Mobile Robots with Dual
Manipulators for Hanling a Single Object in Coordination,” in Int.
Conf. on Intelligent Robots and Systems, pp. 362–367, 2004.
[2] M. Uchiyama, and Dauchez, “A Symmetric hybrid position/force
control scheme for the coordination of two robots,” in IEEE Int. Conf.
on Robotics and Automation, pp. 350–356, 1988.
[3] K. Kosuge, and T. Oosumi, “Decentralized Control of Multiple Robots
Handling an Object,”in IEEE Int. Conf. on Intelligent Robots and
Systems, pp. 318–323, 1996.
[4] K. Yokoyama, H. Handa, T. Isozumi, Y . Fukase, K. Kaneko, F.
-1.5
-1
-0.5
 0
 0.5
 1
 1.5
 2
-0.5 0 0.5 1 1.5 2 2.5
y [m]
x [m]
rZMPA
ZMPA
CoMA
rZMPB
ZMPB
CoMB
obj
Fig. 12. Result of online operation
Kanehiro, Y . Kawai, F. Tomita, and H. Hirukawa, “Cooperative Works
by a Human and a Humanoid Robot,” in IEEE Int. Conf. on Robotics
and Automation, pp. 2985–2991, 2003.
[5] S. Kajita, F. Kanehiro, K. Kaneko, K. Fujiwara, K. Harada, K. Yokoi
and H. Hirukawa, “Biped Walking pattern Generation by Using Pre-
view Control of Zero-moment Point,” in IEEE Int. Conf. on Robotics
and Automation, pp. 1620–1626, 2003.
[6] K. Kreutz-Delgado, M. Long, and H. Seraji, “Kinematic analysis of
7-dof manipulators,” International Journal of Robotics Research, vol.
1, no. 5, pp. 469–481, 1992.
[7] K. Kaneko, F. Kanehiro, S. Kajita, H. Hirukawa, T. Kawasaki, M.
Hirata, K. Akachi and T. Isozumi, “Humanoid robot HRP-2,” in IEEE
Int. Conf. on Robotics and Automation, pp. 1083–1090, New Orleans,
LA, USA, 2004.
[8] F. Kanehiro, H.Hirukawa, and S.Kajita, “OpenHRP: Open Architec-
ture Humanoid Robotics Platform,” International Journal of Robotics
Research, vol. 23, no. 2, pp. 155–165, 2004.
3451
