Modeling User’s Driving-Characteristics in a Steering Task
to Customize a Virtual Fixture Based on Task-Performance
Han U. Yoon, Ranxiao F. Wang, and Seth A. Hutchinson
Abstract—This paper presents an approach for modeling
user’s driving-characteristics in a steering task, and determin-
ing the parameters of a virtual ﬁxture to assist the user-control
on the basis of his/her task-performances. First, we brieﬂy
introduceourassistivehuman-robotinteraction(HRI)interface
and a virtual ﬁxture as backgrounds related to this research.
The designed HRI interface provides assistance by actively
constraining the user-control with a virtual ﬁxture. Second,
we discuss a way to model a user’s driving-characteristics in
a steering task. In modeling the driving-characteristics, we use
techniques from inverse optimal control (IOC), where known
basis functions (speed, steering, and proximities to inner/outer
road boundary) are employed to design a cost function. Third,
we describe the experimental setup and procedures to obtain
user-demonstrated data from human subjects. Utilizing the
obtained data sets, we infer the unknown parameter vector by
solving inverse optimal control. Afterward, the user’s driving-
characteristics are expressed in terms of the balances of the
inferred parameters, allowing us to ﬁnd a relationship between
the modeled driving-characteristics and task-completion time.
Finally, we present a method to set a virtual ﬁxture for a newly
given task by predicting the user’s task-performances.
I. INTRODUCTION
Assistive control is currently prevalent in various ap-
plications due to its unique characteristics of constrain-
ing/regulating user-driven control input, rendering more free-
dom to users’ control [1]. The assistive control (sometimes
together with a haptic guidance) is known to improve user’s
task-performance, including telerobotic tasks [2], steering
task [3], and robot-assisted manipulation [4], and so on.
One way of implementing assistive control in human-robot
collaborative tasks is through a virtual ﬁxture (also known as
active constraint). The virtual ﬁxture is software-generated
user-control constraining strategies that enhance a human
operator’s task performance, and is usually set along with a
referencetrajectory[4].Inassistivecontrol,settingtheproper
level of constraint with virtual ﬁxturing is important because
an excessive level of constraint for a skilled user would slow
down a task completion [5]. In contrast, a lack of constraint
for a novice user may lead to a task failure.
For a decade, the inverse optimal control (IOC) has been
applied to a broad range of ﬁelds, e.g., learning a user’s
driving style [6], operating an autopilot system that mimics
H. U. Yoon is with Ph.D. Candidate of the Department of Electrical
and Computer Engineering, University of Illinois at Urbana–Champaign,
Urbana, IL 61801, USA hyoon24@illinois.edu
R. F. Wang is with Faculty of the Department of Psychology, Uni-
versity of Illinois at Urbana–Champaign, Champaign, IL 61820, USA
wang18@illinois.edu
S. A. Hutchinson is with Faculty of the Department of Electrical
and Computer Engineering, University of Illinois at Urbana–Champaign,
Urbana, IL 61801, USA seth@illinois.edu
specialmaneuversdemonstratedbyahumanpilot[7],ﬁnding
an optimality principle in human walking [8], determining a
user’s driving style with continuous model [9], predicting a
probabilistic pointing target [10], and so on. Through various
applications, IOC has become a powerful tool that grants us
an opportunity to scrutinize the following problems: ﬁnding
the cost function for “ﬂying well” or “driving hastily”? [6].
Namely, the IOC can be utilized in deﬁning ambiguous
characteristics, such as “driving well” or “steering well”,
by inferring the unknown parameter vector of known (pre-
determined) basis functions with a given user-demonstrated
data [6][11].
In this paper, we consider the problems associated with
modeling user’s driving characteristics in a steering task to
set a virtual ﬁxture to assist a user-control on the basis
of his/her task-performances (task-completion time and the
maximumdeviationfromareferencetrajectory).Speciﬁcally,
we model the driving-characteristics by solving IOC to infer
how s/he optimizes the balances of speed, steering, and
proximities to inner/outer road boundary with observed user-
demonstrations. Next, we ﬁnd a relationship between the
modeled driving-characteristics and task-completion time to
determine virtual ﬁxture parameters that will assist the user
with a new task. Finally, we illustrate an example of virtual
ﬁxturing set by predicting the user’s task-performances. In
general, the outcomes from this study will provide an answer
to a class of questions – “Can we provide the right level of
assistance to a user whose driving styles is of certain type?”
The motivation for solving this problem is initiated from
the larger problem of developing assistive interfaces for
human-robot interaction (HRI) that guides a non-expert user
with an expert’s knowledge in a steering task. In particular,
the modeled driving-characteristics can serve as design pa-
rameterstotunetheassistiveHRIinterfaces(includingvisual
feedback, joystick gains, etc). Our focus in this paper is on
the methods for setting a virtual ﬁxture to provide a proper
level of constraint to the user.
We performed the experiment with human subjects to
obtain the user-demonstrated data. The experimental setup
consists of a display device and an input device just as the
user (the subject) plays a video game. From the beginning
to the ﬁnish line, the user is instructed to control a mobile
robot under various road conditions. Afterward, we solve the
IOC problem with the user-demonstrated data to infer the
unknown parameter vector for each user. Then, we obtain
the modeled user’s driving-characteristics in terms of the
balances of the inferred parameters, which in turn designates
the level of assistance to the user by a statistical analysis.
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 625
Finally,withanewtask,theanalysisallowsustosetavirtual
ﬁxture based on the user’s predicted task-performance.
This paper is organized in the following order: In Sec-
tion II, we brieﬂy introduce the background related to this
research. In Section III, we discuss how we model user’s
driving-characteristics using techniques from inverse optimal
control. Section IV describes the experimental setup and
the task procedures of the human subject experiment to
obtain user-demonstrated data. In Section V, we present the
modeled driving-characteristics for all users, and a statistical
approach to set a virtual ﬁxture based on the predicted task-
performances. Finally, we discuss the conclusions and future
works in Section VI.
II. BACKGROUNDS RELATED TO THIS
RESEARCH
Our assistive HRI interface has been developed to assist
a user control by setting active constraint (virtual ﬁxturing)
based on a user’s task-performance together with providing
haptic and visual feedbacks as shown in Fig. 1. Throughout
this paper, we will mainly focus on a method for utilizing
the modeled driving-characteristics to set a virtual ﬁxture. In
this section, therefore, we brieﬂy introduce the backgrounds
of virtual ﬁxturing related to this research.
A. Virtual Fixturing and Assisted Control
Avirtualﬁxturingissoftware-generatedcollaborativecon-
trol strategies in order to improve the safety, accuracy, and
speed of a human operator in robot-assisted manipulation
tasks [4]. In other words, the virtual ﬁxturing is deﬁning
attenuating admittance, denoted by c

?, as a function of
the deviation from a reference trajectory. From now on, we
will refer to the reference trajectory as the spine of a virtual
ﬁxture.
Fig.2illustratestheeffectofvirtualﬁxturingalongaspine
and the resulted assisted control input. Let x(t) and x
†
r
be
current mobile robot position and the closest point on the
spine from x(t) respectively. We deﬁne e as
e(x(t)) =x
†
r
?x(t) (1)
 represents the preferred direction, and points toward the
direction where e decreases (For various ways to deﬁne ,
see [12]). 
?
denotes the non-preferred direction, and is
orthogonal to .
Following [12][13], we can express an original control in-
put,f,asthesummationofthepreferreddirectioncomponent
Fig. 1. The developed system architecture of the assistive HRI interface.
Fig. 2. The effect of virtual ﬁxturing along the spine and the resulted
assisted control input.
and the non-preferred direction component, thus
f =f

+f

? (2)
We deﬁne an assisted control input, f
a
, as the summation of
the preferred direction component and the attenuated non-
preferred direction component
f
a
=f

+c

?f

? (3)
c

? is deﬁned in [12] as
c

?(?e?)
=
?
?
?
?
?
c

?; if ?e?≥
d
2
c

? +
[
d=2??e?

]
n
(1?c

?); if
d
2
? <?e?≤
d
2
1; if ?e?≤
d
2
?
(4)
where
d
2
is the half width of a virtual ﬁxture, and 
determines the width of an interval in which c

? changes its
value from 1 to the lower limit c

? < 1. Note that c

? and
d
2
are two parameters that we want to tune based on a user’s
driving-characteristics and corresponding task-performance.
B. The Level of Assistance
From (4), we know that c

? is a parameter to determine
the maximum level of attenuation. Throughout the paper, the
twocasesofc

?= 0:2andc

?= 0:8willbereferredtoasﬁrm
assistance and soft assistance respectively [3]. Accordingly,
the more a user is skilled the softer assistance is applied to
his control input. Oppositely, the less the user is skilled, the
ﬁrmer assistance is applied.
The effect of virtual ﬁxturing can be clearly seen by
plotting “the amount of attenuation” along the spine. Fig. 3
illustrates virtual ﬁxturings for the cases of soft assistance
and ﬁrm assistance in terms of the amount of attenuation,
1-c

?, with respect to ?e?.
200
205
210
215
220
160
165
170
175
180
0
0.2
0.4
0.6
0.8
1
1-c

?
x1
x2
(a) soft assistance c

?= 0:8
200
205
210
215
220
160
165
170
175
180
0
0.2
0.4
0.6
0.8
1
1-c

?
x1
x2
(b) ﬁrm assistance c

?= 0:2
Fig.3. Softandﬁrmvirtualﬁxturingsintermsoftheamountofattenuation,
1?c

?, with respect to ?e?.
626
III. MODELING USER’S DRIVING-
CHARACTERISTICS USING THE TECHNIQUES
FROM INVERSE OPTIMAL CONTROL
Inthissection,weintroduceamobilerobotkinematics,the
way we adopt techniques from inverse optimal control (IOC)
tomodeluser’sdriving-characteristics,andappliednumerical
method. Throughout the section, we take into account for the
speciﬁc application in which a user controls a mobile robot
along various road shapes with a visual display.
A. Mobile Robot Kinematics in Discrete Time
Fig. 4 illustrates the mobile robot kinematics and the road
boundaries at both sides. Let (x
1
;x
2
) and x
3
are the x-y
position and orientation of a mobile robot of unicycle model,
respectively. With two control inputs by a user, u
1
(linear
velocity) and u
2
(angular velocity), the kinematic equation
of the mobile robot in discrete time is [14]
x
1;k+1
=x
1;k
+t
s
cosx
3;k
u
1;k
x
2;k+1
=x
2;k
+t
s
sinx
3;k
u
1;k
x
3;k+1
=x
3;k
+t
s
u
2;k
(5)
where t
s
and k be a sampling time and corresponding time
step respectively.
We assume that the mobile robot is being driven on a road
whose inner and outer boundaries correspond to the curves

ib
and 
ob
respectively. In our application, these boundaries
are identiﬁed by an image processing, and represented as a
set of discrete points.
B. Discrete Time IOC Formulation: Problem Statement
To model user characteristics in a steering task, we
consider a cost function that represents how the user reg-
ulates/balances a speed, a steering, and distances to road
boundaries. In below, let p
ib
?
ib
and p
ob
?
ob
be the closest
points from current mobile robot position x
1:2
(inspired
by [15], we use MATLAB-like expression x
1:2
:=[x
1
;x
2
]
T
) to
left and right side boundaries respectively.
Consider the following minimization problem [16]
min
x
k
;u
k
t
s
[
N?1
∑
k=0
u
T
k
Ru
k
+(x
1:2;k
?p
ib;k
)
T
Q
ib
(x
1:2;k
?p
ib;k
)
+(x
1:2;k
?p
ob;k
)
T
Q
ob
(x
1:2;k
?p
ob;k
)
]
subject to
x
1;k+1
=x
1;k
+t
s
cosx
3;k
u
1;k
x
2;k+1
=x
2;k
+t
s
sinx
3;k
u
1;k
x
3;k+1
=x
3;k
+t
s
u
2;k
?
?
?
(N)
x
0
=x
start
x
N
=x
free
(6)
where
R =
[
c
v
0
0 c
!
]
; Q
ib
=
[
c
ib
0
0 c
ib
]
=c
ib
I;
and Q
ob
=
[
c
ob
0
0 c
ob
]
=c
ob
I
(7)
OFF ROAD 
(RIGHT SIDE)
OFF ROAD 
(LEFT SIDE)
Mobile robot
u1
u2
x3
(x1;x2)
ob : (pob1;pob2)
ib : (pib1;pib2)
?
?
Fig. 4. The mobile robot kinematics and the road boundaries at both sides.
The subscripted parameters c
v
, c
!
, c
ib
, and c
ob
represent the
parameters related to speed, steering, proximity to the inner
side, and proximity to the outer side, respectively.
Now, suppose that we already have a user-demonstrated
data, which is a set of tuple (x
k
;u
k
). Furthermore, assume
thattheuser-demonstrateddataisa(locally)optimalsolution
of(6);thus (x
?
k
;u
?
k
)iswhatwehave.Then,theIOCproblem
is to infer the unknown parameters, c
v
, c
!
, c
ib
, and c
ob
, in
matrices R, Q
ib
, and Q
ob
with the given (x
?
k
;u
?
k
) [9][17].
C. Applied Numerical Method
Now, to solve IOC problem of (6), we apply the method
developed in [17]. Here, we recapitulate that method, as it
applied to our speciﬁc cost function. First, we rewrite the
above kinematic equation (N) for clarity as
x
k+1
=x
k
+t
s
f(x
k
;u
k
)
then a discrete time HamiltonianH
k
can be deﬁned [18][19]
H
k
(x
k
;u
k
;
k+1
) =L(x
k
;u
k
)+
T
k+1
f(x
k
;u
k
) (8)
where L and  ? R
3
represent Lagrangian and a costate
vector respectively. From (6), we have
H
k
=
[
u
T
k
Ru
k
+(x
1:2;k
?p
ib;k
)
T
Q
ib
(x
1:2;k
?p
ib;k
)
+ (x
1:2;k
?p
ob;k
)
T
Q
ob
(x
1:2;k
?p
ob;k
)
]
+
T
k+1
f(x
k
;u
k
)
(9)
By applying the maximum principle [20][21], we have
@H
k
@x
k
=
?
?
2(x
1;k
?p
ib1;k
)c
ib
+2(x
1;k
?p
ob1;k
)c
ob
2(x
2;k
?p
ib2;k
)c
ib
+2(x
2;k
?p
ob2;k
)c
ob
?
1;k+1
sinx
3;k
u
1;k
+
2;k+1
cosx
3;k
u
1;k
?
?
=?

k+1
?
k
t
s
(10)
Rearranging (10) yields
?
?
2t
s
(x
1;k
?p
ib1;k
)c
ib
+2t
s
(x
1;k
?p
ob1;k
)c
ob
2t
s
(x
2;k
?p
ib2;k
)c
ib
+2t
s
(x
2;k
?p
ob2;k
)c
ob
t
s
(?
1;k+1
sinx
3;k
u
1;k
+
2;k+1
cosx
3;k
u
1;k
)
?
?
+
?
?

1;k+1
?
1;k

2;k+1
?
2;k

3;k+1
?
3;k
?
?
=0
T
(11)
627
We also know
@H
k
@u
k
=
[
2u
1;k
c
v
+(
1;k+1
cosx
3;k
+
2;k+1
sinx
3;k
)
2u
2;k
c
!
+
3;k+1
]
=0
T
(12)
Finally, if we deﬁne a vector z
k
as
z
k
= [c
v
c
!
c
ib
c
ib
c
ob
c
ob

1;k

2;k

3;k

1;k+1

2;k+1

3;k+1
]
T
(13)
then (11) and (12) can be combined and rewritten by the
form
[
A
11;k
A
12;k
A
13;k
A
14;k
A
21;k
A
22;k
A
23;k
A
24;k
]
z
k
:=A
k
z
k
(14)
The submatrices in the ﬁrst row are
A
11;k
=O
3?2
A
12;k
=
?
?
?
?
2t
s
(x
1;k
?p
ib1;k
) 0 0
0 2t
s
(x
2;k
?p
ib2;k
) 0
2t
s
(x
1;k
?p
ob1;k
) 0 0
0 2t
s
(x
2;k
?p
ob2;k
) 0
?
?
?
?
T
A
13;k
=?I
3?3
A
14;k
=
?
?
1 0 0
0 1 0
?t
s
u
1;k
sinx
3;k
t
s
u
1;k
cosx
3;k
1
?
?
(15)
and in the second row
A
21;k
=
[
2u
1;k
0
0 2u
2;k
]
A
22;k
=O
2?4
A
23;k
=O
2?3
A
24;k
=
[
cosx
3;k
sinx
3;k
0
0 0 1
]
(16)
where O
m?n
and I
m?n
represent m-by-n zero matrix
and identity matrix respectively. Hence, with the given
(x
?
k
,u
?
k
), the problem of inferring the unknown parameters,
c
v
;c
!
;c
ib
;c
ob
(which are involved in z
k
), becomes identical
to solve the following least square problem
min
z
k
?A
?
k
z
k
?
2
(17)
where A
?
k
represents the matrix A
k
being evaluated at
(x
?
k
,u
?
k
).
IV. EXPERIMENT WITH HUMAN SUBJECTS TO
OBTAIN USER-DEMONSTRATED DATA
In this section, we describe the experimental setup and
procedure of the human subject experiment. The objective
of the experiment is to obtain the user-demonstrated data
that will be utilized as (x
?
k
,u
?
k
) for the IOC problem.
A. Experimental Setup
A user (a human subject) was provided with an input
device and a display just as he played a video game. We
used a game controller with two analog-sticks, one for speed
and the other for steering, as the input device. Typical 17-
inch monitor was used as a display device. Fig. 5 shows our
Fig.5. Simulatorinterface:aglobalview(leftwindow)andalocalworking
ﬁeld of view (right window). Two circles in the middle and at the top of
the right window represent the start and the goal respectively.
simulator interface provided to a user. The interface window
size was 8.89mm?17.78mm (height?width) approximately
in1280?1024displayresolution,andprovidedaglobalview
andalocalviewoftheenvironmentforthesteeringtask.The
other area of the monitor was ﬁlled with uniform gray color
to prevent distractions caused by background contents.
B. Task Procedure
The experiment was divided into a practice stage and a
testing stage. During the practice stage, the user was asked
to familiarize him/herself with the user interface by driving
a mobile robot around either in- or out-side of the road
boundaries. However, we instructed the user that it would be
regardedasataskfailuretodrivethemobilerobotout-sideof
the road boundary during the real task. The real task started
when the user verbally expressed that he/she felt familiar
with the apparatus and conﬁdent with the task.
During the real task, the user was supposed to drive the
mobile robot from the starting location to the goal. The
simulator provided 4-different task-locations wherein roads
had different curvatures and turning angles. Each task was
repeated 5-times (trials), then the user proceeded to the next
task. Among the 5-trials, the user data that showed the best
performance (thus, the fastest one in task-completion time)
was used as (x
?
;u
?
) for a given task. There was a 3-second
interval between every trial. While the user was performing
thegiventask,aprogramreadthepositionandtheorientation
of the mobile robot every 20-millisecond, and stored the
position, orientation, two control inputs, task number, trial
number, and task result (success or failure).
V. RESULTS
A. Inferred Unknown Parameter Vector by Solving IOC
Let D
j
:{(x
?
k
;u
?
k
)}
Nj
k=1
be a set of user-demonstrated data
fortask#j,whereN
j
istask-completionandj=1;··· ;4(for
4-different task-locations). We solve the IOC problem of
multiple demonstrations by applying the method introduced
in Section III-C (Also, see [17] for IOC with multiple user-
demonstrated trajectories).
[c
v
;c
!
;c
ib
;c
ob
] in Table I shows the inferred parameters
by solving the IOC. Recalling the cost function in (6),
we know that the balance of these parameters is indeed
628
TABLE I
RESULT TABLE FOR SECTION V
GROUP USER# [ cv;c!;c
ib
;c
ob
]
∑
N
j
z
i
= [ c!=cv; c
ib
=c
ob
] r ravg c

?(ravg)
G
1
USER11 [ 0.2329, 0.6693, 1.1646, 1.000 ] 458 z
11
= [ 2.8738, 1.1646 ] 1.8813
1.38 0.8
USER5 [ 0.2198, 0.5901, 1.0989, 1.000 ] 461 z
5
= [ 2.6844, 1.0989 ] 1.0717
USER3 [ 0.2117, 0.4366, 1.0585, 1.000 ] 467 z
3
= [ 2.0622, 1.0585 ] 1.2148
USER6 [ 0.2091, 0.4322, 1.0454, 1.000 ] 488 z
6
= [ 2.0670, 1.0454 ] 1.2140
USER12 [ 0.2314, 0.7383, 1.1569, 1.000 ] 495 z
12
= [ 3.1908, 1.1569 ] 1.5370
G
2
USER2 [ 0.2000, 0.4456, 0.8075, 1.000 ] 516 z
2
= [ 2.2279, 0.8075 ] 15.8932
24.33 0.5
USER7 [ 0.5497, 0.8420, 1.1868, 1.000 ] 517 z
7
= [ 1.5316, 1.1868 ] 11.7397
USER10 [ 0.2033, 1.6280, 1.0166, 1.000 ] 551 z
10
= [ 8.0068, 1.0166 ] 41.1482
USER8 [ 0.2000, 1.1228, 0.9609, 1.000 ] 554 z
8
= [ 5.6140, 0.9609 ] 28.5570
G
3
USER9 [ 0.2009, 0.2775, 0.8903, 1.000 ] 575 z
9
= [ 1.3812, 0.8903 ] 6.1638
4.67 0.2 USER1 [ 0.2000, 0.2011, 0.9767, 1.000 ] 594 z
1
= [ 1.0055, 0.9767 ] 4.0564
USER4 [ 0.2000, 0.2533, 0.9297, 1.000 ] 657 z
4
= [ 1.2663, 0.9297 ] 3.8113
[cv;c!;c
ib
;c
ob
]: inferred parameters;
∑
N
j
: task-completion time; z
i
: sample point; r: Mahalanobis distance; ravg: average r in G;
and c

?(ravg): the desired c

? value at ravg:
?c
ob
is normalized to 1. As we solve (17), the IOC solver returns trivial solution [0;0;0;0] unless we normalize one of [cv;c!;c
ib
;c
ob
].
related to a curvature and a route of the user-demonstrated
trajectory, which in turn determines the task-completion time
and the maximum deviation from a spine. Therefore, if we
deﬁne the driving-characteristics of a user by the inferred
parameters, then it allows us to estimate his/her predicted
task-performance for newly given tasks. We will further
discuss it in the following sections.
B. Driving-Characteristics and a Metric for Skill Level
Due to the limited number of users, i.e., we have 12
user-demonstrations, here we present an example of our
methodology to ﬁnd a relationship between the driving-
characteristics and the task-completion time. Note that the
presented statistical approach is developed for this limited
case.
1) Represent a user as a sample point: First of all, we
express the user #i as a sample point inR
2
, denoted by z
i
,
with the driving-characteristics that is deﬁned as follows:
c
!
=c
v
: how the user controls a steering to a speed
c
ib
=c
ob
: proximity to inner boundary over outer boundary
z
i
=[ c
!
=c
v
;c
ib
=c
ob
] in Table I shows the expressed sample
points.
2) Mahalanobis distance as a metric to represent dif-
ference from a skilled user group: Based on task-
completion time, we classify the samples into three groups,
i.e., a skilled group G
1
:{z
11
;z
5
;z
3
;z
6
;z
12
}, an inter-
mediate group G
2
:{z
2
;z
7
;z
10
;z
8
}, and a novice group
G
3
:{z
9
;z
1
;z
4
}. Then, we assign a weight, (
∑
Nj)
 1
, to the
samples in G
1
, e.g., w
11
=
1
458
. From the ﬁve weighted sam-
ples, we calculate mean
G1
and covariance 
G1
. With
G1
and 
G1
, for all z
i
, we calculate the Mahalanobis distance
r and the group’s average r
avg
as shown in Table I (the third
and the second column from the right, respectively).
C. Setting a Virtual Fixture for a New Task
Recall that, in Section II-B, we have introduced c

? (the
lower limit of c

?) and
d
2
(a half width of virtual ﬁxture)
as two parameters that we want to adjust based on a user’s
driving-characteristics and corresponding task-performance.
1) Deﬁne c

? as a function of r: From r and
∑
Nj in
Table I, we can see that the task-completion time is neither
monotonically increasing nor monotonically decreasing with
respect tor. In this case, one way to deﬁnec

? as a function
ofr is that we set the following three (r
avg
;c

?(r
avg
))-points
for the groups
G
1
: (1:38;0:8); G
3
: (4:67;0:2); and G
2
: (24:33;0:5)
whichconsistofgroup’sr
avg
anddesiredc

? value.Then,we
separatelyperformtwocurveﬁttingstoﬁndcontinuousfunc-
tions that connect (1:38;0:8) to (4:67;0:2) and (4:67;0:2)
to (24:33;0:5), respectively; it yields
c

?(r)
=
?
?
?
?
?
?
?
?
?
?
?
0:8; if 1:07<r≤ 1:38
0:0554r
2
?0:5177r +1:4089; if 1:38<r < 4:67
0:2; if r = 4:67
0:0008r
2
?0:0072r +0:2169; if 4:67<r≤ 24:33
0:5; if 24:33<r≤ 41:15
(18)
We note that the smallest and the largest r values in Table I
are 1.0717 ? 1.07 and 41.1482 ? 41.15, respectively.
2) Deﬁne
d
2
to be a function of the maximum deviation:
We begin by solving (forward) optimal control problem with
the expert’s and the user’s [c
v
;c
!
;c
ib
;c
ob
] to generate the
spine and the user’s predicted trajectories for a new task,
respectively. After generating the spine and the predicted
trajectories, we calculate the maximum deviation between
them, e
max
, and deﬁne
d
2
to be
d
2
(e
max
) =We
?1
max
(19)
where  is a positive constant, and W is a road width
assumed to be consistent during the discrete time interval
[1;N
j
]. If the resulted virtual ﬁxture goes outside of either
inner or outer boundary, we set
d
2
to be the closest distance
to the inner/outer boundary from the spine.
629
 
 
215 220 225 230 235 240 245 250
70
75
80
85
90
95
100
expert
skilled
x1
x2
(a) USER5’s predicted trajectories
220
225
230
235
240
75
80
85
90
95
0
0.2
0.4
0.6
0.8
1
1-c

?
x1
x2
(b) virtual ﬁxturing for USER5
Fig. 6. Predicted trajectory and virtual ﬁxturings for USER5. Parameters
are c

?= 0.8 (thus 1?c

?= 0.2) and
d
2
? 5.
Finally, recalling that our assistive HRI system has been
developed to guide the novice user with the expert’s knowl-
edge in a steering task, we pick USER11 as the expert to
generate the spine for virtual ﬁxturing. Fig. 6 and Fig. 7
illustrate the examples of virtual ﬁxturing for USER5 and
USER1 by (18) and (19).
VI. CONCLUSIONS AND FUTURE WORKS
In this paper, we consider the problem of modeling user’s
driving characteristics in a steering task to customize a
virtual ﬁxture to assist the user-control based on his/her task-
performances.Weperformedthehumansubjectsexperiment,
and inferred the unknown parameter vectors by solving
inverse optimal control problem. Then, we modeled the
user’s driving-characteristics in terms of the balances of the
inferred parameters, deﬁned the driving-characteristics and
the metric for skill level, and deﬁned the parameters to set
a virtual ﬁxture by predicting the user’s task performance.
Byidentifyinguser’sdriving-characteristicsbyourapproach,
we could get an insight into how to tune our designed
HRI interface to assist a user of certain characteristics. The
resulting insight could be utilized to determine not only a
way of assistance but also the level of assistance.
For future works, ﬁrst, we should increase the size of
human subject pool, and ﬁnd more robust/general classiﬁ-
cation method to overcome the limitations of the presented
method, i.e., it was not so straightforward to deﬁne the level
of assistance as a function of the deﬁned metric. Second,
we should verify whether virtual ﬁxturing actually improves
the user’s task-performance by human subjects experiment.
Finally,weshouldcompareourapproachtootherestablished
techniques, e.g., potential ﬁeld, and analyze the results.
REFERENCES
[1] S. A. Bowyer, B. L. Davies, and F. R. y. Baena, “Active con-
straints/virtual ﬁxtures: A survey,” to appear, IEEE Transactions on
Robotics, 2013.
[2] A. Dragan and S. Srinivasa, “Formalizing assistive teleoperation,”
Robotics: Science and Systems, 2012.
[3] L. Marchal-Crespo, S. McHughen, S. C. Cramer, and D. J. Reinkens-
meyer, “The effect of haptic guidance, aging, and initial skill level on
motor learning of a steering task,” Experimental Brain Research, vol.
201, no. 2, pp. 209–220, 2010.
 
 
215 220 225 230 235 240 245 250
70
75
80
85
90
95
100
expert
novice
x1
x2
(a) USER1’s predicted trajectories
220
225
230
235
240
75
80
85
90
95
0
0.2
0.4
0.6
0.8
1
1-c

?
x1
x2
(b) virtual ﬁxturing for USER1
Fig. 7. Predicted trajectory and virtual ﬁxturings for USER1. Parameters
are c

?= 0.2205 (thus 1?c

?= 0.7795) and
d
2
? 2.
[4] J.J.Abbott,P.Marayong,andA.M.Okamura,“Hapticvirtualﬁxtures
for robot-assisted manipulation,” in Robotics research. Springer,
2007, pp. 49–64.
[5] C. Passenberg, R. Groten, A. Peer, and M. Buss, “Towards real-time
haptic assistance adaptation optimizing task performance and human
effort,” in World Haptics Conference (WHC), 2011 IEEE, June 2011,
pp. 155–160.
[6] P.AbbeelandA.Y.Ng,“Apprenticeshiplearningviainversereinforce-
ment learning,” in Proceedings of the 21st International Conference
on Machine Learning. ACM Press, 2004.
[7] A. Coates, P. Abbeel, and A. Y. Ng, “Learning for control from
multiple demonstrations,” in Proceedings of the 25th international
conference on Machine learning, 2008, pp. 144–151.
[8] G. Arechavaleta, J.-P. Laumond, H. Hicheur, and A. Berthoz, “An
optimalityprinciplegoverninghumanwalking,”Robotics,IEEETrans-
actions on, vol. 24, no. 1, pp. 5–14, feb. 2008.
[9] S. Levine and V. Koltun, “Continuous inverse optimal control with
locally optimal examples,” in ICML ’12: Proceedings of the 29th
International Conference on Machine Learning, 2012.
[10] B. Ziebart, A. Dey, and J. A. Bagnell, “Probabilistic pointing target
prediction via inverse optimal control,” in Proceedings of the 2012
ACM international conference on Intelligent User Interfaces, 2012,
pp. 1–10.
[11] S. Levine, Z. Popovic, and V. Koltun, “Feature construction for inverse
reinforcement learning,” Advances in Neural Information Processing
Systems, vol. 23, 2010.
[12] A. Bettini, P. Marayong, S. Lang, A. M. Okamura, and G. D.
Hager, “Vision-assisted control for manipulation using virtual ﬁx-
tures,” Robotics, IEEE Transactions on, vol. 20, no. 6, pp. 953–966,
2004.
[13] J. J. Abbott and A. M. Okamura, “Pseudo-admittance bilateral telema-
nipulation with guidance virtual ﬁxtures,” The International Journal
of Robotics Research, vol. 26, no. 8, pp. 865–884, 2007.
[14] S. Mastellone, D. Stipanovic, and M. Spong, “Remote formation con-
trol and collision avoidance for multi-agent nonholonomic systems,”
in Proceedings of IEEE International Conference on Robotics and
Automation, 2007, pp. 1062–1067.
[15] P. Abbeel and A. Y. Ng, “Exploration and apprenticeship learning
in reinforcement learning,” in Proceedings of the 22nd international
conference on Machine learning, 2005, pp. 1–8.
[16] A.-S. Puydupin-Jamin, M. Johnson, and T. Bretl, “A convex approach
to inverse optimal control and its application to modeling human
locomotion,” in Proceedings of IEEE International Conference on
Robotics and Automation (ICRA), 2012, pp. 531–536.
[17] M. Johnson, “Inverse optimal control for deterministic nonlinear
systems,” Thesis, University of Illinois at Urbana-Champaign, 2013.
[18] D. P. Bertsekas, Dynamic Programming and Optimal Control, Vol. I,
3rd Ed. Belmont, MA: Athena Scientiﬁc, 2005.
[19] F. L. Lewis and D. Vrabie, “Reinforcement learning and adaptive
dynamic programming for feedback control,” Circuits and Systems
Magazine, IEEE, vol. 9, no. 3, pp. 32–50, 2009.
[20] H. J. Sussmann and J. C. Willems, “300 years of optimal control:
fromthebrachystochronetothemaximumprinciple,”ControlSystems,
IEEE, vol. 17, no. 3, pp. 32–44, 1997.
[21] D. Liberzon, Calculus of variations and optimal control theory: A
concise introduction. Princeton University Press, 2012.
630
