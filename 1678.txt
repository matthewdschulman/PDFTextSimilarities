Not Seeing is Also Believing:
Combining Object and Metric Spatial Information
Lawson L.S. Wong, Leslie Pack Kaelbling, and Tom´ as Lozano-P´ erez
Abstract—Spatial representations are fundamental to mobile
robots operating in uncertain environments. Two frequently-
used representations are occupancy grid maps, which only
model metric information, and object-based world models,
which only model object attributes. Many tasks represent space
in just one of these two ways; however, because objects must be
physically grounded in metric space, these two distinct layers
of representation are fundamentally linked. We develop an ap-
proach that maintains these two sources of spatial information
separately, and combines them on demand. We illustrate the
utility and necessity of combining such information through
applying our approach to a collection of motivating examples.
I. INTRODUCTION
Spatial representations are fundamental to mobile robots
operating in uncertain environments. A navigating mobile
robot needs to know which places are free to move into and
what obstacles it might collide with. A mobile manipulation
robot cooking at home needs to be able to ﬁnd and detect
objects such as kitchen utensils and ingredients. These two
tasks typically represent space in distinct ways: navigation
with occupancy grid maps, which we will refer to as ‘metric-
level’; mobile manipulation with objects and their attributes,
which is ‘object-level’. Many tasks represent space in just
one of these two ways, use them in parallel without infor-
mation ﬂow, or infer one solely from the other, but rarely is
there any interaction between the two levels.
Consider a motivating example, as depicted in Fig. 1. Here,
a mobile robot with a camera mounted on top takes an image
and sees the side of a shelf on a table. From the camera point
cloud, it infers that a shelf of some known or measured size
is present, and estimates the shelf’s pose, shown in red and
indicated by the white arrow. Even though most of the shelf
lies within an unobserved region of space, as indicated by
the gray ‘fog’ on the right, the robot can infer that the space
overlapping with the box at its estimated pose is occupied (by
the shelf). This is an example of object-to-metric inference.
Through the act of seeing the shelf, the robot also knows
that the rays between its camera and the front of the shelf
passed through free (unoccupied) space. Since this space is
free, the robot can also infer that no objects are present in
This work was supported in part by the NSF under Grant No. 1117325.
Any opinions, ﬁndings, and conclusions or recommendations expressed in
this material are those of the author(s) and do not necessarily reﬂect the
views of the National Science Foundation. We also gratefully acknowledge
support from ONR MURI grant N00014-09-1-1051, from AFOSR grant
FA2386-10-1-4135, and from the Singapore Ministry of Education under a
grant to the Singapore-MIT International Design Center.
Computer Science and Artiﬁcial Intelligence Laboratory,
Massachusetts Institute of Technology, Cambridge, MA 02139
flsw,lpk,tlpg@csail.mit.edu
Robot	  
Unobs.	  
region	  
Shelf	  
Free	  
space	  
x
Object
pose
?
Occ.
prior
z
Pose
obs.
m
Occu-
pancy
(Occ.)
w
Occ.
obs.
Fig. 1. A mobile robot uses object detections to infer regions of occupied
space, and uses free space observations to eliminate possible locations of
objects. Our framework allows inference across representational layers as
depicted by the graphical model; please see Secs. III–V for details.
this space. This is an example of metric-to-object inference.
We will consider more examples of both types of information
interaction in this paper.
With effort, it is typically possible to use only a single
layer of spatial representation. However, this can unnecessar-
ily complicate the storage of information and the updating
of the representation, because certain types of information
from sensors are more compatible with speciﬁc types of
representation. An identiﬁed rigid object is inherently atomic,
but this is not respected when treated as a collection of
discretized grid cells. If the object is moved, then instead
of simply updating a ‘pose’ attribute in the object state,
the the entire collection of grid cells will need to be
updated. Conversely, free space is easy to represent in an
occupancy grid. However, because it provides information
about the absence of any object, which amounts to ‘cutting
holes’ in each object’s pose distribution, forcing free space
information to be kept in pose space leads to complicated
pose distributions and updates that scale with the number
of known objects instead of the number of newly observed
cells. Moreover, much of this complex updating is wasted,
because information about a local region of free space would
not affect an object’s pose unless the object is nearby.
Our goal is to combine the advantages of each layer of
representation and provide a framework for integrating both
types of information. In particular, we adopt the philosophy
of keeping each type of information in its ‘natural’ represen-
tation, where it can be easily updated, and only combining
them when queries about speciﬁc states are made. This is an
efﬁciency trade-off between ﬁltering and querying; we strive
for simplicity and compactness in the former by delaying
computation to query-time. The speciﬁc representational
choices made will be explored in greater detail in Sec. III.
To illustrate our strategy, Sec. IV develops, in detail,
the approach for a concrete one-dimensional discrete world
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 1253
involving a single object. The general case is in fact not too
different, and will be covered in Sec. V. Several example
applications of the framework are presented in Sec. VI,
where we will demonstrate, for example, how free space
information can be used to reduce uncertainty in object type
and pose, and why object-level representations are necessary
to maintain an accurate metric spatial representation.
II. RELATED WORK
Since Moravec and Elfes [1] pioneered the occupancy grid
model of space, occupancy grids have been used extensively
in robotics, most notably in mapping. These maps have paved
the way for tasks such as navigation and motion planning,
in which knowledge of free and occupied spaces is sufﬁcient
for success. However, as we move to tasks that require richer
interaction with the world, such as locating and manipulating
objects, occupancy information alone is insufﬁcient.
In the mapping community, there has been recognition that
using metric representations only is insufﬁcient. In particular,
the rise of topological mapping, and the combination of
the two in hybrid metric-topological mapping ([2]) suggests
the utility of going beyond metric representations. These
hybrid representations have been successfully applied in
tasks such as navigation ([3]). A related ﬁeld that has been
growing recently is semantic mapping (e.g., [4], [5], [6], [7]),
where typically the focus is to endow topological regions
of space with semantic attributes, such as in the task of
place classiﬁcation. Topological and semantic information is
typically extracted from metric layers (occupancy grids).
Some works in semantic mapping do place greater empha-
sis on the detailed modeling of objects (e.g., [8], [9], [10]).
However, as with the hybrid mapping community, object-
based information is rarely propagated back down to the
metric level. The importance of objects is underscored by
the existence of large computer vision communities that are
dedicated to detecting and recognizing objects. Sophisticated
methods (e.g., [11], [12], [13]) exist to build and maintain
world models, which are representations of space in terms
of objects and their attributes. Although vision techniques
typically rely on geometric features to infer object existence,
we are not aware of any method that allows for information
to ﬂow in the reverse direction, as we do in this paper.
III. PROBLEM DEFINITION AND SOLUTION STRATEGY
Consider a well-localized robot making observations in a
world containing stationary objects. Since the contents of
a spatial representation is ultimately a state estimate, we
ﬁrst describe the state. We assume that each object obj
i
is described by a ﬁxed set of attributes of interest, whose
values are concatenated into a vectorx
i
. Likewise, the world
is discretized into a metric grid (not necessarily evenly
spaced), where each cell cell
j
is endowed with another set
of attributes with value m
j
. For concreteness, it may help
to consider x
i
being the object pose (assuming we know
which object it is), andm
j
being the binary occupancy value
for cell
j
. We shall explore this case further in Sec. IV, and
subsequently generalize to other attributes in Sec. V.
The objects’ statesfx
i
g and the cells’ statesfm
j
g are not
known, and are imperfectly sensed by the robot. We assume
that the perception framework returns two independent types
of observations,fz
i
1:Z
g andfw
j
1:W
g, revealing information
about the objects and cells respectively. The subscripts in-
dicate that each object/cell may have multiple observations.
Observations may be raw sensor readings or be the output
of some intermediate perception pipeline. For example, w
j
may be range sensor readings, whereasz
i
may be the output
of an object detection and pose estimation pipeline.
For convenience, we will use the following shorthand
in the rest of the paper. As in the above presentation,
superscripts always refer to the index of the object/cell.
To avoid the clutter of set notation, we will denote the
set of all objects’ states,fx
i
g, by x

; speciﬁc indices will
denote individual states (e.g., x
i
is obj
i
’s state). Similarly,
m
j
is cell
j
’s state, whereas m

refers to the states of all
cells (previouslyfm
j
g). Likewise, for observations, z
i
k
is
the k’th observation associated with obj
i
, z
i

is the set of
observations associated with obj
i
, and z

is the set of all
object observations (previouslyfz
i
1:Z
g).
Our goal is to estimate the marginal posterior distributions:
P(x

jz

;w

) and P(m

jz

;w

): (1)
In most of our examples, such as the object-pose/cell-
occupancy one described above, x

and m

are dependent:
given that an object is in pose x, the cells that overlap with
the object at pose x must be occupied. Such object-based
dependencies also tend to be local to the space that the
object occupies and hence very non-uniform: cells that do not
overlap with the object are essentially unaffected. The lack
of uniformity dashes all hopes of a nice parametric update
to the objects’ states. For example, if m
j
is known to be
free, all poses that overlap m
j
must have zero probability,
thereby creating a ‘hole’ in pose space that is impossible to
represent using a typical Gaussian pose distribution.
As a result, we must resort to non-parametric represen-
tations, such as a collection of samples, to achieve good
approximations to the posterior distributions. However, the
dimension of the joint state grows with the number of objects
and the size of the world, and sampling in the joint state
quickly becomes intractable in any realistic environment.
This approach can be made feasible with aggressive factoring
of the state space; however, combining different factors
correctly simply introduces another fusion problem. Filtering
a collection of samples over time, or particle ﬁltering ([14],
[15]), also introduces particle-set maintenance issues.
Instead of ﬁltering in the joint state and handling complex
dependencies, our strategy is to ﬁlter separately in the object
and metric spaces, and merge them on demand as queries
about either posterior are made. Our philosophy is to trade
off ﬁlter accuracy for runtime efﬁciency (by using more
restrictive representations that each require ignoring different
parts of the perceived data), while ensuring that appropriate
corrections are made when answering queries. By making
typical independence assumptions within each layer, we can
leverage standard representations such as a Kalman ﬁlter (for
1254
object pose) and an occupancy grid (for metric occupancy) to
make ﬁltering efﬁcient. Speciﬁcally, we propose to maintain
the following distributions in two ﬁlters:
P(x

jz

) and P(m

jw

); (2)
and only incorporate the other source of information at query
time. Computing the posteriors in Eqn. 1 from the ﬁltered
distributions in Eqn. 2 is the subject of the next section.
IV. THE ONE-DIMENSIONAL, SINGLE-OBJECT CASE
To ground our discussion of the solution strategy, in this
section we consider a simple instance of the general problem
discussed in the previous section. In particular, we focus
on the case of estimating the (discrete) location of a single
static object and the occupancy of grid cells in a discretized
one-dimensional world. The general problem involving more
objects and other attributes is addressed in Sec. V.
A. Formulation
The single-object, 1-D instance is deﬁned as follows:
 The 1-D world consists of C contiguous, unit-width cells
with indices 1jC.
 A static object of interest, with known length L, exists in
the world. Its location, the lowest cell index it occupies,
is the only attribute being estimated. Hence its state x
satisﬁes x2 [1;C L+1],f1;:::;C L+1g.
 We are also interested in estimating the occupancy of each
cell cell
j
. Each cell’s state m
j
is binary, with value 1 if
it is occupied and 0 if it is free.
 Cells may be occupied by the object, occupied by
‘dirt’/‘stuff’, or be free. ‘Stuff’ refers to physically-existing
entities that we either cannot yet or choose not to identify.
Imagine only seeing the tip of a handle (which makes the
object difﬁcult to identify) or, as the name suggests, a
ball of dirt (which we choose to ignore except note its
presence). We will not explicitly distinguish between the
two types of occupancy; the cell’s state has value 1 if it is
occupied by either the object or ‘stuff’, and 0 if it is free.
 The assumption above, that cells can be occupied by non-
object entities, allows us to ascribe a simple prior model
of occupancy: each cell is occupied independently with
known probability P(m
j
= 1) = . This prior model
and cell independence assumption are commonly used in
the occupancy grid literature (see, e.g., [16]). This may be
inaccurate, especially if the object is long and is small.
 Noisy observationsz

of the single object’s locationx and
observations w

of the cells’ occupancies m

are made.
We will be intentionally agnostic to the speciﬁc sensor
model used, and only assume that appropriate ﬁlters are
used in light of the noise models.
 The object and metric ﬁlters maintain P(xjz

) and
P(m

jw

) respectively. We assume that the former is a
discrete distribution over the domain of x, and the latter
is an occupancy grid, using the standard log-odds ratio
`
j
= log
P(m
j
=1jw
j

)
P(m
j
=0jw
j

)
for each cell’s occupancy.
 States of distinct cells are assumed to be conditionally
independent given the object state x. This is a relaxation
of the assumption cells are independent, which is typi-
cally assumed in occupancy grids. The current assumption
disallows arbitrary dependencies between cells; only de-
pendencies mediated by objects are allowed. For example,
two adjacent cells may be occupied by the same object and
hence are dependent if the object’s location is not known.
As mentioned in the previous section, what makes this
problem interesting is that x and m

are dependent. In
this case, the crucial link is that an object that is located
at x necessarily occupies cells with indices j 2J(x) ,
[x;x+L 1], and therefore these cells must have as state
m
j
= 1. This means that states of a subset of cells are
strongly dependent on the object state, and we expect this to
appear in the metric posterior P(m

jz

;w

). Likewise, oc-
cupancy/freeness of a cell also supports/opposes respectively
the hypothesis that an object overlaps the cell. However,
the latter dependency is weaker than the former one, as an
occupied cell can be due to ‘dirt’ (or other objects, though
not in this case), and a free cell typically only eliminates a
small portion of the object location hypotheses.
B. Cell occupancy posterior
We now use this link between x and m

to derive the
desired posterior distributions from Eqn. 1. We ﬁrst consider
the posterior occupancym
j
of a single cellcell
j
. Intuitively,
we expect that if the object likely overlapscell
j
, the posterior
occupancy should be close to 1, whereas if the object is
unlikely to overlap the cell, then the posterior occupancy
should be dictated by the ‘stuff’ prior and relevant occupancy
observations (w
j

). Since we do not know the exact location
of the object, we instead have to consider all possibilities:
P(m
j
jz;w

) =
X
x
P(m
j
jx;w
j

)P(xjz;w

): (3)
In the ﬁrst term, because x is now explicitly considered,
object observations z

are no longer informative and are
dropped. Since we assumed that cells are conditionally inde-
pendent given the object state, all other cells’ observations
are dropped too. The second term is the posterior distribution
on the object location, which will be discussed later.
The term P(m
j
jx;w
j

) can be decomposed further:
P(m
j
jx;w
j

)/P(w
j

jm
j
)P(m
j
jx) (4)
The second term,P(m
j
jx), serves as the link between cells
and objects. By the discussion above, for j 2J(x), i.e.,
cells that the object at location x overlaps, m
j
must be
1. In this case, Eqn. 4 is only non-zero for m
j
= 1, so
P(m
j
= 1jx;w
j

) must also be 1. For j = 2 J(x), the
cell is unaffected by the object, hence P(m
j
jx) = P(m
j
).
Eqn. 4 in this case is, by reverse application of Bayes’
rule, proportional to P(m
j
jw
j

), and since this is in fact a
distribution, P(m
j
jx;w
j

) = P(m
j
jw
j

). This reﬂects that
for j = 2J(x), the cell’s state is independent of the object
state. In summary:
P(m
j
jx;w
j

) =
(
1 if j2J(x);
P(m
j
jw
j

) otherwise:
(5)
1255
This ‘link’ between object and cell states matches the in-
tuition given above: the cell is necessarily occupied if the
object overlaps it; otherwise, the object state is ignored and
only occupancy observations are used. The probability value
P(m
j
jw
j

) is readily available from the metric ﬁlter (for an
occupancy grid with log-odds ratio `
j
for cell
j
, the desired
probability is1 
1
1+exp(`
j
)
). Combining Eqns. 3 and 5 results
in a nicely interpretable posterior:
P(m
j
jz;w

) =p overlap +P(m
j
jw
j

)(1 p overlap); (6)
wherep
overlap
,P(x2 [j L+1;j]jz

;w

), the posterior
probability that the object is in a location that overlapscell
j
.
To compute this value, we need the object location’s posterior
distribution, which we turn to now.
C. Object location posterior
By Bayes’ rule,
P(xjz;w

)/P(w

jx;z)P(xjz) =P(w

jx)P(xjz):
(7)
The second term is maintained by the object ﬁlter, and in this
context acts as the ‘prior’ of the object location given only
object-level observations. This distribution is adjusted by
the ﬁrst term, which weighs in the likelihood of occupancy
observations. To evaluate this, we need to consider the latent
cell occupancies m

, and the constraint imposed by x.
Once again, cells overlapping the object must be occupied
(m
j
= 1), so we only need to consider possibilities for the
other cells. The non-overlapping cells are independent of x,
and are occupied according to the prior model (independently
with probability ). Hence:
P(w

jx) =
X
m

P(w

;m

jx)
=
2
4
Y
j= 2J(x)
1
X
m
j
=0
P(w
j

jm
j
)P(m
j
)
3
5
2
4
Y
j2J(x)
P(w
j

jm
j
= 1)
3
5
=
"
Y
j
P(w
j

)
#
2
4
Y
j= 2J(x)
X
m
j
P(m
j
jw
j

)
3
5
2
4
Y
j2J(x)
P(m
j
= 1jw
j

)
P(m
j
= 1)
3
5
=(w

)1
2
4
Y
j2J(x)
1
 

1 
1
1+exp(`
j
)

3
5
(8)
where in the second line we utilized the conditional inde-
pendence of cell states given x to factor the expression, and
(w

) represents the ﬁrst product in the penultimate line.
When substituting Eqn. 8 back into Eqn. 7, recall that
since w

is given, and we only need P(w

jx) up to
proportionality, we can ignore the (w

) term. Hence:
P(xjz;w

)/
2
4
Y
j2J(x)
1
 

1 
1
1+exp(`
j
)

3
5
P(xjz): (9)
Note that the expression above only containsO(L) terms,
sinceJ(x) contains exactly L cells. The complexity there-
fore scales with the number of cells the object affects,
instead of with the whole world (containing C cells, which
is potentially much greater than L). For discrete x with X
possible states, computing P(xjz

;w

) therefore requires
O(LX) time, since Eqn. 7 must be normalized over all
possiblex. Finally, we have all the pieces needed to compute
P(m
j
jz

;w

) as well using Eqn. 6. To compute both the
object and metric posterior distributions, we ﬁrst ﬁnd the
former using Eqn. 9, then ﬁnd the posterior occupancy of
each cell using Eqn. 6. This procedure requiresO(LX+C)
time. In practice, when operating in local regions of large
worlds, it is unlikely that one would want the posterior
occupancy of all cells in the world; only cells of interest
need to have their posterior state computed.
(a) Filter distributions (input) (b) Posterior distributions (output)
Fig. 2. Using only object observations, the object ﬁlter maintains a
distribution over the object’s locations (top left). The object ﬁlter contains
a single distribution, so top plots each sums to 1, whereas the metric ﬁlter
contains a collection of binary distributions, one for each cell, so bottom
plots do not sum to 1. Some cells have increased posterior probability of
occupancy (bottom right), even though no occupancy observations have
been made. Please see text in Sec. IV-D for details.
D. Demonstrations
To illustrate the above approach, we consider two simple
examples where the world containsC = 10 cells and a single
object of length L = 3. In each case, only one type of
information (object location or cells’ occupancy) has been
observed. The methods described in this section are used to
propagate the information to the other representation.
In Fig. 2, we consider the case when only object locations
have been observed. Fig. 2(a) show distributions obtained
from object (top) and metric (bottom) ﬁlters, i.e., P(xjz

)
and P(m

jw

) respectively. Note that the object ﬁlter
contains a single distribution, so the top plot sums to 1,
whereas the metric ﬁlter contains a collection of binary
distributions, one for each cell, so the bottom plot does not
sum to1. The object ﬁlter determines that the object can only
be located at cells5–7 (recall that this is the left-most point of
the object). No occupancy observations have been made, so
each cell’s occupancy probability is initially the prior value,
 = 0:3. In Fig. 2(b) after applying our framework, the
posterior occupancy distribution P(m

jz

;w

) reﬂects the
fact that cells 5–9 might be occupied by the object, even
though no occupancy measurements have been made. In
particular, all possibilities of the object location requirecell
7
to be occupied, hence its occupancy probability is 1. Cells
with no possible overlap with the object are left unchanged.
The distribution on object location is unchanged, too, since
there are no additional observations to be considered.
In Fig. 3, only occupancies of some cells have been
observed. Cells 5–7 have many observations indicating that
they are free, and cell 4 had only one observation indicating
that it is occupied. No object observations have been made,
1256
(a) Filter distributions (input) (b) Posterior distributions (output)
Fig. 3. Using only cell occupancy/freeness observations, the posterior of
the object’s location is changed drastically even though the object has never
been observed. Please see text in Sec. IV-D for details.
so the object location distribution is uniform over the feasible
range. The free cells in the middle of the location posterior
distribution (top right) indicate that it is highly unlikely
that any object can occupy those cells (which correspond
to x2 [3;7]). This makes the posterior distribution multi-
modal. Also, the weak evidence that cell
4
is occupied gives
a slight preference for x = 2. Again, even though the object
has never been observed, the posterior distribution on its
location is drastically narrowed! Unlike the previous case,
the occupancy distribution has changed, too, by virtue of the
domain assumption that an object must exist. Unobserved
cells are also affected by this process; in fact,cell
2
andcell
3
are now even more likely to be occupied than cell
4
(which
had the only observation of being occupied) because of the
possibility that x = 1.
V. GENERALIZING TO ARBITRARY STATES
The previous section used several concrete simpliﬁcations:
the world was one-dimensional, exactly one object existed
in the world, the object’s shape (length) was given, and
the only attributes considered were object location and cell
occupancy. We will remove all these simpliﬁcations in this
section. We will also discuss a way of handling continuous
object states at the end.
Despite removing many simpliﬁcations, the conceptual
framework for computing the two desired posterior distri-
butions is actually quite similar to the development in the
previous section. The major differences now are that multiple
objects are present (x

;z

instead ofx;z), and that domain-
speciﬁc derivations are no longer applicable in general. We
still require the core representational assumption that an
object-based ﬁlter and a metric-based ﬁlter are maintained to
provide efﬁcient access toP(x

jz

) andP(m

jw

) respec-
tively. The latter will typically be maintained independently
for each cell, with distribution P(m
j
jw
j

) for cell
j
. The
typical grid cell assumptions are retained as well: cell states
are conditionally independent given all object states, and
states have a known prior distribution P(m
j
).
Following the derivation in Eqns. 3 and 4, we get for
cell
j
’s posterior distribution:
P(m
j
jz

;w

) =
X
x

P(m
j
jx

;w
j

)P(x

jz

;w

) , where
(10)
P(m
j
jx

;w
j

)/P(w
j

jm
j
)P(m
j
jx

)/
P(m
j
jw
j

)
P(m
j
)
P(m
j
jx

):
(11)
Again assuming that we have already computed the posterior
object state P(x

jz

;w

), all other terms are given except
for P(m
j
jx

). This distribution is the fundamental link
between cells and objects, specifying in a generative fashion
how objects’ states affect each cell’s state (which can be
considered individually since cell states are conditionally
independent given x

). We will see other examples of this
linking distribution in the next section.
For the posterior distribution on object states, we can
likewise follow the derivation in Eqns. 7 and 8:
P(x

jz

;w

)/P(w

jx

)P(x

jz

), where (12)
P(w

jx

) =
X
m

P(w

jm

)P(m

jx

)
=
X
m

"
Y
j
P(w
j

jm
j
)
#"
Y
j
P(m
j
jx

)
#
/
Y
j
"
X
m
j
P(m
j
jw
j

)
P(m
j
)
P(m
j
jx

)
#
: (13)
Again, all terms needed to compute the above are available
from the ﬁlters, the cell prior, and the object-cell link
P(m
j
jx

) described earlier.
As in the previous section, we can compute this latter
posterior distribution more efﬁciently by considering only
the cells that objects affect. For any particular assignment to
x

, letJ(x

) be deﬁned to be the indices of cells whose
state m
j
depends on x

. This implies that if j = 2J(x

),
then P(m
j
jx

) =P(m
j
), and their respective terms in the
product of Eqn. 13 are independent of x

. In fact, for j = 2
J(x

), the sum is equal to 1, a consequence of the fact that
P(w
j

jx

) =P(w
j

) in this case. Hence:
P(x

jz

;w

)
/
2
4
Y
j2J(x

)
X
m
j
P(m
j
jw
j

)
P(m
j
)
P(m
j
jx

)
3
5
P(x

jz

): (14)
Similar to Eqn. 9, the number of product terms has been
reduced from the number of cells to O(jJ(x

)j), for each
x

. This is potentially a major reduction because objects,
for each particular state they are in, may only affect a small
number of cells (e.g., the ones they occupy). Unfortunately,
the expression still scales with the domain size ofx

, which
grows exponentially with the number of objects. In practice,
approximations can be made by bounding the number of
objects considered jointly and aggressively partitioning ob-
jects into subsets that are unlikely to interact with each other.
Alternatively, sampling values ofx

from the ﬁlter posterior
P(x

jz

) can produce good state candidates.
Object state attributes can be continuous, for example
using Gaussian distributions to represent pose. However,
the above framework can only handle discrete states. Apart
from discretizing the state space, one can instead sample
objects’ states from the ﬁlter P(x

jz

) and use Eqn. 14 to
form an approximate posterior distribution, represented as a
weighted collection of samples. These samples can then be
used in Eqn. 10 to compute a Monte-Carlo estimate ofcell
j
’s
posterior distribution P(x

jz

;w

).
1257
VI. APPLICATIONS
In this section, we will look at several scenarios where
object-based and metric-based information need to be con-
sidered together. First, we will introduce additional attributes
(besides location and occupancy from Sec. IV).
A. Shape-based object identiﬁcation
When detecting and tracking objects in the world, un-
certainty typically arises in more attributes than just loca-
tion/pose. In particular, object recognition algorithms are
prone to confusing object types, especially if we only have
a limited view of the object of interest. When multiple
instances of the same object type are present, we also run into
data association issues. Furthermore, we may even be unsure
about the number of objects in existence. Sophisticated ﬁlters
(e.g., [10], [11], [12], [13]) can maintain distributions over
hypotheses of the world, where a hypothesis in our context
is a assignment to the joint state x

.
Let us revisit the one-dimensional model of Sec. IV again,
this time with uncertainty in the object type. In particular,
the single object’s length L is unknown, and is treated as
an attribute in x

(in addition to the object’s location).
Suppose that after making some observations of the object,
we get P(x

jz

) from the ﬁlter, as shown in Fig. 5(a)
(top). The ﬁlter has identiﬁed two possible lengths of the
object (L = 3;5). Here we visualize the two-dimensional
distribution as a stacked histogram, where the bottom bars
(red) shows the location distribution for L = 3, and the top
bars (black) for L = 5. The total height of the bars is the
marginal distribution of the object’s location. Suppose we
have also observed thatcell
7
is most likely empty, andcell
8
most likely occupied (the occupancy grid gives probability
of occupancy 0:01 and 0:99 for the two cells respectively).
The posterior distributions obtained by combining the ﬁlters’
distributions is shown on in Fig. 5(b).
In the object-state posterior, the main difference is that the
probability mass has shifted away from the L = 5 object
type, and towards locations on the left. Both effects are
caused by the free space observations of cell
7
. Because all
locations for L = 5 states cause the object to overlap cell
7
,
implying thatcell
7
is occupied, the observations that suggest
otherwise cause the marginal probability of L = 5 to drop
from 0:50 to 0:10. The drop in probability for locations 5
and 6 is due to the same reason. In conclusion, incorpo-
rating occupancy information has allowed us to reduce the
uncertainty in both object location and object type (length).
Interestingly, among the L = 5 states, although location
3 had the highest probability from the object ﬁlter, it has
the lowest posterior probability mass. This minor effect
comes from the likely occupancy ofcell
8
, which lends more
evidence to the other L = 5 states (which overlap cell
8
)
but not for location 3 (which does not overlap). However,
the strong evidence of cell
8
’s occupancy has much less of
an effect compared to the free space evidence of cell
7
. This
example highlights the fundamental asymmetry in occupancy
information. Recall that the prior model allows for uniden-
tiﬁed, non-object ‘stuff’ to exist in the world, stochastically
(a) Filter distributions (input) (b) Posterior distributions (output)
Fig. 5. A 1-D scenario with a single object, but now the object’s length
is uncertain as well. The object ﬁlter (top left) determines that the object
may have length L = 3 or 5, and for either case, may be in one of several
locations. Because of a strong free space occupancy observation in cell
7
,
the uncertainty in object length has decreased signiﬁcantly in the posterior
object distribution (top right), because a L = 5 object must contradict the
free space evidence ofcell
7
. Please see text in Sec. VI-A for more details.
with probability . Thatcell
8
is occupied only suggests it is
overlapped by some object, or contains ‘stuff’. In particular,
this is the interpretation for cell
8
for the two most likely
L = 3 states in the posterior. An object overlapping the
cell would gain evidence, but the cell’s occupancy does
not need to be explained by an object. In contrast, cell
7
being free means that none of the objects can overlap it,
thereby enforcing a strong constraint on each object’s state.
In the example shown in Fig. 5, this constraint allowed us
to identify that the object is most likely of shorter length.
B. Physical non-interpenetration constraints
When multiple objects are present in the world, a new
physical constraint appears: objects cannot interpenetrate
each other ([17]). For example, in the 1-D scenario, this
means that for any pair of blocks, the one on the right
must have location x
r
 x
l
+L
l
, where x
l
and L
l
is the
location and length of the left block respectively. This is a
constraint in the joint state space that couples together all
object location/pose variables. One possible solution is to
build in the constraint into the domain of x

by explicitly
disallowing joint states that violate this constraint. Although
this is theoretically correct, it forces ﬁltering to be done in
the intractable joint space of all object poses, since there is
in general no exact way to factor the constraint.
We now consider an alternate way to handle object non-
interpenetration that is made possible by considering metric
cell occupancies. So far, we have only distinguished between
cells being occupied or free, but in the former case there is
no indication as to what occupies the cell. In particular, the
model so far allows interpenetration because two objects can
occupy the same cell, and the cell state being occupied is
still consistent. To disallow this, we consider expanding the
occupancy attribute for grid cells. We propose splitting the
previous ‘occupied’ value (m
j
= 1) into separate values,
one for each object index, and one additional value for
‘stuff’/unknown. That is, the cell not only indicates that it is
occupied, but also which object is occupying it (if known).
Then in the object-metric link P(m
j
jx

), if, for example,
obj
2
overlapscell
j
,m
j
is enforced to have value2. The non-
interpenetration constraint naturally emerges, since if obj
1
andobj
2
interpenetrate, they must overlap in some cellcell
j
,
1258
(a) Filter obj
1
, obj
2
marginals (b) Posterior (obj
1
;obj
2
) joint (c) Posterior obj
1
;obj
2
marginals (d) Marginals with cell
2
;cell
10
free
Fig. 4. A 1-D scenario with two objects. When multiple objects are present, a physical non-interpenetration constraint is introduced. (a) The ﬁlter maintains
the object locations as a product of marginals, which does not respect the constraint. The red/black bars are for obj
1
locations with lengths L = 3 and 5
respectively; the yellow bars are for obj
2
locations. (b) After considering the constraint in metric occupancy space, the posterior joint distribution shows
that the two object locations are highly coupled. (c) The posterior marginal distributions reﬂect the constraint’s effects: locations in the middle are unlikely
either object’s left-most cell, because it forces the other object into low-probability states. (d) If additionally cell
2
and cell
10
are observed to likely be
free, only a few joint states are possible. Also, the possibility ofobj
1
having lengthL = 5 is essentially ruled out. Please see text in Sec. VI-B for details.
whose value is enforced to be both 1 and 2, a situation with
zero probability. Such violating joint object states are hence
naturally pruned out when evaluating the posterior (Eqn. 14).
In particular, even if the object ﬁlter’s distribution contains
violating states with non-zero probability, by considering the
objects’ effects on grid cells the constraint is enforced and
such violating states have zero probability in P(x

jz

;w

).
We can therefore use a more efﬁcient ﬁlter representation that
ignores the constraint, such as a product of marginal location
distributions, and enforce the constraint at query time when
metric information is incorporated.
In our 1-D world with two objects, suppose their locations
are maintained by the ﬁlter as a product of marginal distribu-
tions, as depicted in Fig. 4(a). The marginal distribution for
obj
1
is shown in red/black bars; the yellow bars represent
the marginal distribution for obj
2
. In addition, there is
uncertainty in the length of obj
1
. Note that this also factors
into the non-interpenetration constraint, since, for example,
obj
1
at x
1
= 4 with L = 3 is compatible with obj
2
at
x
2
= 7, but this is not true forobj
1
withL = 5 and the same
locations. After enforcing the non-interpenetration constraint
by reasoning about metric cell states, the posterior joint
object location distribution is shown in Fig. 4(b). Here white
location-pairs have zero probability, and the most likely joint
state (x
1
;x
2
) = (3;6) has joint probability of 0:2. Based
on the marginals and the constraint, obj
1
must be to the
left ofobj
2
, hence the only non-zero probabilities are above
the diagonal. The posterior marginal distributions of the two
objects’ states are depicted in Fig. 4(c). Locations in the
middle are less likely for both objects since, for each object,
such locations force the other object into low-probability
states. Also, the lengthL must be 3 the two right-mostobj
1
locations, otherwise it will be impossible to ﬁt obj
2
in any
locations with non-zero marginal probability.
Suppose we additionally observe that cell
2
and cell
10
are likely to be empty. This greatly restricts the states of
the objects; the posterior marginal distributions of the two
objects’ states in this case is shown in Fig. 4(d). We see
that there are basically only two likely locations for obj
1
now, and that its length is most likely 3 (with probabil-
ity 0:98). This is because the additional cell observations
constrain both objects to be between cell
2
and cell
9
, of
which the only object location possibilities are (x
1
;x
2
)2
f(3;6);(3;7);(4;7)g. The larger marginal distribution of
obj
1
at location 3 is due to the fact that two joint states
are possible, and each has relatively high probability from
the input marginal distributions given by the objects ﬁlter.
In summary, occupancy information can both enforce
physical non-interpenetration constraints, as well as reduce
uncertainty in object states via free space observations.
C. Demonstration on robot
We have also empirically validated our approach on a
small real-world example, as shown in Fig. 6 and in the
accompanying video (http://lis.csail.mit.edu/
movies/ICRA14_1678_VI_fi.mp4). The initial setup
is shown in Fig. 6(a): a toy train is placed on a table, and a
PR2 robot is attempting to look at it. However, its view is
mostly blocked by a board (Fig. 6(b)); only a small part of
the train’s front is visible. A simple object instance detector
recognizes it as the front of a toy train. The question is, does
the train have one car (short) or two cars (long) (Figs. 6(c)
and 6(d))? The true answer is one train car in this example.
One way to determine the answer is to move away the
occluding board (or equivalently, moving to a better view-
point). This is depicted by the occupancy grids in Figs. 6(e)-
6(g). The grid consists of cubes with side length 2cm, within
a 1m 0:4m 0:2m volume (hence 10
4
cubes in total).
The ﬁgures show the grid projected onto the table (vertical
dimension collapsed). The yellow and black points show
free space and occupancy observations respectively. These
observations are determined from depth images returned by a
head-mounted Kinect camera: points indicate occupied cells,
and rays between points and the camera contain free cells.
Since it is known that there must be a toy train with at
least one car, performing object-to-metric inference results in
additional cells with inferred potential occupancy, as shown
by the blue (one car) and green (two car) cases. The number
of occupied cells is greater than the train’s volume due to
uncertainty in the object pose; the cells near the middle
have a darker shade because they are more likely to be
occupied. As the board is moved gradually to the right, more
occupancy observations are collected, and eventually there
are free space observations where a second train car should
have occupied (circled in Fig. 6(g)). By inference similar to
that from Sec. VI-A, the two-car case is therefore ruled out.
1259
(a) Demo setup (b) Robot’s view (e) Initial: P(1 car) = 0:43 (f) Board moved: P = 0:73 (g) Free space rules out 2-car
(c) Is it 1 car? (d) Or 2 cars? (h) Arm moves inwards: P(1 car) = 0:44 (i) Arm overlaps and hence rules out 2-car case
Fig. 6. A 3-D demonstration on a PR2 robot. Plots show occupancy grids with 1m 0:4m 0:2m volume, containing 10
4
cubes of side length 2cm,
with the ﬁnal (vertical) dimension projected onto the table. Colors depict occupancy type/source: Yellow = free space observation; Black = occupancy
observation; Blue = inferred occupancy from one-car train; Green = inferred occupancy from two-car train; Red = occupied by robot in its current state. In
this projection, the robot is situated at the bottom center of the plot, facing ‘upwards’; the black line observed near the bottom corresponds to the board.
(a)-(b) A toy train is on a table, but only part of the front is visible to the robot. (c)-(d) This is indicative of two possible scenarios: the train has one car
or two cars; there is in fact only one car. (e)-(g) One way to determine the answer is to move the occluding board away. This reveals free space where the
second car would have been (circled in (e)), hence ruling out the two-car case. (h)-(i) Another way is to use the robot arm. If the arm successfully sweeps
through cells without detecting collision, the cells must have originally been free and are now occupied by the arm. Sweeping through where the second
car would have been therefore eliminates the possibility of the train being there. Please see text in Sec. VI-C and the accompanying video for details.
Without moving either the board or the viewpoint, another
way to arrive at the same conclusion is to use the robot arm,
shown in Figs. 6(h) and 6(i). Here, occupancy ‘observations’
(red) are derived from the robot model – cells overlapping
the robot in its current conﬁguration must be occupied by
the robot. In particular, as in Sec. VI-B, we can augment the
occupancy attribute to indicate that these cells are occupied
by the robot. As the robot arm sweeps through the space
where the second train car would have been, no collisions
are detected. This indicates that the space the arm swept
through is free or occupied by the robot, which by inference
similar to that from Sec. VI-B rules out the two-car case.
VII. CONCLUSIONS AND FUTURE WORK
Through several examples, we demonstrated that there are
many plausible situations in which representing space using
both object-based and metric representations is useful and
necessary. To combine object-based and metric information,
instead of ﬁltering in the complicated joint state space,
we adopted a philosophy of ﬁltering in separate, easily-
manageable spaces, then only computing fused estimates
on demand. The approach for combining object-level and
metric-level states was developed extensively in the paper.
The given examples have been on small, low-dimensional
domains. The prospects of directly scaling up the presented
approach are unclear. As discussed in Sec. IV-C, the com-
plexity of the generic inference calculation is O(LX +C),
where L is the number of cells objects occupy, X is the
number of (discrete) attribute settings for all objects, and
C is the number of grid cells in the world. Potential efﬁ-
ciencies may be exploited if X is (approximately) factored
or if adaptive grids such as octrees are used. Nevertheless,
the number of objects and cells needed to represent large
spatial environments will still present challenges. Instead, our
approach is perhaps most useful for ﬁne local estimation: in-
formation fusion is only performed for few objects/attributes
and small areas of great interest (e.g., to a given task),
in cases where information from either the object-level or
metric-level representation alone is insufﬁcient.
More theoretical and empirical work is needed to de-
termine the ramiﬁcations of our representation when used
in large environments over long periods of time. Handling
continuous and high-dimensional state (attribute) spaces, as
well as scaling up to larger environments containing many
objects, are subjects of future work. Nevertheless, even
in its current simplistic and generic form, our approach
enables novel lines of spatial inference that could not be
accomplished using single layers of spatial representation.
REFERENCES
[1] H. Moravec and A. E. Elfes, “High resolution maps from wide angle
sonar,” in ICRA, 1985.
[2] S. Thrun, “Learning metric-topological maps for indoor mobile robot
navigation,” Artiﬁcial Intelligence, vol. 99, no. 1, pp. 21–71, 1998.
[3] K. Konolige, E. Marder-Eppstein, and B. Marthi, “Navigation in
hybrid metric-topological maps,” in ICRA, 2011.
[4] B. Kuipers, “The spatial semantic hierarchy,” Artiﬁcial Intelligence,
vol. 119, pp. 191–233, 2000.
[5] S. Ekvall, D. Kragic, and P. Jensfelt, “Object detection and mapping
for service robot tasks,” Robotica, vol. 25, no. 2, pp. 175–187, 2007.
[6] A. Pronobis and P. Jensfelt, “Large-scale semantic mapping and
reasoning with heterogeneous modalities,” in ICRA, 2012.
[7] Z. Liu and G. von Wichert, “Extracting semantic indoor maps from
occupancy grids,” RAS, 2013.
[8] A. Ranganathan and F. Dellaert, “Semantic modeling of places using
objects,” in RSS, 2007.
[9] K. M. Wurm, D. Hennes, D. Holz, R. B. Rusu, C. Stachniss,
K. Konolige, and W. Burgard, “Hierarchies of octrees for efﬁcient
3D mapping.” in IROS, 2011.
[10] J. Mason and B. Marthi, “An object-based semantic world model for
long-term change detection and semantic querying,” in IROS, 2012.
[11] G. D. Hager and B. Wegbreit, “Scene parsing using a prior world
model,” IJRR, vol. 30, no. 12, pp. 1477–1507, 2011.
[12] J. Elfring, S. van den Dries, M. J. G. van de Molengraft, and
M. Steinbuch, “Semantic world modeling using probabilistic multiple
hypothesis anchoring,” RAS, vol. 61, no. 2, pp. 95–105, 2013.
[13] L. L. S. Wong, L. P. Kaelbling, and T. Lozano-P´ erez, “Data association
for semantic world modeling from partial views,” in ISRR, 2013.
[14] A. Doucet, J. F. G. de Freitas, and N. J. Gordon, Eds., Sequential
Monte Carlo Methods in Practice. Springer, 2001.
[15] “Robust Monte Carlo localization for mobile robots,” Artiﬁcial Intel-
ligence, vol. 128, no. 12, pp. 99–141, 2001.
[16] S. Thrun, W. Burgard, and D. Fox, Probabilistic Robotics. MIT Press,
2005.
[17] L. L. S. Wong, L. P. Kaelbling, and T. Lozano-P´ erez, “Collision-free
state estimation,” in ICRA, 2012.
1260
