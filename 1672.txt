Three-Finger Precision Grasp on Incomplete 3D Point Clouds
Ilaria Gori
1
, Ugo Pattacini
1
, Vadim Tikhanoff
1
and Giorgio Metta
1
Abstract— We present a novel method for three-ﬁnger preci-
sion grasp and its implementation in a complete grasping tool-
chain. We start from binocular vision to recover the partial 3D
structure of unknown objects. We then process the incomplete
3D point clouds searching for good triplets according to a
function that accounts for both the feasibility and the stability
of the solution. In particular, while stability is determined using
the classical force-closure approach, feasibility is evaluated
according to a new measure that includes information about the
possible conﬁguration shapes of the hand as well as the hand’s
inverse kinematics. We ﬁnally extensively assess the proposed
method using the stereo vision and the kinematics of the iCub
robot.
I. INTRODUCTION
Object manipulation is certainly one of the keys enabling
technologies in a variety of different robotic domains. Ma-
nipulation is also a fertile research topic due to its intrin-
sic complexity. The dimensionality of the hand and arm’s
conﬁguration space and the difﬁculty of retrieving accurate
visual priors are perhaps the two major factors beneath
its complexity. In Napier’s taxonomy [1] grasp actions are
classiﬁed in power grasps and precision grasps. In power
grasp [2], [3] and [4] the object and the hand share large
contact areas, hindering further movements of the ﬁngers.
On the other hand, in precision grasp, the object is contacted
with the tips of the ﬁngers. Power grasps are particularly
suited when the object does not need to be handled precisely,
whereas precision grasps represent the best choice when
speciﬁc tasks have to be fulﬁlled as e.g. in tool use. This
work focuses on precision grasp.
Generating a precision grasp requires ﬁnding a set of
contact points on the object that are stable and feasible,
given the hand’s size and kinematics, its material and contact
properties as well as its overall joints stiffness. A set of
contact points is said to be force-closure if it can resist exter-
nal forces and moments without dropping the object. From
now on, when we mention stable grasps, we will always
intend force-closure grasps. Further, a grasp is feasible when
its conﬁguration, deﬁned as the ﬁnger joint angles along
with the position and the orientation of the end-effector,
allows appropriate contacts at the desired locations on the
object. As ﬁnding complete solutions turns to be difﬁcult, the
literature abounds of partial solutions focusing on isolated
aspects of the problem. For example, the earlier proposals
*This work was supported by the European FP7 ICT project No. 270490
(EFAA), project No. 270273 (Xperience) and project No. 288382 (Poeticon
++)
1
iCub Facility, Istituto Italiano di Tecnologia, Via Morego 30, Genova
filaria.gori, ugo.pattacini, vadim.tikhanoff,
giorgio.mettag@iit.it
only formalize the question of stability, assuming that the
contact points were given [5] [6] [7]. More recently, the
work of Erkan et al. [8] and Rao and colleagues [9] attack
the problem by trying to learn good grasps on the basis
of empirical experience using machine learning techniques.
However they neither account for stability nor feasibility of
the grasp. Yet other methods start from computing a feasible
hand conﬁguration for a set of given stable points [10] [11].
There are also “hybrid” approaches [12] that try to provide
contact points that are stable, feasible or both. Our work falls
squarely into the class of hybrid approaches, tackling the full
grasping problem by computing stable contact points, and
determining a hand conﬁguration that guarantees feasibility.
To the best of our knowledge, all the precision grasp
hybrid approaches use either synthetic objects or complete
point clouds of known objects to compute reliable grasps
[13], [14], [15]. We can certainly store and manage infor-
mation on 3D models of a very large number of objects;
nevertheless, because of the variety of objects’ sizes and
shapes, a robotic grasping strategy should be also robust to
unknown objects. This implicitly extends the robot’s skills
to situations where recognition fails to classify the object.
Being able to deal with unknown objects contributes to the
overall quality of the robot’s grasping skills. This line of
reasoning leads us to the consideration that the robot can
only use incomplete 3D shape information as acquired from
a single viewpoint unless, in the presence of an unknown
object, it starts a complicated exploration and data collection
procedure. Assuming that this is not desirable, we can then
reason on the fact that the robot cannot use points in the
occluded parts of the object. Our method is designed to work
with incomplete 3D point clouds resulting from a single view
of the object, albeit nothing prevents us from exploiting the
additional information where better models are available.
Another popular procedure that often characterizes hybrid
approaches is the approximation of the 3D data with speciﬁc
elementary shapes, as for example, boxes [16], shape primi-
tives [17] or superquadrics [13], [18]. This approach allows
handling regular objects quite precisely although, in many
cases, it may introduce an additional source of uncertainty on
the contact point determination. On highly irregular objects,
the error of the approximation procedure coupled with the
intrinsic noise of the sensors (vision) and the mechanical
error of the hand becomes the recipe for disaster. Our ﬁrst
contribution is a method based on the raw collection of the
3D points, without employing any object modeling.
Most of the hybrid approaches ﬁnd contact points on the
object surface, while assuring their stability using standard
force-closure criteria [15], [19], [13]. Nevertheless, they do
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 5366
Fig. 1. The ﬁgure illustrates the entire pipeline of our algorithm. We reconstruct the object in 3D obtaining a point cloud along with its surface normals.
The point cloud is explored in order to ﬁnd candidate triplets that satisfy speciﬁc criteria. We then compute, for each candidate triplet, the inverse kinematics
of the hand. Finally, we select the best grasp on the basis of the manipulability measure computed on the whole robot’s arm.
not take into account the physical characteristics of the
robotic hand; importantly, this limitation may result in un-
feasible conﬁgurations. In this sense our second contribution
is a measure of the robot’s hand physical properties in
evaluating the stability of the contact points. Privileging
ﬁngers conﬁgurations that lead more often to feasible grasps
can upfront increase the probability of success. Subsequently,
the inverse kinematics of the hand helps to prune unreachable
conﬁgurations altogether.
There are a few hybrid methods that search for stable and
feasible contact points simultaneously [18], [14]. However
they require complete 3D models of the objects. They limit
their analysis to the hand, assuming that it can move freely
around the object: this is not sufﬁcient to make sure that the
robot can reach the desired position, as the hand is connected
to robot’s body, which lies in a speciﬁc position with respect
to the object. Our last contribution is a preliminary attempt
to account for the robot’s position when selecting the best
grasp conﬁguration, in order to use the proposed algorithm
on real robots and speciﬁcally on humanoids.
We identiﬁed a roadmap that progressively evolve from
grasping in purely simulated environments to complete real
world case-studies with a taxonomy determined by the
accuracy of the information that is available to the robot
(i.e. complete 3D point cloud vs. single view): (A) Complete
3D point clouds with simulated grasps; (B) partial 3D point
clouds with simulated grasps; (C) partial 3D point clouds
with the grasp actually executed by the real robot. As far as
we know, all the precision grasp hybrid approaches presented
in the literature were developed either on synthetic objects or
on complete point clouds, exploiting the advantage afforded
by the perfect knowledge of the object. In this paper we
focus on scenario B, developing a method that is closer to
be utilized on a real robot in realistic everyday conditions.
II. METHOD
El-Khoury [18] supports the view that ﬁnding a stable and
feasible set of contact points on an object is the primary goal
when dealing with precision grasp. He further claims that
the simultaneous fulﬁllment of these two conditions brings
robustness to the grasp retrieval procedure. This implies that
both stability and feasibility have to be calculated on the
same type of variables, either discrete of continuous. In
El-Khoury’s work, the optimization is continuous since the
object is approximated with a superquadric and the hand
conﬁguration is also continuous (i.e. the kinematics). On
the contrary, since we do not make use of any surface
ﬁtting, our object models belong to the discrete domain
and cannot be explored jointly with the space of the hand
conﬁgurations. Grasping has thus to be made of two distinct
routines that ﬁnd a sufﬁcient number of candidate points
(triplets) and solve the inverse kinematic problems for the
hand (see Fig. 1).
In the ﬁrst phase, we seek for a number of candidate
triplets – sets of three contact points with corresponding
normals – under the condition that they allow the generation
of a good grasp (according to the stability criterion). Since
running the inverse kinematics on every single triplet is
computationally expensive, we need to guarantee that the
candidate triplets are selective. As a ﬁrst approximation
we privilege triplets that are certainly within the grasping
envelope of the iCub’s hand, as it is pointless to ask the
iCub to grasp a large object (given its child size). Similarly
the iCub cannot position its ﬁrst three ﬁngers at an equal
angle with respect to the center of the object.
Once a sufﬁcient number of candidate sets of contact
points has been found, we select the best one on the basis
of the feasibility of the grasp conﬁguration. We compute the
inverse kinematics of the hand for each candidate triplet and
evaluate the physical feasibility of the solution. Finally, we
consider the position of the robot with respect to the object,
and we select the best grasp among those that do not imply
critical or singular conﬁgurations of robot’s arm and torso.
The remainder of the paper is structured as follows:
Sec. III illustrates the selection of the candidate triplets,
Sec. IV describes the determination of the best grasp using
inverse kinematics, Sec. V presents the experimental results
and Sec. VI draws the conclusion and illustrates future
improvements.
III. TRIPLETS EXTRACTION
We start from an object lying in front of our robot, iCub
[20]. The ﬁrst step of our algorithm consists in exploring
the visible portion of the object and selecting a number of
best candidate triplets. We ﬁrst reconstruct the object in 3D
from a single viewpoint, obtaining an incomplete 3D point
cloud. We then estimate surface normals on each point, and
we sample the cloud assuming that close points have similar
normals. On the sampled cloud, we apply a variant of the
Discrete Particle Swarm Optimization algorithm [21], ﬁnding
5367
Fig. 2. Cost function accounting for the robot’s hand dimension. From the
picture it is possible to infer that bigger areas are privileged. The green line
represents the cost function for acceptable areas. Nevertheless, if the area is
bigger than the maximum area that can be covered by the hand – which is
represented by the big black dot – the measurement grows up dramatically
(red line), indicating a bad triplet.
a number of triplet points that satisfy several conditions. The
ﬁrst condition is related to the triplet stability, whereas the
second and the third conditions are associated to the hand
size and shape, respectively.
A. 3D Reconstruction and Sampling
We rely on stereo vision algorithms in order to retrieve
3D information. The semi-global matching algorithm [22] is
applied to the images recorded by our robot to estimate the
depth map, and project each visible pixel of the object in the
3D space. We then estimate the normal to the surface at each
point of the cloud by running a least-squares ﬁtting over the
point neighborhood to determine the corresponding tangent
plane [23]. We deﬁne the neighborhood P
k
of a point p
i
as the set of k points that lie within a circular area having
radius equal to the radius of the robotic ﬁngertip. Given a
point p
i
and its neighborhood P
k
, the plane tangent to the
surface can be deﬁned as a couple (x
i
;  n
i
), where x
i
is
a point of the plane and  n
i
is the normal to the plane.
The distance d
i
between a point p
i
2 P
k
and the ﬁtting
plane can be expressed as d
i
= (p
i
 x
i
) n
i
; therefore,
the plane parameters are computed minimizing the distance
d
i
for each point. If we assume that x
i
is the centroid of
the neighborhood (i.e. x
i
=
1
k
P
k
j=1
p
j
), then the solution
for  n
i
can be calculated by analyzing the eigenvectors and
eigenvalues of the following covariance matrix:
C =
1
k
k
X
j=1
(x
i
 p
j
)(x
i
 p
j
)
T
: (1)
We thus assemble a 3D voxel grid over the point cloud,
which results in a set of small 3D boxes in the space. We
downsample the point cloud selecting the center of each
3D boxes. Under the reasonable assumption that very close
points have very similar surface normals, we obtain a good
representation of the initial point cloud.
B. Triplet Desired Properties
We now aim to retrieve a sufﬁcient number of good
triplets. A triplet is deﬁned as “good” based on three prop-
erties. A ﬁrst, necessary property is the triplet stability in
terms of force-closure. The other two properties are related,
respectively, to the dimension and the shape of the robotic
hand.
1) Force-closure Grasp: We will exploit the stability
analysis to deﬁne if a triplet is acceptable or not acceptable.
In case the set of contact points is not stable, it cannot be
considered as a candidate triplet.
We adopt the hard ﬁnger contact model [5], which is
the most commonly used. This model is characterized by a
signiﬁcant friction acting on small contact patches, and by no
transmission of the angular velocity or moment components
to the object. Assuming that only static friction holds, we
can build a friction cone F
i
with the vertex in contact
pointp
i
and aligned along the normaln
i
on the point. The
friction cone at point p
i
represents the set of forces that
can be exerted on the point without producing a slippage of
the ﬁnger along the surface of the object. The cone F
i
is
determined by the friction coefﬁcient 
i
on the pointp
i
, as
follows:
F
i
=f(f
in
;f
it
;f
io
)j
q
f
2
it
+f
2
io
<
i
f
in
g: (2)
To ensure that the ﬁnger will not slip along the surface of
the object, the force applied by the ﬁngertip on the point
p
i
must lie within the friction coneF
i
. In order to evaluate
the stability of a grasp, we adopt the force closure analysis.
Intuitively speaking, a grasp is considered force-closure if
and only if we can exert arbitrary force and moment on the
grasped object by pressing the ﬁngertips against the object
[24].
Most of the force-closure evaluation techniques rely on
the examination of the contact wrenches [25] [13], which
consists of the computation of a 6D convex hull and implies
the approximation of the friction cone to a pyramid. On the
one hand, approximating the cone with a pyramid having a
large number of sides entails an increasing computational
complexity. On the other hand, using a small number of
sides makes the friction cone approximation coarser and the
force-closure analysis less reliable. Differently, we based our
evaluation on geometrical considerations. Speciﬁcally, we
use the necessary and sufﬁcient condition proposed by [7]:
a three ﬁnger 3D grasp achieves force-closure if and only if
 the three points are not collinear and meet on a plane
S;
 each friction cone F
i
intersects the contact plane S on
a plane, generating two unit vectors n
i1
and n
i2
that
bound the projection of the cone on the plane;
 the contact unit vectors construct a 2D force-closure
grasp in S.
This condition is fast to compute and does not require any
approximation of the friction cones.
2) HandDimension: In order to choose the best candidate
among the set of available force-closure triplets, we need a
speciﬁc heuristic to extract the most suitable grasp in relation
with the robotic hand. The use of such a heuristic will
also increase the probability of obtaining a feasible grasp
in the subsequent stage. A well-known quality measure to
evaluate how good a triplet is, is the area covered by the
5368
Fig. 3. A: the four classes of force-closure grasps are depicted. Each of
them is characterized by a different number of pairwise counter-overlapping
cones. B: the four classes are illustrated using a human hand grasping
a ball. Yellow arrows indicate which pairs of friction cones are counter-
overlapping. C: left ﬁgure, a 3D model of the iCub’s hand is depicted. The
red arrow represents the biggest distance between the index and the middle
that can be realized. In the center, an image of the iCub’s hand while closing
is showed. This picture is meant to illustrate pictorially that iCub’s hand
is not suitable for shape
3
grasps. Differently, the Barrett hand, showed on
the right, can move the ﬁngers independently and therefore perform grasps
belonging to shape
3
easily.
grasp polygon [26]. The bigger the area is, the better the
grasp will be. We modify this quality measure in order to
account for the robotic hand size (see Fig. 2). In particular,
we privilege triplets that cover large areas, and at the same
time do not exceed the physical limit imposed by the size
of the robot’s hand. Given a triplet T , the area of the grasp
polygon a, and the maximum area a
max
that the robotic
hand’s ﬁngertips can cover, a good triplet must minimize the
following discontinuous function:
d(T) =
(
k
1
(a
max
 a)
2
; if aa
max
k
2
a; otherwise
(3)
where k
1
 0 and k
2
 0 are parameters empirically found.
Speciﬁcally, if the area covered by the triplet is smaller than
a
max
, the function has a paraboloid shape. Contrarily, when
the area covered by the triplet is larger, the function increases
linearly (see Fig. 2).
3) Hand Shape: Another crucial information that, as far
as we know, has never been taken into account, is the speciﬁc
shape of the hand. Indeed, different robotic hands will have
different grasping capabilities. It has been demonstrated
in [6] that there exists four type of force-closure grasps
with three hard-ﬁnger contacts, and they are dependent on
the number of friction cones that pairwise counter-overlap.
Speciﬁcally, two friction conesF
i
andF
j
are said to counter-
overlap if the angle between their principal axes n
i
and
n
j
is smaller than the angle at the basis of the friction
cones, which is equal to 2arctan(), where is the friction
coefﬁcient. The four classes are depicted in Fig. 3, row A;
they represent, respectively, a force-closure grasp with 0
counter-overlapping cones (shape
0
), a force-closure grasp
with 1 counter-overlapping cone (shape
1
), a third force-
closure grasp with2 counter-overlapping cones (shape
2
) and
a last force-closure grasp with 3 counter-overlapping cones
(shape
3
). Fig. 3 also illustrates the four grasps performed
by a human hand, in row B. In Fig. 3 row C the iCub’s
hand and a Barrett hand are depicted. From the images it is
possible to infer that a humanoid robotic hand will strive to
realize a shape
3
grasp, because of the limited displacement
between the index and the middle ﬁngers, which cannot
face each other. This shape can be achieved only when
the friction coefﬁcient takes very high values. The iCub’s
most comfortable force-closure grasp classes will probably
be shape
1
and shape
2
. Therefore, when a good triplet is
selected, it should also have a shape that adapts to the
particular robotic hand in use. A very good example is
represented by a spherical object. It will certainly present
stable triplets belonging to shape
3
, but for a humanoid
robotic hand a triplet belonging to shape
2
or shape
1
will
be preferable in terms of feasibility.
Inspired by these considerations, we develop a novel
measure incorporating the notion of desired shape. Given a
tripletT , a numberm of desired counter-overlapping cones,
and the actual number c(T) of counter-overlapping cones
in the triplet T , we compute the quantity f = m c(T).
If f 6= 0 we build two vectors: a vector u containing
the angles between the pairs of friction cones that counter-
overlap, sorted from the smallest to the biggest value, and
a second vector v that contains the sorted angles between
the pairs of friction cones that do not counter-overlap. We
propose the following measure:
s(T) =
8
>
<
>
:
0; if f = 0
P
f
i=1
v
i
; if f > 0
P
f
i=1
u
i
; if f < 0:
(4)
The above-mentioned formulation represents how much the
current triplet is far from belonging to the class of the desired
shape. As we will minimize these quantities, the smallest the
measure is, the better the triplet is evaluated.
C. Discrete Particle Swarm Optimization
Given a set of points P , we aim at ﬁnding a triplet T =
(fp
i
;n
i
g;fp
j
;n
j
g;fp
k
;n
k
g);p
i
;p
j
;p
k
2P that satisﬁes
the properties illustrated in Sec. III-B. In particular, we want
to solve the following problem:
min
T
d(T)+ws(T)
s. t. T is force-closure;
(5)
which summarizes the characteristics that a candidate triplet
should present. The stability is formulated as a constraint, as
it is necessary to consider a triplet acceptable. At the same
time, we seek to select candidate triplets of a speciﬁc shape;
this is deﬁned bys(T), which corresponds to Eq. (4). Then,
d(T) is Eq. (3), and guarantees that the area covered by the
5369
triplet is large, but does not exceed the maximum area that
can be covered by the hand. Finally, w is a variable chosen
empirically, which regulates the contribution of d(T) and
s(T). Even though the number of possible triplets is ﬁnite,
and thus it would be possible to analyze them all to ﬁnd the
optimal one, an exhaustive search cannot be performed if
the number of point is too large, as it is likely to be in real
scenarios. Furthermore, Borst [27] demonstrated that there
is no need to ﬁnd the globally optimal grasp, because most
of the times an average grasp (in the force-analysis sense)
is acceptable. Therefore we resort to a local optimization
algorithm.
We have a discrete number of points P , thus a discrete,
derivative-free optimization algorithm is requested. On the
other hand, our downsampled point cloud is an approxima-
tion of a surface, and it holds some nice properties that we
would like to exploit. For instance, the fact that close points
are likely to have similar normals. This assumption would
help the optimization algorithm to ﬁnd a good solution fast.
Among the discrete optimization algorithms, a technique that
satisﬁes all our needs is the Discrete Particle Swarm Opti-
mization (DPSO), in the variant presented in [21]. Particle
swarm optimization (PSO), originally presented in [28], is
a population-based optimization method. It initializes a set
of particles that explore the space domain on the basis of
historical information learnt from the swarm population. In
our setting a particle p is represented by three points p
1
,
p
2
and p
3
, therefore p 2 R
9
. At each point the normal
computed as in Sec. III-A is associated, therefore a tripletT
can be represented as the couplefp;ng, wheren is the set
fn
1
;n
2
;n
3
g of normals on the points in p. Each particle
has its position and its velocity; it also keeps track of the best
global positiong

ever visited from the population, as well as
the best positionl

it has visited in the past. For each particle
a ﬁtness function on its associated triplet is computed. In our
case, the ﬁtness function is in the formd(T)+ws(T)+fc(T)
(see Eq. (5)), where fc(T) returns 1 if the triplet is force-
closure, a very large number otherwise. At each iteration, all
the particles update their positions modifying their velocities
on the basis of their past velocity,g

andl

. As in [21], we
use the velocity formula that is used in the standard version
of PSO:
v
t+1
=v
t
+c
1
r
1
(l

 p)+c
2
r
2
(g

 p); (6)
where , c
1
and c
2
are constant values, and r
1
and r
2
are
random values. It is worth noting that only the points explore
the space, whereas the normals are associated to the points in
a ﬁxed way. Therefore the velocity corresponds to an actual
velocity vector in the space. We can use this formulation
under the assumption that close points have similar normals;
therefore if the velocity is small, the particle computed in
the next iteration along with its associated normals will
be similar to the current one. Obviously the velocity is a
continuous variable and may return a particlep whose points
are not contained in our set P ; therefore, as in [21], at each
iteration we select the set of points in P that are closest to
p. When the algorithm terminates, the best particle found is
returned.
An ideal situation would be to analyze every acceptable
triplet through inverse kinematics, in order to check whether
it is actually feasible for the robot. This is not viable for
computational reasons; indeed, even though the inverse kine-
matics algorithm is fast and reliable, it takes500 milliseconds
to ﬁnd a solution. Therefore, running it for every triplet
found by DPSO – which could be a very large number
– is not computationally feasible. We need to develop an
algorithm that can be performed in real-time, thus we rely on
computing a limited number of the best triplets that DPSO
ﬁnds, and we let the kinematics pick the best one. In the
current setting we run 4 parallel DPSO procedures, one for
each hand shape, and we select the best one for each DPSO
routine. If requested, it would be possible to keep track of
a bigger number of the best ranked triplets for each DPSO
routine. These triplets are analyzed by the kinematics of both
the left and the right hand, thus the algorithm can choose
among 8 different solutions in total.
IV. INVERSE KINEMATICS
Given a triplet T , we are asked to ﬁnd a feasible con-
ﬁguration (x;o;q) for the robot’s hand. Speciﬁcally, the
inverse kinematics algorithm should provide the end-effector
position x2 R
3
and orientation o2 R
3
in the Cartesian
space, and ﬁnger conﬁguration q2 R
8
in the joint space.
We use the thumb, the index and the middle ﬁnger of the
iCub’s hand, which are equipped respectively with3,3 and2
joints. The end-effector position and orientation correspond
to the region of the object towards which the hand will move.
The ﬁnger conﬁguration (or hand preshape) corresponds to
the angles to which ﬁnger joints are set to reach the contact
points.
We formulate the inverse kinematics (IK) problem as an
optimization task, similarly to [18] and [11], and we use
IPOPT [29] to solve it. However, our problem is slightly
different with respect to [18] and [11], as we are dealing
with discrete point clouds; therefore we cannot use a model
of the object. In addition, we are only interested in the inverse
kinematics part, whilst [18] and [11] take into account a
larger number of variables. In particular, given the triplet
T = (fp
1
;n
1
g;fp
2
;n
2
g;fp
3
;n
3
g), the object center x
o
and its covariance matrix D containing information about
its dimension, we minimize with respect to x, o and q the
following problem:
min
x;o;q
3
X
i=1
z
i
n
i
s. t. jjf
i
 p
i
jj<; for i = 1; . . .;3
(x x
o
)
T
D
 1
(x x
o
)> 1
l
i
<q
i
<u
i
; for i = 1; . . .;m;
wherel
i
andu
i
are the lower and upper limits for each joint,
m is the total number of joints,z
i
is the direction of the force
exerted by the ﬁngertip and f
i
is the position of the i th
ﬁngertip, computed via forward kinematics of the hand. The
cost function represents the fact that the force exerted by the
5370
Fig. 4. The picture illustrates grasp results on some synthetic data taken
from the KITObjectModels WebDatabase [32].
ﬁngertip should be opposite with respect to the normal on the
point. The ﬁrst set of constraints takes care of minimizing the
distance between the ﬁngertip position and the contact point.
The second constraint prevents the hand from colliding with
the object, imposing that the end-effector should lie outside
the object. The last set of constraints controls that the joint
angles do not exceed their physical bounds.
This minimization problem is solved for all the triplets
retrieved by the step described in Sec. III, and8 solutions are
found – 4 for the right hand and 4 for the left hand. Besides
the value of the cost function, which already provides a good
measure of a conﬁguration’s feasibility, we would need to
consider also the whole robot’s arm. Most of the methods
dealing with precision grasp work in simulation, and they do
not account for the robot’s arm, assuming that the hand can
move freely. Differently, we would like to use the proposed
framework on real robots in the future; to this end, we take a
preliminary step in considering the hand as being connected
to the arm, which is bound to the rest of the robot’s body.
A good measure of how a certain conﬁguration is suitable
for a robot’s joints conﬁguration is provided by the standard
manipulability [30]. To compute this quantity, we make use
of the method in [31] to solve the inverse kinematics (IK)
of the arm and the torso. It provides the joint conﬁguration
that satisﬁes the desired position and orientation of the hand
using 10 degrees of freedom (7 for the arm and 3 for the
torso). The solution that minimizes the cost function and
maximizes the manipulability is ﬁnally selected.
V. EXPERIMENTAL RESULTS
We ﬁrst qualitatively show that our method is suitable
for dealing with complete 3D models of the objects. To
this end, we present some results on the KITObjectModels
WebDatabase [32] in Fig. 4, which contains complete 3D
point clouds of several objects of different shapes.
The scope of our paper though, is showing that our
framework is able to handle also incomplete, raw 3D point
clouds. Therefore we assessed our method on the 8 real
objects showed in Fig. 5. The objects have been reconstructed
using the stereo vision of the iCub. As we are not provided
with the model of the objects, we do not know their friction
coefﬁcients; we then employed a friction coefﬁcient of 0:6,
since smaller values (like in [33]) can prevent from ﬁnding
stable triplets. This is due to two factors: ﬁrst, we retrieve
triplets only on the visible part of the object, therefore not all
the possible force-closure triplets are evaluated. Second, the
force-closure property is computed on the basis of the 3D
reconstruction of the object, which usually does not reﬂect
perfectly its surface. If no stable triplets are found, likely the
visible part of the object does not present suitable contact
points. We perform 10 different trials on each object, for
a total of 80 trials. For each run we launched 4 parallel
DPSO routines, resulting in 4 triplets. We used 20 particles
for DPSO, which are initialized randomly. The inverse kine-
matics of the hand was computed for both left and right arms,
obtaining 8 different solutions for each trial. Among these
conﬁgurations, the one presenting the lowest value of the cost
function and the highest manipulability was selected. The
entire pipeline, from the object reconstruction to the retrieval
of the grasp conﬁguration, takes around4 5 seconds in total
with a standard deviation of 1 second.
As grasping lacks of a standardized benchmark, we pro-
ceeded analyzing the resulting conﬁgurations as follows: if
the ﬁngertips are in contact with the object and there is
no interpenetration among the ﬁngers and the object, each
ﬁnger is lying in a feasible position without crossing the
other ﬁngers, and, ﬁnally, the hand is in a suitable position
for the robot, then the grasp is labelled as successful. We
achieved an overall success rate of 85%. A detailed analysis
of such accuracy is illustrated in Fig. 5. It is worth noting
that the lowest accuracy is reported by the monkey, which is
the biggest object we have used. In all the failure cases, the
retrieved triplets covered a too big area for the hand; probably
the DPSO algorithm was not able to ﬁnd triplets covering a
smaller area. The other object that registered a low accuracy
is the watermelon, which is harder to reconstruct because of
its ﬂat faces; indeed, using stereo vision on ﬂat, continuous
surfaces may bring to inaccurate point projections due to the
lack of matches between the left and the right image. Overall,
most of the failure cases are due to the reconstruction of
the object through stereo vision, which restrains DPSO from
ﬁnding good triplets. Notably, thanks to the manipulability
measure included in the second stage of our framework, all
the selected grasps are feasible for the robot’s position and
do not entail singular or unnatural conﬁguration.
To better discuss the reasons underlying the high success
rate recorded in the simulations, we report hereinafter on
further evaluations carried out on the two components of the
proposed pipeline: the DPSO and the IK routines.
5371
Fig. 5. The picture shows the 8 objects used to assess our algorithm. For each object is also depicted its 3D reconstruction, and the ﬁnal hand conﬁguration
computed by our precision grasp pipeline. The ring and the little ﬁngers are not used.
A. DPSO
The ﬁrst stage of our algorithm is extremely accurate in
retrieving only stable contact points. Indeed, on 80 trials
there was only a single case where DPSO did not ﬁnd any
stable triplet. This was due to the reconstruction of the object,
which provided a distorted point cloud. This leads to an
inaccurate computation of the surface normals, and therefore
to a failure in retrieving stable triplets. On the other hand,
we aim at measuring how many triplets retrieved by DPSO
were actually feasible for the robot’s hand. In Table I we
present, for each object, the percentage of feasible triplets
provided by DPSO. In Table I it is also possible to review
the number of times a speciﬁc grasp shape has been chosen.
Notably, shape
3
is not reported in the table because it is
never selected; indeed, as we mentioned, it is not suitable
for the iCub’s hand. Differently,shape
2
andshape
1
are the
most commonly selected, as we expected.
TABLE I
EXPERIMENTAL RESULTS ON DPSO
Object Feasible Triplets shape
0
shape
1
shape
2
Car 0.9 0 5 5
Carrot 0.9 0 1 9
Dog 0.9 1 3 6
Grapefruit 1.0 0 5 5
Monkey 0.7 2 3 4
Octopus 1.0 0 3 7
Tomato 0.9 0 3 7
Watermelon 0.7 1 1 8
In order to demonstrate that DPSO performs effectively in
our context, we compare it to a pure random search approach
(RS), where triplets are chosen randomly and then evaluated.
We perform two different experiments on the octopus. We
ﬁrst carry out an exhaustive search to obtain the triplet
T

that solves the problem (5), being c

the corresponding
minimum cost. We then measure the amount of time DPSO
and RS take to ﬁnd the best solution over 10 trials. RS
takes 4:71s, whereas DPSO only takes 0:65s on average.
Our second experiment consists of setting up a time deadline
for the search, which cannot last more than 1s; when the
deadline is reached we collect the best solution found by
both the methods. Over 10 trials, DPSO always found the
minimum cost solution T

given by the exhaustive search.
RS, instead, was not able to ﬁnd any good triplet in one
case, as 1s was not enough. In the other trials we obtained
solutions that, on average, implied a cost 180% higher than
c

.
B. Inverse Kinematics
Finally, we assess the accuracy of the IK stage. If the re-
construction is actually accurate and the triplets are feasible,
there is the possibility that the inverse kinematics algorithm
does not converge to adequate hand conﬁgurations. In Table
II we provide information in this regard: we compute the
mean distance between the desired contact point locations
and the ﬁngertip positions, and the mean angle between
the normal on the point and the direction of the force
exerted by the ﬁngertip on each object, when the grasp
has been successful. We remind that the angle should be
close to . In the last column we also report how many
times the inverse kinematics algorithm failed for each object,
when feasible triplets were found. Overall, IK shows to be
effective, achieving small reaching errors.
VI. CONCLUSIONS
We presented a complete, novel algorithm for three-ﬁnger
precision grasp. The main contribution is the possibility to
deal with raw incomplete 3D point clouds. Working on in-
complete 3D point clouds instead of requiring complete mod-
5372
TABLE II
EXPERIMENTAL RESULTS ON INVERSE KINEMATICS
Object Norm [mm] Angle [rad] Failures
Car 4.4 2.13 1
Carrot 3.2 2.17 1
Dog 3.1 2.19 0
Grapefruit 3.5 2.13 0
Monkey 3.9 2.23 0
Octopus 3.5 2.36 0
Tomato 3.3 2.25 1
Watermelon 3.3 2.24 0
els is very important as it allows grasping unknown, partially
perceived objects. Furthermore, we avoid the approximation
of the objects to simpler shapes, meaningfully decreasing
the uncertainty about the contact point locations on the
object. We thus explore the incomplete 3D point cloud,
looking for a number of stable triplets through a variant
of the Discrete Particle Swarm Optimization algorithm. The
candidate triplets should also satisfy speciﬁc properties that
are related to the robotic hand that is performing the grasp, as
different robotic hands have different grasping capabilities.
Therefore, a second contribution is the inclusion of the hand
size and shape in the triplet retrieval step. We also have
proposed a new quality measure on the hand shape. We then
employ IPOPT to solve the hand inverse kinematics. Finally,
we account for the manipulability of the arm pose when
selecting the best grasp conﬁguration.
The main future direction is the reﬁnement of our frame-
work in order to be used safely and reliably on real robots.
REFERENCES
[1] J. Napier, “The prehensile movements of the human hand,” The
Journal of bone and joint surgery, pp. 902–913, 1956.
[2] R. Detry, C. Ek, M. Madry, J. Piater, and D. Kragic, “Generalizing
grasps across partly similar objects,” IEEE International Conference
on Robotics and Automation, 2012.
[3] I. Gori, U. Pattacini, V . Tikhanoff, and G. Metta, “Ranking the
good points: A comprehensive method for humanoid robots to
grasp unknown objects,” IEEE International Conference on Advanced
Robotics, 2013.
[4] M. Roa, M. Argus, D. Leidner, C. Borst, and G. Hirzinger, “Power
grasp planning for anthropomorphic robot hands,” IEEE International
Conference on Robotics and Automation, 2012.
[5] J. K. Salisbury and B. Roth, “Kinematic and force analysis of
articulated mechanical hands,” Journal of Mechanisms, Transmissions
and Automation in Design, 1983.
[6] V .-D. Nguyen, “Constructing force-closure grasps in 3D,” IEEE Inter-
national Conference on Robotics and Automation, 1987.
[7] J. Li, H. Liu, and H. Cai, “On computing three-ﬁnger force-closure
grasps of 2-D and 3-D objects,” IEEE Transactions on Robotics and
Automation, 2003.
[8] A. Erkan, O. Kroemer, R. Detry, Y . Altun, J. Piater, and J. Peters,
“Learning probabilistic discriminative models of grasp affordances un-
der limited supervision,” IEEE International Conference on Intelligent
Robots and Systems, 2010.
[9] D. Rao, Q. V . Le, T. Phoka, M. Quigley, A. Sudsang, and A. Y .
Ng, “Grasping novel objects with depth segmentation,” IEEE/RSJ
International Conference on Intelligent Robots and Systems, 2010.
[10] C. Borst, M. Fischer, and G. Hirzinger, “Calculating hand conﬁg-
urations for precision and pinch grasps,” IEEE/RSJ International
Conference on Intelligent Robots and Systems, 2002.
[11] C. Rosales, R. Su´ arez, M. Gabiccini, and A. Bicchi, “On the syn-
thesis of feasible and prehensile robotic grasps,” IEEE International
Conference on Robotics and Automation, 2012.
[12] A. Sahbani and S. El-Khouri, “An overview of 3D object grasp
synthesis algorithms,” Robotics and Autonomous Systems, 2011.
[13] S. El-Khoury and A. Sahbani, “A new strategy combining empirical
and analytical approaches for grasping unknown 3D objects,” Robotics
and Autonomous Systems, 2010.
[14] M. A. Roa, K. Hertkorn, C. Borst, and G. Hirzinger, “Reachable
independent contact regions for precision grasps,” IEEE International
Conference on Robotics and Automation, 2011.
[15] M. A. Roa and R. Su´ arez, “Independent contact regions for frictional
grasps on 3d objects,” IEEE International Conference on Robotics and
Automation, 2008.
[16] S. Geidenstam, K. Huebner, D. Banksell, and D. Kragic, “Learning
of 2D grasping strategies from box-based 3D object approximations,”
Robotics: Science and Systems Conference, 2009.
[17] A. T. Miller, S. Knoop, H. I. Christensen, and P. K. Allen, “Automatic
grasp planning using shape primitives,”IEEEInternationalConference
on Robotics and Automation, 2003.
[18] S. El Khoury, M. Li, and A. Billarde, “Bridging the gap: One shot
grasp synthesis approach,” International Conference on Intelligent
Robots and Systems, pp. 2027–2034, 2012.
[19] S. El-Khoury and A. Sahbani, “On computing robust n-ﬁnger force-
closure grasps of 3d objects,” IEEE International Conference on
Robotics and Automation, 2009.
[20] G. Metta, G. Sandini, D. Vernon, L. Natale, and F. Nori, “The icub
humanoid robot: an open platform for research in embodied cognition,”
in8thWorkshoponPerformanceMetricsforIntelligentSystems, 2008.
[21] H. Nahvi and I. Mohagheghian, “A particle swarm optimization algo-
rithm for mixed variable nonlinear problems,” International Journal
of Engineering, pp. 65–78, 2011.
[22] H. Hirschmuller, “Stereo processing by semiglobal matching and
mutual information,” TPAMI, 2008.
[23] B. R. Radu, “Semantic 3d object maps for everyday manipulation
in human living environments,” Ph.D. dissertation, Computer Science
department, Technische Universit¨ at M¨ unchen, Germany, October 2009.
[24] V .-D. Nguyen, “Constructing force-closure grasps,”InternationalJour-
nal of Robotics Research, 1988.
[25] A. T. Miller and P. K. Allen, “Examples of 3d grasp quality compu-
tations,” IEEE International Conference on Robotics and Automation,
1999.
[26] R. Su´ arez, M. Roa, and J. Cornella, “Grasp quality measures,” Tech-
nical report, 2006.
[27] C. Borst, M. Fischer, and G. Hirzinger, “Grasping the dice by dicing
the grasp,” IEEE International Conference on Intelligent Robots and
Systems, 2003.
[28] J. Kennedy and R. C. Eberhart, “Particle swarm optimization,” IEEE
international conference on neural networks, 1995.
[29] A. W¨ atcher and L. Bielger, “On the implementation of a primaldual
interior point ﬁlter line search algorithm for large-scale nonlinear
programming,” in Mathematical Programming, 2006, pp. 25–57.
[30] M.-J. Tsai, “Workspace geometric characterization and manipulability
of industrial robots,” Ph.D. dissertation, Ohio State University, 1986.
[31] U. Pattacini, F. Nori, L. Natale, G. Metta, and S. G., “An experimental
evaluation of a novel minimum-jerk cartesian controller for humanoid
robots,” IEEE/RSJ International Conference on Intelligent Robots and
Systems, pp. 1668–1674, 2010.
[32] A. Kasper, Z. Xue, and R. Dillmann, “The kit object models web
database: An object model database for object recognition, localizatino
and manipulation in service robotics,” The International Journal of
Robotics Research, 2012.
[33] K. Matheus and A. M. Dollar, “Benchmarking grasping and manipula-
tion: Properties of the objects of daily living,” IEEE/RSJ International
Conference on Intelligent Robots and Systems, 2010.
5373
