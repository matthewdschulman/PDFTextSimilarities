Online approach for altering robot behaviors based on human in the
loop coaching gestures
Tadej Petriˇ c
1,2
, Andrej Gams
1,3
, Leon
ˇ
Zlajpah
1
, Aleˇ s Ude
1,2
, and Jun Morimoto
2
Abstract—The creation and adaptation of motor behaviors
is an important capability for autonomous robots. In this
paper we propose an approach for altering existing robot
behaviors online, where a human coach interactively changes
the robot motion to achieve the desired outcome. Using hand
gestures, the human coach can specify the desired modiﬁcations
to the previously acquired behavior. To preserve a natural
posture while performing the task, the movement is encoded
in the robot’s joint space using periodic dynamic movement
primitives. The coaching gestures are mapped to the robot
joint space via robot Jacobian and used to create a virtual
force ﬁeld affecting the movement. A recursive least squares
technique is used to modify the existing movement with respect
to the virtual force ﬁeld. The proposed approach was evaluated
on a simulated three degrees of freedom planar robot and on
a real humanoid robot, where human coaching gestures were
captured by an RGB-D sensor. Although our focus was on
rhythmic movements, the developed approach is also applicable
to discrete (point-to-point) movements.
I. INTRODUCTION
The interaction between a pupil and a teacher when
learning or improving existing skills usually involves natural
communication such as speech or gestures. Based on the
instructionsofacoach,humanscanquicklylearnandmodify
their motion patterns to achieve the desired behavior. The
development of an effecting coaching system for humanoid
robots is, however, a difﬁcult task. In practice, modifying
robot behaviors remains the task of experts in robotics.
Robotics researchers developed various robot coaching
methods in the past decade. For example, Nakatani et al.
[1] used the coach’s qualitative evaluations of the robot
performance to improve balancing and walking. In [2],
supervised learning was combined with voice commands of
a human coach, where the voice commands were used as a
reward function in the learning algorithm. In [3], coaching
was used on a mobile platform with the emphasis on learning
high level task representations rather than motor skills. An
approach that uses qualitative, verbal instructions to modify
movements obtained by human demonstration was proposed
in[4].Thedevelopedsystemwassuitablealsofornon-expert
users. Kinesthetic teaching with iterative updates to modify
a humanoid behavior was proposed in [5]. An area closely
relatedtorobotcoachingislearningbydemonstration,where
avarietyofdifferentmethodswereproposed[6],[7],[8],[9],
1
Humanoid and Cognitive Robotics Lab & Dept. of Automatics, Bio-
cybernetics, and Robotics, Joˇ zef Stefan Institute (JSI), Ljubljana, Slovenia.
tadej.petric@ijs.si
2
Dept. of Brain Robot Interface (BRI), ATR Computational Neuroscience
Laboratories, Kyoto, Japan
3
BioroboticsLaboratory,InstituteofBioengineering,EcolePolytechnique
Federale de Lausanne (EPFL), Lausanne, Switzerland
[10], [11]. However, most of the learning by demonstration
methods do not address the problem of easily modifying an
existing behavior to acquire a new desired outcome.
We were inspired by the efﬁciency of human-to-human
skill transfer when developing a more effective approach to
modify the existing robot behaviors. Rather than learning
how to program robots, people can bring their own knowl-
edge from interacting with each other directly into the robot
domain[4].Ideally,thehuman-robotinteractionshouldfocus
on approaches that are intuitive for a human coach. In this
paper we propose an approach for modifying existing robot
behaviors based on online guidance provided by the human
coach. The guidance is provided in the form of pointing
gestures, i.e. the coach indicates to the robot where and how
it should modify its motion. Such an interface is intuitive for
humans as movement shaping through physical guidance and
other means of communication is common in human motor
learning [12].It allows also non-experts to teach and alter the
existing robot skills in order to obtain new desired outcomes.
Amotorrepresentationusedtoencoderobotmovementsin
an online coaching system must have the ability to generate
smooth movements even when its parameters change online.
This is important to supply an immediate feedback to the
coach. Such a capability is provided by dynamic movement
primitives (DMPs) [13], [14], which are deﬁned by a set of
critically damped second order linear differential equations,
supplemented with a nonlinear forcing term. In this paper we
focus on periodic movements [15], but the approach is fully
applicable to discrete (point-to-point) movements as well.
Periodic DMPs are often combined with adaptive oscillators
[16]. Adaptive oscillators generate a stable limit cycle and
provide the phase signal to the DMP. We assume that the
initial motion pattern has been deﬁned somehow, e.g. by
kinesthetic guiding. To avoid losing postural information
when using redundant robots like humanoids, the demon-
strated motion pattern is encoded in the joint-space.
We developed a new DMP adaptation algorithm that can
be used to modify existing motor behaviors encoded by
DMPs based on human coaching gestures. The coaching
gestures are speciﬁed by pointing towards the part of the
movement that needs to be changed. The pointing gesture
deﬁnes the direction and magnitude of change. To demon-
strate the applicability of the proposed coaching approach,
weimplementeditbothinsimulationandonarealhumanoid
robot, where coaching gestures were obtained by Microsoft
Kinect RBG-D sensor and a body tracker. The paper is
organized as follows. In Section II we provide a short review
of periodic DMPs. We then describe the newly developed
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 4770
coaching algorithm. In Section III we analyze the properties
oftheproposed algorithm insimulationand inSection IVwe
evaluate it on a real humanoid robot. Conclusions, summary
and prospective future work are explained in Section V.
II. COACHING SYSTEM
The basic framework of our coaching system consists of
periodic Dynamic Movement Primitives (DMPs) combined
with an adaptive frequency oscillator [16], which can extract
thephaseandthefrequencyfromanarbitraryperiodicsignal.
This framework is also called a two-layered system for
movementimitation[15].Inourpreviouswork[15],[16],we
proposed a learning algorithm that can be used to extract the
basic frequency from the demonstrated periodic movement,
learnthewaveform ofoneperiod, and reconstructthedesired
waveform at an arbitrary frequency. To learn a new control
policy based on the human coaching gestures, this two-
layered imitation system is embedded into the proposed
control framework for coaching.
A. Dynamic movement primitives combined with adaptive
frequency oscillators
The ﬁrst layer of the imitation system is based on adaptive
frequency oscillators combined with the adaptive Fourier
series.Thedetailsandthepropertiesofthelearningapproach
are given in [16]. In summary, an adaptive frequency oscilla-
tor is deﬁned by a set of second order differential equations
˙
? =Ω?K·e·sin(?), (1)
˙
Ω= ?K·e·sin(?), (2)
where Ω is the extracted frequency, ? is the phase, K is the
coupling constant and e is the difference between the actual
and the estimated input signal. Here we denote the input
signal by v and the estimated signal by ˆ v. The input signal
v is the signal on which the motion pattern is synchronized.
Note that once the error signal e becomes zero we obtain
˙
Ω=0 and
˙
? =Ω. The estimated input signal ˆ v is represented
as
ˆ v=
m
∑
c=0
(?
c
cos(c?)+?
c
sin(c?)). (3)
Here m is the size of the Fourier series. Our learning
algorithm simultaneously estimates the frequency Ω and the
input signal ˆ v, ie. the weights?
c
and?
c
. See [16] for details.
We augment this ﬁrst layer by anchoring the dynamic
movement primitives to the phase signal ? of the adap-
tive oscillator as in [15], [16]. This makes it possible to
synchronize an arbitrary trajectory to an arbitrary periodic
signal congruent with the desired behavior. The basic equa-
tions of dynamic movement primitives are summarized from
[14], [13], [15]. For a single degree of freedom denoted
by y, which can either be one of the internal joint-space
coordinates or one of the external task-space coordinates,
the following system of linear differential equations with
constantcoefﬁcients,augmentedbyanonlinearforceingterm
f, has been applied to derive DMPs
˙ z=Ω(?
z
(?
z
(g?y)?z)+ f), (4)
˙ y=Ωz, (5)
where ?
z
and ?
z
are the positive constants, which guarantee
that the system monotonically converges to the desired
trajectory, g is the center of oscillation, and f is the nonlinear
part that determines the shape of the trajectory. It is given
by
f(?)=
N
∑
i=1
w
i
?
i
(?)
N
∑
i=1
?
i
(?)
r, (6)
where r is the parameter that can be used to modulate the
amplitude of the movement and ? are the Gaussian like
kernel functions given by
?
i
(?)=exp(h(cos(? ?c
i
)?1)). (7)
Here, h is the width and c
i
is the distribution on one period.
If not stated otherwise, in the following we used c
i
, i =
1,...,25, and they were equally spread between 0 and 2π.
By applying the locally weighted regression the system
can learn the shape of the trajectory on-line. The equations
for incremental learning are summarized from [15], where
the equations (4) and (5) were rewritten as one second order
differential equation
f
d
=
¨ y
d
Ω
2
??
z

?
z
(g?y
d
)?
˙ y
d
Ω

. (8)
Here the triplet of y
d
, ˙ y
d
and ¨ y
d
denotes the desired position,
the velocity and the acceleration. To update the weights w
i
of the kernel function ?
i
, we use the recursive least-squares
method with the forgetting factor ?. In our experiments, the
forgetting factor was set to? =0.9995. With the given target
(8), the recursive algorithm updates the weights w
i
using the
following rule
P
i
(t+1) =
1
?
 
P
i
(t)?
P
i
(t)
2
r
2
?
?
i
(?(t))
+P
i
(t)r
2
!
, (9)
w
i
(t+1) = w
i
(t)+?
i
(?(t))P
i
(t+1)re
r
(t), (10)
e
r
(t) = f
d
(t)?w
i
(t)r. (11)
If not stated otherwise, we use w
i
(0) = 0 and P
i
(0) = 1,
where i=1,...,25.
In general DMPs provide a comprehensive framework
for generating smooth kinematic control policies. Other
important properties are: time invariance, online modulations
including using a repulsive force to inﬂuence the course
of the trajectory, framework for the trajectory learning, and
smooth behavior in case of sudden change in the trajectory.
Even though the DMP framework already posseses meth-
ods for amplitude, phase and frequency modulation, these
modulations are insufﬁcient to modify the behavior within a
general coaching system. To modify the behavior online with
ahumanintheloop,weproposeanalgorithmthatcanupdate
4771
the weights of the DMP based on the coaching gestures. The
goal is to provide means to generate arbitrary modiﬁcations
to the available movement patterns and successfully perform
the desired task. The coaching system can also be used for
building a library of motion patterns, which can later be used
by movement generalization methods [17].
B. Coaching with Potential Fields
The primary goal of movement modeling with dynamical
systems is to exploit the coupling phenomena to generate
more complex behaviors [14]. We showed in the previous
section how two dynamical systems can be connected to-
gether for imitation learning of periodic movements. In this
section we discuss how to modify a robot trajectory online
based on the input of a human coach. An ability to modulate
movement trajectories online based on the human input is a
veryimportantcapabilityforrobotsthatinteractwithhumans
in natural environments. The proposed algorithm can modify
the robot’s motion online based on the human in the loop
coaching gestures and is therefore an important step towards
providing such a capability.
There are different ways for adding a coupling term to
modify motion patterns. For example, it can be added to the
transformation system or to the canonical system, or even to
both [14]. For 3-D Cartesian space movements, Hoffmann et
al. [18] showed that obstacle avoidance can be achieved by
adding a coupling term C C C
y
to Eq. (4)
˙ z=Ω(?
z
(?
z
(g g g?y)?z)+C C C
y
+ f f f), (12)
where y y y, z z z, g g g, C C C
y
, and f f f are in this case three dimensional
values. In [18] this equation was used to drive the robot’s
behavior and ensure obstacle avoidance. In our case we
intend to modify the behavior permanently, therefore we use
this term as input to the recursive least-squares method for
updating the weights of the canonical system. Since in this
case the reference trajectory is simply the output of the DMP
(there is no training signal y
d
, ˙ y
d
and ¨ y
d
), e
r
(t) as deﬁned
in Eq. (11) would be equal to zero if the DMP equations
had not changed. However, since the differential equation (4)
was changed to (12), there is an additional coupling termC C C
y
,
which was not accounted for during training. Thus Eq. (11)
transforms into
e
r
(t)=C
y,j
(t), (13)
where C
y,j
(t) is the coupling term for the degree of freedom
denoted by j.
A proper deﬁnition of the coupling term C C C
y
is crucial
and of course task dependent. To enable coaching by human
gestures, we modiﬁed the obstacle avoidance coupling term
C C C
y
from [18] as follows
C C C
y
=? s(||o o o?x x x||) exp(???) d d d, (14)
Here x x x is the Cartesian position of the end-effector, o o o is the
center position of the perturbation potential ﬁeld (deﬁned by
hand position), d d d is the perturbation direction (deﬁned by
the pointing gesture), ? and ? are the scaling factors, ? is
given by
? =arccos

(o o o?x x x)
T
˙ x x x
||(o o o?x x x)|| ||˙ x x x||

. (15)
s(r) is deﬁned as
s(r)=
1
1+e
?(r?r
m
)
, (16)
where? is the scaling factor and r
m
the distance at which the
perturbation ﬁeld should start affecting the robot’s motion.
A one degree of freedom example for the coupling term is
shown in Fig. 1.
0
0.1
0.2
0.3
0.4
0.5
0
0.5
1
1.5
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
||(o? x)||
?
C t
Fig. 1. One degree of freedom example coupling term C
y
with parameters
? =30, r
m
=0.2, ? =1, and ? = ?20/π.
To update the trajectories in joint-space while they are
perturbed in task space, where the coupling term is denoted
by C C C
y
, a pseudo inverse of the task Jacobian is used. This
essentially maps the task space velocities into the joint space
velocities with ˙ q q q=J˙ x x x. By applying a similar transformation
to C C C
y
we obtain
C C C
q
=J
†
C C C
y
. (17)
where C C C
q
= [C
q,1
C
q,2
... C
q,k
]
T
and k is the number of
the robot’s degrees of freedom. The components of (17) are
now inserted into (13), which is used for updating the DMP
weights w
i
using (9) and (10). In this way we ensure that the
joint space trajectories encoded by the DMPs are properly
modiﬁed according to the coach’s instructions.
Keeping the movement representation in the joint space is
beneﬁcial because our initial movement trajectories, which
are encoded by DMPs, are usually acquired by kinesthetic
guiding. By using joint space trajectories we avoid losing
information about the selected robot conﬁguration during
human guiding on a redundant robot. Hence the DMP repre-
sentation should remain in the joint space and the behavior
should be modiﬁed there.
4772
III. SIMULATION RESULTS
To show the properties of the proposed approach, we ﬁrst
applied it to a simulated 3 degrees of freedom planar robot.
The robot was simulated using Planar Manipulator Toolbox
[19].Theinitialjointspacetrajectorywasdeﬁnedsuchthatit
produced a circular motion in the task space. The frequency
of motion was constant and it was set to 0.5 Hz. If not stated
otherwise, the coaching parameters were ? = 100, ? = 20,
r
m
=0.35, and ? = ?8/π.
Fig. 2 shows simulation results where the coaching point
was deﬁned with the parameters o o o=[1.8,?0.6] d d d =[0,1]
T
.
The coaching command was inserted at the selected position
after 5 seconds. On the right plot we can see the evolution
of the task space trajectory. Here the red line shows the
initial task space motion and the green line the task space
motion after coaching. The grey lines show the evolution
of DMP modiﬁcation in time. It can be seen that the
coaching command was only acting at the desired location
and therefore it did not affect the rest of the initial trajectory.
This can also be seen in the bottom plot left where the scale
of the coupling term used in recursive least squares is shown.
Here we can see that the coupling term only acts when the
end-effector is close to the perturbation point. In addition,
we can see that the coupling term is iteratively converging
towards zero. The ﬁrst three plots on the left show the joint
trajectories in time. We can see that they are modiﬁed only
when the end-effector is near to the perturbation point and
that they remain smooth.
?2.5
?0.5
?0.2
1
0.2
1.2
0 20 40 60
0
5
10
1 1.5 2 2.5
?1
1.5
q
1
q
2
q
3
C
x
, C
y
x [m]
y [m]
t [s]
Fig. 2. Simulation results where the circular motion in task space was
pushed in. Coaching command parameters were o o o = [1.8,?0.6] and d d d =
[0,1]
T
. The coaching point was activated after 5 seconds.
Similar results can also be observed in Fig. 3, where the
initial task space trajectory was pushed out. In this case the
coaching point parameters were o o o = [1.8,0.8] d d d = [0,1]
T
.
Again the coaching point was inserted after 5 seconds. We
can see the same basic performance as in the case of Fig. 2.
This two study cases clearly show that we can easily modify
the task space behavior at the desired point to achieve the
desired course of movement, even though the trajectories are
encoded in the joint space. These two case studies show
that we can smoothly and iteratively modify the task space
behavior in an arbitrary direction.
?2.5
?0.5
?0.2
1
0.2
1.2
0 20 40 60
0
5
1 1.5 2 2.5
?1
1.5
q
1
q
2
q
3
C
x
, C
y
x [m]
y [m]
t [s]
Fig. 3. Simulation results where the circular motion in task space was
pushed out. Coaching command parameters were o o o = [1.8,0.8] and d d d =
[0,1]
T
. The coaching command was activated after 5 seconds.
To further support the last statement we show in Fig. 4
an experiment where the coaching command is kept at
the constant distance to the end-effector. In other word,
the perturbation point moves along the trajectory and the
perturbation direction d d d is in this case focused towards the
centre of the circle. The coaching begins after 5 seconds.
Herewe cansee intherightplotthatthemotion isconstantly
modiﬁed and directed towards the center of the circle. The
ﬁnal task space trajectory is indicated with the green line
and the initial trajectory with the red line. In the ﬁrst three
plots left we can also see that as expected, the amplitude of
motion is decreasing for all three joints.
?2.5
?0.5
?0.2
1
0.2
1.2
0 20 40 60
?0.5
0
0.5
1 1.5 2 2.5
?1
1.5
q
1
q
2
q
3
C
x
, C
y
x [m]
y [m]
t [s]
Fig. 4. Simulation results where the circular motion in task space was
pushed in all the time, i.e. the direction of coaching command was towards
the center of the circle all the time. The coaching began after 5 seconds.
IV. ROBOT EXPERIMENTS
To show the applicability of the proposed approach in
real world, we implemented it on the JST-ICORP/SARCOS
humanoid robot CBi [20]. We used the Microsoft Kinect
sensor and the associated body tracker to capture human
coaching gestures [21]. Fig. 5 shows the experimental setup,
where the body tracking results can be seen on the display
in the background.
4773
To acquire the human coaching gestures in the coordinate
system of the robot, we calibrated the Microsoft Kinect
sensor to the robot base coordinate system. To obtain the
appropriate transformation matrix, we recorded at least four
pairs of points in both coordinate systems. For this purpose
the human coach placed his hand at the same location as the
robot’s end-effector and the position of the human hand and
the robot’s end-effector were measured in the Kinect’s and
robot base coordinate system, respectively. The transforma-
tion matrix was calculated using least-squares ﬁtting of two
points set as described in [22].
Fig. 5. Experimental setup, where a human coach is modifying the robot’s
motion. The human coaching gesture is captured using Microsoft Kinect
sensor.
Tomakecoachingasintuitiveaspossible,wedevelopedan
interface where the human coach can modify the trajectory
by either pushing it away from him using his right hand or
attracting it towards him with his left hand. The coaching
direction was calculated using the wrist and the elbow
location.Fortherighthand,whichpushesthetrajectoryaway
form the coach, the direction is given by
d d d
R
=
x x x
w,R
?x x x
e,R
||x x x
w,R
?x x x
e,R
||
, (18)
where the x x x
w,R
and the x x x
e,R
are the Cartesian positions of the
right hand wrist and the right hand elbow in the robot’s base
coordinate system. For attracting the trajectory towards the
coach, the direction is given by
d d d
L
=
x x x
e,L
?x x x
w,L
||x x x
e,L
?x x x
w,L
||
. (19)
Here x x x
w,L
and the x x x
e,L
arerespectively theCartesianpositions
of the left hand wrist and the left hand elbow in the robot’s
base coordinate system.
Since Microsoft Kinect sensor relies on depth information
and our humanoid robot has similar body proportions as a
human, the body tracker sometimes becomes confused if the
human approaches the robot very closely. For this reason
the human coach did not approach the robot too closely in
our experiments. Instead, the center of the potential ﬁeld
generated by each hand was moved slightly away from the
respective hand. Fortherighthand, theoriginofthepotential
ﬁeld deﬁned by the coaching gesture was moved in the
direction of the coaching gesture
o o o
R
=x x x
R
+?
R
d d d
R
, (20)
where ?
R
is the scalar that deﬁnes the distance between the
hand and the center of the coaching point in the direction
of d d d
R
. Similar equation is used also for the left hand which
attracts the trajectory towards the hand.
o o o
L
=x x x
L
??
L
d d d
L
. (21)
Here, the effective coaching point is moved in the opposite
direction of perturbation d d d
L
. With such modiﬁcations the
effective origins of potential ﬁelds are always in front of
the human hands in the direction of pointing at the distance
deﬁned by ?
R
and ?
L
.
To determine which hand is active, we use the distance
between both wrist positions x x x
w,L
, x x x
w,R
and the robot’s end-
effector position x x x. The active hand is the one which is closer
to the robot’s hand position.
To show the applicability of the interface for online
modiﬁcation of the initial rhythmic movement using human
in the loop coaching gestures, we ﬁrst provide an example of
pulling-in the task space trajectory. The parameters were set
to ? =10, ? =10, r
m
=0.15 and ? =?10/π. Fig. 6 shows
the task space motion of the robot’s end-effector in the x?y
plane. We can see a successful modiﬁcation of the motion
based on the human coaching gestures. In Fig. 7 we show
the corresponding joint space trajectories as a function of
time. The teaching of the new motion pattern begins after 5
seconds,whichisindicatedwiththeﬁrstverticalline.Wecan
see that the joint space trajectory was modiﬁed successfully
toachieve thedesiredtaskspacemotion.InFig.7wecansee
that at approximately 50 seconds the human coach stopped
?0.55 ?0.5 ?0.45 ?0.4 ?0.35 ?0.3
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
x [m]
y [m]
Fig. 6. Task space motion of the robot’s end-effector, where human coach
was modifying the motion pattern. The initial trajectory is in red and the
ﬁnal trajectory is in green. The time evolution of the trajectory modiﬁcation
is indicated with grey line.
4774
?0.2
0
0.2
0.4
?0.4
?0.2
0
?1
0
1
0 10 20 30 40 50 60 70
1
1.5
2
t [s]
q
SFE
[rad] q
SAA
[rad]
q
HR
[rad]
q
EB
[rad]
Fig. 7. Joint space motion in time of the robot’s right hand, while coaching.
Vertical lines indicate the important events described in text.
modifying the behavior and at approximately 55 seconds the
new motion pattern was switched back to the original motion
pattern. At this point the difference between original motion
trajectory and the modiﬁed motion trajectory is even more
evident. The snapshots showing the original and the modiﬁed
trajectory of the humanoid arm movement are shown in
Fig. 8. This experiment is also shown in the supplementary
video.
Fig. 9 shows four different modiﬁcations of the original
motion. In the top row we can see the horizontal pushing and
pulling of the motion in the x-y plane and in the bottom row
the vertical pushing and pulling in y-z plane. As we can see,
the human coach was successful at modifying the movement
of the robot in the desired direction using either the pushing
or pulling technique, i.e. using either the right or the left
hand to deﬁne the coaching gesture.
V. CONCLUSION AND FUTURE WORK
In this paper we developed a new coaching methodol-
ogy that makes use of coaching gestures to modify an
existing movement encoded by a periodic DMP. The DMP
modiﬁcation method is based on a recursive least-squares
technique for updating the weights of periodic DMPs. With
the developed system a human teacher can iteratively modify
the previously acquired trajectories. It operates online and
can therefore provide an immediate feedback to the coach.
We presented simulation case studies where we successfully
modiﬁed thejointspacetrajectoriestoobtain thenew desired
task space motions. The same method was also applied to
the JST-ICORP/SARCOS humanoid robot CBi, where the
human coach modiﬁed the humanoid robot’s behavior to
obtain the desired outcome. The proposed approach can
easily be extended to discrete DMPs.
0 0.05 0.1 0.15 0.2
?0.65
?0.6
?0.55
?0.5
?0.45
?0.4
?0.35
0.1 0.15 0.2 0.25 0.3
?0.65
?0.6
?0.55
?0.5
?0.45
?0.4
?0.35
0 0.1 0.2 0.3 0.4
0.05
0.1
0.15
0.2
0.25
0 0.1 0.2 0.3 0.4
0.1
0.15
0.2
0.25
0.3
0.35
x [m]
y [m] y [m]
y [m] y [m]
z [m]
Fig. 9. Four different modiﬁcations of the original motion, which are also
shown in the supplemental video. The top left graph corresponds to example
1, the top right graph to example 2, the bottom left graph to example 4 and
the bottom right graph to example 5 in the supplemental video.
The main limitation of the coaching interface was the
inability of the body tracker to distinguish between the robot
and the human arm when a human teacher was close to
the robot. Although the use of Microsoft Kinect sensor is
beneﬁcial because it can be used without much preparations,
i.e. no markers or other special equipment is necessary,
we believe that marker-based systems with more accurate
tracking would provide a better and more accurate interface
to modify the humanoid robot’s movements. With a more
reliable tracking of human coaching gestures, we could
achieve similar results on the real robot as showed in Fig. 4,
which is based on simulated data. The implementation and
evaluation of the proposed algorithm with a more accurate
bodytrackingsystemisanimportantgoalofourfuturework.
On the other hand, it is important that the human interface
stays as intuitive as possible.
ACKNOWLEDGMENT
The research leading to these results has received funding
from the European Community’s Seventh Framework Pro-
gramme FP7/2007-2013 (Speciﬁc Programme Cooperation,
Theme 3, Information and Communication Technologies)
under grant agreements no. 270273, Xperience and no.
600716, CoDyCo. It was also supported by MEXT KAK-
ENHI Grant Number 23120004; by JSPS and SRA: Japan-
Slovenia research Cooperative Program; by MIC-SCOPE; by
JST-SICP; by SRPBS, MEXT; by contract with the Ministry
of Internal Affairs and Communications entitled ’Novel and
innovative R&D making use of brain structures’.
REFERENCES
[1] M. Nakatani, K. Suzuki, and S. Hashimoto, “Subjective-evaluation
oriented teaching scheme for a biped humanoid robot,” in IEEE-
4775
Fig. 8. A sequence of still photos showing the original motion in the top row and the ﬁnal modiﬁed motion in the bottom row. The photos frame rate is
0.4 per second.
RAS International Conference on Humanoid Robots (Humanoids),
Karlsuhe, Germany, 2003.
[2] A. Gruebler, V. Berenz, and K. Suzuki, “Coaching robot behavior us-
ing continuous physiological affective feedback,” in 2011 11th IEEE-
RAS International Conference on Humanoid Robots (Humanoids),
Bled, Slovenia, 2011, pp. 466–471.
[3] M. N. Nicolescu and M. J. Mataric, “Natural methods for robot
task learning: Instructive demonstrations, generalization and practice,”
in Proceedings of the second international joint conference on Au-
tonomous agents and multiagent systems, 2003, pp. 241–248.
[4] M. Riley, A. Ude, C. Atkeson, and G. Cheng, “Coaching: An approach
to efﬁciently and intuitively create humanoid robot behaviors,” in
2006 6th IEEE-RAS International Conference on Humanoid Robots
(Humanoids), Genoa, Italy, 2006, pp. 567–574.
[5] D. Lee and C. Ott, “Incremental kinesthetic teaching of motion
primitives using the motion reﬁnement tube,” Autonomous Robots,
vol. 31, no. 2-3, pp. 115–131, 2011.
[6] S.Schaal,“Isimitation learningtheroutetohumanoidrobots?” Trends
in Cognitive Sciences, vol. 3, no. 6, pp. 233–242, 1999.
[7] A. Billard and K. Dautenhahn, “Experiments in learning by imitation
– grounding and use of communication in robotic agents,” Adaptive
Behavior, vol. 7, no. 3-4, pp. 415–438, 1999.
[8] A. Ude, C. G. Atkeson, and M. Riley, “Programming full-body move-
ments for humanoid robots by observation,” Robotics and Autonomous
Systems, vol. 47, no. 2-3, pp. 93–108, 2004.
[9] T. Asfour, P. Azad, F. Gyarfas, and R. Dillmann, “Imitation learning
of dual-arm manipulation tasks in humanoid robots,” International
Journal of Humanoid Robotics, vol. 5, no. 02, pp. 183–202, 2008.
[10] A. Billard, S. Calinon, R. Dillmann, and S. Schaal, “Robot pro-
gramming by demonstration,” in Springer Handbook of Robotics,
B. Siciliano and O. Khatib, Eds. Berlin, Heidelberg: Springer Verlag,
2008.
[11] S. Calinon, F. D’halluin, E. L. Sauser, D. G. Caldwell, and A. G.
Billard, “Learning and reproduction of gestures by imitation,” IEEE
Robotics & Automation Magazine, vol. 17, no. 2, pp. 44–54, 2010.
[12] R. Schmidt and T. Lee, Motor Control and Learning: A Behavioral
Emphasis. Champaign, IL: Human Kinetics Publishers Ltd., 2011.
[13] S. Schaal, P. Mohajerian, and A. Ijspeert, “Dynamics systems vs.
optimal control – a unifying view,” Progress in Brain Research, vol.
165, pp. 425–445, 2007.
[14] A. J. Ijspeert, J. Nakanishi, H. Hoffmann, P. Pastor, and S. Schaal,
“Dynamical movement primitives: learning attractor models for motor
behaviors,” Neural Computation, vol. 25, no. 2, pp. 328–373, 2013.
[15] A. Gams, A. J. Ijspeert, S. Schaal, and J. Lenarˇ ciˇ c, “On-line learning
and modulation of periodic movements with nonlinear dynamical
systems,” Autonomous robots, vol. 27, no. 1, pp. 3–23, 2009.
[16] T. Petriˇ c, A. Gams, A. J. Ijspeert, and L.
ˇ
Zlajpah, “On-line frequency
adaptation and movement imitation for rhythmic robotic tasks,” The
International Journal of Robotics Research, vol. 30, no. 14, pp. 1775–
1788, 2011.
[17] A. Ude, A. Gams, T. Asfour, and J. Morimoto, “Task-speciﬁc general-
ization of discrete and periodic dynamic movement primitives,” IEEE
Transactions on Robotics, vol. 26, no. 5, pp. 800–815, 2010.
[18] H. Hoffmann, P. Pastor, D.-H. Park, and S. Schaal, “Biologically-
inspired dynamical systems for movement generation: automatic real-
time goal adaptation and obstacle avoidance,” in IEEE International
Conference on Robotics and Automation (ICRA), Kobe, Japan, 2009,
pp. 2587–2592.
[19] L.
ˇ
Zlajpah, “Simulation in robotics,” Mathematics and Computers in
Simulation, vol. 79, no. 4, pp. 879–897, 2008.
[20] G. Cheng, S.-H. Hyon, J. Morimoto, A. Ude, J. G. Hale, G. Colvin,
W. Scroggin, and S. C. Jacobsen, “CB: A humanoid research platform
for exploring neuroscience,” Advanced Robotics, vol. 21, no. 10, pp.
1097–1114, 2007.
[21] Z. Zhang, “Microsoft Kinect sensor and its effect,” IEEE MultiMedia,
vol. 19, no. 2, pp. 4–10, 2012.
[22] K. S. Arun, T. S. Huang, and S. D. Blostein, “Least-squares ﬁtting
of two 3-D point sets,” IEEE Transactions on Pattern Analysis and
Machine Intelligence, vol. 9, no. 5, pp. 698–700, 1987.
4776
