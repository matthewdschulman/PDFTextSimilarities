Human Body Trajectory Generation Using Point Cloud Data for
Robotics Massage Applications
Ren C. Luo, Sheng Y . Chen, Keng. C. Yeh
Abstract— Intelligent robot for improving the quality of
human life is desirable. To let robot perform the intelligent
functions of massage which can serve for humans, adaptive
massage trajectory generator is needed to suit for different
body shape with different people.
Base on the state of the art human pose recognition tech-
niques, we develop a methodology to build the relationship
between camera and human body and generate the speciﬁed
massage trajectories. Assume we can detect human pose and
label each part of human body, we use the RANSAC algorithm
to estimate the frontal and sagittal planes and reﬁne it by
calculating the minimum moment of inertia of point cloud.
The experimental results demonstrate our work which provide a
useful method for massage trajectory generation. As an example
of service robot application, this method is useful for executing
the massage application autonomously.
I. INTRODUCTION
There have been several applications of health care robot.
The DaVinci robot [5] is a telerobotic surgical system which
assists doctors to do more precise control for the surgical
instruments and has been widely used in the hospital, but
doctors have to train up for using the robot system and the
price of the robot is also very expensive. The RIBA (Robot
for Interactive Body Assistance) robot [9][10][11] has the
ability to lift the patients from bed to wheelchair or from
wheelchair to bed, and the RP-VITA robot [17] provides
the remote presence that doctors or nurses can take care the
patients via the remote presence ability as well.
The massage robot has been developed in the previous
work [6][7], it used electromyographic (EMG) signals to
evaluate the massage effect of multi-ﬁnger robot hand. Be-
cause there is physical contact between robot and human,
the impedance control based multi-ﬁnger robot has also been
discussed in the work [8].
Although there are few papers which discussed the topic
of massage robot, it seldom discusses how to generate the
trajectories to adapt different shape of human body. Lu et
al. [13] developed a Chinese medical massage robot system,
and the robot system tries to ﬁnd the acupuncture points of
the people.But it still relies on the doctor to ﬁnd the actual
Ren C. Luo is with International Center of Excellence on Intelligent
Robotics and Automation Research, National Taiwan University, No. 1, Sec.
4, Roosevelt Road, Taipei, Taiwan 106 renluo@ntu.edu.tw
Sheng Y . Chen is with International Center of Excellence on
Intelligent Robotics and Automation Research, National Taiwan
University, No. 1, Sec. 4, Roosevelt Road, Taipei, Taiwan 106
sychen@ira.ee.ntu.edu.tw
Keng. C. Yeh is with International Center of Excellence on
Intelligent Robotics and Automation Research, National Taiwan
University, No. 1, Sec. 4, Roosevelt Road, Taipei, Taiwan 106
kcyeh@ira.ee.ntu.edu.tw
Fig. 1. Dual Arm Robot for Massage Application
acupuncture points and mark it by the colored labels. Wang et
al. [14] based on fuzzy set theory to realize the robot massage
evaluation system, and the evaluation system displays the
three dimensional human shape and marks the acupuncture
point of the people in the evaluation systems.
King et al. [4] developed an assistive robot that performs
bed bath for patient hygiene autonomously. In their work,
the robot mounted the tilting laser range ﬁnder and camera
in the Cudy robot which can obtain the point cloud of the
patient. They provide a user interface in their system that
user determine the region of patient they want to clean by
the interface. But there is the limitation of the robot which
they assume the cleaning region is parallel to the direction
of the gravity, so if the patients change the poses on the bed,
the methodology sometimes will be hard to propel.
Beneﬁt from the advanced of the robotics perception and
sensors, the three dimensional perception has become the
most important part of the robot. The point cloud [14] has
been widely used in the ﬁeld of robotics such as object
recognition, mapping and path planning. In our work, it is
important to know the pose of the humans, and there have
been several researches about human skeleton tracking. The
most popular approach for skeleton tracking is proposed
by Xbox team [15] and Shotton et al. [12], but it has the
limitation due to the needs of speciﬁc initial pose, and the
camera has to be ﬁxed. Buys et al. [2] proposed an adaptable
system for RGB-D based human body detection and pose
estimation methodology that it gets rid of the limitation
of the speciﬁc initial pose, and the camera can be moved
during the tracking of the skeleton. This paper is based on
the human pose recognition methodology which proposed by
[2], and we developed a methodology to build the reference
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 5612
Fig. 2. Dual Arm Robot System developed in NTU-iCeiRA Lab
Fig. 3. Functional Block Diagram of Dual Arm Robot for Massage
Application
coordinate on the human body which is helpful for executing
the massage application autonomously.
The structure of this paper is described as follows: Section
II gives a brief structure of the dual arm robot system. Section
III illustrates the human pose recognition method which we
used in our work. Section IV describes the methodology
which we proposed in this paper of massage trajectory
planning. The experimental results are shown in Section V .
Finally, Section VI concludes our work in this paper.
II. SYSTEM DESCRIPTION
A. Hardware Description
The dual arm robot system developed in NTU-iCeiRA
Lab for massage application which shown in Figure 2. has 6
degree of freedom on each arm, and there is a linear motor
on the bottom of the robot, so that there are totally 13 degrees
of freedom in the dual arm robot system in iCeiRA.
The control of the massage robot is based on the real
time operating system RTX with 1ms servo control loop on
the windows PC. In this paper, we use Microsoft Kinect to
acquire the RGB-D data in our dual arm robot system.
B. Dual Arm Robot with Massage Function
The functional block diagram of dual arm robot is shown
in Figure 3. Our work focused on developing the robot
massage function application. There are three mode to ex-
ecute the massage function. Firstly, people can teach robot
to perform the massage movements, robot repeats the taught
motion by recording from encoder. Robot then provides a
user interface that user can give the desired massage point
from the interface. Since the relationship between image and
space is known (RGB-D camera), the desired point in the
Cartesian space is determined easily.
In order to make robot more intelligent for massage
application, robot should have the ability to execute massage
function automatically. We proposed a methodology to build
a reference coordinate between camera and human body. The
relationship will help robot repeat the massage trajectories
with a reference coordinate. To achieve this function, the fol-
lowing sections will illustrate the methodology we proposed.
III. HUMAN POSE RECOGNITION
In this paper, we use the approach to recognize both human
pose and each body parts which is proposed by Buys et al.
[2]. This approach views the recognition of human pose and
each body parts problem as the object recognition problem;
it ﬁrst segments human body to several parts: head parts
(top and bottom face), neck part, chest parts, hip parts, arm
parts, elbow parts, forearm parts, hand parts, thigh parts,
knee parts, leg parts and foot parts. Each part is divided
into right and left parts except neck. The pose recognition
process computes all of the pixels which came from the
depth camera. All the pixels passed through a classiﬁer and
recognized to which body parts they belonged. The classiﬁer
includes three processes: Database building, depth image
feature deriving and randomized decision forests classifying,
which are illustrated brieﬂy as below:
A. Database Building
To build the database, the training data is necessary. In
this case, the training data which is point cloud of human
body shape is created by computer graphics and real human
tracking techniques (Base character, pose, rotation and trans-
lation, hair and clothing, camera position and orientation).
Furthermore, some weight and height variation and camera
noise are added. Then every training data are labeled each
body parts as described above.
B. Depth Image Features
The depth image is deﬁned to identify each body parts
different characteristic. It is like the feature extraction tech-
niques such as SIFT and SURF in image process, but here
the data is depth data. The depth image feature is deﬁned as
follow:
f
f
(I;x)=d
I
(x+
u
d
I
(x)
) d
I
(x+
v
d
I
(x)
) (1)
Where d
I
(x) represents the depth value of pixel x in depth
image. The parametersf=(u;v) are offset parameters which
should be deﬁned. The term o
1
d
I
(x)
is the normalization factor
which ensures the feature is depth invariant.
5613
Fig. 4. Human Pose Recognition
IV. RANDOMIZED DECISION FORESTS CLASSIFICATION
The randomized decision forests (RDF) are created to
classify the pixel belongs which part. Each split node in the
forests consists of feature f and threshold t. The forests are
kind of binary tree, the current node is updated to left or
right child node is according to the comparison of f
f
(I;x)
and t. Finally the node will reach the last leaf which the
leaves consist of the label c of different human body parts
as described above, then the learned distribution P
t
(c;I;x)
are stored as the result of the t-th tree. The ﬁnal distribution
combines all the results of each tree:
P(cjI;x)=
1
T
T
å
t=1
P
t
(cjI;x) (2)
Here T is the number of created randomized decision
forests.
In our work, we assume the human pose estimation which
we used is reliable. The result of human pose estimation is
shown as Figure 4. Once the relation has been found, the
reference coordinate on the human body has been speciﬁed
as well. It gives robot a reference to repeat the speciﬁed tra-
jectories which designed by designers for massage purpose.
V. MASSAGE TRAJECTORY GENERATION
In this section, we illustrate the methodology of massage
trajectory generating. Based on the work proposed by Buys
et al. [2], the human body is divided into 30 parts, but we
simpliﬁed it into 5 parts in our application. Besides, there
are two main parts of the human body which we used are
the head and torso parts.
A. Determination of Frontal and Sagittal Planes
For the object of generating the massage trajectory on
the human body, the relationship between human and robots
sensor has to be obtained. Once the transformation in the
space is known, the designed massage trajectories can be
repeated for executing speciﬁc massage motions.
At the ﬁrst, we ﬁnd the frontal and sagittal planes of the
human which both their deﬁnitions are shown as Figure 5.
Because the information of each part of the human is
known after human pose recognition process, the region of
Fig. 5. Diagram Showing Sagittal, Frontal and Transverse Planes [16]
interest of the torso of people is determined by (3)(4), and
we estimate the frontal plane equation by using RANSAC
algorithm [3].
left top cornor of ROI=minfu;vjl
i
2l
torso
g (3)
right bottom cornor of ROI=maxfu;vjl
i
2l
torso
g (4)
Where l
i
represents the label on the image with coordinate
(u;v), and l
torso
represents the label of torso part which
contains the hip and chest part with both sides.
After the determination of frontal plane, the border of right
and left torso is extracted to be candidate points which is
used to determine the sagittal plane of the people.
p
c
=fl
i
jl
i
2l
Ltorso
& l
i
is the neighbor of l
Rtorso
g (5)
Wherel
Ltorso
andl
Rtorso
represent the label of left and right
torso parts and here we adopt the 4-neighbor deﬁnition.
The candidate points p
c
will be projected onto the frontal
plane to make sure candidate points lie on the frontal plane.
The projected p
c
is notated as p
cp
. The candidate points
p
cp
are used to estimate the intersection line l
sf
between
frontal and sagittal planes by RANSAC algorithm. Once l
sf
is determined, the normal vector of sagittal plane n
s
is the
cross product ofl
sf
and the normal vectorn
f
of frontal plane.
n
s
=l
sf
n
f
(6)
B. Coordinate Transformation
The camera coordinate can be transformed to human body
coordinate by using the normal vectors of frontal and sagittal
planes as the references. The transformation equation is:
p
0
human body
=R
33
p
caemra
+T
31
(7)
Where R
33
is the rotation matrix and T
31
is the trans-
lation matrix, p
0
human body
and p
camera
are the vectors which
represent the point cloud data with [x y z]
T
in human body
and camera coordinates.
The rotation matrix can be obtained by the relationship of
normal vector of sagittal and transverse planes and camera
coordinate as Fig. 6. Where,
5614
Fig. 6. Relationship of Camera and Human Body Coordinate
n
t
=n
s
n
f
(8)
The camera coordinate has to be rotated twice to let the
human body coordinate coincide with camera coordinate.
First, it rotates the angle b along y-axis between x-axis of
camera coordinate and normal vector n
s
with rotation matrix
R
y
, and then the n
t
becomes to n
0
t
as (9)
n
0
t
=R
y
n
t
(9)
And then, the camera coordinate rotates the angle g
between y-axis of camera coordinate and normal vector n
0
t
along x-axis with rotation matrix R
x
. Where,
R
x
=
2
4
cosg  sing 0
sing cosg 0
0 0 1
3
5
;R
y
=
2
4
cosb 0 sinb
0 1 0
 sinb 0 cosb
3
5
Hence, the equation (7) could be reformed to equation (10)
and (11)
p
00
humanbody
=R
y
p
caemra
(10)
p
0
humanbody
=R
x
p
00
human body
+T (11)
And the translation matrix T can be obtained by arbitrary
choosing the point in p
cp
. In our work, we choose the point
p with maximum y value.
C. Find the Principle Plane of the Back
In consideration of the back of human is not always
straight and the view angle of camera is not ﬁxed in practice,
the plane estimation by RANSAC algorithm could have a
larger angle of inclination along x-axis. To reﬁne the frontal
plane fulﬁlling the tendency of angle with minimum moment
of inertia, we ﬁnd the principle plane of the back which satis-
ﬁed the condition to adjust the reference coordinate. Because
the estimated frontal plane is perpendicular to the sagittal
plane, we ﬁne tune the angle along x-axis by calculating
the projected point on the sagittal plane. Take advantage of
coordinate transformation, all the points p
human body
of the
torso project onto the transformed sagittal plane (y-z plane)
and the axis of minimum moment of inertia is regarded as the
principle axis. To ﬁnd the minimum moment of inertia of the
point cloud, the principle axis is modeled as the parameter
Fig. 7. Finding the Principal Plane from Point Cloud
of r and q in the polar coordinate in Fig. 7. Since the dot
product of the normal vector of line and the distance r which
is shown in Fig. 7 is zero. The equation of the moment of
inertia can be expressed as (12)
G
2
=acos
2
q+bsinqcosq+ccos
2
q (12)
Where
a=
n
å
i=1
(y
0
i
)
2
S
i;j
;b= 2
n
å
i=1
m
å
j=1
(y
0
i
)(z
0
i
)S
i;j
;c=
m
å
j=1
(z
0
i
)
2
S
i;j
and
y
0
=y  ¯ y;z
0
=z  ¯ z
The equation (12) can be expanded as (13) by double angle
formula.
G
2
=
1
2
(a+c)+
1
2
(a c)cos2q+
1
2
bsin2q (13)
Take derivative of equation (13), so when
dG
2
d2q
= 0 (14)
We get equation (15) to obtain q and q2[ 90

;90

]
tan2q =
b
a c
(15)
There are two solutions which cloud be the maximum or
minimum values, and we take another derivate of equation
(15), that is
d
d2q
dG
2
d2q
= 0 (16)
And it returns equation (17)
tan2q =
a c
b
(17)
If equation (17) > 0, there is the minimum value of
moment of inertia of the point cloud, and if equation (17) <
0, there is the maximum value.
And the point cloud is rotated with the angle q along the
x-axis.
p
humanbody
=Rp
0
humanbody
(18)
Here,
5615
Fig. 8. Flowchart of Massage Trajectory Generation
Fig. 9. Estimation of Frontal Plane
Fig. 10. Estimation of Sagittal Plane
R=
2
4
cosq  sinq 0
sinq cosq 0
0 0 1
3
5
D. Trajectory Generating
In previous steps, we found a reference coordinate for
designing the massage trajectory, and the ﬂowchart of each
step is summarized in Fig. 8. We project all points onto the
x-y plane and the intersection of frontal and sagittal planes
is the symmetric line of the back. The trajectory can be
designed on the reference plane and re-project the designed
trajectories which on the reference to the point cloud in the
space.
Fig. 11. Vertical Trajectory (Red Line)
Fig. 12. Horizontal Trajectory (Green Line)
VI. EXPERIMENTAL RESULTS
There are many manipulation ways for massage therapy,
such as press, push, rub, knock, roll, pinch and etc... Some
massage methods need the target point to start the massage
function of the robot, and some massage methods need a
section of trajectory to execute the massage movement like
push with a long distance or rub on the speciﬁc region of
body.
To verify the proposed methodology is workable on
massage trajectory generation, we design three speciﬁed
trajectory include: vertical and horizontal trajectories for
push movement, and circle trajectory for rub movement.
In our experiments, we try to ﬁnd the trajectory which lies
on the either sides of the backbone which there are many
acupuncture points in Chinese medical theorem and bilateral
5616
Fig. 13. Circle Trajectory (Yellow Line)
back of human. By the series of transformations in the space,
we can simply design the trajectories on the x-y plane of
human body coordinate.
The Fig. 9 shows the estimation of frontal plane and Fig.
10 shows the estimation of sagittal plane. Fig. 11 shows the
vertical trajectories which we design on the x-y plane is x=
0:05 meters. Fig. 12 shows the horizontal trajectory on
human back for push movement of massage. Fig. 13 shows
the circle trajectory on human back which is designed for
rub movement.
VII. CONCLUSION
In our work, we propose the methodology to generate the
massage trajectory by the RGB-D sensor. By the deﬁnition
and ﬁnding the frontal and sagittal planes, the point cloud
can be transformed on the reference plane which is useful to
design the massage trajectories on the human body.
The experimental results demonstrate our work which
provide a useful method for massage trajectory generation.
As an example of service robot application, this method is
useful for executing the massage application autonomously.
REFERENCES
[1] A. Aldoma, Z.-C. Marton, F. Tombari, W. Wohlkinger, C. Potthast, B.
Zeisl, et al., ”Tutorial: Point Cloud Library: Three-Dimensional Object
Recognition and 6 DOF Pose Estimation,” Robotics and Automation
Magazine, IEEE, vol. 19, pp. 80-91, 2012.
[2] K. Buys, C. Cagniart, A. Baksheev, T. De Laet, J. De Schutter, and
C. Pantofaru, ”An adaptable system for RGB-D based human body
detection and pose estimation,” Journal of Visual Communication and
Image Representation, 2013.
[3] M. A. Fischler and R. C. Bolles, ”Random sample consensus: a
paradigm for model ﬁtting with applications to image analysis and
automated cartography,” Communications of the ACM, vol. 24, pp.
381-395, 1981.
[4] C.-H. King, T. L. Chen, A. Jain, and C. C. Kemp, ”Towards an assistive
robot that autonomously performs bed baths for patient hygiene,” in
Intelligent Robots and Systems (IROS), 2010 IEEE/RSJ International
Conference on, 2010, pp. 319-324.
[5] J. Leven, D. Burschka, R. Kumar, G. Zhang, S. Blumenkranz, X.
D. Dai, et al., ”DaVinci canvas: a telerobotic surgical system with
integrated, robot-assisted, laparoscopic ultrasound capability,” in Med-
ical Image Computing and Computer-Assisted Intervention?MICCAI
2005, ed: Springer, 2005, pp. 811-818.
[6] R. C. Luo and C.-C. Chang, ”Electromyographic signal integrated
robot hand control for massage therapy applications,” in Intelligent
Robots and Systems (IROS), 2010 IEEE/RSJ International Conference
on, 2010, pp. 3881-3886.
[7] R. C. Luo and C. C. Chang, ”Electromyographic evaluation of thera-
peutic massage effect using multi-ﬁnger robot hand,” in Robotics and
Automation (ICRA), 2011 IEEE International Conference on, 2011,
pp. 2431-2436.
[8] R. C. Luo, C. C. Chang, and Y .-W. Perng, ”Impedance control on
a multi-ﬁngered robot hand based on analyzed electromyographic
information for massage applications,” in Industrial Electronics, 2009.
ISIE 2009. IEEE International Symposium on, 2009, pp. 1228-1233.
[9] T. Mukai, S. Hirano, H. Nakashima, Y . Kato, Y . Sakaida, S. Guo, et
al., ”Development of a nursing-care assistant robot riba that can lift a
human in its arms,” in Intelligent Robots and Systems (IROS), 2010
IEEE/RSJ International Conference on, 2010, pp. 5996-6001.
[10] T. Mukai, S. Hirano, M. Yoshida, H. Nakashima, S. Guo, and Y .
Hayakawa, ”Tactile-based motion adjustment for the nursing-care
assistant robot RIBA,” in Robotics and Automation (ICRA), 2011
IEEE International Conference on, 2011, pp. 5435-5441.
[11] T. Mukai, S. Hirano, M. Yoshida, H. Nakashima, S. Guo, and Y .
Hayakawa, ”Whole-body contact manipulation using tactile informa-
tion for the nursing-care assistant robot riba,” in Intelligent Robots and
Systems (IROS), 2011 IEEE/RSJ International Conference on, 2011,
pp. 2445-2451.
[12] J. Shotton, T. Sharp, A. Kipman, A. Fitzgibbon, M. Finocchio, A.
Blake, et al., ”Real-time human pose recognition in parts from single
depth images,” Communications of the ACM, vol. 56, pp. 116-124,
2013.
[13] L. Shouyin, G. Huanbing, L. Cungen, and W. Tao, ”Design of Chinese
medical massage robot system,” in Electrical and Control Engineering
(ICECE), 2011 International Conference on, 2011, pp. 3882-3885.
[14] T. Wang, T. Bei, and Y . Li, ”Research and realization of the robot
massage evaluation system based on fuzzy set theory,” in Intelligent
Control and Automation (WCICA), 2010 8th World Congress on,
2010, pp. 6498-6501.
[15] Microsoft XBOX Kinect, 2010, http://xbox.com
[16] ”Sigittal Plane, ” http://www.wikipedia.org
[17] InTouch Technologies, http://www.intouchhealth.com
5617
