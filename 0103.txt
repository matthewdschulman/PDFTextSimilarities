A Dynamic and Uncalibrated Method to Visually Servo-control
Elastic Deformations by Fully-constrained Robotic Grippers
David Navarro-Alarcon and Yun-hui Liu
Abstract—In this paper, we address the set-point deforma-
tion control of elastic objects by fully-constrained grippers.
We propose an uncalibrated Lyapunov-based algorithm that
iteratively estimates the deformation Jacobian matrix, with no
prior knowledge of the deformation and camera models. With
this new method we show how, by combining pose information
of the grippers with several visual measurements, we can
independently control elastic deformations of unknown objects.
We report experiments with a 6-DOF robot manipulator to
validate this control approach.
I. INTRODUCTION
In recent years, the problem of the active deformation
control of compliant objects has received signiﬁcant at-
tention from the robotics research community. This inter-
est in controlling deformations seems to come from the
recent advances in surgical robotics [1], the progress in
home/personal-robotics[2],andtheautomationofnewappli-
cations that require to manipulate soft bodies, e.g. handling
foodmaterials[3],orsuturing[4].Notethatinmanyapplica-
tions (specially those in the medical ﬁeld), the manipulated
objects usually have uncertain deformation properties; this
situation clearly complicates the practical implementation.
The research community has made signiﬁcant contribu-
tionssincethework[5],whichtoourknowledge,reportsone
of the earliest efforts to comprehensively address this topic.
Some researchers have studied the active shaping of rheo-
logical materials, see e.g. [6], [7]. To control deformations,
these methods must ﬁrst identify the object’s visco-elastic
properties. For objects that exhibit elastic deformations only,
some researchers have proposed explicit feedback control
methods to indirectly position deformable feature points,
see e.g. [8]–[11]. These model-based controllers also require
prior calibration of deformation and vision models.
Irrespectively of the material’s properties, most controllers
in the literature require a-priori knowledge of a deformation
model, albeit approximated. Very few works address the
simultaneous online estimation and control of elastic defor-
mations (note that standard visual servoing, e.g. classical
[12] or uncalibrated methods [13], do not address active
deformation). Moreover, most existing methods only use
the manipulator’s linear displacements to actively control
deformations; since these control algorithms do not consider
rotations/torsions, they can only impose a limited set of
D. Navarro-Alarcon and Y.-H. Liu. Department of Mechanical and
Automation Engineering, The Chinese University of Hong Kong, Shatin
NT, HKSAR. dnavarro,yhliu[at]mae.cuhk.edu.hk
This work has support from the the Hong Kong RGC (grant num-
bers 415011, CUHK6/CRF/13G); the Hong Kong ITF (grant number
ITS/475/09), and the Shun Hing Institute of Advanced Engineering.
shapes onto the object. For example, [7] presents a method
tocontrolone-dimensionaldeformations(i.e.linearcompres-
sions),whereas[8]–[10]formulatethedeformationcontroller
considering plane motion of the manipulator (these methods
can only control up-to two degree-of-freedom (DOF) with
a single manipulator). Recently, [11] proposed a method to
control deformations with the 6-DOF motion of the end-
effector;thiscontroller,however,requiresa-prioriknowledge
of the object’s deformation properties.
In this paper, we present a new image-based approach to
servo-controlelasticdeformations.Byincorporatingthegrip-
per’s attitude and several visual measurements, our method
can independently control elastic deformations with the 6-
DOF motion of the manipulator—something we can not
achieve with existing controllers including our previous
formulations [14], [15]. The uncalibrated method that we
present does not require identiﬁcation of the deformation
and camera models. For that, we derive a Lyapunov-based
algorithm that computes the unknown deformation Jacobian
matrix in real-time. We report a 6-DOF experimental study
to validate the feasibility of our new set-point deformation
controller.
The rest of this manuscript has the following structure:
In Section II we derive the mathematical models. Section
III details our control method. In Section IV we report the
experiments. Section V gives conclusions and future work.
II. MATHEMATICAL MODELLING
A. Manipulator model
Consider a serial non-redundant manipulator with revolute
joints and an exactly known kinematic structure. We denote
the vectors of joint displacements by q ? R
n
and end-
effector pose (position + orientation) by x?R
n
. The time-
derivative of the pose vector yields the expression
˙ x =
∂x
∂q
(q)˙ q, (1)
where the matrix
∂x
∂q
(q) ? R
n?n
denotes the analytical
Jacobian matrix of the manipulator.
In this paper we only consider kinematically-controlled
manipulators, e.g. as reported in [16]. Therefore, the angular
velocity ˙ q physically stands for the control input to the
system. Note that in real experimental systems this velocity
input typically presents saturation.
B. Deformation model
We consider the case where the robot manipulator phys-
ically interacts with soft objects that exhibit elastic defor-
mations only. To actively modify the object’s shape, the
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 4457
r1
r
k
.
.
.
x
End-e?ector
Elastic
surface
Fig. 1. Conceptual representation of the object’s deformation model.
manipulator has a robotic gripper which rigidly grasps the
elastic body in a fully-constrained manner. Physically, this
situation means that the motion of the manipulator’s tip (in
any linear or rotational direction) produces deformations on
the body.
To represent the elastic conﬁguration of the object, we
use k feature points r
i
? R
3
, for i = 1...,k, located
over the surface of the object (see Fig. 1 for a conceptual
representation). We locally model the quasi-static relation
between the pose x and each feature point r
i
by
r
i
=C
i
?x, (2)
where C
i
?R
3?n
represents a constant deformation matrix
that maps the displacements of the n-dimensional pose to
the deformation of the feature points. The vector ?x =x?
x ? R
n
models the relative pose displacement, with x as
a constant reference. For ease of presentation, we group all
the feature points in the extended feature vector
r =

r
?
1
··· r
?
k

?
?R
3k
. (3)
C. Visual feedback model
Consider m uncalibrated ﬁxed cameras that observe the
object. In our approach, we use multiple independent vision
sensorstomonitor(andeventuallycontrol)theobject’sshape
from different perspectives. For ease of presentation, we
assume that the pointr
i
projects onto one image plane only
1
.
We denote the visual feedback of the point r
i
by
s
i
=

µ i
?
i

?
?R
2
, (4)
where µ i
?R and ?
i
?R denote image pixel coordinates.
We group all the image points s
i
into the extended vector
s =

s
?
1
··· s
?
k

?
?R
2k
. (5)
See Fig. 2 for a conceptual representation of this setup.
In our approach, we locally model the projection of the
feature point r
i
onto the jth image plane by
s
i
=M
j
r
i
+b
j
?R
2
, (6)
with the matrix M
j
? R
2?3
and vector b
j
? R
2
as the
constant calibration terms. We must remark that we use this
1
We can easily extend this formulation to multiple feedback of one point.
r1
.
.
.
s1
si
.
.
.
s
k?j
s
k
.
.
.
r
k
Camera 1 image Cameram image
Fig. 2. Conceptual representation of the k visual feedback points provided
by the m uncalibrated cameras, where 1≤ i≤ j≤ k.
afﬁne model [17] to obtain a simple and linearly parametris-
able expression of the visual deformation feedback; in Sec-
tion III we derive an online estimator that exploits this useful
property (we show that the use of this simple model does
not impose severe implementation constraints to our method
since it continuously updates variable parameters based on
image measurements).
The time-derivative of the extended visual feedback vector
s yields the differential expression
˙ s =L˙ x, (7)
whichrelatestheinputmotionofthegripperswiththeoutput
optical ﬂow. We deﬁne the projection-deformation constant
matrix L?R
2k?n
by
L =
?
?
?
M
1
C
1
.
.
.
M
m
C
k
?
?
?, (8)
where m denotes the number of cameras, and k the number
of feature points. Now, let us group all the elements of the
matrix L into the vector of constant parameters
? =

L
1,1
L
1,2
··· L
2k,n?1
L
2k,n

?
?R
g
, (9)
where g = 2kn ? R represents the number of unknown
components, and L
i,j
?R denotes an element at the ith row
jth column of the matrix L.
D. Deformation feature
To obtain a quantitative metric of the object’s shape (and
thus avoid the open-loop response of robot-centred methods,
e.g. [18]), we introduce the vision-dependent function
y =y(s)?R
h
; for h≤ n, (10)
which we call the deformation feature vector. The coor-
dinates of this smooth function can represent, e.g. visual
displacements, angles, curvatures, line features, etcetera (see
[15]). By time-differentiating this function we obtain
˙ y =J(s)˙ x, (11)
4458
where J(s) ? R
h?n
represents the deformation Jacobian
matrix and has the following deﬁnition:
J(s) =
∂y
∂s
(s)L. (12)
Note that we can not exactly compute this matrix since it
contains unknown terms, namely, the matrix L.
III. CONTROLLER DESIGN
As with traditional visual servoing approaches [12], we
design our controller in terms of the end-effector velocities,
therefore, we deﬁnev = ˙ x?R
n
as the new control variable.
Problem. Given a constant deformation feature y
d
?R
h
,
design an uncalibrated velocity controller v that asymptot-
ically minimises the error ?y = y? y
d
? R
h
, with no
a-priori information of the deformation and camera models.
A. Lyapunov-based estimator
In order to minimise the deformation error ?y, we must
ﬁrst estimate how the gripper’s linear and rotational motions
actively deform the elastic object. For that, in this section
we present an adaptive algorithm that computes an online
estimation of the vector of parameters ?; we denote this
adaptive vector by
b
? ? R
g
. Note that with the vector
b
?
we can construct an estimation of the unknown projection-
deformation matrix L, and in turn, an estimation of the
deformation Jacobian matrix J(s).
Tointroduceouradaptivealgorithm,considerﬁrsttheﬂow
estimation error vector
e =f? ˙ y?R
h
, (13)
for a vector f ?R
h
computed as
f =
∂y
∂s
(s)
b
L˙ x. (14)
The matrix
b
L ? R
2k?n
represents an estimation of the
unknown matrix L. The upper symbol b ? indicates that
we construct this term with the variable parameters
b
?. By
substituting the right-hand sides of the ﬂows (11) and (14)
into the error (13), we can equivalently re-write the error as
e =
∂y
∂s
(s)

b
L?L

˙ x,
=A(s, ˙ x)??, (15)
where ?? =
b
????R
g
denotes the parameters’ estimation
error, and A(s, ˙ x) ? R
h?g
represents a known regression
matrix which has the following simple deﬁnition:
A(s, ˙ x) =
∂y
∂s
(s)
?
?
?
˙ x
?
··· 0
1?n
.
.
.
.
.
.
.
.
.
0
1?n
··· ˙ x
?
?
?
?. (16)
Proposition 1: Consider that for slow (viz. saturated) and
smooth motion of the manipulator, the boundsk˙ xk≤ ?
1
and
k¨ xk≤ ?
2
simultaneously satisfy for positive scalars ?
j
?R.
In this situation, the parameter’s update rule
˙
b
? =??A
?
(s, ˙ x)Ke, (17)
with symmetric and positive matrices ? ? R
g?g
and
K?R
h?h
, stably computes a matrix
b
L that asymptotically
minimises the error e.
Proof: Considering the linearly parametrised error (15),
we can re-write the update rule as
˙
b
? =??A
?
(s, ˙ x)KA(s, ˙ x)??. (18)
To prove the stability of the online estimator, we introduce
the energy-like functional
V =
1
2
??
?
?
?1
???R, (19)
whose time-derivative along (18) satisﬁes
˙
V =???
?
A
?
(s, ˙ x)KA(s, ˙ x)??,
=?e
?
Ke,
≤ 0. (20)
From the Lyapunov’s direct method [19], we see that the
update rule provides a stable (thus bounded) computation
of
b
?. Note that since k˙ xk and k¨ xk have upper bounds,
then, simple computations can show thatk
¨
Vk has also upper
bounds. From the Barbalat’s lemma [19], we prove that as
time approaches inﬁnity, the ﬂow error e?0
h?1
.
In our method, we compute the Jacobian matrix in real-
time and with no model calibration as follows:
b
J(s) =
∂y
∂s
(s)
b
L?R
h?n
. (21)
Remark 1: The update rule (17) does not guarantee the
identiﬁcation of the true parameters? or the Jacobian matrix
J(s). We design our iterative algorithm with the objective of
continuously satisfying the kinematic relation:
˙ y =
b
J(s)˙ x. (22)
This approach resembles the method in [20].
B. Dynamic velocity control
In our method, we use the smooth velocity control input
v =
b
J
+
(s)p, (23)
where the matrix
b
J
+
(s) ? R
n?h
stands for the Moore–
Penrose pseudoinverse. The vector p ? R
h
represents a
dynamicstatevariable—withphysicalinterpretationofvisual
momenta, see [21]—which we compute by the rule
˙ p =?
∂Q
∂y
?
(?y)?Bp, (24)
forQ(?y)?R as a positive-deﬁnite function with a unique
equilibrium at ?y = 0
h?1
. The symmetric and positive
matrix B?R
h?h
represents damping.
Proposition 2: The dynamic velocity control input (23)
asymptotically minimises the deformation error ?y.
Proof: By substituting the controller (23) into the
deformation plant (22) we obtain the closed-loop system

˙ y
˙ p

=

0
h?h
I
h?h
?I
h?h
?B

"
∂H
∂y
?
∂H
∂p
?
#
, (25)
4459
Compliant
object
Fig. 3. The setup used in our experimental study.
with an energy-like function
H(?y,p) =Q(?y)+
1
2
p·p?R, (26)
whose time-derivative satisﬁes
˙
H(?y,p) =?p
?
Bp≤ 0. (27)
This expression shows that the scalar H monotonically
decreases along trajectories of the system (25). To prove
the asymptotic minimisation of the error ?y, we analyse
the equilibria of (25). These equations show that as time
approaches inﬁnity, the error ?y?0
h?1
[19].
IV. EXPERIMENTS
A. Setup
Fig. 3 shows the 6-DOF (n = 6) robot manipulator that
we use to conduct the experimental study. This mechanical
system has an open architecture servo-controller that allows
to set the joint velocity in real-time (see [15] for details).
The manipulator’s gripper rigidly grasps a 2?12?25 mm
soft foam sheet; we place artiﬁcial markers on the surface
of this object. To acquire the visual feedback, we use two
C310 Logitech cameras.
B. Case of study
We test the performance of our control method with
two different 4-DOF deformation tasks (this situation corre-
sponds to y = [y
1
,y
2
,y
3
,y
4
]?R
4
). In the ﬁrst deformation
task we only consider a single view (m = 1) of the
object; the experiment consists in simultaneously position
two deformable points s
1
and s
2
(see Fig. 4). We construct
the deformation feature vector with the pixel coordinates
y =

s
?
1
s
?
2

?
. (28)
In the second task we use two cameras (m = 2) to observe
the upper and side views of the object; the experiment
consists in simultaneously position one deformable point and
two angle features (see Fig. 5). We construct the deformation
vector with four visual feedback points s
i
, and deﬁne its
pixel-angle coordinates by
y =

s
?
1
arccos(u
1
·l
1
) arccos(u
2
·l
2
)

?
, (29)
s2
s1
Fig. 4. Snapshots of the initial and ﬁnal conﬁgurations of the single-view
(m=1) point positioning deformation experiment.
s1
(a) Upper view with a single point feature.
s2
s3
s4
(b) Side view with two angle features.
Fig. 5. Snapshots of the initial and ﬁnal conﬁgurations of the two-view
(m=2) point-angle deformation experiment.
where the constant unit vectors u
i
? R
2
denote arbitrary
references. We compute the feedback-dependent directional
vectors l
i
?R
2
as
l
i
=
s
i+1
?s
i+2
ks
i+1
?s
i+2
k
; for i = 1,2. (30)
To minimise the deformation error ?y, we implement the
potential control action
∂Q
∂y
?
(?y) = ?sat(?y), (31)
where ? = 0.5 represents a proportional feedback gain and
sat(·) :R
4
7?R
4
denotes a saturation function that satisﬁes
?? ≤ sat(·) ≤ ?, for ? ? R
4
as the bound vector. We
set the components of ? to ?
i
= 20 px and ?
j
= 0.2 rad
for the point and angle features, respectively. To compute
the dynamic variable p, we use initialise it with the vector
p(0) =0
h?1
, and use a matrix B = 5I
4?4
. Note that these
values forQ(?y) andB provide a highly dissipative (hence
smooth) behaviour to the system.
To implement the Lyapunov-based estimator, we initialise
the vector of parameters with
b
?(0) = [1,...,1]
?
, and use a
tuning matrix ? = 30000I
g?g
. For our two cases of study,
4460
0
10
20
30
40
50
0 10 20 30 40 50
Error |?y
i
| (px)
Time (s)
 ?y
3
 ?y
4
0
10
20
30
40
50
0 10 20 30 40 50
Error |?y
i
| (px)
 ?y
1
 ?y
2
Fig. 6. Magnitude of the point deformation errors?y
i
of the single-view
task shown in Fig. 4.
-25
-20
-15
-10
-5
0
 ?x
1
 (mm)
-20
-15
-10
-5
0
?x
2
 (mm)  
-20
-15
-10
-5
0
?x
3
 (mm)
•
t = 0
Fig. 7. Trajectory of the relative Cartesian displacements ofthe single-view
task shown in Fig. 4.
we use the ﬂow estimation gain matrices K = I
4?4
and
K = diag(1,1,100,100), respectively.
C. Results
Fig. 4 and Fig. 5 show snapshots of the conducted ex-
periments. The overlaid red and green “curves” represent
the feedback deformation features and the desired constant
targets, respectively.
We ﬁrst present the results of the single-view point posi-
tioning experiment. Fig. 6 depicts the asymptotic minimi-
sation of the four deformation errors ?y
i
. Fig. 7 shows
the resulting Cartesian displacements of the gripper. To
demonstrate the accuracy of our uncalibrated method, in
Fig. 8 and Fig. 9 we present graphical comparisons of the
visuallymeasured deformationﬂow ˙ y andtheﬂow estimated
by f =
b
J(s)˙ x.
Now, we present the results of the two-view point-angle
deformation experiment. Fig. 10 depicts the asymptotic min-
imisation of the pixel and radian deformation errors. Finally,
Fig. 11 shows the relative displacements of the gripper. To
the best of our knowledge, this paper reports for the ﬁrst time
the simultaneous control of 4 independent deformation DOF
by a single manipulator. In [15], we also report the control
of 4-DOF, but jointly performed by two manipulators. The
control of deformation via rotations results instrumental to
our method. Approaches like [8] only consider plane motion,
-4
-2
0
2
4
0 10 20 30 40 50
Flow (px/s)
Time (s)
 dy
2
f
2
-4
-2
0
2
4
0 10 20 30 40 50
Flow (px/s)
 dy
1
f
1
Fig. 8. Comparison of the measured and estimated deformation ﬂows for
the experiment shown in Fig. 4. First and second coordinates.
-10
-5
0
5
10
0 10 20 30 40 50
Flow (px/s)
Time (s)
 dy
4
f
4
-10
-5
0
5
10
0 10 20 30 40 50
Flow (px/s)
 dy
3
f
3
Fig. 9. Comparison of the measured and estimated deformation ﬂows for
the experiment shown in Fig. 4. Third and fourth coordinates.
thus can only control up-to 2-DOF per robot. We must
emphasise that the grasping conﬁguration plays a crucial role
in our formulation. Also note that the manipulator can only
drive the features to physically reasonable targets.
D. Multimedia material
In the accompanying video, we illustrate the performance
of our controller with different deformation control experi-
ments. This video presents a simple procedure to obtain a
good enough initial value for
b
?.
V. CONCLUSIONS
In this paper, we presented a visual servoing method
to servo-control deformations of unknown elastic objects
with the 6-DOF motion of the manipulator. To cope with
the uncertain vision/deformation models, we ﬁrst derived
an algorithm that online estimates the Jacobian matrix.
Next,wepresentedadynamic-statefeedbackvelocitycontrol
law which provides smooth trajectories to the manipulator.
Finally, we reported experimental results to validate the
controller.
In this new method, we incorporate the orientation of the
fully-constrained grippers into the estimation algorithm. This
feature allows us to: (i) increase the number of controllable
deformation DOF, and (ii) extend the dimension of the
Jacobian’s kernel. In our early study [14], we noted that
n = 3 has a restricted number of reachable conﬁgurations
4461
0
0.1
0.2
0.3
0.4
0.5
0 10 20 30 40 50
Error |?y
i
| (rad)
Time (s)
 ?y
3
 ?y
4
0
10
20
30
40
50
0 10 20 30 40 50
Error |?y
i
| (px)
 ?y
1
 ?y
2
Fig. 10. Magnitude of the point and angle deformation errors?y
i
of the
two-view task shown in Fig. 5.
-5
0
5
10
15
20
 ?x
1
 (mm)
-25
-20
-15
-10
-5
0
?x
2
 (mm)  
-50
-40
-30
-20
-10
0
?x
3
 (mm)
•
t = 0
Fig. 11. Trajectory of the relative Cartesian displacements of the two-view
task shown in Fig. 5.
(singularities tend to arise in this situation). In contrast with
our previous estimator [15], the stability (convergence) of
our new online algorithm can be proved with Lyapunov-
like theory; we must remark that this method requires slow
motion of the manipulator and proper ﬁltering of the visually
measured ﬂow signals.
As future work, we want to use the stereo vision system to
estimate the 3D deformation of the object. Additionally, we
would like to extend this uncalibrated controller to perform
shared (robot-human) deformation tasks.
REFERENCES
[1] V. Mallapragada, N. Sarkar, and T. Podder, “Toward a robot-assisted
breast intervention system,” IEEE/ASME Trans. Mechatronics, vol. 16,
no. 6, pp. 1011–1020, Dec. 2011.
[2] M. Cusumano-Towner, A. Singh, S. Miller, J. O’Brien, and P. Abbeel,
“Bringing clothing into desired conﬁgurations with limited percep-
tion,” in Proc. IEEE Int. Conf. Robotics and Automation, 2011, pp.
3893–3900.
[3] Z. Wang and S. Hirai, “Modeling and estimation of rheological
properties of food products for manufacturing simulations,” J. Food
Eng., vol. 102, no. 2, pp. 136 – 144, Jan. 2011.
[4] M. Saha and P. Isto, “Manipulation planning for deformable linear
objects,” IEEE Trans. Robot., vol. 23, no. 6, pp. 1141–1150, Dec.
2007.
[5] D. Henrich and H. W¨ orn, Eds., Robot manipulation of deformable
objects, ser. Advanced manufacturing. New York: Springer-Verlag,
2000.
[6] S. Tokumoto and S. Hirai, “Deformation control of rheological food
dough using a forming process model,” in Proc. IEEE Int. Conf.
Robotics and Automation, vol. 2, 2002, pp. 1457–1464.
[7] M. Higashimori, K. Yoshimoto, and M. Kaneko, “Active shaping of
an unknown rheological object based on deformation decomposition
into elasticity and plasticity,” in Proc. IEEE Int. Conf. Robotics and
Automation, 2010, pp. 5120–5126.
[8] S.HiraiandT.Wada,“Indirectsimultaneouspositioningofdeformable
objects with multi-pinching ﬁngers based on an uncertain model,”
Robotica, vol. 18, no. 1, pp. 3–11, Jan. 2000.
[9] M. Torabi, K. Hauser, R. Alterovitz, V. Duindam, and K. Goldberg,
“Guiding medical needles using single-point tissue manipulation,” in
Proc. IEEE Int. Conf. Robotics and Automation, 2009, pp. 2705–2710.
[10] S.KinioandA.Patriciu,“AcomparativestudyofHinfandPIDcontrol
for indirect deformable object manipulation,” in Proc. IEEE Int. Conf.
Robotics and Biomimetics, 2012, pp. 414–420.
[11] D. Berenson, “Manipulation of deformable objects without modeling
and simulating deformation,” in Proc. IEEE Int. Conf. Intelligent
Robots and Systems, 2013, pp. 1–8.
[12] F. Chaumette and S. Hutchinson, “Visual servo control. Part I: Basic
approaches,” IEEE Robot. Autom. Mag., vol. 13, no. 4, pp. 82–90,
Dec. 2006.
[13] J. Piepmeier, G. McMurray, and H. Lipkin, “Uncalibrated dynamic
visual servoing,” IEEE Trans. Robot. Autom., vol. 20, no. 1, pp. 143–
147, Feb. 2004.
[14] D. Navarro-Alarcon and Y.-H. Liu, “Uncalibrated vision-based de-
formation control of compliant objects with online estimation of the
Jacobian matrix,” in Proc. IEEE Int. Conf. Intelligent Robots and
Systems, 2013, pp. 4977–4982.
[15] D. Navarro-Alarcon, Y.-H. Liu, J. Romero, and P. Li, “Model-free
visually servoed deformation control of elastic objects by robot
manipulators,” IEEE Trans. Robot., vol. 26, no. 6, pp. 1457–1468,
Aug. 2013.
[16] D.Whitney,“Resolvedmotionratecontrolofmanipulatorsandhuman
prostheses,” IEEE Trans. Man-Mach. Syst., vol. 10, no. 2, pp. 47–53,
Jun. 1969.
[17] R. I. Hartley and A. Zisserman, Multiple View Geometry in Computer
Vision, 2nd ed. Cambridge, UK: Cambridge University Press, 2004.
[18] Y.-H. Liu and D. Sun, “Stabilizing a ﬂexible beam handled by two
manipulators via pd feedback,” IEEE Trans. Autom. Control, vol. 45,
no. 11, pp. 2159–2164, Nov. 2000.
[19] J.-J. Slotine and W. Li, Applied Nonlinear Control, 1st ed. New
Jersey: Prentice Hall, 1991.
[20] K. Hosoda and M. Asada, “Versatile visual servoing without knowl-
edge of true Jacobian,” in Proc. IEEE Int. Conf. Intelligent Robots and
Systems, vol. 1, 1994, pp. 186–193.
[21] R. Ortega, A. van der Schaft, I. Mareels, and B. Maschke, “Putting
energy back in control,” IEEE Control Syst. Mag., vol. 21, no. 2, pp.
18–33, Apr. 2001.
4462
