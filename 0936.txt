Full Body Motion Adaption based on Task-Space Distance Meshes
Thomas Nierhoff, Sandra Hirche, Wataru Takano and Yoshihiko Nakamura
AbstractÑ This paper presents a novel robot pose measure
for human movement imitation based entirely on the Euclidean
distance information between any two links of a robot and any
link and object in the robotÕs environment in a Cartesian task
space. A Hidden Markov Model is used to encode the spatio-
temporal information of multiple demonstrations. In combi-
nation with Gaussian Mixture Regression for extracting the
important task properties, feasible full-body motion adaption
can be achieved. The method is suited for use with a humanoid
robot by considering additional constraints like balance control
and collision avoidance. In order to tackle modeling errors
occurring due to the human movement demonstration and the
robotic reproduction, a manipulability based weighting scheme
is proposed. Complexity reduction of the otherwise redundant
pose measure is performed based upon a mechanical analogy
of an interconnected spring system. Experiments are conducted
using a HRP-4 robot and display the applicability of the
presented methods for robotic full-body motion imitation tasks.
I. INTRODUCTION
Programming by demonstration is a promising way for
humanoid robots to learn complex tasks in a human-like
fashion. Instead of programming every desired movement
from scratch, a human movement fulÞlling the desired task is
adopted to a robot and modiÞed when necessary. Movement
modiÞcations are necessary for various reasons, e.g. environ-
mental changes, differences in the pose of human and robot
or intentionally altered movements during reinforcement
learning of a task.
Various adaption schemes are proposed in literature in
order to encode and reproduce task-speciÞc movements. This
includes Dynamic Movement Primitives (DMP), a method
disturbing a stable second order attractor system locally using
a weighted set of nonlinear differential equations. Successful
application is shown in [1], [2] both to one-link manipulators
and humanoid robots being able to react dynamically to
changes in the environment. Another approach are Gaussian
Mixture Models/Gaussian Mixture Regression (GMM/GMR),
encoding a time-index trajectory set by a Þnite number of
Gaussian functions, see [3], [4]. This provides information
about both, most likely trajectory and corresponding spatial
variance. Especially the variance is of interest as it can be
used as a measure of importance of different task elements.
A more speciÞc approach for precise object manipulation
is presented in [5], where the combination of two HMMs
Thomas Nierhoff and Sandra Hirche are with the Institute for
Information-oriented Control (ITR), Faculty of Electrical Engineer-
ing, Technische Universit¬ at M¬ unchen, D-80290 M¬ unchen, Germany
{tn, hirche}@tum.de. Thomas Nierhoff, Wataru Takano and
Yoshihiko Nakamura are with the Department of Mechano-Informatics,
University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, 113-8656 Tokyo, Japan
{takano, nakamura}@ynl.t.u-tokyo.ac.jp.
triggering Þrst the hand motion and then the full body motion
is presented. Last, [6] present an extension to Dynamic
Bayesin Networks, being also able to deal with unforeseen
perturbations.
A common property of all presented methods is the pos-
sible handling of both free space movements and interactive
robot tasks with objects/humans in its environment. Problems
arise as most methods encode the robotÕs joint angles even
if the quality of imitation is mostly evaluated in task space -
either by inspection or using endeffector trajectory deviation
measurements. As the mapping from joint to task space is
highly nonlinear depending on the robotÕs geometry, it can
be prone to errors in case of large environmental changes. In
this case, a measure based upon task space information can
be both more robust and intuitive. Hence various approaches
grab up this idea, see [7], [8].
Therefore this paper presents an entirely task-space based
measure of both the robots pose and the interaction of the
robot with its environment. Inspired by the work presented
in [9], [10] not the joint angles for describing the robots
current pose but instead the Euclidean distance between
any two links of the robot is used. In a similar fashion
for interacting with the environment, the distance between
any link of the robot and any object in the environment is
calculated. The importance of each distance is encoded in
its spatial variance and evaluated using HMM and GMR.
Thus it can be ensured only the important task-speciÞc
properties are considered both for the robot pose and the
environment interaction. Further analysis tackles the question
how the proposed method can be used as a singularity
avoidance scheme and to what extent its complexity can
be reduced. Experiments performing motion adaption on a
HRP-4 humanoid robotic platform show that the proposed
approach can be adapted to real life problems by adding
constraints like collision avoidance, balance of the robot
deÞned by its center of mass or joint angle limits.
The remainder of this paper is organized as follows: Sec. II
displays the general approach and improvements leading
to better overall performance. Experimental results using a
HRP-4 robotic platform are presented in Sec. III. Sec. IV
discusses the presented approach. Last, Sec. V concludes
with a Þnal statement and possible expansions for the future.
Notation: Throughout the article scalars are written in
non-bold letters (e.g a), vectors in bold lower case letters
(e.g.a) and matrices in bold capital letters (e.g.A). Ac-
cessing a speciÞc element of a matrix/vector is denoted
by square subscript brackets (e.g.A
[3,2]
for the third row,
second column ofA).
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 1865
II. MOTION LEARNING AND REPRODUCTION
A. Data Representation
Let the robot be represented as a kinematic chain with k
joints, the corresponding joint angle vector? andl links with
corresponding positionp
l
i
?R
3
,i ={1,...,l}. The same
accounts for a set of objects in the environment. In order
to obtain information about the objects orientation, o object
pointsp
o
i
?R
3
,i ={1,...,o} are deÞned depending on the
objectsÕ geometry. For easier handling, let n = l+o be the
total number andp
i
?R
3
,i ={1,...,n} be the total set of
position vectors to be considered. The time-varying version
of p
i
is denoted p
i,t
. Then the distance mesh vector d ?
R
n(n?1)/2
stores every possible Euclidean distance between
the position vectors. For every time step t ? {0,...,t
max
}
a new distance mesh vector d
t
is calculated, thus encoding
the temporal progress of the distance mesh.
Fig. 1. Conventional approach (left) and new approach (right). Whereas the
conventional approach encodes the robot joint angles (green) and distances
to objects (red) separately, the method presented in this paper encodes the
pose of the robot and the interaction with its environment through the
weighted set of Cartesian link-link (orange) and link-object (red) distances.
B. Data Encoding and Reproduction
A CHMM in combination with GMR is used to encode the
temporal progress of every element of the distance meshd
t
based on multiple task repetitions. The CHMM is represented
by the parameter set {¹,a,w,?,?} with ¹ for the initial
state probabilities, a the state transition probabilities and
w, ? and? for weight, mean and covariance of each state
of the CHMM. In addition to the spatial mean ?
s,g
and
variance ?
s,g
for every Gaussian mixture component g for
a single dimension, the temporal information are used in
addition to calculate the temporal mean ?
t,g
, the temporal
variance ?
t,g
and the covariance between temporal and
spatial data ?
ts,g
, resulting in the spatio-temporal mean
vector?
g
and covariance matrix?
g
. For a single dimension
of the CHMM for a single state it is deÞned as
?
g
=

?
s,g
?
t,g

, ?
g
=

?
s,g
?
ts,g
?
ts,g
?
t,g

. (1)
Data reproduction is performed through GMR based
on ?
g
and ?
g
for every dimension as described
in [11]. This provides a prototypic (i.e. most likely)
distance mesh
ö
d
t
?R
n(n?1)/2
together with its associated
prototypic spatial variance
ö
?
s,t
?R
n(n?1)/2?n(n?1)/2
ö
?
s,t
= diag(?
s,g,1
,...,?
s,g,n(n?1)/2
), (2)
for every time step t. Both
ö
d
t
and
ö
?
s,t
in combination
with the vectorsp
i,t
provide all information about the robotsÕ
pose and its interaction with environmental objects. The
time-dependent variance
ö
?
s,t
encodes the relative impor-
tance of each element of the prototypic distance mesh,
except for those elements of the distance mesh where the
robotÕs geometry imposes a time-invariant constant distance.
Whereas generally the inverse of the variance as
W
t
=
ö
?
?1
s,t
, (3)
is used to represent the variance-dependent
importance matrixW
t
?R
n(n?1)/2
of every element
of the distance mesh, a more general version is used in this
paper as
W
t
= f(
ö
?
?1
s,t
), (4)
such thatW
t
is positive deÞnite.
By measuring all distances in task space and using only
a single weighting term W
t
we overcome the problem of
weighting joint space and task space distances relatively
to each other, see [3]. As the distance mesh includes all
distances between any link of the robot and the task-relevant
objects in the environment, information are provided for
the time-dependent entire robot pose relative to the objects.
Thus the approach differs from other methods which have to
specify the important limbs (e.g. hands/feed) manually.
C. Motion Adaption
When executing the learned task in a new environment, the
reproduced distance mesh
÷
d
t
(?
t
) at time t generally differs
from?
t
. Yet the goal is to Þnd a robot conÞguration deÞned
by the joint angles?
t
such that the cost functionc
cf
based on
the weighted difference between
÷
d
t
(?
t
) and the prototypic
distance mesh
ö
d
t
becomes minimal
d
rel[i]
=
÷
d
t[i]
(?
t
)?
ö
d
t[i]
ö
d
t[i]
, (5)
c
cf
= d
T
rel
W
t
d
rel
, (6)
?
min
= argmin
?t
(c
cf
). (7)
Differing from [4], the relative
deviation (
÷
d
t[i]
(?
t
)?
ö
d
t[i]
)/
ö
d
t[i]
is used instead of the
absolute deviation
÷
d
t[i]
(?
t
)?
ö
d
t[i]
in order to increase
the inßuence of deviations of small elements of the
distance mesh. The corresponding JacobianJ
cf
for the cost
function c
cf
is derived as
J
cf
=
¶c
cf
¶?
t
. (8)
For execution on a real robot, a two-staged prioritized
differential inverse kinematics (IK) approach [12] with in-
cluded inequality constraints as described in [13] is used.
The Jacobians of primary and secondary task are denotedJ
1
and J
2
and the pseudoinverse of a Jacobian J is J
#
.
The joint space velocities
ú
? are related to the task space
velocities ú r
{1,2}
for primary and secondary task as
ú r
{1,2}
=J
{1,2}
ú
?. (9)
1866
Then the general solution of the prioritized IK such that
the secondary task interacts as least as possible in the least
squares sense with the primary task with E as the identity
matrix is
ú
? =J
#
1
ú r
1
+(J
2
(E?J
#
1
J
1
))
#
(ú r
2
?J
2
J
#
1
ú r
1
), (10)
see [12] for an in-depth discussion about this topic. The
motion imitation task is incorporated in the secondary task.
With K
cf
as a variable gain factor controlling the speed of
the gradient descent of c
cf
, it is
J
2
= J
cf
, (11)
ú r
2
= ?K
cf
c
cf
. (12)
Both Jacobian J
1
and vector ú r
1
consist of three elements,
accounting for balance of the robot (J
com
and ú r
com
), Þxed
position of the feet (J
f
and ú r
f
) and self-collision avoidance
(J
ca
and ú r
ca
). It is
J
1
=

J
com
J
f
J
ca

T
, (13)
ú r
1
=

ú r
com
ú r
f
ú r
ca

T
. (14)
Given sufÞciently slow movements, balance of the robot
can be achieved by keeping the center of mass (COM)
p
com
? R
2
within the support polygon of the robot. A
balance controller is used that moves the COM of the robot
towards the centerp
ref
com
?R
2
of the support polygon
ú r
com
= K
com
(p
ref
com
?p
com
), (15)
with adjustable gain K
com
.
By deÞning three sampling points p
i,j,f
and each feet
transformation T
i
?R
3?3
, i = 1,2 (for example the tri-
hedron T
i
[e
x
,1]
T
, T
i
[e
x
,1]
T
, T
i
[e
z
,1]
T
), a single Jaco-
bian J
f
accounting both for orientational and positional
errors of the feet can be calculated based on the cost function
c
f
=
2
X
i=1
3
X
j=1
kp
ref
i,j,f
?p
i,j,f
k
2
2
. (16)
The scalar ú r
f
is then deÞned in terms of the gradient descent
speed ú r
f
=?K
f
c
f
with gain K
f
.
Self-collision avoidance between two links of the robot is
based upon enclosing cylinders covering all robot links. In
this case, if the distance d
i,ca
between two links falls below
a certain threshold d
min
i,ca
, the desired collision avoidance
velocity is expressed as
ú r
i,ca
= K
ca
(d
min
i,ca
?d
i,ca
) if d
i,ca
< d
min
i,ca
, (17)
with gain factor K
ca
, resulting in ú r
ca
and J
ca
. Joint angle
limits are considered through an underlying controller with
bilateral boundaries.
D. Handling Modeling/Measurement Errors
Using only a task-space based measure does not consider
the geometry of the robot, see Fig. 2: Shown are two different
manipulators, one element of the distance mesh - the distance
base-endeffector - and a hypothetical manipulability ellipsoid
for the endeffector. If due to a modeling/measurement error
the distance base-endeffector has to be increased based
on J
cf
, the joint angle changes are minimal for the left
manipulator. The right conÞguration however may enter a
singularity as a consequence of a non-reachable space. When
using the singular-robust (SR) pseudoinverse, the additive
term of the SR pseudoinverse may cause an unpredictable
drift of the joint angles close to a singularity. Thus another
option based on the manipulability ellipsoid is proposed that
modiÞes the cost functionc
cf
in such a way that the elements
of the distance mesh leading to a singular conÞguration are
weighted less.
Fig. 2. Effect of different manipulability: Changing the distance base-
endeffector (red dotted line) results in higher joint velocities on the right
side than on the left side. To incorporate this effect into the cost function
c
cf
, the manipulability along the direction of each mesh distance element
is calculated (red arrow)
In general, the manipulability ellipsoid is deÞned as
ú r
T
(JJ
T
)
?1
ú r = 1, (18)
and used to calculate the manipulability along an arbitrary
direction. Yet we are only interested in the manipulability
along the direction of each element of the distance mesh,
see the red arrows in Fig. 2. Assuming that ú r
i,t
?R
3
is the
direction the i-th element ofd
t
accounts for, we get
ú r
T
i,t
(J
i,t
J
T
i,t
)
?1
ú r
i,t
= 1, (19)
for every element ofd
t
. It is then
D
man
= diag(kú r
1,t
k
2
,...,


ú r
n(n?1)/2,t


2
), (20)
W
t
= D
man
ö
?
?1
s,t
, (21)
i.e. the elements of the distance mesh which change of
length according to (8) would cause high joint velocities
are both weighted less and considered less during gradient
calculation.
For calculating the elements of D
man
it is necessary to
calculate the Jacobian matrices between any two links of the
robot. AssumingJ
i,t
is the Jacobian of linkG with respect to
link F , i.e.J
i,t
=
F
J
G
. Usually, all Jacobians are calculated
with respect to a base link 0, resulting in
0
J
G
and
0
J
F
. The
calculation of
F
J
G
given only
0
J
G
and
0
J
F
is (see [14])
F
J
G,tr
=R
0

0
J
G,tr
?
0
J
F,tr
+(
0
r
G
?
0
r
F
)
? 0
J
F,?
	
,
(22)
with
0
r
G
and
0
r
F
being the position of link G and F with
respect to the base link 0, the subscript
tr
respectively
?
denoting the translational and rotational part of the Jacobian,
the matrixR
0
accounting for the pose of the base link with
1867
respect to world coordinates and
?
for the cross product and
therefore skew-symmetric matrix of a vector.
E. Complexity Reduction
The approach suffers from two large drawbacks: AO(n
2
)
complexity for a given set of position vectors and redundancy
in the weighting matrix W
t
as its elements can differ
by several magnitudes. Two methods are presented in this
chapter that consider only a subset of all distance mesh
elements when calculating the cost function c
cf
. The Þrst
method considers only a fraction of the largest elements
in W
t
. In case very few elements are considered, this
might cause undesired nullspace movements of robot limbs
not included anymore in c
cf
. The second more elaborate
method interprets the distance mesh as a mechanical system
of springs keeping the points p
i
in position. By removing
springs successively, it is investigated how well the points
p
i
can be Þxed to a certain spatial position. This is achieved
by looking at the volume of the unit energy ellipsoid when
displacing every point p
i
. Differing from the Þrst attempt,
this method encodes not only the weightingW
t
but also the
spatial arrangement of the distance mesh.
More in detail, the j-th element that c
cf
consists of can be seen as a mechanical spring
with displacements
j,t
=
÷
d
j,t
(?
t
)?
ö
d
j,t
and spring
constant D
j,t
=
Wjj,t
ö
d
T
j,t
ö
dj,t
.
Under the assumption that one can achieve a perfect re-
production of the movement, it iss
j,t
= 0 ?j,t. For a single
spring between two endpoints and a small displacement of
one of the two endpoints p
i
in a random direction ?s
i,t
(small with respect to
ö
d
j,t
), the displacement forcef
i,t
?R
3
can be expressed as f
i,t
ÅD
j,t
?s
i,t
. Note that we use the
symmetric matrix D
j,t
? R
3?3
instead of the scalar D
j,t
,
accounting for the fact that ?s
i,t
and
ö
d
j,t
are usually not
coaligned. Consequently, the energy E
i,t
required to cause
the displacement can be written as
E
i,t
=
1
2
?s
T
i,t
D
j,t
?s
i,t
. (23)
if there is more than one spring attached to the pointp
i
, the
displacement energy is the sum
E
i,t
=
1
2
?s
T
i,t
(
X
j
D
j,t
)?s
i,t
. (24)
It is visible that the energy required to displace the point
p
i
depends both on the direction of displacement and the
amount of displacement. In order to Þnd conÞgurations
where a displacement of p
i
is possible without changing
of the energy E
i,t
we look at the size of the constant energy
ellipsoid deÞned by
1 =
1
2
?s
T
i,t
(
X
j
D
j,t
)?s
i,t
, (25)
for every pointp
i
. Similar to the manipulability ellipsoid, its
volume v
i,t
can be calculated up to a constant multiplying
factor as
v
i,t
=
s
det((
X
j
D
j,t
)
?1
). (26)
The Þnal cost function c
r,t
can thus be deÞned as the sum
over all volumes v
i,t
c
r,t
=
X
i=1...n
v
i,t
. (27)
Thus, when selecting the elements of the distance mesh, only
those elements are chosen that minimize c
r
.
The matrixD
j,t
is the combination of the scalar stiffness
value D
j,t
and a matrix M only considering the amount
of?s
i,t
that points in the direction of
ö
d
j,t
. Using the rotation
matrixR
j,t
that coaligns the vector[1,0,0]
T
with
ö
d
j,t
, it can
be calculated as
D
j,t
= D
j,t
R
j,t
?
?
1 0 0
0 0 0
0 0 0
?
?
R
T
j,t
. (28)
Whereas theoretically the subset of distance mesh elements
has to be recalculated at every time step, it leads to dis-
continuities as the distance mesh constantly changes its
appearance. Thus only one single subset is calculated based
on the summed values of W
t
and
ö
d
t
, resulting in the cost
function c
r
. Note that Delaunay tetrahedralization as used
originally in [9] is suboptimal as it cannot consider the
weightingW
t
for all possible distance mesh elements.
III. EXPERIMENTAL EVALUATION
Experiments are conducted using a Cortex motion capture
system tracking the movements of a human test person
at 200Hz and providing realistic full-body movements for
a given task [15]. The free space motion is subsequently
mapped onto a HRP-4 humanoid robotic platform, provid-
ing the link-link distances and overcoming the problem of
different link lengths between human and robot. In addition,
the link-object distances are measured directly from the
human test run, causing some inevitable modeling errors
due to the different Þgure of robot and human. Simulations
are performed in Openrave [16]. Real life experiments are
conducted using a HRP-4 robotic platform. The used param-
eterization is K
cf
= 0.2, K
com
,K
f
= 0.3, K
ca
= 0.5. In
total, Þve demonstrations are performed for each scenario.
Two scenarios are analyzed, see Fig. 3: In the Þrst sce-
nario, named clap, the human puts his hands Þrst on the lap
while standing and claps after that with his hands risen up.
This way, the capability of the link-link distances for human
movement imitation is investigated. For the second scenario,
named box, a box has to be lifted from the right side to
the left side of the table. Here also the link-object distances
between human limbs and the box are taken into account.
The comparison with a conventional method encoding
only the joint angle movement, e.g. [17], is shown in Fig. 4.
On the left side, reproduction of the clap scenario is dis-
played for a standing robot (top) and a sitting robot (bottom)
with Þxed leg joints using the method described in Sec. II-
C. For comparison, the right side shows the similar robot
1868
Fig. 3. Human demonstration and HRP4 robot imitation for the clap and
box scenario
movement based on HMM-encoded joint angles, resulting in
the time varying prototypic joint angle vector
ö
?
t
. To ensure
collision avoidance and a stable stand while keeping the
positional joint error
ö
?
t
??
t
small, a prioritized IK in the
form of
ú
? =J
#
1
ú r
1
+K
?
(E?J
#
1
J
1
)(
ö
?
t
??
t
), (29)
with J
1
, ú r
1
andE similar to Sec. II-B, is used.
The reproduction of the original clap scenario differs
slightly for both cases due to the different control loop
used. Whereas the distance mesh based approach tends to
lean backwards when sitting due to the link-link distances
between legs and upper body, the joint based approach fails
to place the robotÕs hands on the lap as it considers only
joint angles but not the task space relation between lap
and hand. Two additional plots provide quantitative results
of the reproduction quality with respect to the reference
robot motion. The left plot illustrates the imitation quality
in terms of c
cf
(6), that is the similarity of the underlying
distance mesh whereas the right plot shows the cumulative
positional joint error
ö
?
t
??
t
. Clearly the mesh-based method
outperforms the joint-based method in terms of c
cf
and vice-
versa when it comes to the positional joint error.
Fig. 5 displays the adaption capability of the proposed
approach to varied environments. Shown in each row are
the generated robot movements for different box positions,
thus indicating that the prototypic movements can be used
for tasks involving object manipulation with varied object
position.
In order to measure the inßuence of the approach presented
in Sec. II-D, two different box scenarios with the weighting
matrix W
t
set either to D
man
ö
?
?1
s,t
(Òwith manipulabilityÓ)
or
ö
?
?1
s,t
(Òwithout manipulabilityÓ) are analyzed. For the Þrst
scenario no COM, feet or collision constraints have been
considered. For the second scenario previously mentioned
constraints are taken into account. Plotted results of the
fastest moving joint versus execution time are shown in
Fig. 6. Close-to-singular conÞgurations exist at 250ms and
2100ms, resulting in sudden joint speed peaks. However,
the effect (and thus the difference between the two graphs)
decreases with increasing number of additional constraints
stand mesh
sit mesh
stand joint
sit joint
0 500
time [ms]
0
2
4
6
8
10
12
14
16
cum ulative joint deviation
stand mesh
stand joint
sit mesh
sit joint
1000
0
2e5
4e5
6e5
8e5
10e5
12e5
14e5
cum ulative m esh deviation
0 500
stand mesh
stand joint
sit mesh
sit joint
1000
time [ms]
Fig. 4. Comparison between the method proposed in this paper (left) and
a joint angle based approach (right) for the clap scenario for a standing and
sitting robot
Fig. 5. Box scenario reproduction for two different box positions
as the weighting W
t
is encoded in the secondary task and
may be overridden by higher-prioritized tasks.
The amount of redundancy in the distance mesh is in-
vestigated in Fig. 7. Shown are results of both scenarios
using only a fraction of the elements of the distance mesh
as described in Sec. II-E. For the box scenario, 32 points are
used to construct the distance mesh, resulting in a maximum
of (32? 31)/2 = 496 elements for the distance mesh. For
the clap scenario, 21 points are used, resulting in up to 210
elements to be calculated. Given a reference scenario using
all elements of the distance mesh, the average task space
error of each point p
i,t
with respect to its position of the
reference scenario is shown when using only a fraction of
50%, 20%, 10% and 5% distance mesh elements. The blue
and red bars correspond to the simple and elaborate method
as described in Sec. II-E.
Final experiments using the HRP4 robot platform are
displayed in Fig. 3. In order to compensate for the entirely
position-controlled robot, a smaller box has been used for
movement reproduction and compliant elements (sponges)
have been attached to each side of the box to make it more
1869
0 1000 2000 3000
time [ms]
0
1
2
3
4
maximum joint speed [rad/s]
with manipulability
without manipulability
0 1000 2000 3000
time [ms]
0
1
2
3
maximum joint speed [rad/s]
with manipulability
without manipulability
Fig. 6. Cumulative speed of the fastest moving joint versus execution
time with reduced number of constraints (left side) and when considering
all constraints (right side). Close to singular conÞgurations are highlighted
with orange circles
average error [m]
0.036 0.046 0.047
0.063
0.029
0.061
0.083
0.307
average error [m]
0.055
0.141 0.130 0.130
0.082
0.278 0.268 0.268
50%          20%          10%           5% 50%          20%          10%           5%
elab.
simple
simple
elab.
box scenario clap scenario
fraction of used elements fraction of used elements
Fig. 7. Average positional error of all distance mesh points depending on
the fraction of distance mesh elements used
elastic and prevent damage to the robot.
IV. DISCUSSION
Experiments show how the proposed approach can be used
both for free space movements and constrained manipulation.
The existing redundancy of the distance mesh constitutes
a tradeoff between a minimal movement representation and
versatile adaption capabilities regarding object manipulation
and postural changes. Even though its O(n
2
) complexity is
disadvantageous for large-scale scenarios, only a fraction of
all distance mesh elements has to be considered in order to
produce satisfying results. A last problem all variance-based
weighting approaches have in common is the incorporation
of hard positional constraints. Due to measurement noise,
probabilistic encoding and reproduction and pseudoinverse-
based differential inverse kinematics, the adaption to new
environments for tasks involving closed kinematic chains
becomes challenging.
The approach is robust towards changes of the parame-
ters K
com
,K
f
,K
ca
,K
cf
as all of them can be varied by
more than one magnitude without severe alterations of the
reproduction result. The main challenge so far is the large
discrepancy of the elements of the variance matrix
ö
?
s,t
,
prioritizing occasionally the wrong (i.e. from a human per-
spective task-irrelevant) distance mesh elements. Similar to
other HMM/GMR-based movement imitation approaches the
method is highly sensitive to the number of HMM/GMR
states.
V. CONCLUSION AND FUTURE WORK
This paper presents a novel method to encode and re-
produce a prototypic robot movement for either free space
or constrained movements using a purely task space based
imitation measure. The advantage over an entirely joint space
based approach in modiÞed environments is demonstrated
in experiments. As the proposed approach allows one to
take also higher prioritized objectives like balance control or
collision into consideration, execution on a humanoid robot
is discussed in theory and shown by experiments.
Future work will be focused on an improved movement
adaption scheme, enabling one to detect hard positional
constraints automatically and to take them into account
properly.
ACKNOWLEDGEMENT
This work is supported in part within the DFG excel-
lence research cluster Cognition for Technical Systems -
CoTeSys (www.cotesys.org) and by the Ministry of
Education, Science, Sports and Culture, Grant-in-Aid for
ScientiÞc Research (S), 2008-2012, 20220001, ÒEstablishing
Human-Machine Communication through Kinesiology and
Linguistics IntegrationÓ (PI: Y . Nakamura)
REFERENCES
[1] D.-H. Park, H. Hoffmann, P. Pastor, and S. Schaal, ÒMovement repro-
duction and obstacle avoidance with dynamic movement primitives
and potential Þelds,Ó in IEEE Humanoids, 2008, pp. 91Ð98.
[2] F. Stulp, J. Buchli, E. Theodorou, and S. Schaal, ÒReinforcement
learning of full-body humanoid motor skills,Ó in IEEE Humanoids,
2010, pp. 405Ð410.
[3] S. Calinon, F. Guenter, and A. Billard, ÒOn learning the statistical
representation of a task and generalizing it to various contexts,Ó in
IEEE ICRA, 2006, pp. 2978Ð2983.
[4] ÑÑ, ÒOn learning, representing and generalizing a task in a humanoid
robot,Ó IEEE SMC, vol. 37, no. 2, pp. 286Ð298, 2007.
[5] H. Kunori, D. Lee, and Y . Nakamura, ÒAssociating and reshaping of
whole body motions for object manipulation,Ó in IEEE IROS, 2009,
pp. 5240Ð5247.
[6] C. Eppner, J. Sturm, M. Bennewitz, C. Stachniss, and W. Burgard,
ÒImitation learning with generalized task descriptions,Ó in IEEE ICRA,
2009, pp. 3968Ð3974.
[7] D. Kulic and Y . Nakamura, ÒComparative study of representations for
segmentation of whole body human motion data,Ó ser. IEEE IROS,
2009, pp. 4300Ð4305.
[8] N. Jetchev and M. Toussaint, ÒTask space retrieval using inverse
feedback control,Ó in ICML, 2011, pp. 449Ð456.
[9] E. S. L. Ho, T. Komura, and C.-L. Tai, ÒSpatial relationship preserving
character motion adaptation,Ó in ACM SIGGRAPH, 2010, pp. 33:1Ð
33:8.
[10] T. Moulard, E. Yoshida, and S. Nakaoka, ÒOptimization-based motion
retargeting integrating spatial and dynamic constraints for humanoid,Ó
in ISR, 2013, pp. FA2Ð4.
[11] A. Billard, S. Calinon, R. Dillmann, and S. Schaal, ÒRobot program-
ming by demonstration,Ó in Springer Handbook of Robotics, 2008, pp.
1371Ð1394.
[12] Y . Nakamura, Advanced robotics - redundancy and optimization, 1991.
[13] K. Yamane and Y . Nakamura, ÒNatural motion animation through
constraining and deconstraining at will,Ó IEEE TVCG, vol. 9, pp. 352Ð
360, 2003.
[14] T. Sugihara, Y . Nakamura, and H. Inoue, ÒRealtime humanoid motion
generation through zmp manipulation based on inverted pendulum
control,Ó in IEEE ICRA, 2002, pp. 1404Ð1409.
[15] G. Venture, K. Ayusawa, and Y . Nakamura, ÒMotion capture based
identiÞcation of the human body inertial parameters,Ó in IEEE EMBS,
2008, pp. 4575Ð4578.
[16] R. Diankov, ÒAutomated construction of robotic manipulation pro-
grams,Ó Ph.D. dissertation, Carnegie Mellon University, Robotics
Institute, 2010.
[17] D. Kulic, W. Takano, and Y . Nakamura, ÒOnline segmentation and
clustering from continuous observation of whole body motions.Ó IEEE
Transactions on Robotics, vol. 25, no. 5, pp. 1158Ð1166, 2009.
1870
