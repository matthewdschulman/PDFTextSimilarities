  
? 
Abstract— To efficiently explore a surface using the sense of 
touch, a novel contact sensing finger was created and a surface 
following control algorithm for the finger was devised. Based on 
the accurate estimation of contact locations, and the direction 
and magnitude of the normal and tangential forces, the finger 
can robustly and rapidly follow surfaces with large change in 
curvature while maintaining a desired constant normal force. In 
this paper, the design and testing of the contact sensing finger 
are presented and the control algorithm for surface contour 
following is proposed and validated using objects with different 
shapes and surface materials. The results demonstrate that 
using the developed finger and the control algorithm, a surface 
can be efficiently explored with rapid sliding speed. To 
demonstrate the potential applications of the proposed 
approach, the friction properties of an explored object surface 
are computed and, for a known object, its pose is estimated. 
I. INTRODUCTION 
Surface exploration through touch is an essential 
mechanism for humans to understand the physical properties 
of an unknown object, such as the surface roughness, object 
shape and compliance [1], [2]. Similarly, to allow a robot to 
autonomously work in unstructured environments, it is 
essential that the robot can perform efficient surface 
exploration to recognize the various attributes of the 
unknown environment with which it interacts. To date, 
numerous methods have been proposed to identify object 
surface properties through surface exploration. The uses of 
tactile sensors to classify the global shape of an object 
through multiple touches have been proposed in [3], [4], [5]. 
In [6], [2], a series of surface sliding strategies have been 
proposed to allow a dexterous robotic finger to recognize the 
object shape and to detect small surface features. To 
recognize surface textures, various methods of using a robotic 
finger to slide over a surface have been proposed, for example 
by analyzing the vibrations [7], [8], [9] or interaction forces 
[10].  
One of the significant challenges to implement these 
aforementioned surface exploration methods for practical 
uses is the capability of controlling a robotic finger to 
adaptively and rapidly follow an unknown surface while 
maintaining a desired gentle force based on the sense of touch. 
A number of studies have applied force/position based 
control scheme for surface contour following. The limitation 
of this approach is that it either requires at least partial 
information of object shape or assumes the non-frictional 
sliding [11], [12], [13]. In addition, this approach has 
 
This work is supported by Grasp Stabilisation Control project funded by 
the TSB - Technology Strategy Board, UK. Junghwan Back, J. Bimbo, 
Y.Noh, L.D. Seneviratne K. Althoefer and H. Liu are with Department of 
Informatics, King’s College London, UK, WC2R 2LS. 
*indicates the correspond author, email{ hongbin.liu@kcl.ac.uk} 
 
 
difficulty to adapt to the rapid change in surface curvature and 
normally has slow execution speed. To improve the 
efficiency of surface following, a popular method is to use 
vision or proximity sensors to estimate and predict surface 
trajectories, such as the works done in [14], [15]. However the 
applications of these methods for robotic hand surface 
exploration are limited, due to the complexity of integrating 
proximity or vision sensors on the hand and the vision 
occlusions which is often generated. More recently, the study 
of surface contour following using a fingertip equipped with 
three axial tactile array sensors was introduced in [16]. 
 This study shows that using distributed three-axial tactile 
information allows the finger to successfully follow an 
unknown shape. However the difficulty of developing 
miniaturized three-axial tactile array sensor and the slow 
excitation time of this method limit its applications. To allow 
a robot finger to rapidly and adaptively follow an unknown 
surface using the sense of touch alone, we propose a novel 
and efficient method for surface following control by using a 
contact sensing finger. In our previous work [10], a contact 
sensing fingertip has been developed with the capability to 
identify simultaneously the contact location and the direction 
and magnitude of the normal and tangential forces at a high 
frequency. In this paper, we developed a robotic finger 
integrated with the contact sensing fingertip and propose a 
surface following control scheme for utilizing the precise 
contact information obtained by the finger. Compared to 
existing methods, the advantages of the proposed method 
includes: 1) no prior knowledge of object shape is required 
and no restriction on surface friction level; 2) due to the 
accurate estimation of instantaneous normal and tangential 
force vectors provided by the fingertip, the surface following 
control is robust and adaptive to sudden geometry change of 
the surface shape; 3) the proposed control algorithm is simple 
and effective, thus allow rapid execution time; 4) only a 
force/torque is required for each finger, thus easy for practical 
implementation. The performance of the surface following 
control using the developed finger has been investigated 
using objects with different shapes and surface materials. The 
results demonstrate that the finger can successfully and 
rapidly follow all the surfaces while maintain a desired gentle 
normal force, even when the surface has a sharp change in 
curvature. The sliding speed of the finger can achieve >5 
mm/s. The experiments show that from the controlled surface 
exploration, the finger is capable of estimating the friction 
properties of the object surface and also the pose of the object 
if the shape is known. 
 
Control a Contact Sensing Finger for Surface Haptic Exploration  
Junghwan Back, Joã o Bimbo, Yohan Noh, Lakmal Seneviratne, Kaspar Althoefer, Hongbin Liu* 
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 2736
  
II. THE CONTACT SENSING FINGER 
A. Finger Design  
To effectively conduct surface haptic exploration, a robotic 
finger was developed, with three links and two revolute joints, 
as shown in Fig. 1. This finger equipped with a contact 
sensing fingertip which is capable of accurately estimating 
the instantaneous friction force and the normal force without 
the prior knowledge of the surface geometry. The algorithm 
for computing such information is introduced in detail in [10]. 
The fingertip consists of a 6-axis force/torque sensor (ATI 
Nano17, resolution 0:003 N) and a hemispherical hat as 
shown in Fig. 1. The fingertip was made of the ABS 
(Acrylonitrile butadiene styrene) plastic material and has a 
diameter of 20 mm. 
 
 
 
Figure 1. The developed Contact sensing finger 
 
Each joint of the finger possesses a DC motor (Faulhaber 
U1512, with 324 gear ratio) and two gears (32 teeth, and 12 
teeth), resulting a total gear ratio of 864. The DC motor driver 
receives velocity input values from the Simulink model and 
outputs encoder values using serial communication between 
the driver and the host computer, an Intel i5 CPU 3.2GHz, 
and 4GB RAM. The Simulink model on the host computer 
reads the output of the force-torque sensor via a National 
Instruments (NI) PCIe-6320 data acquisition card. 
B. Computing of Contact Information 
The information provided by the developed finger includes 
the contact location on fingertip in finger base frame of 
reference and the instantaneous normal and tangential force 
vectors. Normal and tangential forces are calculated based on 
the estimation of the contact location on the fingertip in the 
force/torque sensor reference frame. The contact equilibrium 
system equation proposed in [17] is used to calculate the 
contact location based on force/torque measured. 
 
g(x)= 
{
 
 
 
 
k?? 1
?? ? ? +? ? ? ?? ? k?? 2
?? ? ? +? ? ? ?? ? k?? 3
?? ? ? +? ? ? ?? ? S(x,y,z)
                       (1) 
 
Eq. (1) shows the system of equations to be solved. k?? ? is 
the local torque, and f and m are the forces and moments 
measured on the sensor. S is the surface equation. The 
solution to these equations is found iteratively, using the 
Levenberg-Marquardt method (LMA), as suggested in Liu et 
al [10]. Once the x-y-z coordinates of the contact location are 
computed, the normal vector Q on that point can be calculated 
as ?S(x,y,z),, and the normal component of that force is the 
projection of the resultant force on that normal vector, 
calculated using (2). The tangential component is then 
calculated using (3). 
 
      ? ? =
? ? ? ? ? ? ?  
   (2) 
 
       ? ? =
√1?cos
? ? ?? ?
2
cos(
? ? ?? ?
)
? ?   
   (3) 
   
Applying the above algorithm, the contact information is 
obtained at the frequency of 543 Hz. To validate the accuracy 
of the contact location estimation, the fingertip was marked at 
9 points as shown in Fig. 3. A caliper was used to contact the 
centre locations of two corresponding markers sequentially. 
The distance between the two contact locations identified by 
the algorithm is compared with the caliper’s reading. The 
results are shown in Table I. It was found that the mean error 
was 0.41mm, indicating a high accuracy in contact location 
estimation. 
 
TABLE 1.  VALIDATION OF CONTACT LOCATION ACCURACY 
 
Number Distance from 
Caliper 
Distance from  
Sensor 
Error 
1 
2 
3 
4 
10.854 mm 
11.84 mm 
17.74 mm 
18.73 mm 
10.8561mm 
11.6297mm 
16.7735mm 
19.1651mm 
0.021mm 
0.22103mm 
0.9665mm 
0.4351mm 
 
 
        (a) Caliper Measuring               (b) Fingertip marker with dots at 
                                                    known locations 
 
Figure 2. Examination for accuracy for contact location estimation  
 
Validation of the estimation of normal and tangential 
forces is done by using a benchmarking force-torque sensor, 
pressed flat against the surface, the same procedure as 
described in [10]. The normal force on the fingertip should be 
equal to the z-axis force on the benchmarking sensor, and the 
tangential force on the fingertip should be equal to the norm 
of the resultant x and y-axis forces on benchmarking sensor. 
The maximum errors of normal and tangential forces were 
0:075 and 0:08 Newton respectively, which is comparable to 
the sensor’s noise level. 
 
 
2737
  
III. SURFACE FOLLOWING CONTROL ALGORITHM 
As aforementioned, the effective surface exploration 
requires both force and position control [4], since forces 
generated by the surface contact are coupled with the velocity 
and the position of fingertip. In this paper a position controller 
is developed to work in parallel with a force controller which 
provides desired contact normal or tangential forces. Joint 
encoder values, magnitude and direction of forces are utilized 
as the feedback to the controller. In some situations, the 
fingertip cannot reach desired locations because of the 
resistance force generated by the material surface, resulting 
undesired overshoot and undershoot. This implies that an 
automatic PID gain values adjustment algorithm is required. 
This however, requires high precision control, which is often 
inconvenient. In view of this limitation, a PD controller is 
proposed in this paper to achieve the velocity control using 
desired velocity ratios between the finger joints. It can be 
proven that fingertip trajectory is decided by the ratios 
between the velocities of individual joints irrespective of 
absolute velocities (see Appendix for the proof). 
 
 
Figure 3. Trajectory Analysis (a) trajectories with velocity ratio 2:1;(b) 
gradients on desired x,y location (start location was (0,0), and desired                                
direction (x,y)) 
 
 
Figure 4. The schematic drawing of the control algorithm for surface contour 
following  
 
The velocity ratio controller initially plans a trajectory 
which intersects with the object surface. After the finger is in 
contact with the surface, force feedback is used to 
continuously adjust the velocity ratio of finger joints to allow 
smooth surface following. As shown in Fig.4, the finger 
attempts to move along the tangential direction of the surface. 
Meanwhile, the finger’s position is adjusted along the normal 
direction to reach a desired normal contact force. The P gain 
was chosen so that the angular rotation of each joint is one 
degree per sample time under the initial voltage level and 
zero-load. Role of D gain is to suppress the sharp deviation of 
normal force with respect to the reference. The D gain is 
adaptive depending on contact condition.  
 
 
 
Figure 5. The control diagram for surface contour following using the contact 
sensing finger  
 
The control diagram of the surface following is illustrated 
in Fig.5. The current location of the fingertip is calculated 
with the forward kinematics, using each joint’s encoder value 
as shown below, in (4), where c 1 and s1 are short for cos(? 1
), 
and sin(? 1
), respectively and l1 are the link lengths of the 
robot. 
 
   x=  ? 3
? 1
? 2
?? 3
? 1
? 2
+? 2
? 1
+? ?   
                 y=  ? 3
? 1
? 2
+? 3
? 1
? 2
+? 2
? 1
+? 1
+? ?  
   (4) 
 
The each joint’s angle is limited: for joint 1, 0≤? 1
≤
? 2
 and 
for joint 2, ?
? 2
≤? 2
≤0. x s and y s are the contact locations 
on the fingertip. Then, the desired next position x n, y n of the 
fingertip are given by the direction of the tangential forces 
??
? ,??
? , as shown in 5.  
 
                           ? ? =? +??
? 
                           ? ? =? +??
? 
   
  (5) 
 
? 2? =cos
?1
[
? 2
+? 2
?? 2
2
?? 3
2
2? 2
? 3
]  
   (6) 
 
? 1? = cos
?1
[
?? ? 3
? 2
?(? 3
? 2
+? 2
)? +? 3
? 2
? 2
(?? 3
2
? 2
2
)?(? 3
? 2
+? 2
)
2
] 
   (7) 
 
The angle of joint 2 is determined first using (6). Once the 
next  ? 
2
 is determined, the value of ? 
1
 in next step can be 
formulated using the inverse kinematics model as (7). Once 
the current  ? 
1
,  ? 
2
 and the angular positions  ? 
1? , ? 
2? of 
the next step are known, we can calculate the velocity ratio as 
shown in 8.  
 
?? ? 1
>0, ? 1
= 
? 1? ? 1
,
 ,???? ? 1
= 
? 1
? 1? ,
 
?? ? 2
<0, ? 2
= 
? 2? ? 2
,
 ,???? ? 2
= 
? 2
? 2? ,
  
   (8) 
 
The values of ? 1
and ? 2
 are fed into the PD controller directly. 
These values are modified according to the normal and 
tangential force vectors. When the normal force is outside the 
reference range of force, the fingertip follows the normal 
2738
  
direction to adjust the normal force, as in (9). 
 
          ??
? =
? ??
?? ? ?
   ,      ? ? =?
? ??
?? ? ?
 
 
   (9) 
      if ? ? <min (??? ) : ??
? = ???
? 
                      ??
? = ???
? 
 
 
Otherwise, when the normal force is inside the range of  
0.8N ≤? ? ≤ 1.2N, the controller drives the finger along the 
tangential force direction as in (10). 
 
 
??
? =
? ??
?? ? ?
    ? ? =
? ??
?? ? ?
 
   
(10) 
 
 
 
Figure 6. Surface following on different objects. The dots plot the recorded 
contact trajectory 
 
The developed surface following controller has been 
implemented and achieved a very good performance. It was 
found that the finger can rapidly and robustly follows an 
unknown shape, Fig. 6. During the surface following, the 
normal force is capable to maintain almost constantly at the 
desired level, Fig. 7.  
 
 
 
Figure7. Surface following while maintaining a constant normal force. Three 
different ranges of normal force were applied: (0.8-0.9), (0.6-0.7), (0.2 - 0.3), 
units are in “N” 
IV. FINGER CONTROL FOR SURFACE HAPTIC             
EXPLORATION - APPLICATIONS 
The algorithm for surface exploration is built in Matlab 
Simulink. The finger is attached to the end effector of a 
Mitsubishi RV-6SL robot arm which is controlled using the 
Robot Operating System (ROS) on a separate computer. The 
finger and the arm are synchronized and communicate via a 
UDP communication socket, and the system is shown in Fig. 
10. The two main objectives of surface exploration 
experiments include surface friction properties recognition 
and pose estimation of the target object. During the 
exploration, the finger slides over an unknown shape 
following 5 to 7 different paths; the normal force is 
maintained at range of 0.6-0.7 N. In total, eight different 
objects were investigated. 
 
 
 
Figure 8. Experimental setup 
 
 
 
Figure 9. Exploration of a perfume bottle 
 
 
Figure 10. Exploration of a float wooden board 
A. Friction Properties Acquisition 
Given the ability of the proposed system to measure normal 
and tangential forces during an exploration task, the friction 
ratio between these forces ( ? ? /? ?  ) can be evaluated. While 
the finger is stroking an object, this ratio will not exceed the 
static friction coefficient of each material [18], [19], [10]. 
In the experiments carried out, objects with different 
surface materials were tested and the friction ratios obtained 
are plotted in Fig. 11. This allowed the identification of the 
stroked object, among a database of eight objects (rubber ball, 
rubber tape, steel slab, aluminium can, aluminium bottle 
computer mouse, perfume glass and wooden board). The 
results are expressed in Table II. This information can 
provide clues to recognize the surface material and also for 
object identification, in case there exists previous knowledge 
of existing objects. 
2739
  
 
 
Figure 11. Friction ratios during strokes on different materials. Two strokes 
on each material are displayed. 
B. Object Pose Estimation From Exploration 
  After the identification of the explored object, the spatial 
location of each contacted point on the surface can be 
recorded, taking into account the contact location on the 
fingertip, the forward kinematics of the finger and the pose 
of the robot arm end-effector where the finger is attached, as 
shown previously in Fig. 10. 
 
TABLE II. VALIDATION OF COEFFICIENT OF FRICTION 
 
Object Coefficient of 
Fiction 
Object Coefficient of 
Friction 
Rubber ball 0.5185 Aluminium can 0.1510 
Rubber tape 0.2275 Perfume 
case(glass) 
0.1097 
Wood flat 0.2291 Mouse(plastic) 0.0974 
Steel flat 0.1490 Aluminium 
bottle 
0.1218 
 
This contact information can provide an estimate of the 
object’s current pose by fitting the object’s known geometric 
shape to the finger surface trajectories [20]. One method of 
fitting these two sets of points is the Iterative Closest Point 
(ICP) [21]. A transform is found on the object such that the 
mean-square distances are minimised. In this paper, Kjer’s 
Matlab implementation of ICP was used [22], and yielded the 
results shown in Fig. 12 and 13 for a computer mouse and a 
flat wooden board respectively. These results show that the 
proposed exploration strategy allows the tracking of an 
object’s surface, enabling the estimation of a known object’s 
pose. In Fig. 13 the estimation cannot accurately detect where 
on the board it is touching. This is because in this particular 
object, the points collected during the exploration task could 
fit anywhere on the two larger sides of the board. Despite this 
limitation, the 3D orientation of the object is correctly 
identified.  
 
 
  (a) Finger exploration on a computer mouse    (b) Pose estimation result  
 
Figure 12. Results for the computer mouse exploration 
 
 
 
(a) Exploration on a wooden board            (b) Pose estimation results 
   
Figure 13. Results for a flat wooden board 
 
The fitting errors for both fittings are shown in Fig. 14. 
After 30 iterations, the mean error for the computer mouse 
and for the wooden board fitting were respectively 1.419 mm 
and 0.7931 mm. 
 
Figure 14. Fitting errors for the ICP algorithm after 100 iterations. (Note the 
log scale) 
V. CONCLUSIONS AND FUTURE WORK 
This paper presented a robotic finger and a control 
algorithm to have it explore an object’s surface maintaing 
contact with a reasonably constant normal force. The control 
strategy is based on velocity ratio control between the two 
joints of the finger. It uses the contact information (contact 
location and normal and tangential forces) provided by a 
six-axis force-torque sensor mounted on a fingertip. The 
proposed strategy was proved successful in different surfaces 
and geometries. To illustrate the advantages of this 
exploration method, two applications were presented where 
the finger was able to explore the surface to obtain friction 
information and, given the set of contact points obtained 
2740
  
during the exploration task, to have a good estimate of the 
object’s position and orientation. 
Further developments of this system include the 
recognition of the object based not only on its friction 
properties but also on the local geometries detected. The 
exploration could also be intelligently driven to look for 
particular features and to follow them, such as edges, handles 
and buttons. 
APPENDIX 
 
Proposition: The trajectory of the fingertip (regardless of 
time) is only dependent on the velocity ratio between two 
finger joints  
 
Proof: Given the velocity ratio between two joints are 
constant, the following equation hold, where ? ? 1,2
,??? ??
? 1,2
 
are the different angular velocity sets. 
 
? 1
? (? )
? 2
? (? )
=
??
1
? (? )
??
2
(? )
=?                               (11) 
 
Rearrange Eq.11, the following relationship holds,   
 
? 1
? (? )
??
1
? (? )
=
? 2
? (? )
??
2(? )
=? (? )                           (12) 
 
Given the position of the fingertip is a function of the two 
joint angles, i.e. ? =? (? 1
,? 2
), where ? is position, we need 
to prove that if ? 1
(T)=??
1
(K), where T and K are the different 
time, then ? 2
(T)=??
2
(K). 
 
Let ? 1
(T)=∫ ? 1
? (? )??
? 0
 and ??
1
(K)=∫ ??
1
? (? )??
? 0
   (13) 
 
From Eq.13, we obtain  
 
??
1
(K)=∫
1
? (? )
? 1
? (? )??
? 0
=∫ ? 1
? (? )??
? 0
          (14) 
 
Let ? 2
(T)=
1
? ∫ ? 2
? (? )??
? 0
                    (15) 
From Eq.11, we obtain, 
 
? 2
(T)=
1
? ∫ ? 1
? (? )??
? 0
                       (16) 
 
??
2
(K)=∫
1
? 1
? (? )
? 2
? (? )??
? 0
=
1
? ∫
1
? (? )
? 1
? (? )??
? 0
       (17) 
 
Since ∫
1
? (? )
? 1
? (? )??
? 0
=∫ ? 1
? (? )??
? 0
              (18) 
 
Thus, ??
2
(K)=? 2
(T). Hence the trajectory is determined 
only by the velocity ratio and the statement is proved. 
REFERENCE 
[1] R. L. Klatzky, S. J. Lederman, and V. a. Metzger, “Identifying Objects 
by touch: an “expert system”,” Perception & psychophysics, vol. 37, no. 
4, pp. 299–302, Apr 1985. 
[2] M. Okamura, and R.Cutkosky, “Feature Detection for Haptic 
Exploration with Robotic Fingers,” The International Journal of 
Robotics Research, vol. 20, no. 12, pp. 925–938, Dec 2001. 
[3] H. Liu, X. Song, T. Nanayakkara, L.D.  Seneviratne, K. Althoefer, “A 
computationally fast algorithm for local contact shape and pose 
classification using a tactile array sensor”, in Proceedings of IEEE 
International Conference on Robotics and Automation (ICRA), pp. 
1410-1415, 2012. 
[4] M. Meier, M. Schopfer, R. Haschke, and H. Ritter, “A Probabilistic 
Approach to Tactile Shape Reconstruction,” IEEE Transactions on 
Robotics, vol. 27, no. 3, pp. 630–635, June 2011. 
[5] N. Gorges, S. E. Navarro, D. G¨oger, and H. W¨orn, “Haptic object 
recognition using passive joints and haptic key features,” in 2010 IEEE 
Int. Conf. on Robotics and Automation, pp. 2349–2355,  May 2010. 
[6] A. Okamura, M. Turner, and M. Cutkosky, “Haptic exploration of 
objects with rolling and sliding,” in Proc. IEEE Int. Conf. on Robotics 
and Automation, vol. 3, pp. 2485–2490, Apr 1997  
[7] M. Tanaka, J. L. Leveque, H. Tagami, K. Kikuchi, and S. Chonan, 
“The ”Haptic Finger”- a new device for monitoring skin condition,” 
Skin Research and Technology, vol. 9, no. 2, pp. 131–136, Jan 2003. 
[8] K. Hosoda, Y. Tada, and M. Asada, “Anthropomorphic robotic soft 
fingertip with randomly distributed receptors,” Robotics and 
Autonomous Systems, vol. 54, no. 2, pp. 104–109, Feb 2006. 
[9] N. Jamali and C. Sammut, “Majority Voting: Material Classification 
byTactile Sensing Using Surface Texture,” IEEE Transactions on 
Robotics, vol. 27, no. 3, pp. 508–521, June 2011. 
[10] H. Liu, X. Song, J. Bimbo, L. Senerivatne, and K. Althoefer,   “Object 
Surface Material Recognition through Haptic Exploration using an 
Intelligent Contact Sensing Finger,” in Proceedings of IEEE/RSJ Int. 
Conf. on Intelligent Robots and Systems (IROS’ 2012), Oct 2012. 
[11] U. Nunes, P. Faia, and A. T. de Almeida, “Sensor-based 3-D  
autonomous contour-following control,” in Proc. IEEE/RSJ Int. Conf. 
on Intelligent Robots and Systems IROS’94), vol. 1. IEEE, pp. 
172–179, Sep 1994. 
[12] K. Kiguchi and T. Fukuda, “Position/force control of robot 
manipulators for geometrically unknown objects using fuzzy neural 
networks,” IEEE Transactions on Industrial Electronics, vol. 47, no. 3, 
pp. 641–649, June 2000. 
[13] D. Bossert, U.-L. Ly, and J. Vagners, “Experimental evaluation of a 
hybrid position and force surface following algorithm for unknown 
surfaces,” in Proceedings of IEEE International Conference on 
Robotics and Automation, vol. 3,  pp. 2252–2257. Apr 1996. 
[14] J. Baeten and J. De Schutter, “Hybrid vision/force control at corners in 
planar robotic-contour following,” IEEE/ASME Transactions on 
Mechatronics, vol. 7, no. 2, pp. 143–151,June 2002. 
[15] H. Koch, A. Konig, K. Kleinmann, A. Weigl-Seitz, and J. Suchy, 
“Predictive robotic contour following using lasercamera-triangulation,” 
in 2011 IEEE/ASME International Conference on Advanced Intelligent 
Mechatronics (AIM), pp.422–427 July 2011. 
[16] M. Ohka, J. Takata, H. Kobayashi, H. Suzuki, N. Morisawa, and H. B. 
Yussof, “Object exploration and manipulation using a robotic finger 
equipped with an optical three-axis tactile sensor,” Robotica, vol. 27, 
no. 05, p. 763–770, Nov 2008. 
[17] A. Bicchi, J. K. Salisbury, and D. L. Brock, “Contact Sensing from 
Force Measurements,” The International Journal of Robotics Research, 
vol. 12, no. 3, pp. 249–262, June 1993.  
[18] X. Song, H. Liu, T. Nanayakkara, K. Althoefer, L. Senerivatne,  
“Efficient Break-Away Friction Ratio and Slip Prediction Based on 
Haptic Surface Exploration”, IEEE Transactions on Robotics, vol 
30,no.1, pp.203-219, 2014. 
[19] H. Liu, X. Song, T. Nanayakkara, K. Althoefer, L. Seneviratne, 
“Friction estimation based object surface classification for intelligent 
manipulation,” Workshop on Autonomous Grasping at IEEE 
International Conference on Robotics and Automation, 2011. 
[20] J. Bimbo, H. Liu, L. Senerivatne, and K. Althoefer, “Combining  Touch 
and Vision for the Estimation of an Object’s Pose During    
Manipulation,” in Proceedings of IEEE/RSJ International Conference 
on Intelligent Robots and Systems (IROS’2013) , Nov 2013. 
[21] P. J. Besl and N. D. McKay, “A method for registration of 3-D shapes,” 
IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 
14, no. 2, pp. 239–256, Feb 1992. 
[22] H. M. Kjer and J. Wilm, “Evaluation of surface registration algorithms 
for PET motion correction,” Bachelor’s thesis, Technical University of 
Denmark, DTU, DK-2800 Kgs. Lyngby, Denmark, 2010. 
2741
