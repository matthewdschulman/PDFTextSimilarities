Grid-based Mapping and Tracking in Dynamic Environments
using a Uniform Evidential Environment Representation
Georg Tanzmeister, Julian Thomas, Dirk Wollherr and Martin Buss
Abstract— Mapping and tracking in dynamic environments
for autonomously-moving robots is still challenging, despite
being essential tasks. They are often done separately using
occupancy grids and established object tracking algorithms. In
this work, an approach is presented that estimates a uniform,
low-level, grid-based world model including dynamic and static
objects, their uncertainties, as well as their velocities. It does
not require existing object tracks to ﬁlter out data points not
used for creating and updating the map. Nor does it require
that measurements can be classiﬁed into belonging to a static or
to a moving object. Promising results from experiments with an
autonomous vehicle equipped with a laser scanner demonstrate
the usefulness of the approach.
I. INTRODUCTION
Mapping and tracking are typically done as separate
tasks. While for the former, feature-less occupancy grid
mapping [1] is well established, the latter is often done using
model and shape assumptions. In occupancy grid mapping,
the world is assumed to be static and thus the occupancy
probability of each cell represents the probability of that
cell being occupied by a static object. The environment
is, however, rarely entirely static. If measurements from
dynamic objects are integrated into the grid, artifacts occur.
This can lead to problems in navigation, consider, e.g., an
autonomous vehicle driving behind another vehicle.
If a sensor is used that cannot measure the dynamics of
a point in space, e.g., a laser scanner, often inconsistencies
between the map built so far and the current scan are used to
detect and ﬁlter out those measurements [2]–[6]. Sometimes,
the Dempster-Shafer theory of evidence is used to better
model these inconsistencies as conﬂicts [7]. Using incon-
sistencies as evidence for dynamic information, however,
conﬂicts the original idea of ﬁltering sensor measurements
to incorporate for noise. In addition, such approaches often
fail, e.g., at objects moving perpendicular to the sensor.
As important as a robust representation of the static envi-
ronment, is the representation of the dynamic environment.
In some work, the inconsistencies during mapping are used
as input to an object tracker [4]–[6] and most notably SLAM
and DATMO [4]. In other work, it is directly relied on an
object tracker [8] to ﬁlter out the corresponding measure-
ments that are then not used to update the stationary grid.
Obviously though, relying on object tracking simply transfers
the problem and with the notion of objects and tracks, in
G. Tanzmeister and J. Thomas are with BMW Group Re-
search and Technology, D-80992 Munich, Germany, {georg.tanzmeister,
julian.thomas}@bmw.de.
D. Wollherr and M. Buss are with the Institute of Automatic Control
Engineering of the Technische Universit¨ at M¨ unchen, D-80290 Munich,
Germany, {dw, mb}@tum.de.
comparison to cells or data points, comes the data association
problem. All of the above approaches have in common that
the decision of whether a single sensor measurement is
used to update the grid, is binary and its uncertainty is not
modeled. In addition, separating mapping and tracking leads
to inconsistencies between the representations.
There are also approaches that combine the estimation
of the static and the dynamic environment. In [9] Rao-
Blackwellized SLAM is combined with conditional particle
ﬁlters for tracking, but measurements need to undergo clas-
siﬁcation into static or dynamic. In SLAMMOT [4] a joint
posterior over all generalized objects and the robot pose is
calculated. It is, however, in general computational infeasible
as the authors point out, and builds upon the notion of objects
requiring features and data association. A model-free, grid-
based approach is the Bayesian Occupancy Filter (BOF) [10].
It uses a four-dimensional grid, i.e. two dimensions for the
location plus two dimensions for the velocity. Apart from
scaling and computational issues regarding 4-D grids, the
velocities need to be discretized. Extensions were made to
work in two dimensions [11], while still requiring velocity
discretization, and to increase performance by using an
existing map of the environment [12], [13].
In a different, particle-based approach [14] the velocities
do not need to be discretized but are estimated as continuous
distribution. The particles have a position and speed and can
move freely between cells. The authors describe the particles
as both, velocity hypotheses and the building blocks of the
environment. The particles in a particular cell represent, on
the one hand, the velocity distribution and on the other does
the number of particles represent the occupancy likelihood.
The exact role of the particles and the probability distribution
that is approximated stays, however, unclear. In addition, the
resulting grids do not model free-space and seem noisy. We
still ﬁnd the idea very promising and use it as base for part
of our work.
In this work, a novel evidential framework for simultane-
ously mapping and tracking of the environment is presented.
It uses a uniform, grid-based representation without the
need of shape assumptions nor data association. It also does
not require measurements to be pre-classiﬁed into static or
dynamic and is able to model their uncertainty. The rest of
the paper is structured as follows. In Section II we build
upon the work from [14] and formulate a particle ﬁlter-based
dynamic environment estimator. In Section III, the evidential
framework is introduced, which robustly represents the static
world, the free space and the dynamic world. And ﬁnally, in
Section IV experimental results are given.
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 6090
II. GRID-BASED ESTIMATION AND TRACKING OF THE
DYNAMIC ENVIRONMENT USING PARTICLE FILTERS
In this section, the particle ﬁlter-based dynamic estimator
is given. The approach works on the cell level and thus
without object shape assumptions. As described above, it
is built upon the ideas presented in [14], but this paper
presents a different formulation. In addition, it is shown how
continuous evidences for static and dynamic can be deduced,
which will be used in Section III.
A. Overview
The goal of the method given in this section is to estimate a
mapv
t
of velocity distributions at a particular time instancet.
Every cell i of the velocity map v
t
= {v
i
t
} has attached
to it a random vector V = (V
x
, V
y
)
T
that represents
the velocity distribution in the x and y direction. The cells,
however, although representing dynamic information, are a
ﬁxed discretization of the world in individual areas that do
not move in space.
Similar to occupancy grid mapping, the problem of es-
timating the map posterior p(v
t
|z
1:t
,x
1:t
) given the mea-
surements z
1:t
and the robot poses x
1:t
is broken down
into estimating p(v
i
t
|z
1:t
,x
1:t
) for every cell i using the
assumption that the cells are independent in a single time
instance t
p(v
t
|z
1:t
,x
1:t
) =
Y
i
p(v
i
t
|z
1:t
,x
1:t
). (1)
Notice that the cells are only independent within t. This
does not hold over consecutive time instances, as dynamic
objects move over cells over time. In other words, it is
assumed that the velocity distribution v
i
t
of cell i is in-
dependent of v
j
t
of cell j at time t. This assumption is,
arguably, as strong as the cell occupancy independence in
the standard occupancy grid mapping algorithm. From time
instance t?1 to t, however, the full map posterior is used
for the calculation p(v
i
t
|z
1:t
,x
1:t
) of a particular cell i
p(v
i
t
|z
1:t
,x
1:t
) =
Z
p(v
i
t
|v
t?1
,z
1:t
,x
1:t
)p(v
t?1
|z
1:t?1
,x
1:t?1
)dv
t?1
. (2)
B. Estimating Cell Velocities using Particle Filters
Particle Filters, as described e.g., in [15], are a nonpara-
metric and often used version of the Bayes ﬁlter. They have
proven to be very efﬁcient for low-dimensional problems,
such as localization and also for solving the SLAM problem,
e.g. FastSLAM, where Rao-Blackwellization is used to fac-
torize the full posterior into a localization term, implemented
using particles, and a mapping term, where the robot pose is
assumed to be known [16].
In this approach, the independence assumption from (1), is
used so that particles can represent low-dimensional velocity
hypotheses, rather than full maps. The particles are at a
continuous position in the grid, on creation at the cell center,
and represent velocity and orientation hypothesis, or more
precisely a particular v
x
, v
y
. They move according to their
motion vector and a certain motion model between time steps
and are not ﬁxed to their original cell in which they have
been created. Although the particles move through the grid,
at a particular time instance t, every particle belongs to a
particular cell i and is thus one particular sample of the
motion distribution of that cell. In other words, every cell
carries its own particle ﬁlter. The particles, however, can
move between the cells and thus between the particle ﬁlters.
The map posterior
p(v
t
|z
1:t
,x
1:t
)=
Y
i
p(v
i
t
|z
1:t
,x
1:t
) (3)
=
Y
i
X
v
i
t,[k]
w
[k]
?
v
i
t,[k]
(v
i
t
) (4)
can thus be seen as product of velocity distributions repre-
sented by a sum of weighted particles, where ?
v
i
t
represents
the Dirac delta function at v
i
t
.
C. Particle Sampling
Sampling is an essential part of every particle ﬁlter. Typ-
ically, as in Monte-Carlo localization, the initial distribution
is uniform. It is updated in every step through a weighted
resampling procedure, which is then used to calculate the
sampling distribution of the next time step, e.g., by applying
a motion model on each particle. In general, the concept is
very similar here. Formally, particle k is sampled from
v
i
t,[k]
?p(v
i
t
|v
t?1
). (5)
Applying uniform initial sampling as in [14], makes it
however impossible to exactly represent static objects, since
P(V = (0,0)
T
) = 0. It is therefore proposed to add a
Dirac delta impulse ?
0
centered at (v
x
,v
y
)
T
= (0,0)
T
to
the uniform distributionU
p(v
i
)=w
1
U
±vmax
(v
i
)+w
2
?
0
(v
i
) (6)
in order to better represent the world. The two weights
w
1
,w
2
represent the priors of the amount of dynamic and
static information respectively.
It is clear that, if, for every cell, of which there are l
2
for a grid of width and height l, n particles are created,
the number of particles explodes if the grid size increases.
Fortunately though, most of the cells are either free space
or space that cannot be observed and only occupied cells
can be used to derive reasonable velocities. Particles are,
however, also allowed to exist in the other areas to compen-
sate for missed detections and occlusions and the weighted
resampling, described in the next section, assures that the
number of particles still stays approximately constant over
time, depending on the number of occupied grid cells.
D. Particle Weighting and Resampling
In a particle ﬁlter, the weight of each particle represents
how well that particular sample ﬁts the data and is calculated
by dividing the target distribution, the one that ought to
be estimated, by the proposal distribution, the one where
samples are generated from. Dividing the target
p
target
=p(v
1:t
|z
1:t
,x
1:t
) (7)
6091
by the proposal distribution
p
proposal
=p(v
1:t
|z
1:t?1
,x
1:t
) (8)
=p(v
t
|v
t?1
,x
t
)p(v
1:t?1
|z
1:t?1
,x
1:t?1
) (9)
yields, unsurprisingly,
p
target
p
proposal
=
p(v
1:t
|z
1:t
,x
1:t
)
p(v
t
|v
t?1
,x
t
)p(v
1:t?1
|z
1:t?1
,x
1:t?1
)
(10)
=?p(z
t
|v
t
,x
t
) (11)
the measurement model and, assuming independence, the
weight w
[k]
of particle v
i
t,[k]
yields
w
[k]
=?p(z
i
t
|v
i
t,[k]
,x
t
). (12)
Velocities can, however, rarely be measured directly, such
as with a laser scanner, which is also the sensor used in this
work. Thus it cannot be decided whether or not a particular
sample within one time frame t and within one cell ﬁts the
data better than any other sample in the same cell at t. Since
the particles are not ﬁxed to one and the same cell over
individual time steps, they can still be weighted on a cell
level. Intuitively, a particle that moves through the grid, ﬁts
the real world dynamics well, if every cell on its path was
receiving sensor data at the time that particle was in that
particular cell.
In this work, likelihood ﬁelds [15] are used as observation
model. The minimum probability, though,
min
i
(p(z
i
t
|v
i
t,[k]
,x
t
))=p
survival
(13)
is the probability that a particle survives, even if that cell
or any cell in the neighborhood is not observed. As in the
standard particle ﬁlter algorithm, the weight, which is equal
for all particles in a cell, describes how likely it is that a
particle survives.
E. From Velocity Probability Distributions to Dynamic and
Static Evidences
So far, the velocity grid estimator is presented. For ev-
ery cell in the grid a velocity probability distribution is
calculated using particle ﬁlters. Those velocity probability
distributions are a useful information and can be seen as
a cell-based tracking algorithm. In order to compute static
occupancy grids as well as maps that only contain the
dynamic part of the environment, a classiﬁcation between
static and dynamic based on the velocity distribution is
needed. In [14] a classiﬁer based on the mean and the
variance is used. If the absolute values of all components
of the velocity mean are lower than twice their standard
deviation, the cell is static, otherwise it is dynamic. The
idea of the classiﬁcation from [14] is that static cells can
be seen roughly as those, where the velocity distribution,
starting with a uniform distribution, has not converged yet to
a Gaussian distribution that represents the estimated velocity
of the underlying moving object. Hence, the static parts
are detected indirectly, as where the particle ﬁlters fail to
converge to a peak distribution or where the mean velocity
is low. Drawbacks of this approach are, that at static obstacles
the particles will leave the cells of the object and new
particles have to be continuously created. The classiﬁcation
also correlates with the motion noise applied in the motion
update, since if it is too low, the variance will be too
low and there is a strong bias towards the class dynamic.
Nevertheless, for dynamic evidences, the idea that a good
track of a moving object shows a peak distribution, under
the assumption that a cell is completely covered by only one
object, is adopted in a modiﬁed way as a weighting factor,
as shown below.
Since in this work, the particles are drawn from a different
distribution and pure static particles, i.e. wherev
x
=v
y
= 0,
are used, see Section II-C, static and dynamic particles
can directly be detected based on their velocity. Another
difference is, that this paper does not aim for a binary
decision but infers continuous evidences. This approach uses
the Dempster-Shafer theory of evidence, as will be shown
in the next section, to compute the aforementioned uniform
environment model and thus belief masses are deduced.
LetX =X
S
?X
D
be the set of all particles of a particular
cell that have survived at leastt steps, in order to incorporate
the fact that velocities are estimated indirectly over multiple
time instances. X
S
= {v
[k]
| v
[k]
? X ? ||v
[k]
|| ≤ ?}
andX
D
= {v
[k]
|v
[k]
? X ?||v
[k]
|| > ?} hold the static
and the dynamic particles, respectively. The parameter ? is
used instead of 0 to discard particles that move very slowly
through the cells belonging to a static object. The evidential
belief masses for static, dynamic and unknown
m(S)=
|X
S
|
n
(14)
m(D) =

1?
|?|
?
max

|X
D
|
n
(15)
m(?)= 1?m(S)?m(D) (16)
are calculated based on their set cardinality, where ? is the
standard deviation of the orientation of allv
[k]
? X
D
. Fig. 1
shows a comparison between the approach of [14] and the
one of this paper. To exclude the effects of noise, the same
scan grid from real laser data is used as input for every time
step. In addition a moving object exhibiting constant velocity
is simulated to show evidences for both, static and dynamic.
Although the approach of [14] shows slight convergence
behavior, since at static objects, fast moving particles die
out, it never converges to a stable correct result. Even for
a large number of iterations, the result looks similar to the
bottom row of Fig. 1b. Note in comparison the convergence
property of this approach as well as the continuous measure.
Next, it will be shown how the belief masses are used to
create a unifying environment model.
III. EVIDENTIAL GRID MAPPING IN DYNAMIC
ENVIRONMENTS
Having a cell-based estimator for the dynamics, it is now
possible to represent a unifying grid-based model of the
environment. Although the particle map from the previous
section already estimates static and dynamic evidences, they
do not directly correspond to ﬁltered occupancy probabilities.
6092
(a) Scan grid. (b) Approach of [14], static (left) and dynamic (right) classi-
ﬁcations.
(c) This paper, static (left) and dynamic (right) belief masses.
Static and dynamic particles are equally likely.
Fig. 1. Comparison between the approach of [14] and this paper. Top row depicts the result at t= 2, middle row at t= 10 and bottom row at t= 30.
Particles that have survived at least 2 time steps are accounted for classiﬁcation. Note the convergence property.
The particle map may contain noise, since, whenever the
scan grid measures a previously unoccupied cell, particles are
created, initially at random, in order to estimate the velocities
of dynamic objects. In addition, free-space as well as yet
unobserved areas are not modeled in the particle world. Con-
trary to the work in [14], where occupancy probability was
chosen to correspond to the number of particles, evidences
for static occupancy as well as for free space are calculated
by ﬁltering the beliefs over time.
A. Environment Model
Similar to other work [7], [17], [18], the Dempster-
Shafer theory of evidence is used for computing the uniform
environment representationm
t
at timet. This paper, though,
proposes to use a different frame of discernment than the
commonly used free-occupied model. In this work, the frame
of discernment
? ={F,S,D} (17)
represents hypotheses for free space, for static occupancy
and for dynamic occupancy. In the Dempster-Shafer theory
of evidence, every element of the power set of the frame of
discernment 2
?
is considered. Practically, in this work, only
the elements{?, {F}, {S}, {D}, {S, D}, ?} are used,
since {F, S} and {F, D} are always zero.
To the best of our knowledge, an {F,S,D} model for
grid mapping has not been used before. This model allows
for a direct integration of static and dynamic information
into {S} and {D} respectively, as well as of sensor data,
e.g., from a laser scanner, where no distinction between static
and dynamic is possible, by using {S, D}.
B. Single-Frame Information Fusion
As described above, the particle map from the previous
section calculates cell velocities of the environment and de-
duces belief masses for{S} and{D}. Free space, however,
as well as robustness over noise is not yet represented. To
overcome this, the static and dynamic evidences are fused
with free space information and ﬁltered over time.
Free space information comes from an inverse beam sensor
model [19] similar to what is used in standard occupancy grid
mapping, but instead of occupancy probabilities, evidences
for{F} and{S, D} are deduced. Although the raw data for
the inverse sensor model comes from the same sensor as the
input data for the particle map, the basic belief assignments
have different focal elements, i.e. they carry non-zero belief
masses for different subsets of 2
?
. The particle map and the
inverse sensor model can be seen like different sensors mea-
suring different, partially-complementary information that is
fused to extract a complete representation of the environ-
ment.
The fusion of the belief of the inverse sensor model,
denoted bys
1
, and of the particle map, denoted bys
2
, is done
using the non-normalized Dempster’s rule of combination,
also known as conjunctive rule
m
s
(A) =(m
s1
?m
s2
)(A) =
X
B?C=A
m
s1
(B)m
s2
(C) (18)
?A? ?6=? and the conﬂict
K =
X
B?C=?
m
s1
(B)m
s2
(C) (19)
is not resolved by normalization, like in Dempster’s rule but
resolved explicitly. In this work, the conﬂict
K =m
s1
(F)m
s2
(S)+m
s1
(F)m
s2
(D) (20)
may only arise between free-static and free-dynamic. Empir-
ically, it is chosen to transfer K to m
s
(F), since the inverse
sensor model evidences are closer to the raw sensor data.
Note that the cell index i is dropped.
6093
m
t?1
m
t
m
t?1
(D)?m
t?1
(F) m
s1
m
s2
m
s
weighted CR
m
s
(A)
A??\{D,?}
DR
m
s
(D)
Fig. 2. Overview of belief fusion using Dempster’s combination rule (DR)
and a weighted variant of Jøsang’s cumulative rule (CR).
C. Filtering
In contrast to the previous section, where different focal
elements are fused to yield a logical combination, it was
shown that Dempster’s rule is not the correct operator for
cumulative belief fusion, but only represents an approxima-
tion in such situations [20]. Therefore, in this work, Jøsang’s
cumulative operator [20] is used for temporal ﬁltering.
The rule is, however, not applied to the belief mass of D.
The belief of dynamic is deduced from the estimated velocity
distributions in the particle map through the movement of
the particles. Filtering the dynamic evidences would require
moving the evidences from the previous step according to
the velocity distribution, which is already done in the particle
map. In addition, the ﬁltering would not react quickly enough
to detect new moving objects as well as to allow a moving
object driving over free space. Therefore, the fused belief
mass m
t
(D) is used directly from the particle map.
First, the dynamic mass of m
t?1
is moved to free
m
t?1
(F) =m
t?1
(F)+m
t?1
(D) (21)
m
t?1
(D) =0. (22)
Then, a weighted version of Jøsang’s cumulative operator
m
t
(D) =m
s
(D) (23)
m
t
(A)
A??\{D,?}
=w
m
t?1
(A)m
s
(?)+m
t?1
(?)m
s
(A)
m
t?1
(?)+m
s
(?)?m
t?1
(?)m
s
(?)
(24)
m
t
(?)=w
m
t?1
(?)m
s
(?)
m
t?1
(?)+m
s
(?)?m
t?1
(?)m
s
(?)
(25)
with the normalization weight
w =
(1?m
s
(D))(m
t?1
(?)+m
s
(?)?m
t?1
(?)m
s
(?))
P
A??\{D,?}
m
t?1
(A)m
s
(?)+m
t?1
(?)m
s
(A)
(26)
is applied to all but the dynamic mass, which is directly used
from the fused scan. In Fig. 2 an overview of the update rule
is shown.
(a) Resulting uniform world
representation.
(b) Velocity map.
(c) Standard occupancy grid. (d) Camera image.
Fig. 3. Urban scene showing 3 bicycles and 3 vehicles. Robot is moving.
IV. RESULTS
The algorithm was tested qualitatively on real data coming
from a vehicle equipped with a 4-layer laser scanner, which
is mounted under the front number plate, driving in an urban
environment. The grid resolution was set to 512? 512 and
the cell size was 0.2 m. The velocity range in the particle
map was set to±70 km/h, the probability of sampling a static
particle was0.3 and the particle survival probability was0.5.
The maximum number of particles per cell was set to 50.
Two scenes are shown. The ﬁrst, depicted in Fig. 3, shows
the successful detection and tracking of3 bicyclists, riding in
the same direction as the robot, as well as 3 vehicles coming
towards it. Fig. 3a shows the resulting world representation.
Green, Red and Blue represent the free space, the static cells
and the dynamic cells respectively. The colors are mixed
via alpha compositing, where the alpha value represents
the evidential mass. Unknown is shown as white. Fig. 3b
shows the velocity map using an HSV color coding, where
the hue represents the direction, as given in the image, the
saturation the dynamic evidence and the value 1?m
t
(S).
Also shown are a standard occupancy grid for comparison
and the camera image. The second scene, given in Fig. 4,
shows a trafﬁc crossing exhibiting multiple objects and a
high amount of occlusion. Note especially the artifacts from
the dynamic objects in the standard occupancy grid map,
making reasoning and navigating difﬁcult. Note also, that no
assumptions about the environment are made and that the
representation is low-level. No objects exist and thus any
6094
(a) Resulting uniform world representation.
(b) Velocity map and camera image. (c) Standard occupancy grid.
Fig. 4. Road junction with a high amount of trafﬁc and occlusion
demonstrating the performance of the uniform environment model. Robot
has stopped at trafﬁc light.
shape can be represented and no data association is needed.
The environment model presented in this paper, represents
free space, dynamic cells, static cells and occupied cells, i.e.
static-dynamic cells, where the distinction between static and
dynamic has not been made yet, all as continuous evidences
in the Dempster-Shafer framework. A video demonstrating
the results is attached with this contribution. Despite the good
results in the given scenarios, there are also scenes where the
approach has difﬁculties. Especially continuous, elongated,
static structures such as guard rails, where the sensor has
difﬁculties in capturing it, are likely to be misclassiﬁed as
dynamic cells moving beside the robot at the same speed.
V. CONCLUSION AND FUTURE WORK
The paper presents an approach for estimating a map and
for tracking the environment in a uniform grid-based model.
It allows the integration of uncertainty of whether sensor
measurements belong to static or to dynamic objects in a
novel evidential framework. In this model tracks and objects
do not exist and therefore the data association problem
is not present. In addition, no feature extraction or shape
assumptions about the moving objects are needed and thus
arbitrary objects can be tracked. The utility of the method
was demonstrated with a vehicle equipped with a laser
scanner driving in urban environments. The method shows
several potential beneﬁts for a variety of methods that rely
on a robust environment perception. Future work will focus
on further improvement, quantitative evaluation and in using
the method for navigation.
ACKNOWLEDGMENT
This work was partially funded by the German Federal
Ministry of Economics and Technology through the research
initiative UR:BAN (www.urban-online.org).
REFERENCES
[1] A. Elfes, “Using occupancy grids for mobile robot perception and
navigation,” Computer, vol. 22, no. 6, pp. 46–57, Jun. 1989.
[2] C.-C. Wang and C. Thorpe, “Simultaneous localization and mapping
with detection and tracking of moving objects,” in Proc. IEEE Int.
Conf. Robotics and Automation, vol. 3, 2002, pp. 2918–2924.
[3] T.-D. Vu, O. Aycard, and N. Appenrodt, “Online localization and map-
ping with moving object tracking in dynamic outdoor environments,”
in IEEE Intelligent Vehicles Symp., 2007, pp. 190–195.
[4] C.-C. Wang, C. Thorpe, S. Thrun, M. Hebert, and H. Durrant-Whyte,
“Simultaneous localization, mapping and moving object tracking,” Int.
J. Robot. Res., vol. 26, no. 9, pp. 889–916, Sep. 2007.
[5] S. Pietzsch, T.-D. Vu, J. Burlet, O. Aycard, T. Hackbarth, N. Appen-
rodt, J. Dickmann, and B. Radig, “Results of a precrash application
based on laser scanner and short-range radars,” IEEE Trans. Intell.
Transp. Syst., vol. 10, no. 4, pp. 584–593, Dec. 2009.
[6] M. Bouzouraa and U. Hofmann, “Fusion of occupancy grid mapping
and model based object tracking for driver assistance systems using
laser and radar sensors,” in IEEE Intelligent Vehicles Symp., 2010, pp.
294–300.
[7] J. Moras, V . Cherfaoui, and P. Bonnifait, “Credibilist occupancy grids
for vehicle perception in dynamic environments,” in Proc. IEEE Int.
Conf. Robotics and Automation, 2011, pp. 84–89.
[8] T.-N. Nguyen, B. Michaelis, A. Al-Hamadi, M. Tornow, and M. Mei-
necke, “Stereo-camera-based urban environment perception using oc-
cupancy grid and object tracking,” IEEE Trans. Intell. Transp. Syst.,
vol. 13, no. 1, pp. 154–165, Mar. 2012.
[9] G. Lidoris, D. Wollherr, and M. Buss, “Bayesian state estimation and
behavior selection for autonomous robotic exploration in dynamic
environments,” in Proc. IEEE/RSJ Int. Conf. Intelligent Robots and
Systems, 2008, pp. 1299–1306.
[10] C. Cou´ e, C. Pradalier, C. Laugier, T. Fraichard, and P. Bessiere,
“Bayesian occupancy ﬁltering for multitarget tracking: an automotive
application,” Int. J. Robot. Res., vol. 25, no. 1, pp. 19–30, Jan. 2006.
[11] M. Tay, K. Mekhnacha, C. Chen, M. Yguel, and C. Laugier, “An efﬁ-
cient formulation of the bayesian occupation ﬁlter for target tracking
in dynamic environments,” Int. J. Veh. Auton. Syst., vol. 6, no. 1, pp.
155–171, Jan. 2008.
[12] T. Gindele, S. Brechtel, J. Schroder, and R. Dillmann, “Bayesian
occupancy grid ﬁlter for dynamic environments using prior map
knowledge,” in IEEE Intelligent Vehicles Symp., 2009, pp. 669–676.
[13] S. Brechtel, T. Gindele, and R. Dillmann, “Recursive importance
sampling for efﬁcient grid-based occupancy ﬁltering in dynamic
environments,” in Proc. IEEE Int. Conf. Robotics and Automation,
2010, pp. 3932–3938.
[14] R. Danescu, F. Oniga, and S. Nedevschi, “Modeling and tracking
the driving environment with a particle-based occupancy grid,” IEEE
Trans. Intell. Transp. Syst., vol. 12, no. 4, pp. 1331–1342, Dec. 2011.
[15] S. Thrun, W. Burgard, and D. Fox, Probabilistic Robotics (Intelligent
Robotics and Autonomous Agents). The MIT Press, 2005.
[16] M. Montemerlo, S. Thrun, D. Koller, and B. Wegbreit, “FastSLAM:
A factored solution to the simultaneous localization and mapping
problem,” in Proc. AAAI Conf. Artiﬁcial Intelligence, 2002, pp. 593–
598.
[17] D. Pagac, E. Nebot, and H. Durrant-Whyte, “An evidential approach to
map-building for autonomous vehicles,” IEEE Trans. Robot., vol. 14,
no. 4, pp. 623–629, Aug. 1998.
[18] T. Yang and V . Aitken, “Evidential mapping for mobile robots with
range sensors,” IEEE Trans. Instrum. Meas., vol. 55, no. 4, pp. 1422–
1429, Aug. 2006.
[19] F. Homm, N. Kaempchen, J. Ota, and D. Burschka, “Efﬁcient occu-
pancy grid computation on the GPU with lidar and radar for road
boundary detection,” in IEEE Intelligent Vehicles Symp., 2010, pp.
1006–1013.
[20] A. Jøsang and S. Pope, “Dempsters rule as seen by little colored balls,”
Comput. Intell., vol. 28, no. 4, pp. 453–474, Nov. 2012.
6095
