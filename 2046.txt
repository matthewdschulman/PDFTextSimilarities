Inference Over Heterogeneous Finite-/Inﬁnite-Dimensional Systems Using Factor
Graphs and Gaussian Processes
David M. Rosen, Guoquan Huang, and John J. Leonard
Abstract—The ability to reason over partially observable
networks of interacting states is a fundamental competency in
probabilistic robotics. While the well-known factor graph and
Gaussian process models provide ﬂexible and computationally
efﬁcient solutions for this inference problem in the special cases
in which all of the hidden states are either ﬁnite-dimensional
parameters or real-valued functions, respectively, in many cases
we are interested in reasoning about heterogeneous networks
whose hidden states are comprised of both ﬁnite-dimensional
parametersand functions. To that end, in this paper we propose a
novel probabilistic generative model that incorporates both factor
graphs and Gaussian processes to model these heterogeneous
systems. Our model improves upon prior approaches to inference
within these networks by removing the assumption of any speciﬁc
set of conditional independences amongst the modeled states,
thereby signiﬁcantly expanding the class of systems that can
be represented. Furthermore, we show that inference within
this model can always be performed by means of a two-stage
procedure involving inference within a factor graph followed by
inference over a Gaussian process; by exploiting fast inference
methods for the individual factor graph and Gaussian process
models to solve each of these subproblems in succession, we
thus obtain a general framework for computationally efﬁcient
inference over heterogeneous ﬁnite-/inﬁnite-dimensional systems.
I. INTRODUCTION
Many fundamental problems in robotics can be formulated
as instances of inference over a network of interacting random
states in which the goal is to estimate the values of some subset
of the states given noisy observations of others; for example,
the canonical problems of ﬁltering, smoothing, localization,
and mapping all belong to this class [1]. The development
of computationally efﬁcient inference methods for solving
problems of this type is thus of signiﬁcant practical import.
For the common special case in which all of the states are
ﬁnite-dimensional parameters, factor graphs [2] have proven to
be particularly useful: these models generalize and encompass
both Bayesian networks and Markov random ﬁelds [3] (thus
providing a uniﬁed theoretical framework for inference), and
recent work in the robotics community has led to the devel-
opment of efﬁcient inference algorithms for these models that
can solve problems involving tens of thousands of continuous
random variables in real-time on a single processor [4]–[7].
More recently, Gaussian processes [8] have emerged as
another useful class of models for the special case in which the
hidden states are inﬁnite collections of real values (i.e. real-
valued functions); for example, recent work has applied these
The authors are with the Computer Science and Artiﬁcial Intelligence
Laboratory of the Massachusetts Institute of Technology, Cambridge, MA
02139, USA. Email:fdmrosen,gqhuang,jleonardg@mit.edu.
models to develop generalized Bayes ﬁlters [9] and Rauch-
Tung-Striebel smoothers [10] in which the entire process
and observation models can be estimated nonparametrically
directly from data.
However, we are often interested in modeling heteroge-
neous networks whose states are comprised of both ﬁnite-
dimensional parameters and entire functions (this is the case,
for example, when modeling hybrid discrete-/continuous-time
systems). While some special cases of this problem have
recently been addressed in the robotics literature (e.g. in
[9]–[11]), the approaches presented therein are developed
for networks that assume the conditional independence of
speciﬁc subsets of the modeled states (e.g. the hidden Markov
models in [9], [10]), and therefore may not generalize to
broader classes of networks in which these relations no longer
hold. Indeed, to the best of our knowledge, there has been
no discussion in the robotics literature of efﬁcient inference
methods for heterogeneous ﬁnite-/inﬁnite-dimensional systems
in the general case.
To that end, in this paper we develop a probabilistic
generative model incorporating factor graphs and Gaussian
processes to represent generic heterogeneous ﬁnite-/inﬁnite-
dimensional systems. In contrast to prior work, our model
does not assume any speciﬁc set of conditional independences
amongst the modeled states; the only requirement is that any
interaction between states must be mediated by a ﬁnite set of
ﬁnite-dimensional values (a signiﬁcantly weaker condition).
Furthermore, we show that inference within this model can
always be performed by means of a two-stage procedure
involving inference within a factor graph followed by infer-
ence over a Gaussian process; by applying efﬁcient inference
methods (based upon recent advances in sparse numerical
linear algebra [12]–[14]) for the individual factor graph and
Gaussian process models to solve each of these subproblems in
succession, we are thus still able to opportunistically exploit
whatever conditional independences do hold in a particular
application (in the form of sparse linear systems, as described
in Section II) to achieve fast computation without the need
to explicitly require these independences in the design of
our model itself. Through this approach we thus obtain a
ﬂexible and computationally efﬁcient framework for inference
over heterogeneous ﬁnite-/inﬁnite-dimensional systems in the
general case.
II. REVIEW OF MATHEMATICAL PRELIMINARIES
In this section we review the formulations of the factor
graph and Gaussian process models together with their as-
sociated inference algorithms.
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 1261
A. Factor graphs
1) Model formulation: A factor graph [2] is a bipartite
graph that encodes the factorization of a probability distribu-
tion: given a distribution p: 
 ! R over several variables
 = (
1
;:::;
n
)2 
 with factorization
p() =
m
Y
i=1
p
i
(
i
); (1)
where 
i
f
1
;:::;
n
g for all 1im, the corresponding
factor graphG = (F; ;E) is:
F =fp
1
;:::;p
m
g;
 =f
1
;:::;
n
g;
E =f(p
i
;
j
)j
j
2 
i
g:
(2)
By (2), the factor nodes p
i
2 F of G are in one-to-one
correspondence with the factors ofp in (1), the variable nodes

j
2  are in one-to-one correspondence with the arguments
of p, and factor node p
i
and variable node 
j
share an edge
e
ij
= (p
i
;
j
)2E if and only if the variable 
j
appears as an
argument to factor p
i
in (1).
2) Inference in factor graphs: In general, we will be
interested in the problem of Bayesian inference: given a
hidden parameter , an observable variable Z, and the joint
distributionp(Z; ) =p(Zj)p() relating the two, we wish
to obtain the posterior belief p(jZ) for  given a measured
value of Z:
p(jZ) =
p(Z; )
p(Z)
: (3)
Unfortunately, without assuming special structure in the
joint distributionp(Z; ) (e.g. prior conjugacy, etc.), the com-
putation of the exact posteriorp(jZ) is generally intractable,
since this requires the evaluation of a (possibly very high-
dimensional) integral to obtain the evidence p(Z):
p(Z) =
Z
p(Z; )d: (4)
On the other hand, it is often relatively straightforward to
obtain the maximum a posteriori (MAP) point estimate
^

MAP
:
^

MAP
= argmax

p(jZ); (5)
for even ifp(Z) in (3) is unknown, it is constant with respect
to , and therefore (by virtue of (3) and (5)),
^

MAP
= argmax

p(Z; )
p(Z)
= argmax

p(Z; ): (6)
Computation of
^

MAP
thus only requires that it be tractable
to optimize the joint distribution p(Z; ) as a function of .
Let us assume in the sequel (as is commonly the case
in practice) that p(Z; ) is a twice-differentiable probability
density function, and that it factors as
p(Z; ) =
m
Y
i=1
p
i
(Z
i
; 
i
): (7)
Under these conditions, the computational cost of optimizing
(6) using Newton-type methods [15] turns out to be determined
by the sparsity pattern of the factor graph corresponding to (7).
To see this, observe that
^

MAP
= argmax

p(Z; )
= argmin

  lnp(Z; )
= argmin

 
m
X
i=1
lnp
i
(Z
i
; 
i
);
(8)
so that (by virtue of the ﬁnal line of (8)) the Hessian
H =
@
2
@
2
[  lnp(Z; )] = (H
jk
)
dim()
j;k=1
(9)
has H
jk
6= 0 only if 
j
;
k
2 
i
for some factor p
i
in
(7), i.e., only if variable nodes 
j
and 
k
are connected to
a common factor node p
i
inG. The edge setE of the factor
graphG corresponding to (7) thus directly encodes the sparsity
pattern of the Hessian H, and this in turn determines the
cost of computing the update step during each iteration of
the optimization (8) (cf. e.g. [5]–[7] for details).
After computing the point estimate
^

MAP
in (8), one can
additionally recover an approximation for the entire posterior
p(jZ) by means of the Laplaceapproximation [16, Sec. 4.4]:
jZN

^

MAP
; 
 1
jZ

(10a)

jZ
=
@
2
@
2
[  lnp(Z; )]




=
^
 MAP
; (10b)
this approach approximates the true posterior using a Gaussian
distribution that is locally ﬁtted to p(jZ) at
^

MAP
(more
precisely, it ﬁts a second-order Taylor series expansion to
  lnp(Z; ) at
^

MAP
). We observe that the information matrix

jZ
deﬁned in (10b) is simply the Hessian in (9) evaluated
at
^

MAP
; since Newton-type methods compute this matrix (or
an approximation to it) as part of solving the optimization (8),
it is thus available at no additional computational cost beyond
that needed to compute
^

MAP
itself.
B. Gaussian processes
1) Model formulation: Formally, a Gaussian process is a
collection of random variablesfF
x
g
x2X
 R
d
indexed by
some (possibly inﬁnite) setX , any ﬁnite subset of which have
a jointly Gaussian distribution [8], [17].
Since ﬁnite-dimensional Gaussian distributions are com-
pletely determined by their means and (co)variances, the
joint distribution for a ﬁnite subset fF
xi
g
n
i=1
of Gaussian
process-distributed random variables can be completely spec-
iﬁed by ﬁrst and second moments of the form E[F
x
] and
E[(F
x
 E[F
x
])(F
x
0 E[F
x
0])
T
] for x;x
0
2fx
i
g
n
i=1
. Since
these moments exist for any choices of x;x
0
2X , we may
deﬁne functions according to
m:X!R
d
m(x) =E[F
x
]
(11)
1262
and
k :XX!R
dd
k(x;x
0
) =E

(F
x
 E[F
x
])(F
x
0 E[F
x
0])
T

=E

(F
x
 m(x))(F
x
0 m(x
0
))
T

;
(12)
the functions m and k deﬁned in (11) and (12) are called
the mean function and covariance function for the Gaus-
sian process, respectively. Conversely, given any function
m:X ! R
d
and any positive-deﬁnite matrix-valued kernel
k :XX ! R
dd
, m and k determine (by means of (11)
and (12)) a Gaussian processfF
x
g
x2X
R
d
for which they
are the mean and covariance functions [8], [17]. We write
fGP(m;k) (13)
to denote that f , fF
x
g
x2X
is a collection of random
variables distributed according to the Gaussian process with
mean function m and covariance function k.
Since the Gaussian process (13) assigns to each x 2 X
a Gaussian-distributed random value F
x
2 R
d
, the entire
collection of random variables f =fF
x
g
x2X
can be thought
of as a random function f :X ! R
d
. In this view (the so-
called function-space view [8]), a Gaussian processGP(m;k)
speciﬁes a probability distribution over the entire set of func-
tionsff :X!R
d
g whose domain isX . Gaussian processes
thus provide a very useful class of priors for performing
nonparametric regression and interpolation/extrapolation in
a Bayesian setting when the true parametric form of the
regression function is itself uncertain.
2) Inference in Gaussian processes: When performing in-
ference with Gaussian process models, we will generally be
interested in determining the posterior belief for a function
with a Gaussian process prior given observations of its values
at several points. More precisely, we wish to determine the
belief for

f,fjF , where fGP(m;k) and
X = (x
1
;:::;x
n
X
)2X
n
X
;
F =f(X) = (f(x
1
);:::;f(x
n
X
))2R
dn
X
(14)
denote a vector of n
X
points inX and the corresponding
vector of f’s values at those points, respectively.
First, we observe that in order to recover the posterior belief
for

f, it sufﬁces to determine the posterior belief F

jF for
f’s values F

= f(X

) on some second ﬁnite subset of test
points X

2X
n
X
, since we can then obtain fjF from F

jF
by simply taking X

=x

2X to be a single test point and
then allowing it vary pointwise over the entire domainX .
To that end, consider the joint distribution for (F;F

):

F
F


N

M
M


;

K(X;X) K(X;X

)
K(X

;X) K(X

;X

)

; (15)
where
M =m(X) = (m(x
1
);:::;m(x
n
X
))2R
dn
X
; (16)
M

= m(X

) analogously, and K(X;Y ) denotes the Gram
matrix
K(X;Y ) =
2
6
4
k(x
1
;y
1
)  k(x
1
;y
n
Y
)
.
.
.
.
.
.
k(x
n
X
;y
1
)  k(x
n
X
;y
n
Y
)
3
7
52R
dn
X
dn
Y
(17)
for two vectorsX2X
n
X
andY 2X
n
Y
. SinceF andF

are
jointly Gaussian-distributed according to (15), the conditional
distribution F

jF is also Gaussian-distributed according to
F

jFN
 
M
FjF
; 
FjF

;
M
FjF
=M

+K(X

;X)K
 1
X
(F M);

FjF
=K(X

;X

) K(X

;X)K
 1
X
K(X;X

);
(18)
where we have introduced the notationK
X
,K(X;X) since
this quantity is constant with respect to X

.
Now since (18) holds for every choice of X and X

, then
letting X

= x

2X be a single point (so that F

= f(x

)
is just the value of f at x

), we ﬁnd that the posterior belief
for

f is again Gaussian process-distributed according to

fGP(  m;

k); (19a)
 m(x) =m(x) +k
X
(x)K
 1
X
(F M); (19b)

k(x;x
0
) =k(x;x
0
) k
X
(x)K
 1
X
k
X
(x
0
)
T
; (19c)
where k
X
is the single-variable function deﬁned by
k
X
:X!R
ddn
X
k
X
(x) =K(x;X)
(20)
for ﬁxedX. Gaussian processes thus provide a class of priors
on the set of functionsff :X ! R
d
g that is closed under
posterior updates given observations of the function values
F =f(X) on some ﬁnite subset of points X2X
n
X
.
3) A word on the design of Gaussian process models:
As in all kernel-based methods, the covariance (i.e. kernel)
function k(x;x
0
) plays a crucial role in Gaussian process
models. In this subsection, we show how to characterize
several practically-important properties of Gaussian processes
(e.g. sample function differentiability class) in terms of easily-
ascertained properties of their kernel functions, and provide a
few guidelines for the design of kernels in application.
Given f  GP(m;k), equations (19)–(20) show how to
obtain the posterior belief for

f = fjF after incorporating
knowledge of f’s values F =f(X) on a vector X of inputs.
When using this posterior belief to predict the value of f at
other (unobserved) inputs, the corresponding point estimator
is just the posterior mean  m:X!R
d
, since
 m(x

) =E[f(x

)jf(X)] = argmax
f(x)2R
d
p(f(x

)jf(X)) (21)
for all x

2X by virtue of (19). Since K
X
, F , and M are
constant with respect to x

, equations (17) and (19b) imply
that the posterior prediction function  m is a linear combination
of the prior mean functionm and terms of the formk(;x
i
)v
i
,
where v
i
2 R
d
for 1 i n
X
; in particular, if m 0 (as
is commonly assumed in practice), the predictor  m is just
1263
a linear combination of the terms k(;x
i
)v
i
. Domain-speciﬁc
knowledge can thus inform the design of the kernel function
k so as to obtain a predictor  m with a parametric form that is
well-suited to the prediction task at hand.
The kernel function k(x;x
0
) also serves to deﬁne a notion
of “similarity” between pointsx;x
0
2X in the input space, or
equivalently, how tightly coupled the function valuesf(x) and
f(x
0
) are. In particular, if the kernel functionk(;x
i
):X!R
has a neighborhood N(x
i
) outside of which kk(;x
i
)k is
negligibly small, then f(x

) and f(x
i
) are only weakly
coupled wheneverx

= 2N(x
i
), and in this case equation (19b)
shows that f’s value f(x
i
) at x
i
does not signiﬁcantly affect
the value of the posterior mean prediction  m(x

). The choice
of a kernel function k with a characteristic spatial scale (e.g.
the radial basis kernel) thus gives rise to a Gaussian process
whose sample functions f and posterior mean  m likewise
have a characteristic spatial scale over which their values
vary (cf. [8, Sec. 4.2]). Thus, if the system being modeled
has a characteristic spatial scale, this knowledge can again be
incorporated in the design of k.
Furthermore, knowledge of such a characteristic spatial
scale can also be exploited in the design of k to reduce the
computational cost of performing inference over the resulting
Gaussian process model. As shown in (19), computing the
posterior mean and covariance functions  m and

k requires
the evaluation of a matrix-vector or matrix-matrix product
with the inverse of the kernel matrix K
X
2 R
dn
X
dn
X
; in
general, these operations are O(d
3
n
3
X
), which can quickly
become prohibitively expensive as the number of observations
n
X
increases. However, if k is chosen such that each k(;x
i
)
is supported on a compact set whose size is determined by the
spatial scale in the modeled system, then many of the elements
k(x
i
;x
j
) in K
X
will be zero, i.e. K
X
(and likewise k
X
(x))
will be block sparse; this sparsity can then be exploited to
signiﬁcantly reduce the computational cost of prediction (19).
Finally, for cases in whichXR
n
, the kernel function also
determines the continuity and differentiability classes of the
sample functions drawn from a mean-zero Gaussian process.
If f GP(0;k) with k :XX ! R (so that f is scalar-
valued) and there exists > 0 and C > 0 such that
E

jf(x) f(y)j
2


C
jlogkx ykj
1+
(22)
for allx;y2I withIX a compact set, thenf is continuous
onI with probability 1; for the common special case in which
k is a stationary kernel (i.e. in which k(x;y) =(x y) for
some :X!R), condition (22) simpliﬁes to
(0) (x)
C
jlogkxkj
1+
(23)
(cf. [18, pgs. 60–62]). Conditions (22) and (23) can be used
to establish vector-valued sample function differentiability up
orderD as follows. LetfGP(0;k) withk :XX!R
dd
,
and write f and k in coordinates as
f(x) = (f
1
(x);:::;f
d
(x))2R
d
;
k(x;x
0
) = (k
ij
(x;x
0
))
d
i;j=1
2R
dd
=
2
6
4
k
11
(x;x
0
)  k
1d
(x;x
0
)
.
.
.
.
.
.
k
d1
(x;x
0
)  k
dd
(x;x
0
)
3
7
5:
(24)
If
@
2
kii
@xa@x
0
a
(x;x
0
) exists at (x

;x

)2XX , then the mean-
square partial derivative
@fi
@xa
exists at x

and is jointly mean-
zero Gaussian process-distributed with f according to
E

f
i
(x)
@f
j
@x
b
(x
0
)

=
@k
ij
@x
0
b
(x;x
0
)
E

@f
i
@x
a
(x)
@f
j
@x
b
(x
0
)

=
@k
ij
@x
a
@x
0
b
(x;x
0
)
(25)
where 1  a;b  n (cf. [8, Secs. 4.1.1 and 9.4]). By
induction, if each of the mixed partial derivatives
@
+
kij
@x

@x
0
exists at (x

;x

)2XX for all multi-indices ;2 N
n
with 0jj;jjD, then f has mean-square mixed partial
derivatives
@

fi
@x

(x

) of all orders up to and including D, and
all of these partial derivatives are jointly mean-zero Gaussian
process-distributed with f according to
E

@

f
i
@x

(x)
@

f
j
@x

(x
0
)

=
@
+
k
ij
@x

@x
0

(x;x
0
): (26)
Equation (26) and conditions (22)–(23) can be used to estab-
lish that f2 C
D
(I;R
d
) with probability 1 by showing that
each of the partial derivatives
@

fi
@x

has continuous sample
paths on IX with probability 1 for all 1 i d and all
0jj D (cf. [19, Sec. 2.5]). Thus, for applications in
which sample functions must belong to a certain smoothness
class (e.g. in the case of physical mechanical systems obeying
Newton’s laws, for which the trajectory is the second integral
of the applied forces with respect to time), this knowledge
can once again be incorporated into the design of the kernel
k. Furthermore, the fact that f and its derivatives
@

fi
@x

are
jointly Gaussian process-distributed according to (26) allows
the integration of observations of f’s derivatives into the
inference framework outlined in Section II-B2 whenever such
observations are available (cf. [8, Sec. 9.4] and [20]).
Interested readers are encouraged to consult [17], [21] for
more information on kernel-based machine learning techniques
in general (including an extensive listing of commonly-used
kernel functions and methods for constructing new kernels out
of old), and [8], [18], [19], [21] for more information on the
design of Gaussian process models in particular.
III. INFERENCE OVER HETEROGENEOUS
FINITE-/INFINITE-DIMENSIONAL SYSTEMS
The factor graph and Gaussian process models of Section
II provide extremely useful approaches for probabilistic infer-
ence over ﬁnite-dimensional parameters or entire functions,
respectively; in this section, we show how to incorporate
both of these models into a framework that enables inference
1264
Fig. 1. The factor graph describing the joint distribution of the ﬁnite-
dimensional parameters in the model (27): here  is a hidden parameter with
priorp

(),F =f(X) is the hidden vector of (random) values of a function
fGP(m;k) evaluated on the input points X2X
n
X
, and Z is a vector
of observations related toF and  through the likelihood (i.e. measurement)
modelp
Z
(jF; ). We also introduce an additional hidden vector of function
values F = f(X) on the inputs X 2 X
n
X that does not directly
inﬂuence the observationZ, but whose posterior distribution we nevertheless
wish to infer using the Gaussian process prior on f.
over heterogeneous systems whose states are comprised of
both ﬁnite-dimensional parameters and entire functions. We
begin in Section III-A by introducing a probabilistic generative
model to describe these systems, and then derive a set of com-
putationally efﬁcient algorithms for performing (approximate)
Bayesian inference within this model in Section III-B.
A. Model formulation
We are interested in performing inference over heteroge-
neous systems whose hidden states consist of both ﬁnite-
dimensional parameters and functions. To that end, we deﬁne
the following probabilistic generative model:
p

()
fGP(m;k)
F =f(X)
ZjF; p
Z
(jF; );
(27)
where  is a ﬁnite-dimensional parameter with prior p

(),
f :X!R
d
is a function with priorGP(m;k) taking values
F =f(X) onX2X
n
X
, andZ is a ﬁnite-dimensional vector
of observations related toF and  through the likelihood (i.e.
measurement) model p
Z
(jF; ). The factor graph describing
the joint distribution of the ﬁnite-dimensional parameters ,
F , and Z in (27) is shown in Fig. 1.
As can be seen in Fig. 1, (27) models the observation Z
as arising from the interaction of a ﬁnite-dimensional hidden
state  and a ﬁnite set of values F of a hidden function
f. It does not enforce any conditional independence relations
between , F , and Z (equivalently, it does not require that
p(),p(F ), orp(ZjF; ) admit any nontrivial factorizations),
and therefore sufﬁces to model any measurement arising from
any interaction amongst (ﬁnite- or inﬁnite-dimensional) hidden
states that is mediated by a ﬁnite-dimensional set of values, as
claimed. Finally, we point out that although (27) does constrain
the observationZ to be ﬁnite-dimensional, this is not actually
a limitation in practice, as physical sensors are only capable
of collecting ﬁnitely many measurements.
B. Inference
In this section we derive inference methods for computing
the joint posterior distribution p(f; jZ) and the marginals
p(fjZ) and p(jZ) in the model (27).
To begin, we observe that (by the same logic as was used in
Section II-B2) performing inference over the entire function
f is equivalent to replacing f with F

= f(X

) and then
allowing X

= x

2X to vary pointwise over all ofX . To
that end, we consider the joint posterior p(F

;F; jZ):
p(F

;F; jZ) =p(F

jF; ;Z)p(F; jZ)
=p(F

jF )p(F; jZ);
(28)
where the ﬁrst equality follows from the chain rule of proba-
bility and the second from the fact that F

?? (Z; )jF (cf.
Fig. 1). The ﬁrst distribution p(F

jF ) in (28) comes directly
from the Gaussian process prior on f and is given in closed
form by (18); the second p(F; jZ) can be approximated by
applying the Laplace approximation (10) to the subgraph in
Fig. 1 determined by the solid edges (as described in Section
II-A2) to produce:

F


jZN

 
F
 


;

 
F

F
 
F


 


F
 




: (29)
We can further decompose this distribution as
p(F; jZ) =p(Fj;Z)p(jZ); (30)
and by virtue of (29) we have
jZN ( 

;  



) (31)
and
Fj;ZN
 
 
Fj


;  
Fj



;
 
Fj


= 
F
+  
F



 1




(  

);
 
Fj


=  
F

F
   
F



 1




 


F
:
(32)
Now, we can obtain the joint distribution p(F

; jZ) from
p(F

;F; jZ) by marginalizingF . By virtue of (28) and (30),
this can be written as:
p(F

; jZ) =
Z
p(F

;F; jZ)dF
=p(jZ)
Z
p(F

jF )p(Fj;Z)dF:
(33)
We observe that the distributions p(F

jF ) and p(Fj;Z) in
the integrand in the ﬁnal line of (33) can be interpreted as a
(Gaussian) likelihood for F

given F and a (Gaussian) prior
forF , respectively, so that the entire integral simply represents
the marginal distribution for F

given  and Z:
p(F

j;Z) =
Z
p(F

jF )p(Fj;Z)dF: (34)
In general, given the Gaussian prior and likelihood models:
xN (
x
; 
x
)
yjxN
 
Ax +b; 
yjx

;
(35)
the marginal distribution of y is:
yN (
y
; 
y
);

y
=A
x
+b;

y
= 
yjx
+A
x
A
T
(36)
1265
(cf. e.g. [16, Sec. 2.3.3]). Equations (18), (32), and (34)–(36)
together imply that the distributionp(F

j;Z) in (34) is given
in closed form by:
F

j;ZN
 
 
Fj


;  
Fj



;
 
Fj


=M(X

) +K(X

;X)K
 1
X
 
 
Fj


 M

 
Fj


=K(X

;X

) K(X

;X)K
 1
X
K(X;X

)
+K(X

;X)K
 1
X
 
Fj


K
 1
X
K(X;X

):
(37)
Finally, (33), (34), and (37) in turn imply that the joint
posterior distribution p(f; jZ) we seek is given by:
p(f; jZ) =p(fj;Z)p(jZ); (38)
where p(jZ) is given by (29) and (31), and
fj;ZGP

m 
fj


; k 
fj



m 
fj


(x) =m(x) +k
X
(x)K
 1
X
( 
F
+  
F



 1




(  

))
k 
fj


(x;x
0
) =k(x;x
0
) +k
X
(x)K
 1
X
k
X
(x
0
)
T
+k
X
(x)K
 1
X
 
Fj


K
 1
X
k
X
(x
0
)
T
:
(39)
Now it remains only to determine the marginal distribution
p(fjZ) (the marginal distributionp(jZ) having already been
determined in (29) and (31)). We observe that
p(F

jZ) =
Z
p(F

jF )p(FjZ)dF (40)
withp(F

jF ) given by (18) andFjZN ( 
F
;  
F

F
) by (29).
A second application of equations (35) then shows that
F

jZN
 
 
F
;  
F

;
 
F
=M(X

) +K(X

;X)K
 1
X
( 
F
 M);
 
F
=K(X

;X

) K(X

;X)K
 1
X
K(X;X

)
+K(X

;X)K
 1
X
 
F

F
K
 1
X
K(X;X

):
(41)
Thus, the marginal posterior distribution p(fjZ) is given by:
fjZGP(m 
f
;k 
f
);
m 
f
(x) =m(x) +k
X
(x)K
 1
X
( 
F
 M);
k 
f
(x;x
0
) =k(x;x
0
) k
X
(x)K
 1
X
k
X
(x
0
)
T
+k
X
(x)K
 1
X
 
F

F
K
 1
X
k
X
(x
0
)
T
:
(42)
Equations (29) and (31), (38)–(39), and (42) admit the
computation ofp(f; jZ) and its marginals using a two-stage
inference procedure: ﬁrst we compute the Laplace approxima-
tion for (F; )jZ in (29) by applying the method of Section
II-A2 to the factor graph determined by the solid edges in
Fig. 1, and then we recover p(f; jZ) or p(fjZ) by fusing
p(F; jZ) with the conditional distribution for fjF induced
by the Gaussian process prior over f using (38)–(39) or (42),
respectively.
Finally, we observe that although our algorithmic develop-
ment has thus far involved only a single functionf, parameter
, and observationZ, the fact that all of these may be vector-
valued implies that this procedure immediately generalizes
to incorporate any number of functions f
1
;:::;f
n
f
, param-
eters 
1
;:::; 
n
and observations Z
1
;:::;Z
n
Z
by simply
deﬁning f = (f
1
;:::;f
n
f
),  = (
1
;:::; 
n
), and Z =
(Z
1
;:::;Z
n
Z
). Any conditional independence relationships
that hold amongst these variables can subsequently be ex-
ploited in the form of factor graph sparsity (when performing
inference over the ﬁnite-dimensional parameters F , , and
Z) or block sparsity of kernel matrices (when inferring the
posterior distributions for

f = (

f
1
;:::;

f
n
f
)). As we will see
in the next section, the exploitation of sparsity enables fast
inference over networks of the form (27) containing hundreds
or thousands of continuous random variables.
IV. AN EXAMPLE APPLICATION
In this section we demonstrate the application of the infer-
ence framework developed in Section III using a toy target-
tracking example; speciﬁcally, we consider a novel hybrid
discrete-/continuous-time formulation of the cooperative lo-
calization and target tracking (CLATT) problem. For ease
of exposition, in this demonstration we will consider only a
single mobile robot and a single target; however, the inference
algorithm that we derive immediately generalizes to arbitrary
numbers of robots and targets following the argument given
at the end of Section III-B.
To that end, we consider a single mobile robot attempting
to track a single target, both moving in the plane. We model
the robot pose at timet
i
ass
i
= (x
r
i
;y
r
i
;
r
i
), where (x
r
i
;y
r
i
)2
R
2
is the robot’s position in the plane and 
r
i
2 ( ;] its
heading angle. We assume that the robot is equipped with a
proprioceptive sensor (e.g. an inertial measurement unit) that
enables it to estimate its ego-motion s
i;i+1
between two
subsequent poses s
i
and s
i+1
according to:
s
i;i+1
=
2
4
(x
r
i+1
 x
r
i
) cos(
r
i
) + (y
r
i+1
 y
r
i
) sin(
r
i
)
(x
r
i+1
 x
r
i
) sin(
r
i
)  (y
r
i+1
 y
r
i
) cos(
r
i
)

r
i+1
 
r
i
3
5
;
(43)
and that these measurements are subject to mean-zero additive
Gaussian noise with a standard deviation of:03 meters in each
translational direction and 1 degree in rotation.
To prevent the accumulation of drift in its own state esti-
mate, the robot also estimates the positions of, and relocalizes
itself with respect to, any landmarks that it discovers as it
moves through its environment (more precisely, it performs
smoothing SLAM [1]). For this purpose, we assume that the
robot is equipped with a sensor that enables it to measure the
relative range and bearing m
i;j
= (r
i;j
;
i;j
) from its current
pose s
i
to a landmark at position l
j
= (x
j
;y
j
):
x
i;j
=x
j
 x
r
i
;
y
i;j
=y
j
 y
r
i
;
r
i;j
=
q
x
2
i;j
+ y
2
i;j

i;j
= arctan(y
i;j
; x
i;j
) 
r
i
:
(44)
We assume that the measurements (44) are subject to zero-
mean additive Gaussian noise with a standard deviation of:10
1266
?40 ?30 ?20 ?10 0 10 20 30 40
?30
?20
?10
0
10
20
30
Y (meters)
X (meters)
Ground truth 
 
 
Observed target positions
Target trajectory
Robot poses
Landmark positions
(a) Ground truth
?80 ?70 ?60 ?50 ?40 ?30 ?20 ?10 0 10 20
?40
?30
?20
?10
0
10
20
30
40
Y (meters)
X (meters)
Initial discrete?time variable estimates
 
 
Target position estimates
Robot pose estimates
Landmark position estimates
(b) Initial discrete-time estimates
?60 ?50 ?40 ?30 ?20 ?10 0 10
?30
?20
?10
0
10
20
30
Y (meters)
X (meters)
Final estimates
 
 
Estimated target positions
Posterior target trajectory
Estimated robot poses
Estimated landmark positions
(c) Final estimates
0 20 40 60 80 100 120 140
?3
?2
?1
0
1
2
3
Time (seconds)
Error (meters)
Tracking error in X
 
 
Error
3? bounds
0 20 40 60 80 100 120 140
?3
?2
?1
0
1
2
3
Time (seconds)
Error (meters)
Tracking error in Y
 
 
Error
3? bounds
(d) Tracking errors
Fig. 2. Tracking a target with a mobile robot. (a): Ground truth for this experiment, showing the robot poses (red circles), landmark locations (magenta
asterisks), and the target’s continuous-time trajectory (blue curve) and positions at which it was observed (blue circles). Landmark observations are indicated
by a dashed green line connecting the landmark and the robot pose from which it was observed. (b): The initial estimate of the discrete-time variables (robot
poses, observed target positions, and landmark locations) used to initialize the numerical optimization to compute the MAP estimate as described in Section
II-A2. (c): The ﬁnal MAP estimates for the discrete-time variables and the posterior marginal estimate for the entire target trajectory obtained as described in
Section III-B. (d): The globally-registered target tracking errors in x and y, together with the 3 conﬁdence bounds reported by the inference method.
meters in range and 1 degree in bearing, and that the sensor
has a 180-degree forward-facing ﬁeld of view and a maximum
range of 20 meters.
Finally, we assume that the robot is also equipped with a
sensor that enables it to measure the relative range and bearing
from its current pose to the tracked target according to (44).
For the sake of simplicity, in this example we will assume that
this sensor is always able to observe the target, independent
of its position relative to the robot, and that it is likewise
subject to zero-mean additive Gaussian noise with a:10 meter
standard deviation in range and a 1 degree standard deviation
in bearing.
A discrete-time formulation sufﬁces to model the robot state
in this problem because we assume direct access to odometry
measurements; these observations form a “backbone” of pose-
to-pose constraints that (in combination with the landmark
observations) enables smoothing over the robot’s trajectory.
Unfortunately, direct odometric measurements are generally
not available for the target in target-tracking applications. In
practice, it is common to replace odometry measurements with
constraints derived from an assumed target motion model (e.g.
constant-velocity models); however, it is not always clear a
priori how to select an appropriate parametric class for such
a model (particularly when the target is highly maneuverable
or unpredictable), which renders this approach vulnerable to
model misspeciﬁcation.
Bearing these considerations in mind, in this example
we propose to model the target position as an unknown
continuous-time functionf :R!R
2
with a Gaussian process
prior; this avoids the necessity of specifying a particular para-
metric form for the target motion model (hence also the model
misspeciﬁcation problem) while still enabling smoothing over
the target’s observed positions by enforcing smoothness in the
target’s estimated trajectory through an appropriate design of
the covariance function k (as described in Section II-B3). To
that end, we suppose that fGP(0;k
f
), where
k
f
:RR!R
2
k
f
(t;t
0
) =k
pp1;2

jt t
0
j
l


2
f
0
0 
2
f

;
(45)
and k
pp1;2
:R! R is the piecewise-polynomial radial basis
kernel deﬁned in [8, pg. 88]. This kernel has several desirable
properties for this application, including stationarity, compact
support on intervals of length l (corresponding to the length
of the “sliding window” over which we wish to smooth the
target path, and thus the sparsity of the kernel matrix K
X
),
a maximum (co)variance magnitude of 
2
f
(specifying the
strength of the applied smoothing), and ﬁrst-order sample
function differentiability (thus enforcing the condition that the
target trajectory should be at least ﬁrst-order differentiable, as
we should expect for any physical system obeying Newton’s
laws). Based on prior knowledge of the target’s maneuverabil-
ity characteristics, in this example we will take
f
= 5 meters
and l = 10 seconds.
The experimental setup is shown in Fig. 2(a). The simulated
environment is an 80 60 meter grid containing 45 randomly
distributed landmarks. The robot traverses a single counter-
clockwise loop of radius 25 meters through this environment
at a constant speed of 1:2 m/s, while the tracked target follows
a Lissajous curve at speeds between 1:7 and 6:0 m/s (with
an average speed of 4:1 m/s). The robot measures the target
position, its own ego-motion relative to its prior pose, and any
nearby landmarks once every second, for a duration of 130
seconds. The entire simulation thus comprises 45 landmarks
(with 745 observations), 131 robot poses (with 130 odometry
measurements connecting them), and 131 target positions
(each with one measurement).
This raw data was batch-processed using the two-stage
procedure outlined in Section III-B. First, an initial estimate
for the discrete-time variables (the robot poses, landmark
positions, and measured target positions) was obtained by
integrating the robot odometry measurements and initializ-
ing the landmarks and target positions relative to the robot
1267
pose from which they were ﬁrst observed (Fig. 2(b)). This
estimate was then used as the initialization for an iterative
numerical optimization to compute the MAP estimate and
the Laplace approximation to the posterior distribution of the
discrete-time variables as outlined in Section II-A2. Optimiza-
tion was performed using MATLAB’s lsqnonlin with the
trust-region-reflective method (requiring 11 itera-
tions and 3.37 seconds); the resulting MAP estimate
^

MAP
and
the Hessian approximationH(
^

MAP
) 2J
T
(
^

MAP
)J(
^

MAP
)
were then used to approximate the posterior distribution ac-
cording to (10). Finally, this approximate posterior distribu-
tion for the discrete-time variables was used to compute the
marginal posterior distribution for the unknown target path
f(t) using (42). The ﬁnal estimates are shown in Fig. 2(c).
To evaluate the performance of this method, we computed
the least-squares-optimal registration between the robot’s co-
ordinate system and the global coordinate system based upon
aligning the landmark position estimates (as would be done
in practice when localizing the robot with respect to the
global reference frame), and then computed the target tracking
error as the difference between the robot’s globally registered
estimate and the ground truth; results are shown in Fig. 2(d).
In this experiment we observed median tracking errors of
 :018 and  :016 meters in x and y, respectively, and a
total RMS error of :44 meters. Comparison of Figs. 2(a)
and 2(d) reveals that most of this error arises when tracking
the target through the aggressive turns at the corners of the
environment; furthermore, while the tracking error may be
somewhat high in these regions, the posterior 3 conﬁdence
bounds produced by the inference method correctly capture the
greater uncertainty in these sections of the estimate, thereby
preserving consistency. This demonstrates the feasibility of
the proposed nonparametric hybrid discrete-/continuous-time
approach to the CLATT problem.
V. CONCLUSION
In this paper we developed a probabilistic generative model
and an associated set of inference algorithms for reasoning
over general heterogeneous ﬁnite-/inﬁnite-dimensional sys-
tems. Our approach generalizes prior work by relaxing the
requirement that a speciﬁc set of conditional independences
amongst the modeled states must hold, yet is nevertheless
still able to opportunistically exploit whatever conditional
independences do obtain in a particular application to achieve
fast computation. Through this approach we thus obtain a
ﬂexible and computationally efﬁcient framework for inference
over heterogeneous ﬁnite-/inﬁnite-dimensional systems in the
general case.
In closing, we remark that while the inference framework
developed herein has been formulated in the batch setting, we
believe it should be possible to adapt this approach to the
online case by applying incremental methods (e.g. [5]–[7]) to
efﬁciently solve the sequences of individual factor graph and
Gaussian process subproblems. We intend to investigate this
possibility in future research.
ACKNOWLEDGEMENTS
This work was partially supported by the Ofﬁce of Naval
Research under grants N00014-10-1-0936, N00014-11-1-0688
and N00014-13-1-0588 and by the National Science Founda-
tion under grant IIS-1318392, which we gratefully acknowl-
edge.
REFERENCES
[1] S. Thrun, W. Burgard, and D. Fox, Probabilistic Robotics. Cambridge,
MA: The MIT Press, 2008.
[2] F. Kschischang, B. Frey, and H.-A. Loeliger, “Factor graphs and the
sum-product algorithm,” IEEE Trans. Inf. Theory, vol. 47, no. 2, pp.
498–519, Feb. 2001.
[3] D. Koller and N. Friedman, Probabilistic Graphical Models: Principles
and Techniques. Cambridge, MA: The MIT Press, 2009.
[4] M. Kaess, V . Ila, R. Roberts, and F. Dellaert, “The Bayes tree: An algo-
rithmic foundation for probabilistic robot mapping,” in Intl. Workshop
on the Algorithmic Foundations of Robotics, WAFR, Singapore, Dec.
2010.
[5] M. Kaess, H. Johannsson, R. Roberts, V . Ila, J. Leonard, and F. Dellaert,
“iSAM2: Incremental smoothing and mapping using the Bayes tree,”
Intl. J. of Robotics Research, vol. 31, no. 2, pp. 216–235, Feb. 2012.
[6] D. Rosen, M. Kaess, and J. Leonard, “An incremental trust-region
method for robust online sparse least-squares estimation,” in IEEE Intl.
Conf. on Robotics and Automation (ICRA), St. Paul, MN, May 2012,
pp. 1262–1269.
[7] ——, “Robust incremental online inference over sparse factor graphs:
Beyond the Gaussian case,” in IEEE Intl. Conf. on Robotics and
Automation (ICRA), Karlsruhe, Germany, May 2013, pp. 1017–1024.
[8] C. Rasmussen and C. Williams, Gaussian Processes for Machine Learn-
ing. Cambridge, MA: The MIT Press, 2006.
[9] J. Ko and D. Fox, “GP-BayesFilters: Bayesian ﬁltering using Gaus-
sian process prediction and observation models,” Autonomous Robots,
vol. 27, no. 1, pp. 75–90, Jul. 2009.
[10] M. Deisenroth, R. Turner, M. Huber, U. Hanebeck, and C. Rasmussen,
“Robust ﬁltering and smoothing with Gaussian processes,” IEEE Trans.
on Automatic Control, vol. 57, no. 7, pp. 1865–1871, Jul. 2012.
[11] C. Tong, P. Furgale, and T. Barfoot, “Gaussian process Gauss-Newton
for non-parametric simultaneous localization and mapping,” Intl. J. of
Robotics Research, vol. 32, no. 5, pp. 507–525, May 2013.
[12] P. Matstoms, “Sparse QR factorization in MATLAB,” ACM Trans. Math.
Softw., vol. 20, no. 1, pp. 136–159, Mar. 1994.
[13] T. Davis, J. Gilbert, S. Larimore, and E. Ng, “A column approximate
minimum degree ordering algorithm,” ACM Trans. Math. Softw., vol. 30,
no. 3, pp. 353–376, Sep. 2004.
[14] Y . Chen, T. Davis, W. Hager, and S. Rajamanickam, “Algorithm
887: CHOLMOD, supernodal sparse Cholesky factorization and up-
date/downdate,”ACMTrans.Math.Softw., vol. 35, no. 3, pp. 22:1–22:14,
Oct. 2008.
[15] J. Nocedal and S. Wright, Numerical Optimization, 2nd ed. New York:
Springer Science+Business Media, 2006.
[16] C. Bishop, Pattern Recognition and Machine Learning. New York:
Springer Science+Business Media, 2006.
[17] M.
´
Alvarez, L. Rosasco, and N. Lawrence, “Kernels for vector-valued
functions: A review,” Computer Science and Artiﬁcial Intelligence
Laboratory, Massachusetts Institute of Technology, Tech. Rep. MIT-
CSAIL-TR-2011-033, CBCL-301, Jun. 2011.
[18] R. Adler, The Geometry of Random Fields. Philadelphia: The Society
for Industrial and Applied Mathematics (SIAM), 2010.
[19] C. Paciorek, “Nonstationary Gaussian processes for regression and
spatial modeling,” Ph.D. dissertation, Carnegie Mellon University, 2003.
[20] E. Solak, R. Murray-Smith, W. Leithead, D. Leith, and C. Rasmussen,
“Derivative observations in Gaussian process models of dynamic sys-
tems,” in Advances in Neural Information Processing Systems (NIPS),
Vancouver, Canada, 2003, pp. 1033–1040.
[21] B. Sch¨ olkopf and A. Smola, Learning with Kernels. Cambridge, MA:
The MIT Press, 2002.
1268
