Completeness of Randomized Kinodynamic Planners with
State-based Steering
St´ ephane Caron
1
, Quang-Cuong Pham
2
, Yoshihiko Nakamura
1
Abstract— The panorama of probabilistic completeness re-
sults for kinodynamic planners is still confusing. Most exist-
ing completeness proofs require strong assumptions that are
difﬁcult, if not impossible, to verify in practice. To make
completeness results more useful, it is thus sensible to establish
a classiﬁcation of the various types of constraints and planning
methods, and then attack each class with speciﬁc proofs and
hypotheses that can be veriﬁed in practice. We propose such a
classiﬁcation, and provide a proof of probabilistic completeness
for an important class of planners, namely those whose steering
method is based on the interpolation of system trajectories
in the state space. We also provide design guidelines for the
interpolation function and discuss two criteria arising from our
analysis: local boundedness and acceleration compliance.
I. INTRODUCTION
A deterministic motion planning algorithm (or planner)
is said to be complete if it returns a solution to a motion
planning problem whenever one exists (see e.g., [1]). A
randomized planner is said to be probabilistically complete
if the probability of returning a solution tends to one as
execution time goes to inﬁnity. The concepts of complete-
ness and probabilistic completeness, although theoretical by
nature, are also of practical interest: proving them requires
one to specify what assumptions are needed for a planner
to ﬁnd solutions, i.e., what types of problems can be solved.
This provides more general guarantees than empirical results.
Experiments can show that a planner works for a given
combination of robot, environment, task, (set of tweaks and
heuristics), but a proof of completeness is a certiﬁcate that
the planner works for a whole set of problems, the size of this
set being determined by the assumptions required to make
the proof (the weaker the assumptions, the larger the set of
solvable problems).
While the probabilistic completeness of randomized plan-
ners has been well established for systems with geometric
constraints (such as obstacle avoidance), proofs for systems
with kinodynamic constraints [2], [3], [4] have not yet
reached the same level of generality: in many proofs, the
assumptions made are quite strong and difﬁcult to verify on
practical systems (as a matter of fact, none of the previously
mentioned works veriﬁed their hypotheses on non-trivial
systems). One of the reasons for this lies in the large variety
of kinodynamic constraints and planning methods that can
be found.
To make completeness proofs more useful in practice, it
is thus necessary to estabish a classiﬁcation of the different
1
Department of Mechano-Informatics, The University of Tokyo, Japan
2
School of Mechanical and Aerospace Engineering, Nanyang Technolog-
ical University, Singapore
types of constraints and planning methods, and then attack
each class with speciﬁc proofs and hypotheses that can be
more easily checked. In section II, we propose such a clas-
siﬁcation based on kinodynamic constraints (non-holonomic
or dynamics-bound-based) and planning methods (depending
upon their underlying steering methods: analytic, control-
based or state-based). We also discuss the shortcomings of
existing completeness proofs. Then, in section III, we prove
a completeness result for the class of state-based steering
planners applied to systems with dynamics bounds. Finally,
in section IV, we conclude by discussing the implications of
our results as well as future research objectives.
II. CLASSIFICATION OF KINODYAMIC CONSTRAINTS
AND OF STEERING METHODS
A. Classiﬁcation of Kinodynamic Constraints
Motion planning was ﬁrst concerned only with geometric
constraints such as obstacle avoidance or those imposed by
the kinematic structures of manipulators [5], [6], [4], [2].
More recently, kinodynamic constraints, which stem from the
dynamical equations the systems are subject to, have also
been taken into account [7], [2], [8].
Kinodynamic constraints are more difﬁcult to deal with
than geometric constraints because they cannot in general
be expressed using only conﬁguration-space variables –
such as the joint angles of a manipulator, the position and
the orientation of a mobile robot, etc. They indeed involve
higher-order derivatives of the conﬁguration-space variables.
However, these derivatives appear in the constraints in two
main different ways, which involve different types of difﬁ-
culties:
1) Non-holonomic constraints are non-integrable equal-
ity constraints on higher-order derivatives of the
conﬁguration-space variables. They can be ﬁrst-order,
as found in wheeled vehicles [9], or second-order, as
found in under-actuated manipulators or space robots.
2) Bounds on dynamic quantities are inequality constraints
on higher-order derivatives of the conﬁguration-space
variables. These include torque bounds for manipula-
tors [10], ZMP constraints for walking robots, friction
constraints in grasp synthesis, etc.
Some authors have considered systems that are subject to
both types of constraints, such as under-actuated manipula-
tors with torque bounds [11].
We shall see in section II-C that control-based steering
is more adapted to systems with non-holonomic constraints
while state-based steering is more adapted to systems with
inequality constraints.
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 5818
B. Structure of Randomized Planners
Randomized planners such as such as Probabilistic
Roadmaps (PRM) [6] or Rapidly-exploring Random Trees
(RRT) [2] build a roadmap on the state space. In PRM,
multiple samples are drawn from the free state space, and
local steering is used to connect nearby states. Meanwhile,
starting from an initial state x
init
, RRT grows a tree by
sampling random states and connecting them to their closest
neighbor in the tree. Both behaviors are represented by the
extension step, as given by Algorithm 1 below. It has the
following sub-routines (see Fig. 1 for an illustration):
• Sampling SAMPLE(S): randomly samples from a
set S;
• Antecedent selection PARENTS(x
? ,V): returns a set
of states x belonging to the roadmap V , from which
steering towards x
? will be attempted;
• Local steering STEER(x,x
? ): tries to steer the system
from x towards x
? . If successful, returns a new node
x
steer
ready to be added to the roadmap. Depending on
the planner, the successfulness criterion may e.g., be
“reach x
? exactly” or “get close enough to x
? ”.
The design of each sub-routine greatly impacts the quality
and even the completeness of the resulting planner.
Algorithm 1 Extension step in randomized planners
Require: initial node x
init
, number of iterations N
1: (V,E)? ({x
init
},?)
2: for N steps do
3: x
rand
? SAMPLE(X
free
)
4: X
parents
? PARENTS(x
rand
,V)
5: for x
parent
in X
parents
do
6: x
steer
? STEER(x
parent
, x
rand
)
7: if x
steer
is a valid state then
8: V ?V?{x
steer
}
9: E?E?{(x
parent
,x
steer
)}
10: end if
11: end for
12: end for
13: return (V,E)
x'=SAMPLE()
ROOT
P
1
STEER(P , x')
1
P
2
STEER(P , x')
2
P
3
STEER(P , x')
3
Fig. 1. Illustration of the extension routine of randomized planners. To grow
the roadmap toward the sample x
? , the planner selects a number of parents
PARENTS(x
? ) = {P
1
,P
2
,P
3
} from which it applies the STEER(P
i
,x
? )
method.
In the literature, SAMPLE is usually implemented as
uniform random sampling. Some authors have suggested to
use adaptive sampling to improve the performance of RRT
or PRM planners.
In geometric planners, PARENTS is usually implemented
by deﬁning a metric (e.g., the ? 2
norm) on the conﬁguration
space, and using nearest-neighbors as antecedents. Such a
choice results in the so-called V oronoi bias of RRTs [2]. Both
experiments and theoretical analysis support this choice for
geometric planning. However, when moving to kinodynamic
planning, designing a metric that yields good antecedents
becomes as challenging as the motion planning problem
itself, and the Euclidean norm becomes highly inefﬁcient
(see e.g., [12] for an illustration in the case of the actuated
pendulum subject to torque bounds).
The next section discusses the various implementations of
the STEER sub-routine.
C. Classiﬁcation of Steering Methods
We propose to classify existing steering methods into three
categories. Analytical steering is the best method but is
available only for a very limited class of systems. State-
based steering is efﬁcient but relies on inverse dynamics,
and thus unapplicable to most systems with non-holonomic
constraints. Control-based steering relies instead on forward
dynamics and can thus be applied to a wider range of
systems.
1) Control-based steering: compute a control function
u : [0,T]?U
adm
and generate the corresponding trajectory
using forward dynamics. This approach does not guarantee
that the desired state is reached by the end of the trajectory. In
works such as [2], [8], random functionsu are sampled from
a family of primitives (e.g., piecewise-constant functions),
a number of them are tried and only the one bringing the
system closest to the target is retained. Linear-Quadratic
Regulation (LQR) [13], [14] is also control-based steering:
in this case, u is computed as the optimal policy for a linear
approximation of the system given a quadratic cost function.
2) State-based steering: interpolate a trajectory e ? :
[0,?
e
t]?C, for instance a Bezier curve matching the initial
and target conﬁgurations and velocities, and compute a con-
trol that makes the system track it. For fully-actuated system,
this is typically done using inverse dynamics. If no suitable
control exists, the trajectory is rejected. Note that both the
space Im(e ?) and time
˙
e ?(t) information of the interpolated
trajectory have an effect on dynamic quantities, and thus the
existence of admissible controls. More sophisticated methods
such as Admissible Velocity Propagation [15] can be applied
to restrict the interpolation to space, computing time and
controls separately.
3) Analytical steering: with control-based steering, it is
easy to respect differential constraints but difﬁcult to reach
the desired state. Conversely, with state-based steering, it
is easy to reach the desired state but difﬁcult to enforce
differential constraints (for instance, inverse dynamics cannot
always be used with non-holonomic systems). For some
systems, steering functions satisfying both requirements are
5819
known, like Reeds and Shepp curves for cars. When it is the
case, the problem can be reduced to path planning [9].
D. Previous Proofs of Probabilistic Completeness
Randomized planners such as Rapidly-exploring Random
Trees (RTT) and Probabilistic Roadmaps (PRM) are popular
because they are simple to implement yet efﬁcient in practice.
Proofs of probabilistic completeness come as another indi-
cator in their favor. However, one should beware of general
conceptions such as “RRT is probabilistically complete”:
as we will see, it is not always true for systems with
kinodynamic constraints. Let us review completeness results
that have been published for such systems.
Completeness of RRT planners has been established for
path planning [2], [3], [4]. In their proof, Hsu et al. quantiﬁed
the problem of narrow passages in conﬁguration space with
the notion of (?,?)-expansiveness [4]. The two constants
? and ? express a geometric lower bound on the rate of
expansion of reachability areas. The authors later extended
their solution to kinodynamic planning [8], using the same
notion of expansiveness, but this time in theX?T (state
and time) space with control-based steering. They established
that, when?> 0 and? > 0, their planner is probabilistically
complete. However, whether ? > 0 or ? = 0 in theX?T
space remains undiscussed, and the problem of evaluating
(?,?) is deemed as difﬁcult as the initial planning problem
[4].
LaValle et al. provided a completeness argument for
kinodynamic planning [2]. In their proof, they assumed the
existence of an attraction sequence, which is a covering of
the state space where two major problems of kinodynamic
planning, namely steering and antecedent selection (see
Section II-C), are already solved. However, conditions of
existence of such a sequence are not discussed.
These two examples highlight our concern about com-
pleteness proofs: in both cases, probabilistic completeness
is established under assumptions whose veriﬁcation is at
least as difﬁcult as the motion planning problem itself. This
observation does not question the quality of the associated
planners, which have also been checked experimentally.
Rather, it hints that too much of the complexity of kino-
dynamic planning has been abstracted into hypotheses. As a
result, these completeness proof do not help us understand
why these planners work (or don’t work) in practice.
Karaman et al. introduced their path planning algorithm
RRT* in [3] and extended it to kinodynamic planning with
differential constraints in [16], providing a sketch of proof for
the completeness of their solution. However, they assumed
that their planner had access to the optimal cost metric and
optimal local steering (wich means STEER(x
1
,x
2
) always
returns the optimal trajectory starting from x
1
and ending at
x
2
), which restricts the analysis to systems for which these
ideal solutions are known.
The same authors tackled the problem from a slightly
different perspective in [17]. They now assumed that the
PARENTS function computes w-weighted boxes, which are
abstractions of the system’s local controlability. It remains
unclear to us how these boxes can be computed or approx-
imated in practice, given that their deﬁnition involves the
joint ﬂow of vector ﬁelds spanning the tangent space of the
system’s manifold. Although their set of assumptions is of
primary concern to us since we follow a similar approach
in Section III, they did not prove their theorem, arguing that
the reasoning was similar to the one in [3] for kinematic
systems.
To the best of our knowledge, as of yet, there is no com-
pleteness proof for kinodynamic planners using state-based
steering. We will establish such a result in the following
section.
III. COMPLETENESS OF STATE-BASED STEERING
KINODYNAMIC PLANNERS
A. Terminology
A function is smooth when all its derivatives exist and are
continuous. A functionf :A?B between metric spaces is
Lipschitz when there exists a constant K
f
such that
?(x,y)?A, kf(x)?f(y)k≤ K
f
kx?yk.
Throughout the present paper, we will work within normed
vector spaces and k·k will refer to the Euclidean norm
k·k
2
. We will also consistently denote by K
f
the (smallest
possible) Lipschitz constant of any Lipschitz function f.
LetC denote n-dimensional conﬁguration space, where
n is the number of degrees of freedom of the robot. We
will call state space the 2n-dimensional manifold X of
conﬁguration and velocity coordinates. In the present paper,
we only consider fully actuated systems. Let the control
input space (“control space” for short) be an n-dimensional
manifoldU. The dynamics of the robot follow the equations
of motion, which can be written in generalized coordinates
as
M(q)¨ q +C(q, ˙ q)˙ q +g(q) =u. (1)
Equivalently, the robot’s dynamics follow the time-invariant
differential system
˙ x(t) = f(x(t),u(t)), (2)
where x(t)?X and u(t)?U. We will assume that f is
Lipschitz continuous in both of its arguments. The setU
adm
of admissible controls is assumed to be a compact subset of
U.
A trajectory is a continuous function ? : [0,T]?C. A
path is the image of a trajectory. An admissible trajectory is a
solution to the differential system (2). The kinematic motion
planning problem is to ﬁnd a path in the collision-free subset
C
free
?C from an initial conﬁguration q
init
to any conﬁgu-
ration q
goal
in a set of goals. Meanwhile, the kinodynamic
motion planning problem is to ﬁnd an admissible trajectory
fromq
init
toq
goal
, both avoiding obstacles and following the
system’s dynamics.
A control function t7? u(t) is said to have ?-clearance
when its image is in the ?-interior of the set of admissible
controls, i.e., for any time t,B(u(t),?)?U
adm
.
5820
We deﬁne the distance between a state x?X and the
curve ? as:
dist
?
(x) := min
t?[0,T]
k(?, ˙ ?)(t)?xk
Whenever considering two states x and x
? , we will write
x =: (q, ˙ q) and x
? =: (q
? , ˙ q
? ). The preﬁx ? will be used to
denote variations between x and x
? , such as ?x := x
? ?x,
?q := q
? ?q, and so on. Similarly, for two time instants
t < t
? , we will write ?t := t
? ?t and ?g := g(t
? )?g(t)
for any function g.
B. Assumptions for the Completeness Theorem
Our model for anX -state randomized planner is given
by Algorithm 1 using state-based steering. We make the
following three assumptions on the system:
Assumption 1: The system is fully actuated.
Assumption 2: The set of admissible controls U
adm
is
compact.
Assumption 3: The inverse of the differential constraintf
from Equation (2), i.e., the function f
?1
s.t. u =f
?1
(x, ˙ x),
is Lipschitz in both of its arguments.
Assumption 1 is a pre-requisite for the function f
?1
used
in Assumption 3 to be well-deﬁned. The latter assumption is
satisﬁed when f is given by the dynamics equations (1) as
long as the matrices M(q) and C(q, ˙ q) have bounded norm,
and the gravity term g(q) is Lipschitz. Indeed, for a small
displacement between x and x
? ,
ku
? ?uk ≤ kMkk¨ q
? ? ¨ qk+kC(q, ˙ q)kk˙ q
? ? ˙ qk
+K
g
kq
? ?qk
(3)
Regarding Assumption 2, since torque constraints are our
main concern, we will make our proof of completeness for
(note that the comparison is component-wise)
U
adm
:={u?U, |u|≤?
max
},
which is indeed compact. The generalization to an arbitrary
compact set presents no technical difﬁculty.
Let us now turn to the design of the interpolation routine.
We make the following three hypotheses:
Assumption 4: Interpolated trajectories e ? are smooth Lip-
schitz functions, and their time-derivatives
˙
e ? (i.e., interpo-
lated velocities) are also Lipschitz.
Assumption 5 (Local boundedness): We suppose that
there exists a constant ? such that, for any (x,x
? )?X
2
, the
interpolated trajectory e ? : [0,?
e
t]?C between x and x
? is
included in a ball of center x and radius ?kx
? ?xk.
Assumption 6 (Acceleration compliance): The accelera-
tion of interpolated trajectories uniformly converges to the
discrete velocity derivative, i.e., there exists some? > 0 such
that, ife ? : [0,?
e
t]?C results from INTERPOLATE(x,x
? ),
then
??? [0,?
e
t],




¨
e ?(?)?
k˙ qk
k?qk
?˙ q




≤ ?k?xk
Assumption 4 is quite easy to satisfy. Assumption 5
bounds the position and velocity of interpolated trajecto-
ries with respect to the neighborhood of x and x
? , while
Assumption 6 bounds their acceleration with respect to the
discrete derivative of the velocity between x and x
? . These
three assumptions are design guidelines for the interpolation
routine. They ensure that the resulting local planner will
always look for smaller trajectories when working in smaller
neighborhoods. Note that we consider fully-actuated (thus
small-space controllable) systems for which such solutions
always exist.
C. Verifying the Assumptions on the Double Pendulum
To illustrate the practicality of these assumptions, let us
consider the standard example of a fully-actuated double
pendulum under torque constraints.
1) System assumptions: When pendulum links have
mass m and length l, the gravity term g(?
1
,?
2
) =
mgl
2
[sin?
1
+sin(?
1
+?
2
) sin(?
1
+?
2
)] is Lipschitz with
constant K
g
= 2mgl. Meanwhile, the inertial term is
bounded bykMk≤ 3ml
2
and, when joint angular velocities
are bounded by ?, the norm of the Coriolis tensor is
bounded by 2?ml
2
. Therefore, from Equation (3), there exist
a Lipschitz constant K
f
?1.
2) Interpolation: A simple second-order polynomial in-
terpolation is given by:
?(t) =
?˙ q
2?t
t
2
+

?q
?t
?
?˙ q
2

t+q, (4)
where ?t :=
k?qk
k˙ qk
. This expression only matches position
and acceleration constraints (in particular, it does not work
when k˙ qk = 0). One can use higher-order polynomials
in a similar fashion to take velocities into account as
well. All polynomials satisfy the smoothness Assumption
4. Meanwhile, Assumption 6 is veriﬁed as the dominating
term in (4) is exactly the discrete velocity time-derivative.
Finally, one can check with no computational hassle that
k?(t)??(0)k≤ (1+k?˙ qk/k˙ qk)k?qk? 0 whenk?xk?
0.
D. Completeness Theorem
We can now state our main result:
Theorem 1: Consider a time-invariant differential system
(2) with Lipschitz-continuous f and full actuation over a
compact set of admissible controlsU
adm
. Suppose that the
kinodynamic planning problem between two states x
init
and
x
goal
admits a smooth Lipschitz solution ? : [0,T]?C with
?-clearance in control space. LetK denote a randomized
motion planner (Algorithm 1) using state-based steering and
a locally bounded, Lipschitz, acceleration-compliant interpo-
lation primitive.K is probabilistically complete.
Let us start the proof of this theorem with three lemmas.
Detailed proofs of these lemmas are provided in the supple-
mentary material.
1
Lemma 1: Let g : [0,T]?R
k
denote a smooth Lipschitz
function. Then, for any (t,t
? )? [0,T]
2
,




˙ g(t)?
g(t
? )?g(t)
|t
? ?t|




≤
K
g
2
|t
? ?t|.
1
Supplementary material for this paper is available online at:
http://scaron.info/papers/icra-2014/supmat.pdf
5821
Lemma 2: If there exists a trajectory ? with ?-clearance
in control space, then there exists ?
? <? and a trajectory ?
? with?
? -clearance in control space such that inf
t
k¨ ?
? (t)k> 0.
Lemma 3: If there exists a trajectory ? with ?-clearance
in control space, then there exists ?
? <? and a trajectory ?
? with?
? -clearance in control space such that inf
t
k˙ ?
? (t)k> 0.
Let ? : [0,T]?C,t7? ?(t) denote a smooth Lipschitz
admissible trajectory from x
init
to x
goal
with ?-clearance in
control space. We deﬁne:

˙
M := max
t
k˙ ?(t)k
˙ m := min
t
k˙ ?(t)k

¨
M := max
t
k¨ ?(t)k
¨ m := min
t
k¨ ?(t)k
From lemmas 2 and 3, we can suppose without loss of
generality that ˙ m > 0 and ¨ m > 0. Consider two states x
and x
? and the corresponding time instants on the trajectory

t := argmin
t
k(?(t), ˙ ?(t))?xk,
t
? := argmin
t
k(?(t), ˙ ?(t))?x
?k.
We can suppose w.l.o.g. that t < t
? . First, note that there
exists ?t
1
> 0 such that, for any ?t≤?t
1
,
k??k
?t
≥
˙ m
2
,
k?˙ ?k
?t
≥
¨ m
2
,
k?˙ ?k
k??k
≤
2
¨
M
˙ m
.
Indeed, the three functions ?t7?
k??k
?t
, ?t7?
k?˙ ?k
?t
and
?t 7?
k?˙ ?k
k??k
. are continuous over the compact set [0,T],
hence uniformly continuous, and their limits when ?t? 0
are respectivelyk˙ ?(t)k≥ ˙ m,k¨ ?(t)k≥ ¨ m and
k¨ ?(t)k
k˙ ?(t)k
≤
¨
M
˙ m
.
In what follows, we will then suppose that ?t is smaller
than this ﬁrst threshold ?t
1
.
Let e ? : [0,?
e
t] ? C denote the result of
INTERPOLATE(x,x
? ). For?? [0,?
e
t], the torque required
to follow the trajectory e ? is e u(?) := f(e ?(?),
˙
e ?(?),
¨
e ?(?)).
Since Im(u)? int
?
(T ),
|e u(?)| ≤|e u(?)?u(t)|+|u(t)|
≤


f(e ?(?),
˙
e ?(?),
¨
e ?(?))?f(?(t), ˙ ?(t),¨ ?(t))



+(1??)?
max
,
where the comparison here is component-wise. If the ﬁrst
term in this upper bound is≤ ??
max
, then the system will
be able to track e ? at time ?. We can rewrite it as follows:


f(e ?(?),
˙
e ?(?),
¨
e ?(?))?f(?(t), ˙ ?(t),¨ ?(t))



≤


f(e ?(?),
˙
e ?(?),
¨
e ?(?))?f(?(t), ˙ ?(t),¨ ?(t))



∞
≤ K
f


(e ?(?),
˙
e ?(?))?(?(t), ˙ ?(t))


+K
f



¨
e ?(?)? ¨ ?(t)



≤K
f
[(? +?)k?xk+ dist
?
(x)]
| {z }
distance term (D)
+K
f




k˙ qk
k?qk
?˙ q? ¨ ?(t)




| {z }
acceleration term (A)
, (? )
where we used the triangular inequality, the Lipschitz condi-
tion on f, as well as local boundedness (Assumption 5) and
acceleration compliance (Assumption 6) of the interpolated
trajectory. The transition from the norm k·k
∞
to k·k is
possible because all norms ofR
n
are equivalent (a change
in norm will be reﬂected by a different constant K
f
).
1) Bounding the acceleration term: the discrete velocity
derivative
k˙ qk
k?qk
?˙ q can be further decomposed into:




k˙ qk
k?qk
?˙ q? ¨ ?(t)




≤




?˙ q
k˙ qk
k?qk
??˙ ?
k˙ ?(t)k
k??k




+
k?˙ ?k
k??k




k˙ ?(t)k?
k??k
?t




+




?˙ ?
?t
? ¨ ?(t)




.
Let us call these three terms (A1), (A2) and (A3). From
Lemma 1, (A3)≤
K ˙ ?
2
?t and
(A2) ≤
K
˙ ?
2
k?˙ ?k
k??k
?t ≤
K
˙ ?
¨
M
˙ m
?t.
Then, deﬁning ?t
2
:= min

?t
1
,
?? max
2K ˙ ?
,
? ˙ m? max
4
¨
MK ˙ ?

, we have
that, for any ?t<?t
2
, (A2) and (A3) are upper bounded by
?? max
4K
f
. The expression?˙ q
k˙ qk
k?˙ qk
in (A1) represents the discrete
derivative of the velocity ˙ q between q and q
? (its continuous
analog would be
k˙ qkd˙ q
k˙ qkdt
=
d˙ q
dt
). Thus, (A1) can be seen as the
deviation between the discrete accelerations of e ? and ?. Let
us decompose this expression in terms of norm and angular
deviation:
(A1) ≤





?˙ ?
k?˙ ?k
?
?˙ q
k?˙ qk

k˙ ?kk?˙ ?k
k??k
+
?˙ q
k?˙ qk

k?˙ ?kk˙ ?k
k??k
?
k?˙ qkk˙ qk
k?qk




≤ 2
k˙ ?kk?˙ ?k
k??k

1?cos
\
(?˙ q,?˙ ?)

| {z }
angular deviation term (?)
+




k˙ ?kk?˙ ?k
k??k
?
k?˙ qkk˙ qk
k?qk




| {z }
norm deviation term (N)
Since the factor
2k˙ ?kk?˙ ?k
k??k
before the angular deviation (?) is
bounded by
4
˙
M
¨
M
˙ m
,
\
(?˙ q,?˙ ?)? 0 is a sufﬁcient condition
for (?)? 0. We will show that both the norm and angular
deviation terms tend to zero as ?t? 0.
2) Bounding the norm (N): let us suppose that dist
?
(x)
and dist
?
(x
? ) are≤
1
2
˙ m?t
2
=: ??. We can expand (N) as
follows:
(N) ≤
k?˙ ?k
k??k
|k˙ ?k?k˙ qk|+k˙ qk




k?˙ ?k
k??k
?
k?˙ qk
k?qk




≤
2
¨
M
˙ m
??+
k˙ qk
k??kk?qk
|k?˙ ?kk?qk?k?qkk?˙ qk|
≤
2
¨
M
˙ m
??+
k˙ qk(k??k+k?˙ ?k)??
k??kk?qk
≤
2
¨
M
˙ m
??+??
k˙ qk
k?qk
"
1+
2
¨
M
˙ m
#
≤
2
¨
M
˙ m
??+??
k˙ ?k+??
k??k???
"
1+
2
¨
M
˙ m
#
5822
(N) ≤
"
¨
M?t+
( ˙ m+2
¨
M)(2
˙
M + ˙ m?t
2
)
˙ m
2
(1??t)
#
?t
This last bound is expressed only in terms of ?t and
constants ˙ m,
˙
M and
¨
M. Since it tends to zero as ?t? 0,
there exists some duration ?t
3
≤ ?t
2
such that, for any
?t≤?t
3
, (N)≤
?? max
8K
f
.
3) Bounding the angular deviation: simple vector geom-
etry shows that
sin
\
(?˙ q,?˙ ?)≤
dist
?
(x)+ dist
?
(x
? )
k?˙ ?k
≤
??
¨ m?t
≤
˙ m
2¨ m
?t.
Since 1? cos? < sin? for any ?? [0,π/2], there exists
a duration ?t
4
≤ ?t
3
such that ?t < ?t
4
? (?)≤
?? max
8K
f
.
Combining our bounds on terms (A2), (A3), (N) and (?),
we have showed so far that, when ?t is small enough, the
acceleration term is upper bounded by
3
4
??
max
.
4) Bounding the distance term (D): the remaining term
is proportional to
(? +?)k?xk+ dist
?
(x) ≤ (2??+k??k)(? +?)+??
≤
K
?
(? +?)+3 ˙ m?t
2
?t
Hence, there exist a ﬁnal ?t≤?t
4
such that, when ?t<?t,
this last bound becomes≤
?? max
4K
f
as well. Combining all our
bounds, we have established the existence of a duration ?t
such that ?t≤?t?|e u(?)|≤?
max
.
5) Link with completeness: let us summarize our reason-
ing so far. We have iteratively constructed a duration ?t and
a radius ??, independent from t or t
? , such that, as soon as
|t
? ?t| < ?t, dist
?
(x) < ?? and dist
?
(x
? ) < ??, the system
can track the trajectory INTERPOLATE(x,x
? ).
The proof of completeness of the whole randomized
planner follows directly from this construction. Let us denote
byB
t
:=B((?, ˙ ?)(t),??), the ball of radius ?? centered on
(?, ˙ ?)(t)?X . Suppose that the roadmap contains a state
x?B
t
, and let t
? := min(T,t+?t). If the planner samples
a state x
? ?B
t
? , the interpolation between x and x
? will be
successful and x
? will be added to the roadmap. Since the
volume ofB
t
? is non-zero for the Lebesgue metric, the event
{SAMPLE(X
free
)?B
t
?} will happen with probability one
as the number of extensions goes to inﬁnity.
At the initialization of the planner, the roadmap is reduced
to x
init
= (?(0), ˙ ?(0)). Therefore, using the property above,
by induction on the number of time steps ?t, the last state
(?(T), ˙ ?(T)) will be eventually added to the roadmap with
probability one, which establishes the probabilistic complete-
ness of the randomized planner.
IV. CONCLUSION
The goal of the present paper was to clarify the panorama
of completeness results in randomized kinodynamic plan-
ning. We noted that existing proofs usually rely on assump-
tions too strong to be veriﬁed on practical systems. We
proposed a classiﬁcation of the various types of kinodynamic
constraints and planning methods used in the ﬁeld, and
went on to prove probabilistic completeness for an important
class of planners, namely those which steer by interpolating
system trajectories in the state space. Along the way, our
analysis also provided some insights into the design of such
interpolation functions.
The proof strategy that we used, i.e., the inclusion of the
solution trajectory into a “tube” of non-zero volume, is not
new. It is related to the “attraction sequence” hypothesized
in [2], and can be traced back to seminal papers such as [7].
However, to the best of our knowledge, our work is the ﬁrst
theoretical analysis to establish the existence and explicitely
construct such a bounding tube. This construction is an extra
link with reality: for a given system, one can actually check
for full actuation, compacity of the control set and Lips-
chitz continuity of the dynamics function. Similarly, when
designing her interpolation function, one can easily check
for properties such as local boundedness and acceleration
compliance.
REFERENCES
[1] S. LaValle, Planning algorithms. Cambridge Univ Press, 2006.
[2] S. M. LaValle and J. J. Kuffner, “Randomized kinodynamic planning,”
The International Journal of Robotics Research, vol. 20, no. 5, pp.
378–400, 2001.
[3] S. Karaman and E. Frazzoli, “Sampling-based algorithms for optimal
motion planning,” The International Journal of Robotics Research,
vol. 30, no. 7, pp. 846–894, 2011.
[4] D. Hsu, J.-C. Latombe, and R. Motwani, “Path planning in expansive
conﬁguration spaces,” in Robotics and Automation, 1997. Proceed-
ings., 1997 IEEE International Conference on, vol. 3. IEEE, 1997,
pp. 2719–2726.
[5] T. Lozano-Perez, “Spatial planning: A conﬁguration space approach,”
Computers, IEEE Transactions on, vol. 100, no. 2, pp. 108–120, 1983.
[6] L. E. Kavraki, P. Svestka, J.-C. Latombe, and M. H. Overmars, “Proba-
bilistic roadmaps for path planning in high-dimensional conﬁguration
spaces,” Robotics and Automation, IEEE Transactions on, vol. 12,
no. 4, pp. 566–580, 1996.
[7] B. Donald, P. Xavier, J. Canny, and J. Reif, “Kinodynamic motion
planning,” Journal of the ACM (JACM), vol. 40, no. 5, pp. 1048–1066,
1993.
[8] D. Hsu, R. Kindel, J.-C. Latombe, and S. Rock, “Randomized kino-
dynamic motion planning with moving obstacles,” The International
Journal of Robotics Research, vol. 21, no. 3, pp. 233–255, 2002.
[9] J.-P. Laumond, Robot Motion Planning and Control. New York:
Springer-Verlag, 1998.
[10] J. Bobrow, S. Dubowsky, and J. Gibson, “Time-optimal control of
robotic manipulators along speciﬁed paths,” The International Journal
of Robotics Research, vol. 4, no. 3, pp. 3–17, 1985.
[11] F. Bullo and K. M. Lynch, “Kinematic controllability for decoupled
trajectory planning in underactuated mechanical systems,” Robotics
and Automation, IEEE Transactions on, vol. 17, no. 4, pp. 402–412,
2001.
[12] A. Shkolnik, M. Walter, and R. Tedrake, “Reachability-guided sam-
pling for planning under differential constraints,” in Robotics and Au-
tomation, 2009. ICRA’09. IEEE International Conference on. IEEE,
2009, pp. 2859–2865.
[13] A. Perez, R. Platt, G. Konidaris, L. Kaelbling, and T. Lozano-Perez,
“Lqr-rrt*: Optimal sampling-based motion planning with automatically
derived extension heuristics,” in Robotics and Automation (ICRA),
2012 IEEE International Conference on. IEEE, 2012, pp. 2537–
2542.
[14] R. Tedrake, “Lqr-trees: Feedback motion planning on sparse random-
ized trees,” 2009.
[15] Q.-C. Pham, S. Caron, and Y . Nakamura, “Kinodynamic planning in
the conﬁguration space via velocity interval propagation,” Robotics:
Science and System, 2013.
[16] S. Karaman and E. Frazzoli, “Optimal kinodynamic motion planning
using incremental sampling-based methods,” in Decision and Control
(CDC), 2010 49th IEEE Conference on. IEEE, 2010, pp. 7681–7687.
[17] ——, “Sampling-based optimal motion planning for non-holonomic
dynamical systems,” in IEEE Conference on Robotics and Automation
(ICRA), 2013.
5823
