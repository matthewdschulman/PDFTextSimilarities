Learning Efﬁcient Control of Robots Using Myoelectric Interfaces
Mark Ison, Chris Wilson Antuvan and Panagiotis Artemiadis
Abstract— Myoelectric controlled interfaces are a vital com-
ponent for advancing applications in prostheses, exoskeletons,
and robot teleoperation. Current methods search for optimal
neural decoders for enhanced initial user performance. How-
ever, recent studies demonstrate learning an inverse model
of abstract decoders to improve performance over time. This
paper proposes a paradigm shift on myoelectric interfaces by
embedding the human as controller of a system and allowing
the human to learn how to control it via control tasks with
similar mapping functions. The method is tested using two
different control tasks and four different abstract mappings
of upper limb myoelectric signals to control actions for those
tasks. The results conﬁrm that all subjects are able to learn
the mappings and improve performance efﬁciency over time.
A cross-trial evaluation reveals a signiﬁcant learning transfer
when a new control task is presented using the same mapping
as a previous task, resulting in enhanced initial performance
with the new task. Comparison of EMG signal evolution across
subjects indicates a signiﬁcant population-wide muscle synergy
development that results from learning and implementing the
inverse model of the mapping function to complete the tasks.
This suggests that efﬁcient performance may be achieved by
learning a constant, arbitrary mapping function applied to
multiple control tasks rather than dynamic subject- or task-
speciﬁc functions. Moreover, this method can be used for the
neural control of any device or robot, without restricting them
to anthropomorphic or human-related counterparts.
I. INTRODUCTION
Myoelectric controlled interfaces, through mediating con-
nections between electromechanical systems and humans, are
a vital component for advancing applications in prostheses,
orthoses, and robot teleoperation. This technology offers
promise to help amputees regain independence [1], [2],
humans perform tasks beyond their physical capabilities [3],
[4], and robotic devices be teleoperated with precision [5],
[6], [7], [8]. Breakthroughs in reliable detection of neural sig-
nals using electromyography (EMG) have given researchers
noninvasive access to muscle activity, bringing myoelectric
interfaces to the forefront for further advancement of these
applications.
A. Neural Decoding
Current research has focused on improving performance
of myoelectric controlled interfaces through optimal de-
coding of neural signals. Various algorithms use machine
learning techniques, but wide inter-user variability in EMG
signals requires intense training phases to create a decoder
speciﬁcally for a given user [1], [2], [9], [10]. Even with
Mark Ison, Chris Wilson Antuvan and Panagiotis Artemiadis are with
the School for Engineering of Matter, Transport and Energy, Arizona State
University, Tempe, AZ 85287 USA
Email: fmison, cantuvan, panagiotis.artemiadisg@asu.edu

Corresponding author.
training, this highly non-linear system makes satisfactory
decoding accuracy difﬁcult to achieve [11]. Other methods
use intuitive decoders to control an interface with a small
set of simple commands, translating to predeﬁned actions by
a robot [12], [13]. However, the rigid set of actions limit
users’ ability to learn better control of the system, and the
performance cannot generalize to new tasks. Both methods
intend to maximize the initial performance of the user. This
does not capitalize on a human’s natural ability to learn
and optimize control strategies while performing tasks [14].
Thus, these approaches may not provide a foundation for
efﬁcient performance over time.
Alternatively, other works investigate the capacity to learn
an inverse model of a predeﬁned decoding function. H´ eliot et.
al [15] form a model of the brain to convert ﬁring neurons
to two dimensional (2D) positions for center to reach out
tasks. This model simulates how minimizing output error
inﬂuences brain plasticity to learn the inverse model of the
decoding function. Kim et. al [16] conﬁrm these results
experimentally with closed loop training. Chase et. al [17],
when comparing performance of two decoding algorithms,
show signiﬁcant performance differences between decoders
in open loop tasks, but minimal difference in online closed
loop control tasks.
Closed loop myoelectric controlled interfaces are further
investigated by Radhakrishnan et. al [18] to understand
human motor learning. Two distinct decoders are used to
decode EMG signal amplitude from six muscles to generate
a 2D cursor position. The intuitive decoder maps muscles to
a vector along the 2D plane most consistent with limb move-
ment when the muscle contracts. The non-intuitive decoder
maps muscles randomly along equally spaced vectors in the
plane. Results indicate learning via performance trends best
ﬁt by exponential decay. While the intuitive decoder gives
better initial performance, the non-intuitive decoder provides
a steeper learning rate and achieves nearly equal performance
after 192 trials.
Pistohl et. al [19] demonstrate the natural extension of this
motor learning to practical robotic applications. Using EMG
signals to control ﬁngers on a robotic hand, subjects are able
to learn a non-intuitive decoding function with comparable
performance to a 2D cursor control task similar to [18].
These studies establish that humans can learn to control
myoeletric interfaces using various decoders when presented
with closed-loop feedback. The study presented in this paper
expands these ﬁndings by investigating the performance
impact of previously learned mappings on new control tasks.
In addition, population-wide muscle synergy development is
evaluated to conﬁrm learning of a more efﬁcient control.
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 2880
Muscle synergies represent a series of muscle activation
patterns used to achieve a behavioral goal. The Central
Nervous System, instead of activating each individual muscle
separately, activates a combination of muscle synergies to
produce a desired motion [20]. Previous studies have identi-
ﬁed synergies from EMG signals of a given user to simplify
decoding of arm kinematics [21] and predict hand motions
[9]. Synergies have also been associated with improved
control during interaction with abstract decoding functions
[22].
Before presenting the novelty of the proposed technique,
two concepts frequently used in this paper are deﬁned:
Control task
The task to be executed using myoelectric controls,
implying both the device (e.g. a robot hand) and its
possible functions (e.g. open/close ﬁngers etc).
Mapping function
A mathematical function relating myoelectric ac-
tivity to controls for the task (e.g. a function
translating bicep EMG to opening the ﬁngers of
a robot hand).
B. Contribution
This paper proposes a paradigm shift on myoelectric inter-
faces by suggesting arbitrary mapping functions between the
neural activity and the control actions that can be learned via
alternative control tasks. More speciﬁcally, this paper investi-
gates user performance efﬁciency and population synergy de-
velopment with myoelectric interfaces and arbitrary mapping
functions which were neither designed for the subject nor the
task. Expanding on recent conclusions that visual feedback is
effective for learning decoders in myoelectric interfaces [16],
[17], [18], [19], this paper provides evidence that subjects
do not only learn mappings between their actions and a
speciﬁc control task, but they can retain this learning and
generalize it to different control tasks having similar mapping
functions. The implications of this contribution are vast,
suggesting that efﬁcient control of robots can be achieved
through learning to control different myoelectric interfaces
using similar mapping functions. To the best of the authors’
knowledge, no other study has performed such an analysis
to support the shift to human embedded control of devices
using generalizable myoelectric interfaces.
II. METHODS
A. Experimental Setup
The experiments are designed to evaluate transfer of
human motor learning across new control tasks and compare
muscle synergy development across subjects. The setup for
the experiment (shown in Fig. 1) includes wireless EMG
sensors (Delsys Trigno Wireless, Delsys Inc), and a multi-
function data acquisition card (DAQ) (USB-6343X, NI),
which acquires the signal and sends it to a Personal Com-
puter (PC). A C++ program processes the signal in real time
and a mapping function transforms it into control outputs
for performing the two tasks. The tasks are displayed on the
monitor via OpenGL API [23] to provide visual feedback.
Task 1 Task 2 or
PC DAQ
EMG
electrode
Task 1 Task 2
Fig. 1. Experimental setup includes an EMG system, DAQ, and visual
interface (top). The two tasks the subjects control using EMG signals
(bottom).
B. Control Tasks
Two distinct tasks provide different visual feedback for the
subject (see Fig. 1). The goal of each task is to transition
a virtual object from its initial state to one of eight target
states as quickly as possible. Task 1 is a standard center to
reach out task, requiring the subject to move a red circle
from the center to one of eight targets (green circle) when
prompted. The eight targets are symmetrically spaced along
the four quadrants of a circle. Task 2 consists of a (red)
rectangular object which the subject can re-size and rotate
to match one of eight target (green) rectangles. The eight
targets are grouped equivalently to the four target areas in
Task 1. With the same mapping function, the set of targets in
both tasks require equal input sequences to reach the target
from the starting state.
C. Mapping Functions
EMG signals are acquired at 1kHz from four right arm
muscles: Biceps Brachii (BB), Triceps Brachii (TB), Flexor
Carpi Radialis (FCR) and Extensor Carpi Ulnaris (ECU).
The raw EMG signals are pre-processed with full-wave
rectiﬁcation and a low pass ﬁlter (2nd order Butterworth,
cut-off 8Hz) to remove high frequency noise and obtain a
linear envelope of the signal [11]. The processed signal is
then transformed through the mapping function to produce
the output command.
A mapping function is a 24 matrix W
i
, relating a 41
vector e of ﬁltered EMG to a 2 1 vector u of control
outputs:
u =W
i
e; i2f1; 2; 3; 4g (1)
where each W
i
is as deﬁned in Fig. 2. The control outputs
are represented visually in 2D control space, with control
axes corresponding to the x (horizontal) and y (vertical)
velocities of the moving circle in the case of Task 1. For Task
2, the two control axes correspond to the angular velocity and
change in size of the rectangle. An activation threshold of
2881
Fig. 2. Mapping of input EMG amplitudes to two output control axes
using the mapping function deﬁned in (1).
0.02mV is set for each muscle to nullify any control output
at rest.
The mapping functionW
1
should be the most intuitive for
subjects, according to [18]. Each set of antagonistic muscles
(BB-TB and FCR-ECU) map divergently along one control
axis. Mapping functions W
2
and W
3
require a combination
of two muscles to command direction along a single control
axis, with W
3
encouraging co-contraction of antagonistic
muscles. W
4
is a random matrix with zero row mean so
that equal activation of all muscles results in no motion.
D. Trials
A single experiment for a subject consists of 8 trials (four
mapping functions for each of the two types of control tasks)
performed over two days. The trials are randomly scheduled
under the constraints that the tasks alternate and mapping
functions are not repeated until every other mapping function
has been seen in between. Each mapping function appears
only once per day to minimize the feeling of familiarity for
each trial. Each trial consists of the scheduled combination of
task and mapping function which is unknown to the subject
before the trial begins. The subject is assigned to repeatedly
transition the red virtual object on the screen from a default
initial state to the green target state as quickly as possible.
This is repeated for a set of 128 evenly distributed (16
repetitions per target) and randomized sequence of targets,
with short 5 second breaks after each successfully reached
target. A long break is given after 64 attempts to prevent
excessive muscle fatigue. With targets grouped into pairs to
represent their respective quadrants, each trial gives 32 data
points, representing time taken to reach the ﬁnal state, for
targets in a given quadrant and 32 sets of processed EMG
signals, representing the input commands used by the subject
while performing the task.
III. RESULTS
Five healthy right-handed subjects (23-30 years old, 1
Female, 4 Male) participated in the experiments. Each gave
informed consent according to the procedures approved by
the ASU IRB (Protocol: #1201007252). A qualitative survey
was given to the subjects after the experimenet to determine
their conscious awareness of the differences in each trial.
All subjects considered Task 1 to be easier than Task 2, and
suggested some mapping functions were easier than others.
None realized the same sets of input responses were required
to reach the targets in both tasks, although some noticed
a few trials required similar muscle activity to move the
objects.
Quantitative evaluation looks at performance efﬁciency
and synergy development during operation. An increase in
performance efﬁciency, measured by the time taken to com-
plete a given task, indicates more efﬁcient interaction with
the interface to complete tasks quickly. Synergy development
conﬁrms convergence toward efﬁcient muscular control of
the task-space. Transferring this learning to new control
tasks would result in better initial performance and control
efﬁciency.
A. Learning
The assumption behind evaluating learning transfer and
synergy development is that learning occurs within each trial
when the task and mapping function remain constant. From
prior work [17], [18], a chronological plot of time taken to
reach each target i (i2f1; 2; 3; 4g) for a given trial z (z2
f1; 2;:::; 8g) is expected to follow an exponential decay,y
z
i
,
with respect to the number of attempts x
z
i
:
y
z
i
(x
z
i
) =a
z
i
10
 b
z
i
x
z
i
+c
z
i
;x2f1; 2;:::; 32g (2)
where a
z
i
> 0, b
z
i
> 0, and c
z
i
are the initial performance,
learning rate, and steady state value, respectively, for trial z
and target i. This equation represents an initially high time
required (a) to successfully perform any task and a constant
exponential decrease (b) towards a ﬁnal steady-state value
(c). Thus, b gives the learning rate for the system. For this
analysis, as most subjects are unable to reach steady state
in any of the 8 trials, and perfect control of the system
would give data points very near 0, each c is assumed to
be negligible. Then, to better quantify the results in terms of
learning rate, the analysis here plots the data on a logarithmic
scale and performs least squares regression to ﬁt a straight
line, t
z
i
, equivalent to the log of (2):
t
z
i
(x
z
i
) = log
10
(y
z
i
(x
z
i
)) = log
10
(a
z
i
) b
z
i
x
z
i
(3)
In (3), steeper slope corresponds to better learning rate.
Figure 3 shows an example of a typical data pattern for one
quadrant in a given trial, both with original data and the
corresponding logarithmic scale. These trends occur for all
target quadrants, trials, and subjects, with an overall mean

b = 0:0108ms per attempt and standard deviation (b) =
0:0074ms per attempt. These learning rates are signiﬁcant
on a student t-test with p = 3:4570e
 41
, consistent with
previous ﬁndings that learning occurs within each trial.
B. Learning Transfer
With signiﬁcant learning occurring within each trial, learn-
ing transfer can be compared among subsequent trials with
2882
Fig. 3. Typical chronological performance trend for a trial in a given
environment, both raw data and logarithmic plots.
either the same control task or mapping function. That
is, identify whether the subject is learning to operate the
controls of each mapping function irrespective of the control
tasks, or whether the subject is learning to interact with
each control task better irrespective of the different mapping
functions. Learning transfer can be evaluated by analyzing
trials chronologically along similar control tasks (Case 1)
or mapping functions (Case 2). For a representative subject,
two plots are generated to evaluate learning transfer (see
Fig. 5). The ﬁrst plot (Case 1) contains the logarithmic data
points for all four trials performed with Task 1, and the
second plot (Case 2) contains the logarithmic data points for
both trials performed with Mapping Function 2, both plotted
horizontally by chronological trial order. Learning transfer
is indicated by a smooth transition from the learning curve
of one trial, t
z0
i
(x
z0
i
), to the next one, t
z0+1
i
(x
z0+1
i
). In the
logarithmic scale, a smooth transition corresponds to two
factors, the similarity between b
z0
i
and its adjacent b
z0+1
i
,
and the gap between the last data point of one trial, t
z0
i
(32)
and the ﬁrst data point in the next trial, t
z0
i
(1). Both of
these factors are quantiﬁed and incorporated into a transition
index to determine transition smoothness for a given set of
chronologically ordered trials:
 Root mean squared error (RMSE) between the line
ﬁtted over the entire data (all chronologically-ordered
trials) and eacht
z
i
in the set, shifted to the appropriate
order (Fig. 4). A smaller value indicates that each
subsequent trial has roughly equal learning rate with
increasingly better initial performance.
 Mean Gap (MG), or average difference, between each
end point of a previous trial’s best ﬁt line (t
z0
i
(32)) and
the start point of the next trial’s best ﬁt line (t
z0+1
i
(1)).
A lower value indicates more performance continuity
between successive trials.
Both variables are summed to obtain the transition index,
with 0 representing a perfect learning transfer:
TI(s;i) =
RMSE(s;i)
n
+MG(s;i) (4)
whereTI(s;i) is the transition index of subjects at quadrant
i, and n is the number of trials used when calculating the
RMSE, in order to normalize the index.
The transition index indicates the relative smoothness of
the learning transfer between a set of trials, but it does not
Fig. 4. Example learning transfer plots to evaluate the transition index.
The top plot shows poor transition in Case 1, while the bottom plot shows
better transition in Case 2. In both cases, the transition index agrees with the
amount of learning transfer. Black lines represent the best-ﬁt line for each
individual trial, while the magenta line represents best-ﬁt over all trials.
Fig. 5. Example learning transfer plots to evaluate the transfer value. The
top plot shows the reference case of no learning transfer, with the ﬁrst trial
repeated, giving TI
0
(1;1) = 1:4660. The bottom plot shows the actual
trial sequence, with the learning from the ﬁrst trial transferring to subsequent
trials,TI(1;1) = 0:3249. The total transfer valueTV(1;1) = 1:1411.
quantify the total amount of transfer. The amount of learning
that can be transferred is dependent upon the amount of
learning that took place within a given trial. That is, if no
learning occurred in the initial trial, there cannot be any
learning transferred to subsequent trials, even though it is
possible to achieve a perfect transition index. Contrastingly,
if the ﬁrst trial has a high learning rate, more learning can be
transferred even without a perfect transition index. Without a
reference, the transition index does not quantify the amount
of learning that transferred to subsequent trials. If no transfer
occurs, all subsequent trials should look identical to the
initial trial, regardless of its learning rate. This case is the
0 reference quantifying the maximum amount of transfer
possible (see Fig. 5). Therefore, the amount of transfer is a
measure of the transition index of the initial trial repeated
n times, TI
0
(s;i), subtracted by the transition index of the
sequence of n trials, TI(s;i):
TV (s;i) =TI
0
(s;i) TI(s;i) (5)
2883
A higher learning rate in the initial trial, b
z0
i
, results in
a higher TI
0
, indicating more learning is available to be
transferred, and vice versa. As TI ! 0, TV approaches
its maximum value relative to learning achieved in the ﬁrst
trial. AsTI!TI
0
, no learning is transferred, andTV ! 0.
TV < 0 indicates that the performance in subsequent trials
is negatively inﬂuenced by or not related to the performance
of the ﬁrst trial. TV > 0 indicates at least some learning
from the initial trial transferred to the subsequent trials.
The transfer values are calculated for both Case 1 and Case
2 for all subjects. Case 1 has mean transfer

TV
1
= 0:0831
and standard deviation (TV
1
) = 0:4695. A student t-
test shows insigniﬁcant learning transfer when the same
task is presented with a different mapping function (p =
0:2695). Familiarity with the control task does not help sub-
jects achieve better performance when the mapping function
changes. Conversely, Case 2 analysis reveals a signiﬁcant
amount of learning transfer when the same mapping function
is presented with a different control task (

TV
2
= 0:3177,
(TV
2
) = 0:4483, p = 1:33e
 8
). This suggests that the
subjects learn new motor controls the ﬁrst time a mapping
function is presented, and retain this learning for at least
24 hours to apply and reﬁne the learning in a completely
different task. These results imply that efﬁcient controls
can be transfered to any myoelectric interface implementing
consistent mapping functions.
C. Synergy Development
Synergy development is analyzed through the evolution
of EMG patterns for each individual trial. EMG patterns are
initially disorganized while the user identiﬁes the mapping
function, but after many trials the EMG pattern becomes
more structured, signifying the development of a new syn-
ergy. EMG patterns between subjects have more similarities
as the number of attempts at a given target increases (see
Fig. 6), indicating convergence to a more efﬁcient control.
The increasing similarities can be quantiﬁed using mutual
information, a general measure of dependencies between
variables based on information theory [24]. Brieﬂy, given
a discretized system F of M
F
states, where each state f
i
occurs with probabilityp(f
i
), the expected information gain
from a measurement of value f
i
is the entropy H(F ) of
the system [24]. Two discrete systems, F and G, have joint
entropyH(F;G). Given thatH(F;G)H(F )+H(G), the
mutual information between F and G is
I(F;G) =H(F ) +H(G) H(F;G): (6)
So long as bothF andG have some uncertainty, as in EMG
sequences, normalized mutual information (NMI) is found
by:
NMI(F;G) =
s
I(F;G)
2
H(F )H(G)
;H(F )> 0;H(G)> 0 (7)
withNMI = 0 for independentF andG andNMI = 1 for
perfectly correlatedF andG. To use (7) to evaluate synergy
development, the time-varying sequence of EMG data is ﬁrst
Fig. 6. Example EMG sequence for 3 attempts to reach a given target.
The top plot shows a scrambled EMG signal on a subject’s ﬁrst attempt
to reach the target. The middle plot shows a more structured EMG signal
on the subject’s last attempt in the same trial. The bottom plot shows a
similar EMG signal on another subject’s last attempt for the same trial
combination. The similarity of the EMG signals after 32 attempts reveals a
common synergy developing between subjects.
normalized with respect to completion time and total effort
put into the system for each target attempt. The signal is
ﬁrst resampled along the time axis with cubic interpolation
to a common set of 500 samples. Then the EMG signal for
each muscle at each sample is normalized with respect to the
sum of all EMG signals at that sample. The resulting signal
contains percentage of motion completeness along one axis
and EMG ratios along the other (see Fig. 6).
When comparing adjacent target attempts for a given
trial, NMI shows a linear trend with positive slope. For all
trials and subjects, the mean slope for all best-ﬁt lines is
0.0011 per attempt, which is signiﬁcant on a student t-test
(p = 2:6696e
 23
). Comparing NMI across all subjects for
each trial combination reveals an identical linear trend. For
each attempt in a given trial, NMI is calculated between all
combinations of two subjects. The mean NMI between all
subjects is plotted against the number of attempts for each
trial (see Fig. 7). The mean slope m of the best ﬁt line for
all trials is signiﬁcantly positive (  m = 0:0010 per attempt,
(m) = 0:0005, p = 7:1228e
 12
). This conﬁrms that the
EMG signals of all subjects are slowly converging towards
a common signal pattern, supporting the hypothesis that all
subjects are developing the same set of basis synergies while
learning the inverse model of the mapping function.
IV. CONCLUSIONS
This paper investigates the transfer of learning and
population-wide synergy development for efﬁcient perfor-
mance in myoelectric controlled interfaces. The results reveal
a signiﬁcant learning transfer when a new control task is
presented to a subject using the same mapping function as
a previous control task. This gives evidence that subjects
do not only learn those mappings between their actions and
the control task, but they can retain this learning and gen-
eralize it to different control tasks resulting in better initial
performance and control efﬁciency. Moreover, comparison of
EMG signals for all subjects show that the signals become
2884
0 5 10 15 20 25 30
0.3
0.4
Quadrant 1
Mean NMI
Mean Cross Subject Normalized Mutual Information
0 5 10 15 20 25 30
0.3
0.4
Quadrant 2
Mean NMI
0 5 10 15 20 25 30
0.3
0.4
Quadrant 3
Mean NMI
0 5 10 15 20 25 30
0.3
0.4
Quadrant 4
Mean NMI
Attempt Number
Fig. 7. Example Normalized Mutual Information trends.
signiﬁcantly more similar as subjects spend more time using
a speciﬁc mapping function and control task. This suggests a
development of population-wide synergies while learning the
inverse model of a given decoder, conﬁrming convergence
towards efﬁcient muscular control of the task-space.
These two ﬁndings support the idea of the human embed-
ded control of devices using myoelectric interfaces, which
can result in a paradigm shift in the research ﬁeld of neuro-
prosthetics. More speciﬁcally, results show that humans can
be trained to control different tasks by learning new motor
controls mapping directly to the control axes of the tasks
(i.e. embedded control). The implications of this method are
vast, since it means that myoelectric controlled interfaces can
extend beyond anthropomorphic controls and user-speciﬁc
decoders. Instead, humans can learn to efﬁciently control the
interface through practice and synergy development, opening
new avenues and capabilities for the intelligent control of
myoelectric controlled robotic systems.
REFERENCES
[1] S. Bitzer and P. van der Smagt, “Learning EMG control of a robotic
hand: towards active prostheses,” in Robotics and Automation, 2006.
ICRA 2006. Proceedings 2006 IEEE International Conference on.
IEEE, may 2006, pp. 2819–2823.
[2] C. Castellini, A. E. Fiorilla, and G. Sandini, “Multi-subject / Daily-
Life Activity EMG-based control of mechanical hands,” Journal of
Neuroengineering and Rehabilitation, vol. 6, no. 41, 2009.
[3] P. K. Artemiadis and K. J. Kyriakopoulos, “EMG-Based Position and
Force Estimates in Coupled Human-Robot Systems: Towards EMG-
Controlled Exoskeletons,” in Experimental Robotics, ser. Springer
Tracts in Advanced Robotics, O. Khatib, V . Kumar, and G. J. Pappas,
Eds. Springer Berlin Heidelberg, 2009, vol. 54, pp. 241–250.
[4] C. Zhu, S. Shimazu, M. Yoshioka, and T. Nishikawa, “Power assis-
tance for human elbow motion support using minimal EMG signals
with admittance control,” in Mechatronics and Automation (ICMA),
2011 International Conference on. IEEE, Aug 2011, pp. 276–281.
[5] T. S. Saponas, D. S. Tan, D. Morris, and R. Balakrishnan, “Demon-
strating the feasibility of using forearm electromyography for muscle-
computer interfaces,” in Proceedings of the SIGCHI Conference on
Human Factors in Computing Systems, ser. CHI ’08, ACM. New
York, NY , USA: ACM, 2008, pp. 515–524.
[6] P. K. Artemiadis and K. J. Kyriakopoulos, “A Switching Regime
Model for the EMG-Based Control of a Robot Arm,” IEEE Transac-
tions on Systems, Man, and Cybernetics, Part B: Cybernetics, vol. 41,
no. 1, pp. 53–63, Feb 2011.
[7] M. S. Erkilinc and F. Sahin, “Camera control with EMG signals
using Principal Component Analysis and support vector machines,”
in Systems Conference (SysCon), 2011 IEEE International. IEEE,
Apr 2011, pp. 417–421.
[8] J. V ogel, C. Castellini, and P. van der Smagt, “EMG-based teleopera-
tion and manipulation with the DLR LWR-III,” in Intelligent Robots
and Systems (IROS), 2011 IEEE/RSJ International Conference on,
sept. 2011, pp. 672–678.
[9] A. B. Ajiboye and R. F. Weir, “Muscle synergies as a predictive
framework for the EMG patterns of new hand postures,” Journal of
Neural Engineering, vol. 6, no. 3, p. 036004, Jun 2009.
[10] F. Orabona, C. Castellini, B. Caputo, A. Fiorilla, and G. Sandini,
“Model adaptation with least-squares SVM for adaptive hand prosthet-
ics,” in Robotics and Automation, 2009. ICRA ’09. IEEE International
Conference on. IEEE, May 2009, pp. 2897–2903.
[11] F. E. Zajac, “Muscle and tendon: properties, models, scaling, and
application to biomechanics and motor control,” Stanford University,
vol. 17, pp. 359–411, 1989.
[12] C. Cipriani, F. Zaccone, S. Micera, and M. Carrozza, “On the Shared
Control of an EMG-Controlled Prosthetic Hand: Analysis of User-
Prosthesis Interaction,” Robotics, IEEE Transactions on, vol. 24, no. 1,
pp. 170–184, Feb 2008.
[13] P. Nilas, P. Rani, and N. Sarkar, “An innovative high-level human-
robot interaction for disabled persons,” in Robotics and Automation,
2004. Proceedings. ICRA ’04. 2004 IEEE International Conference
on, vol. 3. IEEE, april-1 may 2004, pp. 2309–2314 V ol.3.
[14] J. P. Cunningham, P. Nuyujukian, V . Gilja, C. A. Chestek, S. I. Ryu,
and K. V . Shenoy, “A closed-loop human simulator for investigating
the role of feedback control in brain-machine interfaces,” Journal of
Neurophysiology, vol. 105, no. 4, pp. 1932–1949, Apr 2011.
[15] R. H´ eliot, K. Ganguly, J. Jimenez, and J. M. Carmena, “Learning in
Closed-Loop Brain–Machine Interfaces: Modeling and Experimental
Validation,” IEEE Transactions on Systems, Man, and Cybernetics,
vol. 40, p. 11, 2010.
[16] S. Kim, S. JD, H. LR, D. JP, and B. MJ, “Neural control of computer
cursor velocity by decoding motor cortical spiking activity in humans
with tetraplegia,” J Neural, vol. 5, p. 22, 2008.
[17] S. M. Chase, A. B. Schwartz, and R. E. Kass, “Bias, optimal linear
estimation, and the differences between open-loop simulation and
closed-loop performance of spiking-based brain computer interface
algorithms,” Neural Networks, vol. 22, no. 9, pp. 1203–1213, Nov
2009.
[18] S. M. Radhakrishnan, S. N. Baker, and A. Jackson, “Learning a novel
myoelectric-controlled interface task,” J Neurophysiol, vol. 1, p. 47,
2008.
[19] T. Pistohl, C. Cipriani, A. Jackson, and K. Nazarpour, “Abstract and
Proportional Myoelectric Control for Multi-Fingered Hand Prosthe-
ses,” Annals of Biomedical Engineering, vol. 41, no. 12, pp. 2687–
2698, Dec 2013.
[20] A. d’Avella and F. Lacquaniti, “Control of reaching movements by
muscle synergy combinations,” Frontiers in Computational Neuro-
science, 2013.
[21] P. Artemiadis and K. Kyriakopoulos, “EMG-Based Control of a
Robot Arm Using Low-Dimensional Embeddings,” Robotics, IEEE
Transactions on, vol. 26, no. 2, pp. 393–398, april 2010.
[22] K. Nazarpour, A. Barnard, and A. Jackson, “Flexible Cortical Control
of Task-Speciﬁc Muscle Synergies,” Journal of Neuroscience, vol. 32,
no. 36, pp. 12 349–12 360, Sep 2012.
[23] [Online]. Available: http://www.opengl.org
[24] R. Steuer, J. Kurths, C. Daub, J. Weise, and J. Selbig, “The mutual in-
formation: Detecting and evaluating dependencies between variables,”
Bioinformatics, vol. 18 Suppl.2, pp. S231–S240, 2002.
2885
