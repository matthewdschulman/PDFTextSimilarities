Uncertainty-Constrained Robot Exploration:
A Mixed-Integer Linear Programming Approach
Luca Carlone and Daniel Lyons
Abstract— In this paper we consider the situation in which a
robot is deployed in an unknown scenario and has to explore the
entire environment without possibility of measuring its absolute
position. The robot can take relative position measurements
(from odometry and from place revisiting episodes) and can
then estimate autonomously its trajectory. Therefore, the qual-
ity of the resulting estimate depends on the motion strategy
adopted by the robot. The problem of uncertainty-constrained
exploration is then to explore the environment while satisfying
given bounds on the admissible uncertainty in the estimation
process. We adopt a moving horizon strategy in which the
robot plans its motion T steps ahead. Our formulation leads
to a mixed-integer linear problem that has several desirable
properties: (i) it guarantees that the robot motion is collision
free, (ii) it guarantees that the uncertainty constraints are
met, (iii) it enables the design of algorithms that efﬁciently
solve moderately sized instances of the exploration problem.
We elucidate on the proposed formulation with numerical
experiments.
I. INTRODUCTION
Numerous application endeavors, ranging from search and
rescue to planetary exploration and surveillance, require the
robot to explore an unknown environment. Exploration can
be functional to provide the robot with the situational aware-
ness needed to accomplish a given task (e.g., monitoring
and surveillance) or can be useful to build a model of the
environment (map) that supports human intervention (e.g.,
for search and rescue). In presence of absolute localization
information (e.g., GPS), the exploration process reduces to
choose the exploration targets that maximize the opportunity
of visiting unknown areas, see, e.g., [18]. Related approaches
can be found in [2], [8], while examples of generalizations
to the multi robot case are [3], [9].
When no absolute localization service is available to the
robot, the exploration task, which can be considered a deci-
sional process, needs to be accompanied by the concurrent
estimation of robot positions (and possibly a map of the
environment). This estimation process is usually referred to
as Simultaneous Localization and Mapping (SLAM). While
the maturity of SLAM has been recognized by the robotic
community, the problem of exploration under uncertainty
still remains an open issue. In literature, the problem is
sometimes referred to as active SLAM and exploration and
the contributions are usually tailored to a particular technique
used for position estimation (e.g., Extended Kalman Filter).
An early contribution to active SLAM and exploration with
EKF is proposed by Feder et al. [7]. A model predictive
control (MPC) strategy, associated with EKF-SLAM, is in-
troduced by Huang et al. [10]; an attractor-based heuristic is
L. Carlone is with the College of Computing, Georgia Institute of
Technology, USA. luca.carlone@gatech.edu
D. Lyons is with the Intelligent Sensor-Actuator-Systems
Laboratory, Karlsruhe Institute of Technology, Germany.
daniel.lyons@kit.edu
associated to MPC in [12]. Kollar and Roy propose the use of
a reinforcement learning approach in [11]. Sim and Roy ad-
dress the problem using ideas from A-optimal experimental
design in [16]. Martinez-Cantin et al. use a simulation-based
active policy learning algorithm [14]. In [13], instead, the
problem is solved by applying a Bayesian method that allows
reducing the number of simulations needed for planning.
More recently, a lucid treatment of EKF-based active SLAM
is provided in [5], which also discusses the use of different
uncertainty metrics.
While it is common to most part of the mentioned papers
to frame the planning problem in terms of mathematical
optimization, several issues arise from the literature review.
In most EKF-based approaches there is no explicit modelling
of the obstacles, therefore, the feasibility of the planned
trajectory is not guaranteed in general. Moreover, the ob-
jective function of the corresponding optimization problem
is often intangible and can be only evaluated at few points,
as it happens in simulation-based approaches, e.g., [1], [14].
Furthermore, the objective function is usually an additive
cost comprising (at least) two summands [4]: a cost related
to exploration and a cost related to uncertainty reduction; the
weights assigned to these costs are scenario-dependant and
difﬁcult to assign in general. As a consequence, the solution
is not guaranteed to be optimal in general, and solving the
problem is computationally demanding.
In this work we adopt a slightly different perspective on
the estimation aspect of the problem: we consider a simple
linear framework to estimate robot’s positions; this enables a
better understanding of the structure of the matrices describ-
ing the estimation error and allows quantifying the estimation
uncertainty without recurring to simulations. Moreover, we
explicitly model the requirement that robot motion has to be
collision free, hence our planning strategy is guaranteed to
produce feasible trajectories over a given planning horizon.
Our formulation leads to a mixed-integer linear problem
(MILP), that can be solved with reasonable computational
effort in practice, and has been already demonstrated to be an
effective solution for planning collision-free trajectories (an
application to spacecrafts’ navigation can be found in [15]).
Although MILPs are NP-hard to solve in the worst case, they
are known to be tractable for moderate problem sizes or by
employing problem-speciﬁc heuristics.
The structure of the paper is as follows: uncertainty-
constrained exploration is formalized in Section II, where we
specify the requirements that guide autonomous exploration.
In Section III we rewrite these requirements in mathematical
terms. Finally, we present numerical results in Section IV.
II. PROBLEM FORMULATION
A disc-shaped mobile robotR is deployed at time t = 0
in an unknown bounded environmentS  R
d
(scenario),
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 1140
Rob ot Non-traversable region Obstacle Obstacle T ra v ersable region (a) (b)
Fig. 1. (a) An example of scenarioS with the robot depicted as a red dot,
the traversable regionT in white, the obstacles O in dark grey, and the
non traversable regionO delimited by a dashed line. (b) Zoomed in view
of the robot, its sensing radius r
SR
(dashed circle), and the local visited
region with frontiers (in green) and obstacle boundaries (in blue).
with d 2 f2; 3g (planar or three-dimensional scenario).
Denoting with x
t
2 R
d
the position of the robot at time
t, we will interpretR(x
t
) as the set of points in R
d
that
belongs to the robot when it is in position x
t
. In particular,
if r
R
is the radius of the (holonomic) robotic platform,
R(x
t
) =B(x
t
; r
R
), whereB(x
t
; r
R
) is the Euclidean ball
of radius r
R
centered on x
t
. In the environmentS we can
distinguish a set of obstacles O and a connected obstacle-free
region T. Notice that the robot cannot assume all positions
within T: if the centerx
t
of the robot is closer than r
R
to an
obstacle, then the robot is touching the obstacle. Therefore,
it is convenient to deﬁne a (possibly non-connected) non
traversable regionO (points in the environment that lead
the robot to touch an obstacle), and a traversable regionT ,
which is a connected set of collision-free positions. Clearly,
it holdsT = T	B(r
R
) andO = OB(r
R
), whereB(r
R
)
is the ballB(0
d
; r
R
), and and	 are the Minkowski sum
and difference among sets, respectively. Note that T[ O =
T[O =S, see Fig. 1(a).
After travelling fort discrete time steps the robot describes
the positions (discrete trajectory) x
0:t
= [x
>
0
::: x
>
t
]
>
; at
each time (i = 0;:::;t  1) the robot applies a motion
command  z
i;i+1
2 R
d
to its locomotion system, which
corresponds to the desired displacement between the current
position and the next position. However, because of actuation
noise, the actual motion of the robot isz
i;i+1
:
=x
i+1
 x
i
6=
 z
i;i+1
; equivalently, we may consider  z
i;i+1
as a noisy mea-
surement of the displacement between consecutive positions
(odometry). By assumption the commands are limited (since
the robot travels at limited speed), therefore,k z
i;i+1
k r
V
for all i, with r
V
being a known bound (maximum speed).
While moving, the robot also acquires exteroceptive sensor
measurements. Exploiting exteroceptive sensors, we assume
that the robot is able to recognize an already visited place
(loop closing): if at time t the robot revisits the same place
observed from position x
i
, i < t, it is able to take a noisy
measurement of the relative positionz
t;i
:
=x
i
 x
t
, by com-
paring the current perception with the sensor reading taken
at time i. We call  z
t;i
the relative position measurement.
Common techniques for measuring  z
t;i
are scan matching
and vector registration. Clearly, in order to measure  z
t;i
,
the position x
t
should be close enough to the previous
position x
i
. We assume that a loop closing is possible if
kx
i
 x
t
k r
LC
, where r
LC
is a known loop closing radius.
We take the following assumption on measurement noise.
Assumption 1 (Unknown-but-bounded (UBB) noise). A
generic measurement  z
i;j
(being it a command or a loop
closing) can be written as  z
i;j
= x
j
  x
i
+ 
i;j
, with

>
i;j
(P
z
i;j
)
 1

i;j
 1. Moreover, we assume that P
z
i;j
=
(
2
i;j
I
d
), i.e., the noise is bounded within a ball of radius

i;j
.
The previous assumption is taken for simplicity, although
a similar derivation can be obtained assuming a probabilistic
setup; for instance one may consider zero mean Gaussian
noise and then consider an -conﬁdence ellipsoid that, with
probability , contains the measurement noise, leading to a
(probabilistic) bounded-noise setup. Similarly, if we have a
generic ellipsoidal set 
>
i;j
(P
z
i;j
)
 1

i;j
 1, we can compute
a bounding ball containing the ellipsoidal set and then we
can write 
>
i;j
(
2
i;j
I
d
)
 1

i;j
 1 for a suitable 
i;j
.
When the robot is in positionx
t
, it can sense a surrounding
regionV(x
t
) (local visited region), see Fig. 1(b). The shape
of the setV(x
t
) is sensor-dependent and, in general, satisﬁes
the conditionV(x
t
)B(x
t
; r
SR
), whereB(x
t
; r
SR
) is the
Euclidean ball with radius r
SR
> 0 (sensing radius), and
center x
t
. We will denote the overall visited region with
V(x
0:t
) =[
t
i=0
V(x
i
).
Assumption 2. For each time t = 0; 1;:::, the local visited
regionV(x
t
) is a polygon (not necessarily the same at all
times), whose vertices are exactly known with respect to the
position x
t
.
The polygonal representation of Assumption 2 essentially
comes without loss of generality, since we do not specify
any shape or number of edges (or convexity properties of
the polygon). The hypothesis of accurate knowledge of the
polygon w.r.t. the corresponding positionx
t
is only taken for
simplicity and it may be relaxed; as we will see in a while in
our setting are the positions themselves to be uncertain. As
a consequence of Assumption 2, along the boundary of each
local visited region, we can distinguish a collection of line
segments, that can be classiﬁed as either obstacle boundaries
or frontiers, see Fig. 1(b).
We now introduce few deﬁnitions to formally characterize
the exploration problem.
Deﬁnition 1 (Collision-free positions). A set of positions
x
0:t
= [x
>
0
::: x
>
t
]
>
is said to be collision-free if x
i
2T ,
for all i2f0;:::;tg.
For safe operation, the robot has to travel along collision-
free positions. In our case, the robot has to satisfy this
requirement while exploring an unknown scenarioS. We
assume that the robot has no prior knowledge about the sce-
nario. Then, after deployment, it has to apply suitable motion
strategies to visit the entire environment. The exploration
process ends when it is not possible to further expand the
sensed areas.
Deﬁnition 2 (Exploration complete). The exploration pro-
cess is said to be complete at time t, ifV(x
0:t
)[V( x) =
V(x
0:t
), for any position  x2T (i.e., no new observation
can enlarge the visited area).
Deﬁnitions 1 and 2 are common to other works in
which the exploration process is carried out with accurate
knowledge of the positions x
0:t
assumed by the robot.
Now, instead, we characterize the concept of uncertainty-
constrained exploration. In this work we assume that x
0:t
is
1141
unknown, and we only have an estimate ^ x
0:t
of the positions,
together with a matrix describing the estimation error. How
this estimate is obtained from the available measurements
is discussed in Section II-A. We notice that the robot, at
each time step t, knows the command  z
t;t+1
. However, the
possibility of acquiring loop closing measurements depends
on the motion strategy of the robot (i.e., if it revisits known
places or not). Therefore, the (position) estimation and the
exploration problem are interdependent, contrarily to the case
in which direct measurements of robot positions are taken
(e.g. from GPS). For this reason, here we want to design an
algorithm that allows the robot to complete the exploration
while satisfying given bounds on the estimation error.
Problem 1 (Uncertainty-constrained exploration, UCE). The
robotR has to completely explore the scenarioS, moving
along collision-free positions, while satisfying a given con-
straint on the admissible uncertainty of position estimation.
A. Preliminaries on trajectory estimation
As discussed in the previous section the available measure-
ments come from commands  z
i;i+1
,i = 0;:::;t 1, and loop
closing measurements  z
j;i
between position j and position
i; in both cases the measurements evaluate the difference
between two positions. Graph formalism provides a natural
model for the problem at hand: we consider a graphG
0:t
(position graph), where the vertex (or node) set N
0:t
is
f0; 1;:::;tg, and the edge setE
0:t
is the unordered set of
pairs (i;j) such that if (i;j)2E
0:t
, then a measurement
in the form  z
i;j
was acquired in the time interval [0;t].
Therefore, the position estimation problem reduces to assign
a position estimate ^ x
i
to each nodei2N
0:t
. Since, the robot
is only able to measure relative positions between node pairs,
nodes’ position can be only deﬁned up to an arbitrary roto-
translation. For avoiding this ambiguity, the ﬁrst node is set to
the origin of the reference frame, i.e.,x
0
is conventionally set
tox
0
= 0
d
. Therefore, the estimand is the vectorx
1:t
2R
dt
.
We label the available measurements from 1 tom and we de-
ﬁne the measurement vector  z = [ z
>
1
:::  z
>
m
]
>
2R
dm
. We
also deﬁne the matrix

P
z
= diag(P
z
1
;:::;P
z
m
)2R
dmdm
,
and the corresponding inverse



z
=

P
 1
z
. Then the available
measurements can be rewritten as:
 z =

A
>
x
1:t
+ (1)
where  is a bounded noise, satisfying 
>



z
 1, while

A = A
 I
d
, where A is the reduced incidence matrix of
graphG,
 is the Kronecker product, and I
d
is the identity
matrix of size d. The reduced incidence matrix is the graph
incidence matrix without the ﬁrst row, corresponding to the
node that was set to 0
d
. The effect of the Kronecker product
is to substitute the entries 1 and +1 of the incidence matrix
with I
d
and +I
d
, respectively. We assume that the BLUE
(Best Linear Unbiased Estimator)
1
is used for estimatingx
1:t
from (1):
^ x
1:t
= (

A



z

A
>
)
 1

A



z
 z: (2)
From Assumption 1 we can write



z
:
=
diag(
1

2
1
I
d
;:::;
1

2
m
I
d
). Let us deﬁne 

z
:
= diag(
1

2
1
;:::;
1

2
m
),
then it holds



z
= 

z

 I
d
. Since

A = A
 I
d
, we may
1
We postulate the use of the BLUE estimator, for two main reasons: (i) it
enables extensions to the probabilistic setup, and (ii) it can be efﬁciently
computed in practice, using both iterative and batch algorithms.
exploit the inverse and the mixed-product property of the
Kronecker product to write:
(

A



z

A
>
)
 1
= (A

z
A
>
)
 1

 I
d
(3)
This equality will be useful later, since (

A



z

A
>
)
 1
and
(A

z
A
>
)
 1
play an important role in the estimation pro-
cess, according to the following proposition.
Proposition 1. The following facts hold true when using the
BLUE for estimating robot trajectory in the UBB setup:
1) The trajectory estimation error
1:t
:
= ^ x
1:t
 x
1:t
satisﬁes

>
1:t

P
 1
1:t

1:t
 1, with

P
1:t
:
= (

A



z

A
>
)
 1
;
2) The error in the estimation of the i-th robot position

i
:
= ^ x
i
 x
i
satisﬁesk
i
k
2

2
i
, where 
2
i
is the i-th
diagonal element of P
1:t
:
= (A

z
A
>
)
 1
.
Proof: The ﬁrst fact can be proven by substituting the
measurement model (1) into the expression of the BLUE:
^ x1:t = (

A


z

A
>
)
 1

A


z  z =
(

A


z

A
>
)
 1

A


z(

A
>
x1:t +) =x1:t +1:t:
with
1:t
:
= (

A



z

A
>
)
 1

A



z
. Now, recalling that
>



z

1 it is easy to demonstrate that 
>
1:t

P
 1

1:t
 1 (
1:t
is a
linear combination of ), with

P
1:t
:
= (

A



z

A
>
)
 1
, which
proves the ﬁrst claim. The second claim stems from a well
known property of ellipsoidal sets: if 
>
1:t

P
 1

1:t
 1 and
we consider a subvector of 
1:t
, say 
i
, corresponding to
the estimation error for the i-th position, then 
>
i

P
 1
i

i

1 where

P
i
is the submatrix of

P
1:t
corresponding to the
subvector 
i
; in a probabilistic setup this would correspond
to marginalizing 
i
from 
1:t
. Now, recalling (3), we also
have

P
i
= 
2
i
I
d
, where 
2
i
is the i-th diagonal element of
P
1:t
. Therefore,

>
i

P
 1
i
i 1 ()
>
i
(
2
i
I
d
)
 1
i 1()
>
i
i
2
i
(4)
that concludes the proof.
We call

P
1:t
the uncertainty matrix and P
1:t
the re-
duced uncertainty matrix. When convenient, we adopt the
equivalent notation



1:t
=

P
 1
1:t
(information matrix) and


1:t
=P
 1
1:t
(reduced information matrix). With the notation
introduced so far we can take the last assumption required
for our derivation.
Assumption 3. Let t = 0; 1;:::, and deﬁne 
2
max
(t)
:
=
max
i=f1;:::;tg

2
i
as the maximum diagonal entry of P
1:t
,
and 
2
cmd
as the maximum actuation noise, i.e., 
2
cmd
:
=
max
i=f0;1;:::g

2
i;i+1
. We assume that, given a planning hori-
zon T , r
SR
> 
max
(t) + r
R
+
p

2
max
(t) +T
2
cmd
, and
r
LC
>
p
2
2
max
(t) +T
2
cmd
, for all t.
The assumption requires that the sensing radius and the
loop closing radius are bigger than the maximum accumu-
lated estimation error. Also in this case the assumption is
not strict since our objective is to bound the estimation error,
which in practice remains smaller than the two radii.
B. Uncertainty metrics
In the rest of the paper we will be interested in con-
straining some metrics related to the uncertainty matrix

P
1:t
. Examples of uncertainty metrics are: (i) the determi-
nant det(

P
1:t
), (ii) the maximum eigenvalue 
max
(

P
1:t
),
(iii) the trace tr(

P
1:t
), (iv) the maximum diagonal entry
1142

2
max
(

P
1:t
), (v) the i-th diagonal entry 
2
i
(

P
1:t
). Exploit-
ing relation (3) we notice that we can infer the previ-
ous metrics directly from the reduced uncertainty matrix
P
1:t
, since

P
1:t
is only an augmented version of P
1:t
. In
particular, the following equivalences hold (they are ob-
tained from basic properties of the Kronecker product):
(i) det(

P
1:t
) = det(P
1:t
)
d
, (ii) 
max
(

P
1:t
) = 
max
(P
1:t
),
(iii) trace(

P
1:t
) = d trace(P
1:t
), (iv) 
2
max
(

P
1:t
) =

2
max
(P
1:t
), (v) 
2
d(i 1)+1
(

P
1:t
) =
2
d(i 1)+2
(

P
1:t
) = ::: =

2
d(i 1)+d
(

P
1:t
) = 
2
i
(P
1:t
). Therefore, we can bound the
metric on P
1:t
, instead of the corresponding metric applied
to

P
1:t
. The advantage is thatP
1:t
has a simpler structure, as
discussed in Section III-C. Moreover, according to Propo-
sition 1, the diagonal entries of P
1:t
have a very intuitive
meaning: the i-th diagonal entry is the square of the radius
of the Euclidean ball bounding the estimation error for the
i-th position.
III. UNCERTAINTY-CONSTRAINED EXPLORATION
In the following, we adopt a standard receding horizon
planning strategy, in which the robot at time t (decision
time), has to decide an optimal (in a sense discussed later)
motion strategy over a ﬁnite time horizon consisting of
T steps. A motion strategy is encoded in a collection
of waypoints 
t+1
;:::;
t+T
the robot has to reach in
order to maximize the explored areas, while satisfying
the constraints. Notice that deciding over the variables

t+1
;:::;
t+T
is the same as deciding over the commands
 z
t;t+1
;:::;  z
t+T 1;t+T
: indeed
t+k
= ^ x
t
+
P
t+k 1
i=t
 z
i;i+1
,
for k 2 f1;:::;Tg; we here prefer to adopt the former
parametrization, since the waypoints have the more natural
interpretation of “desired positions the robot wants to reach”.
Since the robot has no knowledge about the scenario outside
of its visited region, his goal for exploration can only be to
extend the visited region as quickly as possible. Therefore,
an optimality criterion for a motion strategy is the following.
Deﬁnition 3 (Optimal motion strategy over the horizon T ).
A motion strategy 
t+1
;:::;
t+T
is optimal if it satisﬁes
problem constraints (uncertainty bounds and collision-free
trajectories) and leads the robot to a frontier of the visited
regions in the smallest number of steps, i.e., if 
t+k
is on
a frontier of the visited region there exists no other feasible
plan that reaches a frontier at time j <k.
We now present a pseudo-optimization program that summa-
rizes the planning problem the robot has to solve at time t:
P[UCE]:
variables: 
t+1
;:::;
t+T
objective:
reach a frontier in the smallest
number of time steps
(i) explore the
environment
(5)
s.t.:
k
t+k
 
t+k 1
k r
V
k2f1;:::;Tg;
(ii) respect speed
limit
(6)
x
t+k
2T
k2f1;:::;Tg;
(iii) follow collision-
free trajectories
(7)
size(P
1:t+T
)<

U
(iv) satisfy uncertainty
constraints
(8)
where size() is a function measuring the uncertainty of the
trajectory estimate, chosen among the metrics proposed in
Section II-B and

U is a given uncertainty bound. We set
t
=
^ x
t
, i.e., the plan starts from the current position estimate.
The constraint (6) is convex and is already expressed in
mathematical form, hence it does not need further manipula-
tions. The constraints (7) and (8), and the objective (5) need
further elaboration. For instance, constraint (7) requires the
knowledge of the traversable regionT and the future position
of the robot x
t+k
, that are unknown in practice. Similar
complications emerge for constraint (8), which requires the
knowledge of P
1:t+T
, that is only known a-posteriori (i.e.,
after the motion steps
t+1:t+T
are applied). The role of the
following sections is to formalize the constraints (7) and (8),
and the objective (5).
A. Constraint (7): Collision-free Trajectory
In this section we show how the robot, thus having
uncertain knowledge of its own position and, hence, only an
estimate of obstacles’ position, can still plan collision-free
trajectories.
1) Estimating a subset of the traversable region: Propo-
sition 1 guarantees that the estimation error of robot position
at time t, 
t
= ^ x
t
 x
t
, satisﬁesk
t
k
t
. This means that
the true position of the robot at timet lies within a radius
t
around the estimated position. We also recall that, at time t,
the robot senses the local visited regionV and can construct
the estimated local visited regionV(^ x
t
) (which is built on
the estimated position, since x
t
is unknown).
Let us deﬁne the set of points inV(^ x
t
) that have a distance
greater than or equal to  from the boundary ofV(^ x
t
):
V(^ x
t
)	B()
:
=fx2V(^ x
t
):B(x;)V(^ x
t
)g : (9)
Lemma 1. For t = 0; 1;:::, it holds thatV(^ x
t
)	B(
t
)
V(x
t
), i.e., when we “scale down” the estimated local visited
region by the uncertainty in the position estimate, it will be
contained in the true visited region.
Proof: The error made from V(^ x
t
) to V(x
t
) is a
translational error, i.e., there exists a ﬁxed vectorz such that
V(x
t
) =V(^ x
t
)z
:
=fx +z : x2V(^ x
t
)g. Then it holds
that there exists a z such that x
t
= ^ x
t
+z withkzk =
kx
t
  ^ x
t
k
t
by Proposition 1. Let x

2V(^ x
t
)	B(
t
).
Forx

it holds that for all ~ z withk~ zk
t
x

+ ~ z2V(^ x
t
).
Hence, also x

+z2V(^ x
t
) but it also holds that x

+z2
V(^ x
t
)z =V(x
t
).
This is an important statement since, by deﬁnition,
V(x
t
)  T, i.e., the true local visited region is a subset
of the obstacle-free region, and thereforeV(x
t
)	B(r
R
)
T ; therefore, the lemma can guarantee that, even under
estimation errors, a subset of the estimated local visited
region is included in the traversable region. Therefore, a
simple way to build a subset of the traversable region is
provided by the following proposition.
Proposition 2. Deﬁne the (estimated) traversable subregion:
^
T (t) =
[
i=0:t
V(^ xi)	B(i + rR) (10)
where 
0
is conventionally set to 0 (no uncertainty of the
position x
0
, i.e., ^ x
0
= x
0
). Then, it holds true that
^
T (t) is
a non-empty polygon and
^
T (t)T .
Proof: From Assumption 2,
^
T (t) is a polygon (each
estimated local visited region V(^ x
i
) is a polygon, and
remains a polygon after applying the Minkowski difference
1143
and the union). Moreover, Assumption 3 assures that each
setV(^ x
i
)	B(
i
+r
R
) is non-empty, since r
SR
>
max
(t)+
r
R
+
p

2
max
(t) +T
2
cmd
 
i
+ r
R
. The second claim
follows from Lemma 1: for each i = 0;:::;t, it holds
V(^ x
i
)	B(
i
)V(x
i
), which impliesV(^ x
i
)	B(
i
+r
R
)
T ; since
^
T (t) is the union of subsets ofT , it is itself a subset
ofT .
In the previous proposition we ensured that
^
T (t) is a
subset of the traversable regionT . In the next proposition
we show that a motion strategy for that the planned positions

t+1:t+T
lie within a certain subset of
^
T (t) is guaranteed
to produce collision-free positions x
t+1:t+T
, satisfying con-
straint (7). We remark that the mismatch between 
t+1:t+T
and x
t+1:t+T
is a consequence of actuation noise.
Proposition 3. Assume that the robot at time step t
computes the plan 
t+1:t+T
, and use the plan to apply
the motion commands for the successive time steps t;t +
1;:::;t + T   1. Then, it holds k
t+k
k
:
= k
t+k
 
x
t+k
k 
q

2
t
+
P
t+k 1
i=t

2
i;i+1
. Moreover, if 
t+k
, k 2
f1;:::;Tg; is such that 
t+k
2
^
W(t + k)
:
=
^
T (t)	
B(
q

2
t
+
P
t+k 1
i=t

2
i;i+1
) then x
t+k
2T , i.e., the actual
robot positions at time t +k is collision free.
Proof: Consider a k 2 f1;:::;Tg. We observed at
the beginning of Section III that we can write 
t+k
=
^ x
t
+
P
t+k 1
i=t
 z
i;i+1
. Now we write the estimate and the
commands in terms of actual quantities plus noise: 
t+k
=
x
t
+
t
+
P
t+k 1
i=t
(x
i+1
 x
i
+
i;i+1
). The sum of the true
(unknown) positions can be simpliﬁed as follows: 
t+k
=
x
t+k
+ 
t
+
P
t+k 1
i=t

i;i+1
, which demonstrates that the
desired position 
t+k
and the true position x
t+k
may only
differ by
t+k
:
=
t
+
P
t+k 1
i=t

i;i+1
. Recalling Assumption 1
and Proposition 1 we have that the linear combination 
t+k
satisﬁes
>
t+k

(
2
t
+
P
t+k 1
i=t

2
i;i+1
)I
d

 1

t+k
 1, which
impliesk
t+k
 x
t+k
k =k
t+k
k
q

2
t
+
P
t+k 1
i=t

2
i;i+1
.
Therefore, considering a 
t+k
2
^
W(t +k) guarantees that
the actual x
t+k
lies within
^
T (t), which is a subset ofT by
Proposition 2, and then is collision free.
2) Stay in the traversable subregion: In the previous sec-
tion we demonstrated the implication 
t+k
2
^
W(t +k) =)
x
t+k
2T ,k2f1;:::;Tg. In this section, we formalize the
constraint
t+k
2
^
W (we omit the time index for simplicity).
In general,
^
W is a nonconvex set, therefore, the resulting
optimization problem (with nonconvex contraints) will be
hard to solve. In order to address this issue we propose a
mixed-integer linear formulation of the constraint. According
to Proposition 2,
^
W is a polygon and we can divide it
into n
^
W
convex polygons
^
W
i
, such that[
n
^
W
i=1
^
W
i
=
^
W.
Therefore, the condition 
t+k
2
^
W is equivalent to the
condition that there exists an i, such that 
t+k
2
^
W
i
:

t+k
2
^
W()
t+k
2
^
W1_  _
t+k
2
^
Wn
^
W
(11)
Since, for each i = 1;:::;n
^
W
,
^
W
i
is a convex polygon
with n
f
i
faces, the condition 
t+k
2
^
W
i
can be written
explicitly using n
f
i
linear inequalities:

t+k
2
^
Wi, a
j
i

t+k
b
j
i
; j = 1;:::;n
f
i
: (12)
where is the scalar product. In order to encode the “or”
condition in (11) we employ the “big M” method [17], by
replacing the “or” constraints in (11) with binary decision
variables. The constraint 
t+k
2
^
W is then equivalent to
8i = 1;:::;n
^
W
; j = 1;:::;n
f
i
: a
j
i

t+k
b
j
i
+
i
t+k
M (13)
n
^
W
X
i=1

i
t+k
n
^
W
  1; 
i
t+k
2f0; 1g ; (14)
where 
i
t+k
, i = 1;:::;n
^
W
, are binary slack variables and
M is some arbitrary big number. In (13), if 
i
t+k
= 0, then
the constraints a
j
i

t+k
 b
j
i
, j = 1;:::;n
f
i
are enforced,
and 
t+k
belongs to the i-th polygon at time t +k. If, for
somei,
t+k
does not belong to the polygon
^
W
i
, one of the
corresponding linear inequalities will not be satisﬁed and

i
t+k
has to be set to 1. In (14) we then limit the number of
relaxations, such that at least one of the 
i
t+k
has to be set
to zero, i.e., the robot has to be inside at least one region
^
W
i
, for some i2f1;:::;n
^
W
g. Since the planning is done
with a receding horizon approach, we need to enforce these
constraints for all 
t+k
, k2f1;:::;Tg. Constraints (13)–
(14) constitute a sufﬁcient condition to satisfy the “ideal”
constraint (7).
B. The Objective (5): Frontier-based Exploration
The objective function of the optimization problem P[UCE]
rewards the robot for extending the visited region. A sufﬁ-
cient condition for extending the visited region is to reach
a frontier of V. Now, Assumption 3 guarantees that the
sensing radius is bigger than the maximum displacement of
the frontiers caused by uncertainty (in Propositions 2 and 3,
we scale down each estimated visited region by a quantity
that is smaller than 
max
(t) + r
R
+
p

2
max
(t) +T
2
cmd
);
therefore, reaching a frontier of
^
W is sufﬁcient for extending
the visited region.
According to our problem setup, each frontier is essen-
tially a line segment; callx
j
1
andx
j
2
the endpoints of thej-th
frontier, and deﬁne the vector n
j
0
, that is normal to the line
that goes throughx
j
1
andx
j
2
. Then, the robot position
t+k
is
on the line throughx
j
1
;x
j
2
when:n
j
0

t+k
=n
j
0
x
j
1
. In order
to enforce that the position is on the segment betweenx
j
1
;x
j
2
we introduce the vectors n
j
1
:
= (x
j
2
 x
j
1
), n
j
2
:
= (x
j
1
 x
j
2
).
and the constraintsn
j
1

t+k
n
j
1
x
j
2
andn
j
2

t+k
n
j
2
x
j
1
.
These constraint are again relaxed via the “big M” method
to
n
j
0

t+k
n
j
0
x
j
1
+
j
t+k
M; (15)
 n
j
0

t+k
 n
j
0
x
j
1
+
j
t+k
M (16)
n
j
1

t+k
n
j
1
x
j
2
+
j
t+k
M; (17)
n
j
2

t+k
n
j
2
x
j
1
+
j
t+k
M; 
j
t+k
2f0;1g; (18)
where if
j
t+k
= 0, then
t+k
is on thej-th frontier, while if

j
t+k
= 1, 
t+k
is not on the frontier. Constraints (15)–(18)
are imposed for all future time steps k2f1;:::;Tg; the
sum of the binary variables 
j
t+k
is added to the objective
function in order not to force the robot to be on a frontier
but to encourage it: the cost function (5) is then
P
k;j

j
t+k
(with k2f1;:::;Tg and j going from 1 to the number of
frontiers). This follows since the sum is minimal if the robot
is on as many frontiers as possible, since then as many
j
t+k
as possible are equal to zero.
1144
C. Constraint (8): Bounding the Estimation Uncertainty
We now formalize the uncertainty constraints, exploiting
basic insights from graph theory and linear algebra.
1) Estimation Uncertainty and Graph Structure: In order
to understand how robot motion (and then, graph structure)
relates with the uncertainty matrix P
1:t+T
we should spend
some words on the structure of this matrix. We start our
derivation from the inverse of P
1:t+T
, namely 

1:t+T
. The
matrix 

1:t+T
has a very natural interpretation in terms of
graph theory since it corresponds to the (weighted) graph
Laplacian matrix without the ﬁrst row and column (corre-
sponding to the node that we set to 0
d
). If we callN
IN
(i) the
neighbors of node i in the graph, 

1:t+T
has the following
structure:
 the i-th diagonal element is equal to
P
j2N IN(i)

1

2
i;j

;
 the element in position (i;j) in the matrix is equal to
 1=
2
i;j
if a measurement between node i and j is
available, or is zero otherwise.
We recall thatE
0:t+T
is the set of edges added in the
interval of time [0;t +T ], and thatE
1:t+T
=E
0:t+T
since
no edge is added at time 0 (initially there is only one node
in the graph). Then, it is easy to see that we can write the
matrix 

1:t+T
as:

1:t+T =
X
(i;j)2E
1:t+T
1

2
i;j
aija
>
ij
(19)
where a
ij
2 f 1; 0; +1g
t+T
is a vector modelling edge
(i;j), that has at most two nonzero elements, one equal to
 1 in position i and one equal to +1 in position j; the
only case in which there is a single nonzero element is the
case in which the edge connects a node i with the node
corresponding to x
0
: in this case the only nonzero element
is in position i and is  1 (respectively +1) if the edge
goes out (respectively is incoming) from node i. Note that
if the decision time is t (i.e., we are planning the motion
steps 
t+1
;:::;
t+T
) then the edges added until time t
cannot be modiﬁed by the plan; therefore we can write
E
1:t+T
= E
1:t
[E
t+1:t+T
, where we distinguish from the
edgesE
1:t
, already present in the graph at time t, from the
edgesE
t+1:t+T
introduced in the next T time steps. Fur-
thermore, we recall that the commands are always available,
independently on the chosen motion strategy, while what our
plan can change is the possibility to revisit previous nodes,
i.e., may eventually add loop closings. Therefore, we write
E
t+1:t+T
= E
cmd
t+1:t+T
[E
lc
t+1:t+T
, where E
lc
t+1:t+T
groups
the edges corresponding to loop closings, whileE
cmd
t+1:t+T
contains the remaining edges. We can then rewrite (19) as:

1:t+T =
X
(i;j)2E
1:t
1

2
i;j
aija
>
ij
+
X
(i;j)2E
cmd
t+1:t+T
1

2
i;j
aija
>
ij
+
X
(i;j)2E
lc
t+1:t+T
1

2
i;j
aija
>
ij
= const. +
X
(i;j)2E
lc
t+1:t+T
1

2
i;j
aija
>
ij
(20)
where we remarked that the ﬁrst two sums cannot be
modiﬁed by our plan (they give a constant matrix, which
can be precomputed at time t). Equation (20) highlights
the fundamental structure of our problem: the uncertainty
reduction problem consists in deciding which loop closings
the robot has to perform to meet given constraints on
P
1:t+T
. Now we notice that in (19) we already obtained
explicit expressions for 

1:t+T
, and we may use these
expressions to pose constraints on the uncertainty for the
optimization problem. For instance, if we want to bound
det(P
1:t+T
), 
max
(P
1:t+T
), or tr(P
1:t+T
) we simply rec-
ognize that det(P
1:t+T
) = det(

 1
1:t+T
), 
max
(P
1:t+T
) =
1
min(

1:t+T
)
and tr(P
1:t+T
) = tr(

 1
1:t+T
); bounds on these
quantities can be formulated as convex constraints [6] in the
entries of 

1:t+T
, which is a desirable condition. However,
the objective of this paper is to formulate a mixed-integer
linear program, therefore we want to further work out the
expressions to obtain linear constraints. For this purpose, let
us study the effect of adding an edge on P
1:t+T
.
Proposition 4. If we call P
pre
1:t+T
the uncertainty matrix
before the addition of a loop closing edge (i;j), andP
1:t+T
the uncertainty matrix after the addition of edge (i;j) it
holds:
P
1:t+T
=P
pre
1:t+T
 
1

2
i;j
P
pre
1:t+T
a
ij
 
1+
1

2
i;j
a
>
ij
P
pre
1:t+T
a
ij
!
 1
a
>
ij
P
pre
1:t+T
Proof: Let us deﬁne the information matrix 

pre
1:t+T
before the insertion of edge (i;j) and the information matrix


1:t+T
after edge (i;j) is included in the graph:
P1:t+T = 

 1
1:t+T
=



pre
1:t+T
+
1

2
i;j
aija
>
ij

 1
(21)
then, recalling that (

pre
1:t+T
)
 1
= P
pre
1:t+T
, the result is a
simple application of the matrix inversion lemma.
Corollary 1. The addition of a loop closing edge can only
reduce (i) the determinant, (ii) the maximum eigenvalue, (iii)
the trace, (iv) each diagonal element of P
1:t+T
.
The proof of the corollary (omitted for brevity)
stems from the fact that the matrix G
i;j
:
=
1

2
i;j
P
pre
1:t+T
a
ij

1 +
1

2
i;j
a
>
ij
P
pre
1:t+T
a
ij

 1
a
>
ij
P
pre
1:t+T
is
positive deﬁnite, hence, ”reduces” the original uncertainty
P
pre
1:t+T
.
The previous corollary remarks that the addition of edges
may only help in meeting our uncertainty constraints. More-
over, the advantage, or the information gain, in adding a
speciﬁc edge can be quantiﬁed in G
i;j
, i.e., the larger is the
matrix G
i;j
(w.r.t. one of the considered metrics), the larger
is the uncertainty reduction in adding edge (i;j).
Remark 1. While each edge has an additive effect on the
matrix 

1:t+T
, it has a more complex impact on P
1:t+T
.
In fact, while adding a single edge (i;j) leads to P
1:t+T
=
P
pre
1:t+T
 G
i;j
, adding several edges leads to complex nonlin-
ear expressions, becauseG
i;j
depends onP
pre
1:t+T
; therefore,
in general, it holds P
1:t+T
6=P
1:t
 
P
(i;j)2E
t+1:t+T
G
i;j
.
2) A Bound on the Estimation Uncertainty: Now consider
the situation in which we have to impose a constraint of
the type size(P
1:t+T
)

U, where size is an uncertainty
metric chosen among the ones mentioned in Section II-B,
and

U is a desired upper bound. We exploit Corollary 1
to ﬁnd a simple (linear) way of imposing the uncertainty
constraint. The basic idea is the following: we can pre-
compute a matrix P
pre
1:t+T
assuming that there are no loop
closings in [t + 1;t +T ]; then, if we plan a motion strategy

t+1
;:::;
t+T
that allows to include the loop closing edge
1145
(i

;j

), we can guarantee that the actual uncertainty at time
t +T is no larger than P
pre
1:t+T
 G

i;j
, since, according to
Corollary 1, the addition of further edges can only reduce
the uncertainty. More formally, for each (i

;j

)2E
t+1:T
, it
holds: P
1:t+T
P
pre
1:t+T
 G

i;j
, then
size(P
pre
1:t+T
 G

i;j
)

U =) size(P1:t+T )

U (22)
Therefore, we can simply plan the inclusion of a single edge
(i

;j

) that satisﬁes size(P
pre
1:t+T
  G

i;j
) 

U and we
can assure that the uncertainty bound is satisﬁed. Clearly,
in this way we are actually imposing a stricter constraint
on the uncertainty, but this carries an important advantage:
both P
pre
1:t+T
and G

i;j
, can be computed a-priori, i.e., before
the execution of the plan, and the inequality size(P
pre
1:t+T
 
G

i;j
)

U can be formulated as a linear constraint as we
will see in a while.
For deciding on the addition of an edge we use a collection
of binary variables: 
j
t+k
with k 2 f1;:::;Tg and j 2
f1;:::;tg; if 
j
t+k
= 1 we plan to add an edge between the
planned position 
t+k
and the previous estimated position
^ x
j
; if 
j
t+k
= 0 no edge is added between node t +k and
j. Therefore, the uncertainty bound is imposed through the
following constraint:
size

P
pre
1:t+T
 
X
k2f1;:::;Tg
j2f1;:::;tg

j
t+k
G

i;j



U (23)
X
k2f1;:::;Tg
j2f1;:::;tg

j
t+k
 1; 
j
t+k
2f0; 1g; (24)
where the ﬁrst constraint corresponds to the upper
bound (22), while the second condition imposes that we can
plan to add at most one edge (the bound (22) holds for a
single edge).
We miss a last ingredient to model the uncertainty con-
straints. We recall from Section II that we cannot add any
edge (i;j) arbitrarily: these edges may only connect two
nodes whose distance is smaller or equal than the loop
closing radius r
LC
. In order to impose this restriction, we
have to force 
j
t+k
= 0 whenkx
j
 x
t+k
k r
LC
. Also in
this case, however, we should cope with the uncertainty: we
do not knowx
j
andx
t+k
, but we know ^ x
j
and
t+k
. We can
then impose the more conservative condition that prevents to
plan the addition of an edge when:
k^ xj 
t+k
k rLC 
q
2
2
max
(t) +T
2
cmd
; (25)
which is always a positive quantity by Assumption 3. It is
possible to demonstrate that (25) is a necessary condition
forkx
j
 x
t+k
k r
LC
, i.e., that the plan does not enable
loop closings that are not possible in the reality. The proof
follows from Proposition 1 and Proposition 3 and is omitted
here due to space restrictions.
We impose that 
j
t+k
= 0 as soon as inequality (25) is
satisﬁed; we do this by introducing a constraint for each
binary 
j
t+k
with k2f1;:::;Tg and j2f1;:::;tg:
k^ xj 
t+k
k rLC 
q
2
2
max
(t) +T
2
cmd
+ (1 
j
t+k
)M (26)
Ifk^ x
j
 
t+k
k r
LC
 
p
2
2
max
(t) +T
2
cmd
the constraints
forces (1 
j
t+k
) to be 1, then
j
t+k
has to be zero, avoiding
loops between far nodes. Constraints (23)–(26) constitute our
formalization for the original uncertainty constraint (8).
Remark 2 (Final prescription). The norm constraints (26)
and (6) are linear when using the `
1
(Manhattan) norm for
measuring distances. Recall that for any vector x, it holds
kxk
1
kxk
2
, then the satisfaction of a constraint under the
`
1
-norm is a sufﬁcient condition for the satisfaction of the
corresponding constraint under the `
2
-norm.
IV. NUMERICAL EXPERIMENTS
We consider an experiment in which the robot has to
explore the scenario in Fig. 2. The robot radius is r
R
= 0:3
m, the sensing radius is r
SR
= 7 m, and the loop closing
radius is r
LC
= 2 m. The measurement noise if bounded
in a ball of radius 
i;j
= 0:15 m, while the commands are
bounded by r
V
= 3 m. We initialize the time horizon to
5, and we increase it in case it is not sufﬁcient to let the
robot reach a frontier (replanning). We use the maximum
diagonal entry of the P
1:t+T
as uncertainty metric, i.e.,
size(P
1:t+T
) =
2
max
(P
1:t+T
), and we impose the bound

2
max
(P
1:t+T
)1.
(a) (b)
Fig. 2. Scenario with obstacles in dark grey. In (a) the blue lines
depict the obstacle boundaries and the green lines the frontiers. In (b) we
show the convex polygons that together deﬁne the estimated visited region.
For collision-free motion these are scaled down by the security margins
(Proposition 3), giving the convex polygons
^
W
i
.
The results of the implementation of the proposed MILP
are reported in Figures 3(a)–3(c), which describe the CPU
time required for the optimization at each decision time and
the trend of
2
max
. Also, we depict the length of the planning
horizons for each decision time (they may vary when a
replanning is needed). After planning we let the robot apply
all commands in the plan, therefore, if at time t the robot
plans a trajectory over an horizon T , the next planning time
occurs at time t +T ; this justiﬁes the gaps in Fig. 3(c) that
essentially correspond to time steps in which the robot is
applying the previous plan (without solving any optimization
problem).
We notice that in few time steps the current uncertainty

2
max
(P
1:t
) is above the threshold. This is consistent with out
formulation, since we require that 
2
max
(P
1:t+T
) 1, i.e.,
the robot has to guarantee constraint satisfaction only after
applying the entire plan; for instance the robot may plan a
loop closing when reaching the last position in the plan
t+T
,
and the uncertainty reduction only occurs at timet +T . For
this reason, the red markers in Fig. 3(b), corresponding to
the decision times, are always below the desired uncertainty
bound. Our formulation may also accommodate the stricter
constraint that at each step the uncertainty should be smaller
than the bound. We preferred not to consider this setup since
it may easily lead to infeasible problem instances, while with
the formulation P[UCE] the robot may always ﬁnd a suitable
1146
0 100 200 300 400
0
1
2
3
4
5
6
7
8
9
10
11
time step
runtime [s]
(a)
0 100 200 300 400
0
0.2
0.4
0.6
0.8
1
1.2
time step
uncertainty
(b)
0 100 200 300 400
0
10
20
time step
length planning horizon
(c)
0 50 100 150 200
0
0.2
0.4
0.6
0.8
1
1.2
time step
runtime [s]
(d)
0 50 100 150 200
0
0.2
0.4
0.6
0.8
1
time step
uncertainty
(e)
Fig. 3. (a) Runtime in seconds, (b) current uncertainty 
2
max
(P
1:t
), and (c) lengths of the planning horizon for the P[UCE] algorithm. In (b) the red
markers denote the decision times, i.e., the time steps in which the optimization problem is solved. (d) Runtime in seconds and (e) uncertainty metrics for
each time step for P[UCE] with thresholding. At the time steps marked in red the objective was geared towards uncertainty reduction and at the time steps
marked in green the objective was focused on exploration. In (e) the solid red line denotes the upper bound
2
max
(P
pre
1:t+T
), while the line with green and
red markers corresponds to 
2
max
(P
1:t
).
time horizon that makes the uncertainty constraint feasible.
We notice that for few decision times, the solution of P[UCE]
required several seconds, since the robot had to plan over
a longer horizon. Although the reported times are still ac-
ceptable in real applications, this motivated us in developing
a variant of the exploration algorithm, named P[UCE] with
thresholding. In this variant, when the uncertainty rises above
a bound, the robot is required to reduce the uncertainty below
a lower bound (0:6 in our experiments) before continuing
the exploration. We implement this variant as follows: at the
beginning the objective function is the one of Section III-B;
when the quantity 
2
max
(P
pre
1:t+T
) (see Section III-C.1) rises
above the uncertainty bound we substitute the exploration
objective with one rewarding the addition of edges, exploit-
ing the results of Section III-C.1. Note that 
2
max
(P
pre
1:t+T
)
is the maximum position uncertainty assuming that no loop
closing is done in the interval [t+1;t+T ], then it constitutes
an upper bound for the actual uncertainty 
2
max
(P
1:t+T
).
The exploration-driven objective is re-established as soon as

2
max
(P
pre
1:t+T
) drops below 0:6. The results of this variant are
reported in Fig. 3(d) and 3(e). The variant shows a relevant
boost in the performance w.r.t. the original approach and it
will be subject of future research
2
.
V. CONCLUSION
We formulated a mixed-integer linear program that allows
the robot to establish a suitable motion strategy to explore
an unknown environment without any absolute position in-
formation. The formulation explicitly models the presence
of obstacles in the environment, rewards the robot for ex-
panding the visited regions, and includes several tools for
bounding the uncertainty in position estimation. The paper
enriches related literature by bridging between optimization-
based planning techniques and estimation theory applied to
localization and mapping. Future work includes an extensive
numerical evaluation and the investigation of fundamental
questions that still remain without answer. For instance, is it
possible to prove that the complete environment is explored
in ﬁnite time? How do the measurement error and the other
parameters inﬂuence the time required for completing the
exploration process?
2
A video showing an example of uncertainty-constrained exploration
with the algorithm P[UCE] with thresholding can be found at
http://www.lucacarlone.com/index.php/resources/videos.
REFERENCES
[1] J.L. Blanco, J.A. Fernandez-Madrigal, and J. Gonzalez. A novel mea-
sure of uncertainty for mobile robot SLAM with Rao-Blackwellized
particle ﬁlters. Int. J. Robot. Res., 27(1):73–89, 2008.
[2] F. Bourgault, A.A. Makarenko, S.B. Williams, B. Grocholsky, and
H.F. Durrant-Whyte. Information based adaptive robotic exploration.
In Proc. IEEE-RSJ Int. Conf. on Intelligent Robots and Systems, 2002.
[3] P. Brass, F. Cabrera-Mora, A. Gasparri, and J. Xiao. Multirobot tree
and graph exploration. IEEE Transactions on Robotics, 27(4):707–
717, 2011.
[4] L. Carlone, J. Du, M. Kaouk Ng, B. Bona, and M. Indri. An application
of Kullback-Leibler divergence to active SLAM and exploration with
particle ﬁlters. In Proc. of the IEEE Int. Conf. on Intelligent Robots
and Systems, pages 287–293, 2010.
[5] H. Carrillo, I. Reid, and J.A. Castellanos. On the comparison of
uncertainty criteria for active SLAM. In Proc. of Int. Conf. on Robotics
and Automation, 2012.
[6] C. Durieu, E. Walter, and B.T. Polyak. Multi-input multi-output
ellipsoidal state bounding. J. Opt. Theory Appl., 111(2):273–303,
2001.
[7] H.J.S. Feder, J.J. Leonard, and C.M. Smith. Adaptive mobile robot
navigation and mapping. Int. Journal of Robotics Research, 18(7):650–
668, 1999.
[8] D. Fox, J. Ko, K. Konolige, B. Limketkai, D. Schulz, and B. Stewart.
Distributed multirobot exploration and mapping. Proc. of the IEEE,
94(7):1325–1339, 2006.
[9] A. Franchi, L. Freda, G. Oriolo, and M. Vendittelli. The sensor-based
random graph method for cooperative robot exploration. IEEE/ASME
Transactions on Mechatronics, 14(2):163–175, 2009.
[10] S. Huang, N. Kwok, G. Dissanayake, Q. Ha, and G. Fang. Multi-step
look-ahead trajectory planning in SLAM: Possibility and necessity. In
Proc. of Int. Conf. on Robotics and Automation, pages 1091–1096,
2005.
[11] T. Kollar and N. Roy. Trajectory optimization using reinforcement
learning for map exploration. Int. Journal of Robotics Research,
27(2):175–196, 2008.
[12] C. Leung, S. Huang, and G. Dissanayake. Active SLAM using model
predictive control and attractor based exploration. In Proc. of the
IEEE-RSJ Int. Conf. on Intelligent Robots and Systems, pages 5026–
5031, 2006.
[13] R. Martinez-Cantin, N. de Freitas, E. Brochu, J. Castellanos, and
A. Doucet. A bayesian exploration-exploitation approach for optimal
online sensing and planning with a visually guided mobile robot.
Autonomous Robots, 27:93103, 2009.
[14] R. Martinez-Cantin, N. De Freitas, A. Doucet, and J.A. Castellanos.
Active policy learning for robot planning and exploration under
uncertainty. In Proc. of Robotics: Science and Systems, 2007.
[15] A. Richards, T. Schouwenaars, J.P. How, and E. Feron. Spacecraft
Trajectory Planning with Avoidance Constraints Using Mixed-integer
Linear Programming. Journal of Guidance, Control, and Dynamics,
25(4):755–764, 2002.
[16] R. Sim and N. Roy. Global A-optimal robot exploration in SLAM.
In Proc. of Int. Conf. on Robotics and Automation, pages 661–666,
2005.
[17] H.A. Taha. Operations research: an introduction, volume 8. Prentice
Hall Upper Saddle River, NJ, 1997.
[18] B. Yamauchi. A frontier-based approach for autonomous exploration.
In Proc. of CIRA 17, 1997.
1147
