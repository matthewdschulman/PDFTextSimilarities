Game theoretic controller synthesis for multi-robot motion planning
Part I : Trajectory based algorithms
Minghui Zhu, Michael Otte, Pratik Chaudhari, Emilio Frazzoli
Abstract— We consider a class of multi-robot motion plan-
ning problems where each robot is associated with multiple
objectives and decoupled task speciﬁcations. The problems are
formulated as an open-loop non-cooperative differential game.
A distributed anytime algorithm is proposed to compute a Nash
equilibrium of the game. The following properties are proven:
(i) the algorithm asymptotically converges to the set of Nash
equilibrium; (ii) for scalar cost functionals, the price of stability
equals one; (iii) for the worst case, the computational complexity
and communication cost are linear in the robot number.
I. INTRODUCTION
Robotic motion planning is a fundamental problem where
a control sequence is found to steer a robot from the initial
state to the goal set, while enforcing the environmental
rules. It is well-known that the problem is computationally
challenging [23]. The situation is even worse for multi-
robot motion planning since the computational complexity
exponentially grows as the robot number.
For multi-robot motion planning, non-cooperative game
theoretic controller synthesis is interesting in two aspects:
descriptive and perspective. From the descriptive point of
view, Nash equilibrium is desirable in inherently competitive
scenarios. More speciﬁcally, Nash equilibrium characterizes
the stable scenarios among inherently self-interested players
where none can beneﬁt from unilateral deviations. From the
perspective point of view, non-cooperative game theoretic
learning holds the promise of providing computationally
efﬁcient algorithms for multi-robot controllers where the
robots are assumed to be self-interested. Although Nash
equilibrium may not be socially optimal, game theoretic
approaches remain useful when the computational efﬁciency
dominates.
There have been limited results on rigorous analysis of
game theoretic controller synthesis for multi-robot motion
planning. The paper [19] tackles multi-robot motion planning
in the framework of feedback differential games. However, it
lacks of the rigorous analysis of the algorithm’s convergence
and computational complexity. In addition, static game the-
ory has been used to synthesize distributed control schemes
M. Zhu is with the Department of Electrical Engineering, Pennsylvania
State University, 201 Old Main, University Park, PA, 16802.
Email: muz16@psu.edu.
M. Otte, P. Chaudhari and E. Frazzoli are with the Laboratory for Infor-
mation and Decision Systems, Massachusetts Institute of Technology, 77
Massachusetts Avenue, Cambridge MA, 02139.
Email: ottemw@mit.edu, pratikac@mit.edu, frazzoli@mit.edu.
This research was supported in part by ONR Grant #N00014-09-1-0751
and the Michigan/AFRL Collaborative Center on Control Sciences, AFOSR
grant #FA 8650-07-2-3744.
to steer multiple vehicles to stationary and meaningful con-
ﬁgurations; e.g., in [29] for optimal sensor deployment, in [1]
for vehicle routing and in [2] for target assignment.
Contributions. This paper presents the ﬁrst distributed,
anytime algorithm to compute open-loop Nash equilibrium
for non-cooperative robots. More speciﬁcally, we consider a
class of multi-robot motion planning problems where each
robot is associated with multiple objectives and decoupled
task speciﬁcations. The problems are formulated as an
open-loop non-cooperative differential game. By leveraging
the RRG algorithm in [16], iterative better response and
model checking, a distributed anytime computation algo-
rithm, namely the iNash-trajectory algorithm, is proposed to
ﬁnd a Nash equilibrium of the game. We formally analyze
the algorithm convergence, the price of stability as well
as the computational complexity and communication cost.
The algorithm performance is demonstrated by a number
of numerical simulations. Proofs of various theorems and
lemmas are ommitted due to lack of space, please refer
to [30] for the extended analysis.
Literature review. Sampling based algorithms have been
demonstrated to be efﬁcient in addressing robotic motion
planning in high-dimension spaces. The Rapidly-exploring
Random Tree (RRT) algorithm and its variants; e.g., in [18],
[20], are able to ﬁnd a feasible path quickly. Recently, two
novel algorithms, PRM

and RRT

, have been developed
in [16], and shown to be computationally efﬁcient and
asymptotically optimal. In [17], a class of sampling-based
algorithms is proposed to compute the optimal trajectory
satisfying the given task speciﬁcations in the form of de-
terministic -calculus.
Regarding the multi-robot open-loop motion planning,
the approaches mainly fall into three categories: centralized
planning in; e.g., [24], [28], decoupled planning in; e.g., [15],
[26] and priority planning in; e.g., [9], [12]. Centralized
planning is complete but computationally expensive. In con-
trast, decoupled and priority planning can generate solutions
quicker, but are incomplete. However, the existing algorithms
assume the robots are cooperative and are not directly
applicable to compute Nash equilibrium where none of self-
interested robots is willing to unilaterally deviate from.
Another set of relevant papers are concerned with nu-
merical methods for feedback differential games. There
have been a very limited number of feedback differential
games whose closed-form solutions are known, including
homicidal-chauffeur and the lady-in-the-lake games [8],
[13]. The methods based on partial differential equations;
e.g., in [6], [7], [27], viability theory; e.g., in [3], [4], [10]
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 1646
and level-set methods, e.g., in [25] have been proposed to
determine numerical solutions to differential games. How-
ever, the papers aforementioned only study one-player and
two-player differential games. Multi-player linear-quadratic
differential games have been studied in; e.g., [8].
II. PROBLEM FORMULATION
Consider a team of robots, labeled byV
R
,f1; ;Ng.
Each robot is associated with a dynamic system governed by
the following differential equation:
_ x
i
(t) =f
i
(x
i
(t);u
i
(t)); (1)
where x
i
(t) 2 X
i
 R
ni
is the state of robot i, and
u
i
(t) 2 U
i
is the control of robot i. For system (1), the
set of admissible control strategies for robot i is given by:
U
i
,fu
i
() : [0; +1)!U
i
; measurableg;
where U
i
 R
mi
. For each robot i, 
[i]
: [0; +1)!X
i
is a dynamically feasible trajectory if there are T  0 and
u
i
: [0;T ]!U
i
such that: (i) _ 
[i]
(t) = f
i
(
[i]
(t);u
i
(t));
(ii) 
[i]
(0) = x
[i]
init
; (iii) 
[i]
(t)2X
F
i
for t2 [0;T ]; (iv)

[i]
(T )2X
G
i
. The set of dynamically feasible trajectories
for roboti is denoted by 
i
. Note that the trajectories in 
i
do not account for the inter-robot collisions.
Let 
i
be a ﬁnite set of atomic propositions and 
i
:
X
i
! 2
i
associates each state inX
i
with a set of atomic
propositions in 
i
. Given a trajectory 
[i]
of (1), deﬁne by
T (
[i]
) the set of time instances when 
i
(
[i]
(t)) changes.
The word w(
[i]
),fw
0
;w
1
;g generated by the trajec-
tory 
[i]
is such that w
i
= 
i
(
[i]
(t
i
)) where t
0
= 0 and
T (
[i]
) =ft
1
;t
2
;g.
In this paper, we consider reachability tasks where each
robot has to reach an open goal setX
G
i
X and simultane-
ously maintain the state x
i
(t) inside a closed constraint set
X
F
i
X . As an example, let 
i
=fp
G
;p
F
g be the set of
atomic propositions. The proposition p
G
is true if x
i
2X
G
i
and similarly, p
F
is true if x
i
2X
F
i
. Consider an example
task speciﬁcation 
i
expressed using the ﬁnite fragment of
Linear Temporal Logic, (FLTL) [21] as 
i
=F p
G
^G p
F
where F is the eventually operator and G stands for the
always operator. If the word formed by a trajectory 
[i]
is such that for w(
[i]
) = w
0
;w
1
;:::; there exists some
w
k
such that p
G
2 w
k
and p
F
2 w
i
for all i  0, we
say that the word w(
[i]
) satisﬁes the LTL formula 
i
. Let
us note that FLTL formulae such as those considered here
can be automatically translated into automata. The word
w(
[i]
) satisﬁes the formula if it belongs to the language
of the corresponding automaton. Please refer [5] for a more
thorough exposition of these concepts. Denote by [
i
] 

i
the set of trajectories fulﬁlling 
i
. Each robot then
determines a trajectory belonging to [
i
].
In addition to ﬁnding a trajectory that satisﬁes these
speciﬁcations, the robot may have several other objectives
such as reaching in the goal region in the shortest possible
time. To quantify these objectives, we deﬁne Cost : !
R
p
0
as the cost functional which maps each trajectory in
 ,
N
i2V
R

i
1
to a non-negative cost vector and each
component ofCost corresponds to an objective of the robots.
In what follows, we assume that Cost is continuous. In
addition, the robots want to avoid the inter-robot collisions;
i.e., keeping the state x(t) outside the collision setX
col
.
The above multi-robot motion planning problem is for-
mulated as an open-loop non-cooperative game where each
robot seeks to ﬁnd a trajectory which is collision-free,
fulﬁlls its task speciﬁcations and minimizes the induced
cost given the trajectories of other robots. That is, given

[ i]
2 
 i
2
, each robot i wants to ﬁnd a best trajectory in
the feasible set Feasible
i
(
i
;
[ i]
),f
[i]
2 
i
j 
[i]
2
[
i
]; CollisionFreePath(
[i]
;
[ i]
) = 1g where the
procedure CollisionFreePath will be deﬁned later. The
solution notion we will use is Nash equilibrium formally
stated as follows:
Deﬁnition 2.1 (Nash equilibrium): The collection of
trajectories ( 
[i]
)
i2V
R
2  is a Nash equilibrium if for any
i2V
R
, it holds that  
[i]
2 Feasible
i
(
i
;  
[ i]
) and there
is no 
[i]
2 Feasible
i
(
i
;  
[ i]
) such that Cost(
[i]
)
Cost( 
[i]
)
3
.
Intuitively, none of the robots can decrease its cost by
unilaterally deviating from a Nash equilibrium. Denote by

NE
  the set of Nash equilibria. Note that Deﬁnition 2.1
is an extension of the standard one; e.g., in [8] where the cost
functional of each player is scalar. We will compare Nash
equilibrium with social (Pareto) optimum deﬁned as follows:
Deﬁnition 2.2 (Social (Pareto) optimum): The collec-
tion of trajectories ( 
[i]
)
i2V
R
2  is socially (Pareto) optimal
if there is no (
[i]
)
i2V
R
2  such that
L
i2V
R
Cost(
[i]
)
L
i2V
R
Cost( 
[i]
).
4
Denote by 
SO
  the set of social optimum. Through-
out this paper, we assume that 
SO
6= ;. In general, a
Nash equilibrium may not be socially optimal. When Cost
is scalar, the gap between the set of Nash equilibrium and
the set of social optimum is usually characterized by price
of anarchy and price of stability in; e.g., [22].
A. Primitives
Here we deﬁne a set of primitives which will be used in
the subsequent sections.
a) Sampling: The Sample(A) procedure returns uni-
formly random samples from set A.
b) Local steering: Given two states x;y, the Steer
procedure returns a statez by steeringx towardsy for at most
> 0 distance; i.e., Stear(x;y), argmin
z2B(x;)
kz yk.
In addition to this, we require that (x;y), the trajectory
connecting statesx andy, is such thatjT ((x;y))j 1, i.e.,
the label ((x;y)) changes at most once. This property of
the local steering function is called trace inclusivity [11].
1
N
represents the product.
2
We use i to denote all the robots other than i.
3
The relation is deﬁned onR
p
and given by: for a;b2R
p
, ab if
and only if a
`
b
`
for all `2f1; ;pg. Note that is a partial order
onR
p
.
4
L
represents the summation.
1647
c) Nearest neighbor: Given a statex and a ﬁnite setS
of states, the Nearest procedure returns the state in S that
is closest to x; i.e., Nearest(S;x), argmin
y2S
ky xk.
d) Near vertices: Given a state x, a ﬁnite set S and
a positive real number r, the NearVertices procedure
returns the states in S where each of them is r-close to x;
NearVertices(S;x;r),fy2Sjkx ykrg.
e) Path generation: Given a directed graph G with a
single root and no directed cycles, the PathGeneration(G)
procedure returns the set of paths from the root to the leaf
vertices.
f) Collision check of paths: Given a path and a set of
paths , theCollisionFreePath(; ) procedure returns 1
if collides any path in ; i.e.,(t)2X
free
,
N
i2V
R
X
F
i
\
X
col
; otherwise returns 0.
g) Feasible paths: Given the path sets of 
i
and

[ i]
, Feasible
i
(
i
;
[ i]
) is the set of paths 
[i]
2

i
such that for any 
[i]
2 
i
, it holds that
CollisionFreePath(
[i]
;
[ i]
) = 1.
h) Weakly feasible paths: Given the path sets of

i
and 
[ i]
, WeakFeasible
i
(
i
;
[ i]
) is a subset of
Feasible
i
(
i
;
[ i]
) and consists of the paths 
[i]
where
for each path 
[i]
, there are a sequence of pathsf
[i]
`
g with

[i]
`
2 
i
and a diminishing and non-negative sequencef
`
g
such that (i)
[i]
`
converges to
[i]
; (ii)B(
[i]
`
(t);
`
)2X
F
i
;
(ii)k
[i]
`
(t) 
[j]
(t)k +
`
for all j6=i for all t.
i) Strongly feasible paths: Given the path sets of

i
and 
[ i]
), StrongFeasible
i
(
i
;
[ i]
) is a subset of
Feasible
i
(
i
;
[ i]
) and consists of the paths where for
each path
[i]
, there are a sequence of pathsf
[i]
`
g with
[i]
`
2

i
, a diminishing and non-negative sequencef
`
g and> 0
such that (i)
[i]
`
converges to
[i]
; (ii)B(
[i]
`
(t);
`
)2X
F
i
;
(ii)k
[i]
(t) 
[j]
(t)k + for all j6=i.
III. INASH-TRAJECTORY ALGORITHM
In this section, we propose the iNash-trajectory Algorithm
to solve the open-loop game deﬁned above. It is followed by
the algorithm analysis and discussion.
A. Algorithm statement
The iNash-trajectory Algorithm leverages the RRG algo-
rithm in [16], iterative better response and model checking,
and informally stated as follows. At each iteration k, each
robot i samplesX
i
once, and adds the new sample x
[i]
rand
to its vertex set V
[i]
k
. Robot i extends its previously gener-
ated graph G
[i]
k 1
towards the new sample x
[i]
rand
via local
steering, and obtains the new graph G
[i]
k
. After they ﬁnish
the construction of the new graphs, the active robots play a
game on their product graph for one round in a sequential
way. Robot i is active at time k if its goal set is reachable
through some path of G
[i]
k
. The active robot with the least
index, say i, ﬁrst chooses a smaller-cost and feasible path
on G
[i]
k
by performing the BetterResponse procedure in
Algorithm 3. Then robot i informs all other robots the new
path. After that, the active robot with the second least index,
say j, performs the better response to update its path on
Algorithm 1: The iNash-trajectory Algorithm
1 for i = 1 :N do
2 V
[i]
(0) x
[i]
init
;
3 E
[i]
(0) ;;
4 A
k
 ;;
5 k 1;
6 while k<K do
7 for i = 1 :N do
8 x
[i]
rand
 Sample(Xi);
9 G
[i]
k
 Extend(G
[i]
k 1
;x
[i]
rand
);
10 for i2VRnA
k 1
do
11 if V
[i]
k
\X
G
i
6=; then
12 A
k
 A
k 1
[fig;
13 for i2A
k
do
14 ~ 
[i]
k
=
[i]
k 1
;
15 for i = 1 :N do
16 if i2A
k
then
17 
[i]
k
 ff
[j]
k
gj2A
k
;j<i;f~ 
[j]
k
gj2A
k
;j>ig;
18 
[i]
k
 BetterResponse(G
[i]
k
; 
[i]
k
);
19 k k + 1;
G
[j]
k
and the new path is sent to other robots. The remaining
active robots sequentially update the planned paths on their
own graphs and announce the new paths to others. Once all
the active robots ﬁnish the path updates, the game terminates
for the current iteration k. At the next iteration k + 1, the
same steps are repeated. The iNash-trajectory Algorithm is
formally stated in Algorithm 1.
The iNash-trajectory algorithm is an anytime algorithm;
i.e., assuming a solution can be found within the allotted
planning time, then it is continually improved while planning
time remains
B. Discussion
The Extend procedure is similar to that in the RRG
algorithm [16] with the difference that the edges leaving from
the new sample are not added. Instead, G
[i]
k
is identical to
the auxiliary graph G
n
used in the proof of Theorem 38
in [16] for RRT

. Notice that G
[i]
k
is a directed graph and
does not include any directed circle. So there are a ﬁnite
number of paths for the root to reach any leaf vertex and the
PathGeneration procedure in Algorithm 3 is well-deﬁned.
The tree structure returned by RRT

in [16] is more com-
putationally efﬁcient than the graph G
[i]
k
in our algorithm.
However, the rewiring step in RRT

induces that G
[i]
k 1
may not be a subgraph of G
[i]
k
. This property is crucial for
the algorithm convergence to Nash equilibria in the next
section. To verify if (
[i]
\ G
[i]
k
) 2 [
i
] on Line 4 of
the BetterResponse procedure, we check if the sequence

i
= (
[i]
\ G
[i]
k
) satisﬁes 
i
by translating 
i
into the
corresponding Buchi automaton.
C. Analysis
In this section, we analyze the asymptotic optimality,
computational complexity, and communication cost of the
1648
Algorithm 2: The Extend Procedure
1 V V
[i]
k 1
;
2 E E
[i]
k 1
;
3 xnearest Nearest(E;x
[i]
rand
);
4 xnew Steer(xnearest;x
[i]
rand
);
5 if ObstacleFree(xnearest;xnew) then
6 Xnear NearVertices(E;xnew; minf(
logk
k
)
1
n
;g);
7 V V[fxnewg;
8 for xnear2Xnear do
9 if ObstacleFree(xnearest;xnew) then
10 E E[f(xnearest;xnew)g;
11 return G = (V;E)
Algorithm 3: The BetterResponse Procedure
1 P
[i]
k
 PathGeneration(G
[i]
k
);
2 P
[i]
f
 ;;
3 for 
[i]
2P
[i]
k
do
4 if CollisionFreePath(
[i]
; 
[i]
k
) ==
1 && (
[i]
\G
[i]
k
)2 [i] then
5 P
[i]
f
 P
[i]
f
[f
[i]
g;
6 
[i]
min
 
[i]
k 1
;
7 for 
[i]
2P
[i]
f
do
8 if Cost(
[i]
) Cost(
[i]
min
) then
9 
[i]
min
 
[i]
;
10 Break;
11 return 
[i]
min
iNash-trajectory Algorithm. Before doing that, we ﬁrst prove
the existence of Nash equilibrium.
Lemma 3.1 (Existence of Nash equilibrium): It holds
that 
SO
 
NE
and 
NE
is non-empty.
Let
^
 be the set of limit points off
[i]
k
g
i2V
R
. We are ready
to show the convergence of the iNash-trajectory Algorithm.
Theorem 3.1 (Asymptotic optimality): There is  c
[i]
`
 0
such that Cost
`
( 
[i]
) =  c
[i]
`
for anyf 
[i]
g
i2V
R
2
^
. In
addition, any limit pointf 
[i]
g
i2V
R
is a Nash equilibrium.
Next, we will analyze the computational complexity of
the algorithm in terms of the CollisionFreePath pro-
cedure. Let 
n
to be the total number of calls to the
CollisionFreePath procedure at iteration n.
Lemma 3.2 (Computational complexity): It holds that

n

L
i2V
R
jP
[i]
k
j, where P
[i]
k
is deﬁned in Algorithm 3.
In Lemma 3.2, the quantityjP
[i]
k
j is independent of the
robot number. So the worst computational complexity of the
iNash-trajectory grows linearly in the robot number. It is in
contrast to the exponential dependency in centralized path
planning. The computational efﬁciency comes with the non-
cooperative game theoretic formulation where each robot
myopically responds to others. Note that a Nash equilibrium
may not be socially optimal for the robot team.
Let#
n
to be the number of exchanged paths in iterationn.
The following lemma shows the worst communication cost
is linear in the robot number.
Lemma 3.3 (Communication cost): #
n
 2N.
Algorithm 4: The iOptimalControl Algorithm
1 for i = 1 :N do
2 V
[i]
(0) x
[i]
init
;
3 E
[i]
(0) ;;
4 A
k
 ;;
5 k 1;
6 while k<K do
7 for i = 1 :N do
8 x
[i]
rand
 Sample(Xi);
9 G
[i]
k
 Extend(G
[i]
k 1
;x
[i]
rand
);
10 for i2VRnA
k 1
do
11 if V
[i]
k
\X
G
i
6=; then
12 A
k
 A
k 1
[fig;
13 (
[i]
k
)i2A
k
 OptimalTrajectory(
N
i2A
k
G
[i]
k
);
14 k k + 1;
Algorithm 5: The OptimalTrajectory Procedure
1 for i2A
k
do
2 Q
[i]
k
 PathGeneration(G
[i]
k
);
3 for i2A
k
do
4 P
[i]
f
 ;;
5 for 
[i]
2Q
[i]
k
do
6 if CollisionFreePath(
[i]
;Q
[ i]
k
) ==
1 && (\
N
i2A
k
G
[i]
k
)2 [] then
7 P
[i]
f
 P
[i]
f
[f
[i]
g;
8 min Sample(
N
i2A
k
P
[i]
f
);
9 for 2
N
i2A
k
P
[i]
f
do
10 if
L
i2A
k
Cost(
[i]
)
L
i2A
k
Cost(
[i]
min
) then
11 min ;
12 return min
D. Comparison
In order to demonstrate the scalability of iNash-trajectory
Algorithm, we consider the benchmark algorithm, the iOp-
timalControl Algorithm. The key difference between the
iOptimalControl and iNash-trajectory Algorithms is that a
centralized authority in the iOptimalControl Algorithm de-
termines a social optimum on the product graph at each
iteration. In the iOptimalControl Algorithm, we use the
notation (\
N
i2A
k
G
[i]
k
) 2 [] for (
[i]
\G
[i]
k
) 2 [
i
]
for all i2A
k
.
The following theorem guarantees the asymptotic optimal-
ity of the iOptimalControl Algorithm.
Theorem 3.2 (Asymptotic optimality): Any limit point
f 
[i]
g
i2V
R
is a social optimum.
Next, we will analyze the computational complexity of
the algorithm in terms of the CollisionFreePath pro-
cedure. Let 
0
n
to be the total number of calls to the
CollisionFreePath procedure at iteration n.
Lemma 3.4 (Computational complexity): It holds that

0
n
=
N
i2V
R
jQ
[i]
k
j, where Q
[i]
k
is deﬁned in Algorithm 5.
The above lemma shows that the computational complex-
ity exponentially grows vs. robot number. Table I summarizes
the comparison of the iOptimalControl and iNash-trajectory
1649
Algorithms where the prices of anarchy and stability are
compared for the case p = 1. In particular, the price
of stability (POS) [22] is the ratio between the minimum
additive cost function value in 
NE
and that of one in 
SO
,
and deﬁned as follows:
POS =
inf
2NE
L
i2V
R
Cost(
[i]
)
L
i2V
R
Cost( 
[i]
)
;
for any  2 
SO
. By Lemma 3.1, we know 
SO
 
NE
and thus POS is equal to 1. On the other hand, the price
of anarchy (POA) [22] is the ratio between the maximum
additive cost function value in 
NE
and that of one in 
SO
,
and given by:
POA =
sup
2NE
L
i2V
R
Cost(
[i]
)
L
i2V
R
Cost( 
[i]
)
;
for any  2 
SO
. The value of POA depends on a number of
factors; e.g., the obstacle locations, the dynamic systems and
so on. It is interesting to ﬁnd a lower bound on 
SO
given
more information as in; e.g., [14], and utilize mechanism
design to eliminate the price of anarchy.
TABLE I: The comparison of the iOptimalControl and
iNash-trajectory Algorithms
iOptimalControl iNash-trajectory
Solution Notion Social optimum Nash equilibrium
Solution Feasibility Yes Yes
Price of stability N/A One
Price of anarchy N/A Unknown
Coordination High Low
Asymptotic optimality Yes Yes
Computational complexity Exponential Linear
IV. EXPERIMENTS
We perform two experiments in simulation to evaluate the
performance of iNash. The ﬁrst involves 8 circular robots
moving in an environment with randomly generated obstacles
(Figure 2-left), while the second involves 6 robots in a
trafﬁc intersection scenario (Figure 2-right); both involve
state spaces consisting of ﬁrst order dynamics and time.
Robots are holonomic discs with radii of 0:5 meters.
We compare iNash to two prioritized methods that are
not guaranteed to return a Nash-Equilibrium, but are ar-
guably similar to our proposed algorithm. The ﬁrst is the
standard prioritized approach from [12]. Each robot builds
its own random graph; then robots select their paths in
order such that the path of robot i does not conﬂict with
robots 1;:::;i  1. The second is an any-time version of
the prioritized method. Each time robot i ﬁnds a better path
that does not conﬂict with the paths of robots 1;:::;i  1,
then forj =i+1;i+2;::: (in order) robotj must choose a
new path that does not conﬂict with robots 1;:::;j 1. This
differs from our algorithm (where new paths must respect the
paths of all other robots), and the solution is not guaranteed
to converge to a Nash Equilibrium.
For experiments we consider the task speciﬁcations for
each robot to be of the form 
i
=F p
Gi
^G p
F
, i.e., each
robot tries to reach a different goal region in the shortest
q
0
q
1
p
F
^:p
Gi
p
F
^p
Gi
p
F
Fig. 1: Automaton for i =F pG
i
^G pF .
possible distance while respecting the same constraint set
X
F
. The automaton consists of two states (see Fig. 1).
Discussion of Experimental Results: Experimental results
are summarized in tables II-III. In iNash all robots tend to
bear the burden of conﬂict resolution similarly, on average.
This contrasts with the prioritized methods, in which robot’s
with lower IDs have shorter paths and reach the goal more
frequently than robots with higher IDs. The result that some
iNash paths are longer than the prioritized paths is expected,
given that in iNash robots act in their own self interest.
V. CONCLUSIONS
This paper discusses a class of multi-robot motion plan-
ning problems where each robot is associated with multiple-
objectives and independent class speciﬁcations. We formu-
lated the problem as an open-loop, non-cooperative differ-
ential game and proposed a distributed, anytime algorithm
to compute the Nash equilibrium. Techniques from Rapidly-
exploring Random Graphs and iterative better response were
used to provide convergence guarantees and analyse the
price of stability as well as the communication cost of the
algorithm. We also presented results of simulation exper-
iments that demonstrate the efﬁciency and anytime nature
of the algorithm. Future directions include coupled task
speciﬁcations of robots and algorithms which can eliminate
the price of anarchy.
REFERENCES
[1] A. Arsie, K. Savla, and E. Frazzoli. Efﬁcient routing algorithms for
multiple vehicles with no explicit communications. IEEE Transactions
on Automatic Control, 54(10):2302–2317, 2009.
[2] G. Arslan, J. R. Marden, and J. S. Shamma. Autonomous vehicle-
target assignment: A game theoretic formulation. ASME Journal on
Dynamic Systems, Measurement, and Control, 129(5):584–596, 2007.
[3] J.P. Aubin. Viability theory. Springer, 2009.
[4] J.P. Aubin, A. Bayen, and P. Saint-Pierre. Viability theory: New
directions. Springer-Verlag, New York, 2011.
[5] Christel Baier, Joost-Pieter Katoen, et al. Principles of model checking,
volume 26202649. MIT press Cambridge, 2008.
[6] M. Bardi and I. Capuzzo-Dolcetta. Optimal control and viscosity
solutions of Hamilton-Jacobi-Bellman equations. Birkh¨ auser, 1997.
[7] M. Bardi, M. Falcone, and P. Soravia. Numerical methods for pursuit-
evasion games via viscosity solutions. Annals of the International
Society of Dynamic Games, 4:105 – 175, 1999.
[8] T. Basar and G. Olsder. Dynamic noncooperative game theory. SIAM
Classics in Applied Mathematics, 1999.
[9] S. J. Buckley. Fast motion planning for multiple moving robots. In
IEEE International Conference on Robotics and Automation, pages
322–326, May 1989.
[10] P. Cardaliaguet, M. Quincampoix, and P. Saint-Pierre. Set-valued
numerical analysis for optimal control and differential games. Annals
of the International Society of Dynamic Games, 4(1):177 – 247, 1999.
[11] Luis I Reyes Castro, Pratik Chaudhari, Jana Tumova, Sertac Karaman,
Emilio Frazzoli, and Daniela Rus. Incremental sampling-based algo-
rithm for minimum-violation motion planning. In Proc. of 52nd IEEE
Conference on Decision and Control, 2013.
[12] M. Erdmann and T. Lozano-Perez. On multiple moving objects.
Algorithmica, 2(6):477–521, 1987.
1650
?50 ?40 ?30 ?20 ?10 0 10 20 30 40 50
?50
?40
?30
?20
?10
0
10
20
30
40
50
?50 ?40 ?30 ?20 ?10 0 10 20 30 40 50
?50
?40
?30
?20
?10
0
10
20
30
40
50
?15 ?5 5 15
?15
?10
?5
0
5
10
15
Fig. 2: Experimental environments. Obstacles are outlined in black, paths are colored lines. Robots start at ‘O’s and end at ‘X’s (’O’s
are drawn 3x the robot radii to help visualization). Left/Center: 8 robots in a randomly generated environment; the Nash Equilibrium in
the left trial allows 6 of 8 robots to reach their goals, while all 8 reach their goals in the center trial. Right: 6 Robots at an intersection
and the paths corresponding to a Nash equilibrium where all robots reach their goals
TABLE II: Experimental Results, Random Environment
Mean path length over 20 trials (ratio vs. socially optimal length)
Algorithm
Robot ID
1 2 3 4 5 6 7 8
iNash (any-time) 1:295 1:343 1:324 1:301 1:166 1:293 1:224 1:202
Prioritized 1:084 1:149 1:263 1:316 1:228 1:326 1:312 1:349
Prioritized (any-time) 1:081 1:129 1:153 1:200 1:126 1:168 1:163 1:204
Total times reached goal (of 20)
Robot ID
1 2 3 4 5 6 7 8
20 19 18 20 16 15 18 17
20 20 18 19 20 18 18 15
20 20 18 20 19 20 20 20
TABLE III: Experimental Results, Intersection Environment
Mean path length over 20 trials (ratio vs. socially optimal length)
Algorithm
Robot ID
1 2 3 4 5 6
iNash (any-time) 1:168 1:228 1:245 1:243 1:201 1:166
Prioritized 1:107 1:238 1:384 1:492 1:339 1:300
Prioritized (any-time) 1:085 1:212 1:165 1:248 1:136 1:251
Total times reached goal (of 20)
Robot ID
1 2 3 4 5 6
11 14 12 14 16 15
19 18 19 13 12 4
19 18 20 19 20 15
[13] R. Isaacs. Differential Games: A Mathematical Theory with Appli-
cations to Warfare and Pursuit, Control and Optimization. Dover,
1999.
[14] R. Johari and J.N. Tsitsiklis. Efﬁciency loss in a network resource
allocation game. Mathematics of Operations Research, 29(3):407–
435, 2004.
[15] K. Kant and S.W. Zucker. Toward efﬁcient trajectory planning: The
path-velocity decomposition. The International Journal of Robotics
Research, 5(3):72 – 89, 1986.
[16] S. Karaman and E. Frazzoli. Sampling-based algorithms for opti-
mal motion planning. International Journal of Robotics Research,
30(7):846 – 894, 2011.
[17] S. Karaman and E. Frazzoli. Sampling-based algorithms for optimal
motion planning with deterministic mu-calculus speciﬁcations. In 2012
American Control Conference, pages 735–742, Montr´ eal, Canada,
December 2012.
[18] J.J. Kuffner and S.M. LaValle. RRT-connect: An efﬁcient approach
to single-query path planning. In IEEE Conference on Robotics and
Automation, pages 995–1001, 2000.
[19] S.M. LaValle and S.A. Hutchinson. Optimal motion planning for
multiple robots having independent goals. IEEE Transactions on
Robotics and Automation, 14(6):912–925, 1998.
[20] S.M. LaValle and J.J. Kuffner. Randomized kinodynamic planning.
The International Journal of Robotics Research, 20(5):378–400, 2001.
[21] Zohar Manna. Temporal veriﬁcation of reactive systems: safety,
volume 2. Springer, 1995.
[22] N. Nisan, T. Roughgarden, E. Tardos, and V .V . Vazirani. Algorithmic
Game Theory. Cambridge University Press, 2007.
[23] J.H. Reif. Complexity of the mover’s problem and generalizations.
In The 20th Annual IEEE Conference on Foundations of Computer
Science, pages 421–427, 1979.
[24] G. Sanchez and J.C. Latombe. On delaying collision checking in prm
planning – application to multi-robot coordination. The International
Journal of Robotics Research, 21:5 – 26, 2002.
[25] J.A. Sethian. Level Set Methods: Evolving Interfaces in Geometry,
Fluid Mechanics, Computer Vision and Materials Science. Cambridge
University Press, 1996.
[26] T. Simeon, S. Leroy, and J.-P. Lauumond. Path coordination for multi-
ple mobile robots: a resolution-complete algorithm. IEEE Transactions
on Robotics and Automation, 18(1):42 – 49, 2002.
[27] P.E. Souganidis. Two-player, zero-sum differential games and viscosity
solutions. Annals of the International Society of Dynamic Games,
4(1):69 – 104, 1999.
[28] E.K. Xidias and N.A. Aspragathos. Motion planning for multiple
non-holonomic robots: a geometric approach. Robotica, 26:525–536,
2008.
[29] M. Zhu and S. Mart´ ınez. Distributed coverage games for energy-aware
mobile sensor networks. SIAM Journal on Control and Optimization,
51(1):1–27, 2013.
[30] M. Zhu, M. Otte, P. Chaudhari, and E. Frazzoli. Distributed anytime
game-theoretic learning for multi-robot motion planning - Part I :
Trajectory based algorithms. http://arxiv.org/abs/1402.2708.
1651
