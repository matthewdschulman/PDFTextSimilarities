Robot Learning Based on Partial Observable Markov Decision Process
in Unstructured Environment
Hongtai Cheng, Member, IEEE, Heping Chen, Senior Member, IEEE, Lina Hao and Wei Li
Abstract—Robot teaching is necessary for the current in-
dustrial robot applications. Because work stations have to
be stopped to perform teaching processes, the manufacturing
efﬁciency is decreased. In this paper we propose to utilize
an uncalibrated vision system mounted on a mobile robot
(“Adult” robot) with learning capability to supervise a group
of ﬁxed robots (“Child” robots) to accomplish a robot teaching
task automatically without stopping work stations. To increase
the system ﬂexibility, hand-eye calibration and calibration be-
tween the robots are eliminated. A Partial Observable Markov
Decision Process(POMDP) is formulated and solved using
the Successive Approximation of the Reachable Space under
Optimal Policies (SARSOP) algorithm to enable the teaching
process using image features with uncertainties. The proposed
algorithm was tested using the “adult” robot to teach a “child”
robot to perform a high accuracy peg-in-hole assembly process.
Theexperimentalresultsverifytheeffectivenessoftheproposed
approach.The proposedmethod can also be used in other areas
to enable robot teaching.
I. INTRODUCTION
Currently robot teaching is a necessary process in the
industrial robot applications because industrial robots are
typically lack of adaptability to the environmental changes
and workpiece variations. Before a new application is de-
ployed, ofﬂine programming and simulation packages such
as RobotStudio [1] can be used to generate robot programs.
Because of the unmodeled factors and parts’ location errors,
to transfer the virtually tested programs to the real appli-
cation, a teaching process has to be performed to correct
the errors in the work station. Even for robots in operation,
when different batches of parts are launched, the pre-tuned
robot tool locations may not be applicable because of the
part variations. Thus the work station has to be stopped in
order to correct the part location errors. Therefore the goal
of this research is to investigate a fully automated system to
enable industrial robots to situate themselves without human
intervention such that the manufacturing efﬁciency can be
increased.
Vision systems are widely used to correct the part location
errors. However, the location output from the vision system
may not be reliable because of the deviation of camera
calibration. Hence directly using the vision system may
not be able to correct the part location errors. Therefore,
H. Cheng and L. Hao are with Department of Mechanical Engineer-
ing and Automation, North East University, Shenyang, Liaoning, China,
fchenght,haolinag@me.neu.edu.cn
H.CheniswiththeIngramSchoolofEngineering,TexasStateUniversity,
San Marcos, USA, hc15@txstate.edu
W. Li is with Yantai Tongxing Industrial Co. Ltd., Yantai, Shandong,
China, davidlee83@126.com
part location correction with uncalibrated vision systems is
desirable.
Even though a vision system can be installed at each work
station, the cost of n vision systems (n is the number of
work stations) in a production line will be very high and
the maintenance issues caused by many vision systems are
signiﬁcant. Hence installing a vision system on a simple
mobile platform, instead of n vision systems, could reduce
the cost and thus be a better solution to deal with the
part location errors. A mobile robot equipped with cameras
(“Camera-in-Mobile”) is an “adult” robot that can teach
a group of “child” robots in a production line. Since the
“adult” robot has to move around, calibration between the
camera and “child” robots is unrealistic. Therefore, the key
difﬁculty of utilizing such a mobile “adult” robot lies in how
to guarantee the teaching accuracy without calibration.
Without any prior knowledge, the mobile “adult” robot
has to work in an unstructured environment. Motion con-
trol in such an environment is still a challenging problem
since models of the working environment are not known
as a prior. There are many methods proposed to solve this
problem, such as 3D information retrieval including multi-
view geometric techniques using single movable camera[2],
[3] and Simultaneous Localization And Mapping(SLAM)[4].
However due to the limitation of vision systems, they cannot
meet the requirements for highly precise and ﬂexible robot
teachingapplications[5],[6].Visualservoingwithuncalibrat-
edcameras[7],[8]hasbeenproposedtosolvethelocalization
problem. Because of the strict requirements for the prior
knowledge of robot dynamics and the environmental uncer-
tainties such as lighting condition and part variations, visual
servoing methods could generate big errors to command a
robot and thus damage the system and/or parts.
In this paper, we utilize an “adult” robot with a 2D camera
to realize the teaching process. By observing the uncertain
workpiece features from the camera, formulating and solving
thePartialObservableMarkovDecisionProcess(POMDP)[9]
model, the “adult” robot learns and teaches a “child” robot
how to choose an action in the corresponding state. Ex-
periments are performed to evaluate the proposed method.
Becausethereisnocalibrationbetweenthe“adult”robotand
the “child” robot, it is easy to deploy the developed system
in robot teaching. Thus human workers can be released
from the teaching work and the manufacturing efﬁciency
can be improved. The proposed method can also be used
for teaching processes using ﬁxed cameras on a work station
without calibration.
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 4399
II. PROPOSED SOLUTION
The proposed “adult” robot enabled teaching process is
shown in Figure 1. This teaching process contains three
subtasks:learningtheprimitivemotion,ofﬂinerobotlearning
and online robot teaching. The fourth task is about the
assembly process.

	
















Fig. 1. Structure of the proposed robot enabled learning approach for robot
teaching problem in the unstructured environment. The compliant assembly
is a built-in function of the “child” robot.
Since there is no calibration between the “adult” and
“child” robots, to ensure that the “child” robot moves along
the right direction, the “adult” robot must learn its moving
direction ﬁrst. This subtask is performed using the following
primitive motion learning algorithm.
A. Primitive Motion Learning
As mentioned above, the mobile “adult” robot has no prior
knowledge about the coordinate frames of the “child” robot
tool(C
t
) and target(C
h
). It has to learn how to guide the
“child” robot ﬁrst. The relationship betweenC
t
andC
h
drawn
in the camera coordinate frame is shown in Figure 2. Since
the goal is to drive the tool to the target position, it is natural
to learn how to guide the “child” robot tool along the target
coordinate frame C
h
.
( )
0 0
, u v
X
O Y
Z
h
C
h
c
( ) , ,
p p p
P X Y Z =
( ) , ,
p p p
P X Y Z ? ? ? ? =
x
P
+
y
P
+ x
P
?
y
P
?
t
C
t
c
Fig. 2. Coordinate projection from the robot tool coordinate frame, target
coordinate frame to the image 2D coordinate frame. c
h
and c
t
are the
projected target and robot tool coordinate frames respectively. The view
cone is a cone connecting the camera origin to the target. Objects in the
cone will block the target. Four points P
x+
;P
x?
;P
y+
;P
y?
are selected as the
critical points for the block property.
The “adult” robot can command the “child” robot to offset
along its tool coordinate frame C
t
. To guide the “child”
robot tool along C
h
, the relationship between C
t
and C
h
should be determined. The difference between these two
coordinatedframesisdeterminedbyarotationangle?.Since
it is difﬁcult to obtain this angle in the original C
t
and C
h
,
we calculate it in the projected coordinate frames c
t
and
c
h
. By driving the “child” robot to move along its X-axis
and recording the starting and ending positions (u
1
;v
1
) and
(u
2
;v
2
) in the image coordinate frame one can get
[∆u ∆v]=[u
2
?u
1
v
2
?v
1
] (1)
where ∆u;∆v are the projected tool position changes in the
imagecoordinateframe.Therefore,theslopeoftheprojected
X-axis of C
t
can be obtained by k
x
=∆u=∆v. Furthermore,
when the “adult” robot identiﬁes the target, it can deﬁne the
target coordinate frame C
h
and its projection c
h
. Therefore,
the rotation angle ? can be calculated using the X-axis of
the projected coordinate frames c
h
and c
t
.
? =arctank
x
h
?arctank
x
(2)
where k
x
h
is the slope of the X-axis of the projected tar-
get coordinate frame c
h
. Thus, one can get the coordinate
transform equation.
[
∆x
t
∆y
t
]
T
=M(?)
[
∆x
h
∆y
h
]
T
(3)
where M(?) is the rotation matrix; (∆x
t
;∆y
t
) are the
command values sent to the “child” robot for realizing
offset(∆x
h
;∆y
h
) along the target coordinate frame.
B. Ofﬂine Robot Learning
To guide the robot tool to the desired position using
2D information, the position transformation from 3D to 2D
should be analyzed. Based on the Pinhole camera model,
the Z coordinate is missing during the projection process
which means each single pixel (x;y) in the image coordinate
frame stands for a 3D line in camera coordinate frame, i.e.
X = xZ=f;Y = yZ=f, where f is the camera focal length
and (X;Y;Z) are the coordinates in the camera coordinate
frame. For the two points P and P
?
in Figure 2, although it is
impossible to measure their actual coordinates, it is possible
to determine whether P
?
(X
?
p
;Y
?
p
;Z
?
p
) blocks P(X
p
;Y
p
;Z
p
).
1) POMDP: As aforementioned, to increase the system
ﬂexibilityandreliability,thecameracalibrationiseliminated.
Thus the only information we have is whether the critical
points are blocked or not. Therefore the problem is how to
estimate the underlying position errors and make correct de-
cisions with limited observations, which meets the deﬁnition
and requirements of POMDP [9].
The POMDP consists of a tuple {S;A;O;T;Z;R;?}, where
S is the state set; A is the action set; O is the observation set;
T is the transition function; Z is the observation function; R
is the reward function and ? ? (0;1) is the discount factor.
Differentfromthe standardMarkovDecision Process(MDP),
the state cannot be fully observed. Instead, an observation
set O is introduced to describe the possible observations and
observationfunctionZ isintroducedtodescribethestatistical
relationship between O and the underlying state S.
2) Model Construction: For the robot teaching problem,
the goal is to drive the “child” robot tool toward the target
position.Thestateshouldbechosenaccordingtotheposition
error between the robot tool and target. Although the state
spaceandrobotmanipulatordynamicsarecontinuous,dueto
the limitation of the sensor and motion accuracy, the action
and state are better represented using discrete variables.
It is natural to discretize the state space into a grid. Figure
3(a) shows a 2D Peg-in-hole example demonstrating the
grid. The grid intersects with the view cone. Thus when the
“child” robot moves the tool into this area, there always exist
grids to block or unblock the target. The desired state lies
exactly in front of the target as shown in Figure 3(a).
4400
In these experiments, we considered the most common
scenario: the “adult” robot comes, stands still and performs
a teaching task. During the experiments, the camera and the
mobile robot are ﬁxed and there is no calibration between
the camera, the “adult” robot and the “child” robot.
A. Experimental Procedure
The whole assembly process contains four subtasks: prim-
itive motion learning, ofﬂine robot learning, online robot
teaching and compliant assembly. These subtasks are inte-
grated to accomplish the assembly task. During the primitive
motion learning stage, the “adult” robot ﬁrstly sends com-
mands to the “child” robot with offsets ∆x=5mm, records
the starting and ending position of the “child” robot tool and
calculates the primitive motion transformation matrix.
1) Ofﬂine Robot Learning: To obtain the policy for con-
trolling the “child” robot, the POMDP model has to be
generated ﬁrst. Parameters of the system conﬁguration are
listed in TABLE I. We consider two groups of parameters
with different grid sizes.
TABLE I
POMDP MODEL PARAMETERS
g
x
g
y
g
z
N
X
N
Y
N
Z
D
hole
?
1
/rad ?
2
/rad
5mm 5mm 5mm 8 8 8 22mm 0.67 -0.49
2mm 2mm 2mm 16 16 16 22mm 0.67 -0.49
The discount factor ? is chosen as 0.95. The
POMDP model is solved using the Approxi-
mate POMDP PLanning toolkit(APPL) solver
(http://bigbird.comp.nus.edu.sg/pmwiki/farm/appl/) which
implements the SARSOP algorithm.
Here the initial state is assumed to the states which have
theobservationof o
2
andare20mmaway(alongZ-axis)from
thetargetposition.Forthe5mmgridPOMDPmodel,ittakes
about 10.2s to ﬁnd the optimal policywhile forthe 2mm grid
POMDP model, the solving process lasts 3003.1s.
2) Online Robot Teaching: To Verify the effectiveness
of the proposed robot teaching algorithm and the accuracy
of the obtained POMDP policy, we utilized the parameters
shown in TABLE II to generate the random initial posi-
tions. The case 1 parameters are for 5mm grid conﬁgura-
tion experiments and case 2 parameters are for 2mm grid
conﬁguration experiments.These initial positions follow the
normal distribution and satisfy the initial observation of the
aforementioned POMDP(Block only the top critical point).
Where µ
·
,?
·
and B
·
are the mean, the standard deviation and
TABLE II
PARAMETERS FOR GENERATING THE INITIAL POSITION
case µ
x
?
x
B
x
µ
y
?
y
B
y
µ
z
?
z
B
z
1 10 3 [6,16] -14 3 [-21,-7] -29 1 >-40
2 10 3 [6,16] -7 3 [-13,-2] -29 1 >-32
the bounds of each variable. These points are also plotted
in Figure 6(b) and 8(b). After performing the above ofﬂine
optimizing process, the “adult” robot is able to teach the
“child” robot. The “adult” robot selects the action greedily
according to the one step look ahead algorithm and send it to
the “child” robot until the “child” robot reaches the desired
position.
3) Compliant Assembly: The “child” robot is prepro-
grammed with compliant assembly algorithm proposed by
Chen [14]. The assembly process is divided into three stages:
searching, insertion and settle-down. The controller searches
the hole position along a spiral curve with a 2mm search
radius and inserts the tool into the hole using a force control
method. Therefore, the goal of the robot teaching is to guide
the robot tool close enough to the target hole within the
accuracy of 2mm. A more accurate ﬁnal position will lead
to a more efﬁcient assembly process.
B. Experimental Results
1) Experiments with 5mm grid size: We ﬁrst tested the
policy generated using the 5mm grid size. The tool trajecto-
ries are plotted in Figure 6(a). The tool started from random
initial positions and was guided toward the target using the
learned primitive motions. In each step, the tool moved 5mm
along the selected moving direction. It took about 14 steps
for the “child” robot to arrive at the target location.
?5
0
5
10
15 ?20
?10
0
10
20
?35
?30
?25
?20
?15
?10
?5
0
y/mm
x/mm
z/mm
(a)
?5
0
5
10
15
20
?20
?15
?10
?5
0
5
?40
?30
?20
?10
0
 
y/mm
x/mm
 
z/mm
initial position
final position
(b)
Fig. 6. Experiments of the 5mm grid size. a) Two robot tool motion
trajectories. The diamond is the target position. b) Distribution of the initial
positions and ﬁnal positions.
Using randomly generated initial positions, we repeated
this process for 100 times. The initial and ﬁnal positions are
plotted in Figure 6(b). The “child” robot was successfully
guided to the target. However, since the grid size is 5mm,
the ﬁnal tool position has a 5mm variation along each axis.
The statistic results are listed in TABLE III where the case
1 is for 5mm grid conﬁguration and case 2 is for 2mm grid
conﬁguration.
TABLE III
STATISTICAL RESULTS OF THE FINAL ROBOT TOOL POSITION
case µ
x
?
x
µ
y
?
y
µ
z
?
z
1 -2.10 1.29 3.02 1.22 -3.42 1.41
2 -0.97 0.51 1.03 0.77 -1.01 0.52
During the teaching process, the “adult” robot updated
its belief state based on the action and observation. Figure
7 shows the maximus belief at each step. We can ﬁnd
that the belief is increasing when more and more actions-
observations are made.
2) Experiments with 2mm grid size: In order to improve
the teaching accuracy, we decreased the grid size from 5mm
to 2mm. And thus the system dimension has to be doubled to
covermostoftheinitialpositions.Figure8(a)showssomeof
the “child” robot tool trajectories. The “child” robot moved
about 25 steps to reach the target. We repeated this process
for 100 times and the initial and ﬁnal positions are plotted
in Figure 8(b).
4403
0 5 10 15 20 25
0
0.2
0.4
0.6
0.8
1
steps
max belief
 
 
5mm
2mm
Fig. 7. Maximum belief during the teaching process. Ideally the maximum
belief is nondecreasing. However, due to noises and errors, there is a sudden
drop in one of the maximum belief curve.
?2
0
2
4
6
8
10
12
14
15
?12
?10
?8
?6
?4
?2
0
2
?30
?25
?20
?15
?10
?5
0
y/mm
z/mm
x/mm
(a)
?2
0
2
4
6
8
10
12
14
16 ?15
?13
?11
?9
?7
?5
?3
?1
1
2
?40
?20
0
 
y/mm
x/mm
 
z/mm
initial position
final position
(b)
Fig. 8. Experiments of the 2mm grid size. a) Two robot tool motion
trajectories. The diamond is the target position. b) Distribution of the initial
positions and ﬁnal positions.
The statistical results of the ﬁnal position for 2mm grid
size is listed in TABLE III.
3) Discussion: According to the above results, small grid
size can achieve better accuracy. However, when the grid
size becomes smaller, it imposes strict computational and
accuracy requirements for the POMDP observation and state
transition model. If the real environment does not match
the model based on which the policy is generated, the
“adult” robot may not be able to ﬁnd any possible state,
i.e. ∑
s?S
b(s)=0, which contradicts with the deﬁnition of the
belief state and makes the algorithm fail. To deal with the
problem, we introduced? in the observation model (7). Once
a “wrong” observation is received, the maximum belief will
drop but the belief state still satisﬁes the deﬁnition. However,
utilizing a robust observation model and decreasing the grid
size to meet the accuracy requirements greatly increase the
computational complexity.
This work is an initial attempt to perform robot teach-
ing with a single uncalibrated camera. The experimental
results verify the effectiveness of the POMDP modeling
and SARSOP solving algorithm and also demonstrate that
the obtained optimal policy can deal with uncertainty and
gather useful information for decision making with limited
observations.
IV. CONCLUSION
This paper discusses the problem of robot teaching in un-
structured industrial robot applications using an uncalibrated
vision system. We propose to use a mobile “adult” robot
holdingacameratomovearoundandteachagroupofrobots
working in a production line. To eliminate the calibration
process and reduce the restrictions between the sensors and
robots, a POMDP is formulated to estimate the underlying
positionerrorsandmakedecisionsateachstep.Theprimitive
motionlearning,POMDPbasedofﬂinelearning,onlinerobot
teaching and compliant assembly subtasks are integrated
to accomplish a successful robot teaching and assembly
process. Experimental results show the effectiveness of the
proposed method in robot teaching using vision systems with
uncertainties. Because the calibration process is eliminated,
the ﬂexibility of the proposed method is greatly increased.
Hence it can be easily applied in industrial applications
where robot teaching is needed. The proposed method can
also be used for robot teaching using ﬁxed cameras on a
work station without calibration.
ACKNOWLEDGMENT
The research is partially sponsored by the Research En-
hance Program(REP). Grant No.9000000936, Texas State
University, San Marcos. And it is also partially sponsored
by the Startup Research Fund. Grant No.02090021233043,
Northeastern University, China.
REFERENCES
[1] C. Connolly, “Technology and applications of abb robotstudio,” In-
dustrial Robot: An International Journal, vol. 36, no. 6, pp. 540–545,
2009.
[2] A. Kundu, K. Krishna, and J. Sivaswamy, “Moving object detection
by multi-view geometric techniques from a single camera mounted
robot,” in Intelligent Robots and Systems, 2009. IROS 2009. IEEE/RSJ
International Conference on, oct. 2009, pp. 4306 –4312.
[3] G. Hu, W. MacKunis, N. Gans, W. Dixon, J. Chen, A. Behal, and
D. Dawson, “Homography-based visual servo control with imperfect
cameracalibration,”AutomaticControl,IEEETransactionson,vol.54,
no. 6, pp. 1318 –1324, june 2009.
[4] A. Davison, I. Reid, N. Molton, and O. Stasse, “Monoslam: Real-time
single camera slam,” Pattern Analysis and Machine Intelligence, IEEE
Transactions on, vol. 29, no. 6, pp. 1052 –1067, june 2007.
[5] T. Murao, H. Kawai, and M. Fujita, “Passivity-based control on
dynamicvisualfeedbacksystemswithmovablecameraconﬁguration,”
Electronics and Communications, vol. 92, no. 6, pp. 286–294, 2009.
[6] V. Lippiello, B. Siciliano, and L. Villani, “Eye-in-hand/eye-to-hand
multi-camera visual servoing,” in IEEE Conference on Decision and
Control, European Control Conference, dec. 2005, pp. 5354 – 5359.
[7] M. Marshall, M. Matthews, A.-P. Hu, G. McMurray, and H. Lipkin,
“Uncalibrated visual servoing for intuitive human guidance of robots,”
in Robotics and Automation (ICRA), 2012 IEEE International Confer-
ence on, may 2012, pp. 4463 –4468.
[8] P. Goncalves, L. Mendonca, J. Sousa, and J. Pinto, “Uncalibrated eye-
to-hand visual servoing using inverse fuzzy models,” Fuzzy Systems,
IEEE Transactions on, vol. 16, no. 2, pp. 341 –353, april 2008.
[9] G. Shani, J. Pineau, and R. Kaplow, “A survey of point-based pomdp
solvers,”VitalAndHealthStatistics.Series20DataFromTheNational
Vitalstatistics System Vital Health Stat 20 Data Natl Vital Sta, 2012.
[10] G. Wang, Q. Wu, and Z. Ji, “Pose estimation from circle or parallel
lines in a single image,” in Computer Vision C ACCV 2007, ser.
Lecture Notes in Computer Science, Y. Yagi, S. Kang, I. Kweon, and
H. Zha, Eds. Springer Berlin / Heidelberg, 2007, vol. 4844, pp.
363–372.
[11] J. Pineau, G. Gordon, and S. Thrun, “Point-based value iteration: An
anytime algorithm for pomdps,” 2003.
[12] T. Smith and R. Simmons, “Heuristic search value iteration for
pomdps,” in Proceedings of the 20th conference on Uncertainty in
artiﬁcialintelligence,ser.UAI’04. Arlington,Virginia,UnitedStates:
AUAI Press, 2004, pp. 520–527.
[13] H. Kurniawati, D. Hsu, and W. S. Lee, “Sarsop: Efﬁcient point-based
pomdp planning by approximating optimally reachable belief spaces,”
in In Proc. Robotics: Science and Systems, 2008.
[14] H. Chen, J. Wang, G. Zhang, and T. Fuhlbrigge, “Robotic soft servo
for industrial high precision assembly,” Assembly, pp. 24–29, 2008.
4404
