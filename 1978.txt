Physics-Aware Informative Coverage Planning for Autonomous Vehicles
Michael J. Kuhlman
1
, Student Member, IEEE, Petr

Svec
2
, Member, IEEE, Krishnanand N. Kaipa
2
,
Member, IEEE, Donald Sofge
3
, Member, IEEE, and Satyandra K. Gupta
4
, Senior Member, IEEE
Abstract? Unmanned vehicles are emerging as an attractive
tool for persistent monitoring tasks of a given area, but
need automated planning capabilities for effective unattended
deployment. Such an automated planner needs to generate
collision-free coverage paths by steering waypoints to locations
that both minimize the path length and maximize the amount of
information gathered along the path. The approach presented
in this paper signicantly extends prior work and handles
motion uncertainty of an unmanned vehicle and the presence of
obstacles by using a Markov Decision Process based approach
to generate collision-free paths. Simulation results show that the
proposed approach is robust to signicant motion uncertainties
and reduces the probability of collision with obstacles in the
environment.
I. INTRODUCTION
There are many applications that need persistent monitor-
ing of a given area, requiring repeated travel over the area to
gather new information. Unmanned vehicles are well-suited
for performing such tasks, but require automated planning.
Moreover, certain locations in the area are designated as key
locations and hence are more valuable from the information
gathering perspective. Surveillance platforms in persistent
monitoring tasks vary from aerial vehicles to surface vehicles
(e.g., boats) depending upon the application.
Consider the use of an unmanned surface vehicle (USV)
conducting harbor patrols to detect intruders. It is reasonable
to assume that possible intruders will enter the harbor (Fig.
1(a)) from certain locations such as harbor entrances and
shipping channels. This suggests the use of an ?information
value map? (see Fig. 1(b)) that signies how some regions
are more dynamic or interesting and should be observed more
often. Though the underlying technical approach developed
in this paper is intended for application to USV harbor
patrolling, it is applicable to many different domains.
The problem of traveling over an area and gathering
information can be viewed as a coverage planning problem
[1]. There are many practical and theoretical challenges in
solving the coverage planning problem in the context of
1
M.J. Kuhlman is with the Department of Electrical and Computer
Engineering, University of Maryland, College Park, MD 20742, USA
and the Laboratory for Autonomous Systems Research, Naval Research
Laboratory, Washington, DC 20375, USA mkuhlman@umd.edu
2
P.

Svec and K.N. Kaipa are with the Department of Mechanical
Engineering, University of Maryland, College Park, MD 20742, USA
fpetrsvec,kkrishnag@umd.edu
3
D. Sofge is with Navy Center for Applied Research in Articial
Intelligence, Naval Research Laboratory, Washington, DC 20375, USA
donald.sofge@nrl.navy.mil
4
S.K. Gupta is with the Department of Mechanical Engineering and
Institute for Systems Research, University of Maryland, College Park, MD
20742, USA skgupta@umd.edu
Fig. 1. (a) An example of a harbor patrol environment with multiple entry
points for intruders (A harbor in Hollywood, FL; source: Map data c 2013
Google). (b) Obstacle regions (black) and the ?information value? map
.
regions of varying information value. It is possible for static
obstacles to exist around the harbor, such as shoals. Further,
windy conditions or swift currents can contribute signicant
uncertainty to the USV's location and motion, compounding
the problem. This suggests using a physics-aware planner
that is capable of planning under motion uncertainty while
avoiding obstacles in the environment.
We begin with a short review of existing techniques for
informative path planning for coverage planning problems.
Branch and bound search was used in [2] to maximize the
?informativeness? of a plan. In [3], Fisher information matri-
ces, combined with rapidly-exploring random trees (RRTs),
was used for information-rich path planning.
Persistent sensing approaches [4] model the information
uncertainty in the environment as a eld dened over a set
of locations and assume that the eld increases linearly at
locations beyond the sensing range of the robot and decreases
linearly at locations within the robot's range. Control-based
approaches involving locational optimization include [5]?
[7]. There also exist information-theoretic approaches that
specify which areas are of interest and attempt to maximize
the informativeness of a plan. In [8], agents followed the
gradient of mutual information to minimize total entropy. In
[9], a data structure called a probabilistic quad tree was pro-
posed and used to provide a tree structure to the total entropy
in the environment during target search. Other examples of
information-theoretic coverage planning work include [10],
[11]. Another approach to solve the problem of interest is
direct planning using graph search. Conceptually, one could
pick areas of interest in the environment and nd the optimal
path connecting xed nodes, which is equivalent to solving
the Traveling Salesman Problem (TSP). While TSP is an
NP-complete problem, many approximate solutions exist and
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 4741
10 20 30 40
10
20
30
40
(a) Initial conguration.
10 20 30 40
10
20
30
40
(b) Iteration 50: obstacle free dy-
namics.
10 20 30 40
10
20
30
40
(c) Iteration 431: end of obstacle
free dynamics.
10 20 30 40
10
20
30
40
(d) Proposed modication.
Fig. 2. An example simulation of the proposed algorithm for generating
collision-free informative paths under motion uncertainty. The background
colors indicate the sensor function, connected black ?x's? the waypoints,
and the black cells are (impassable) obstacles.
have been used in path planning [12].
After analyzing direct planning approaches, we noticed
several challenges associated with them. The nodes need
not necessarily be xed in place, which is a common as-
sumption for search problems; new information coming from
sensors could update the node locations as areas become
no longer interesting while persistently monitoring an area.
Alternatively, the traversal cost to reach a node could be
discovered to be prohibitive, yet a nearby location could be
reached to gather sufcient information while maintaining
lower path traversal cost. All these factors point to challenges
in selecting xed locations to visit without considering the
path length/information gain trade-off.
We believe that a more continuous, online update policy
that also allows the locations of nodes to change in Euclidean
space is preferable in our application. In fact, this approach
was used in the work by Soltero et al. [5] and our work in
this paper is inspired by their approach. We extend their
approach by developing a waypoint feedback policy that
morphs the informative coverage plan to: (1) minimize ex-
pected path traversal cost, accounting for motion uncertainty
and presence of obstacles, and (2) maximize information
gathered along the path. We formulate the problem using
a Markov Decision Process (MDP) based approach (See
Section II-A, [13], [14]). Paths generated using this approach
can be executed on autonomous unmanned surface vehicles
described in our prior work [15].
II. PROBLEM FORMULATION & APPROACH
In this section we describe an approach for computing
an informative coverage path for a vehicle operating in an
environment with static obstacles and motion uncertainty. Let
X =f(x;y)gR
2
be the continuous state space. LetX
d
=
f(x
i
;y
i
)gX be the nite, discrete regular grid. LetE =
(;O) be the environment, where :X!R
+
is the sensor
function that assigns the density of information in each state,
andOX
d
is the set of states occupied by obstacles. Let
 =fp
i
g
N
i=1
 X be the informative coverage path that
consists of a sequence ofN waypoints. Finally, since this is
a persistent monitoring task, we assume that  is a closed
path, where i =N + 1 is identied with i = 1.
The task is to update by steering waypoints to locations
that both minimize path costs (e.g., sum of path lengths
between neighboring waypoints) and maximize the amount
of information gathered along the path. These competing
objectives are formulated as a single-objective optimization
problem in Section II-B and is similar to the approach
proposed in [5]. However, we extend the previously used
notion of minimizing path length to factor motion uncertainty
and the presence of obstacles by minimizing expected path
traversal cost. Generating a single path is not sufcient to
account for motion uncertainty. Since the vehicle can deviate
from a planned path during execution, use of a feedback plan
which consists of a collection of state action pairs (x
i
;u
i
)
is needed for each x
i
2X
d
.
We have formulated a Markov Decision Process (MDP)
problem for each waypoint so the vehicle generates collision
free feedback plans to traverse from waypoint to waypoint
and can predict expected path traversal costs (see Section II-
A). The MDP problem is solved using the probabilistic value
iteration [13] and its solution (value function and feedback
plan) is directly integrated into the coverage plan using the
proposed algorithm outlined in Section II-C. Analysis in Sec-
tion IV shows that this modication to the waypoint steering
algorithm reduces the probability of collision while executing
the coverage plan compared to previous informative coverage
planning algorithms.
A. Markov Decision Process Formulation
A Markov Decision Process (MDP) is dened as the
following tuple MDP = (X
d
;U
d
; ;L;X
goal
) [13]. The
state space of the MDP is the regular grid X
d
 R
2
,
where X
goal
 X
d
is a collection of goal states. Let the
vehicle's action space be U
d
= f 1; 0; 1gf 1; 0; 1g,
which are the free choices the vehicle can make when
moving inX
d
. However, we assume that there is uncertainty
in the vehicle's state transitions. Given time indexk, nature's
actions on the system state 
k
are dened such that the
vehicle's state transitions satisfy x
k+1
=x
k
+
k
. Here, 
k
is a random variable that is drawn from the sample space

k
= (x
k
;u
k
) (see Fig. 3). The probabilities of nature's
actions on the system state are dened as Pr[
k
jx
k
;u
k
].
L = L(x;u;;O) is the cost functional for transitioning
between states, which also encodes the position of obstacles
4742
x
k
x
k
0.2
0.6
0.2 0.2
0.6
0.2
x
k+1
u
k
?
k
(x
k
,u
k
)
?
k
Fig. 3. A graphical depiction of possible state transitions fromx
k
tox
k+1
conditioned on the control actionu
k
. Each
k
2 (x
k
;u
k
) has an assigned
probability. Note that u and  need not reside within the same space.
by assigning innite cost to movements that cause the vehicle
to collide with obstacles.
Probabilistic Backwards Value Iteration (PBVI) is used to
solve the MDP to generate the value function (expected path
traversal cost-to-go)  : X
d
! R
+
and optimal feedback
plan  : X
d
! U
d
[13]. In short, denote PBVI : MDP7!
(;), where  satises the Bellman equation (1).
(x) = min
u2U
E

[L(x;u;;O) + (x +(x;u))] (1)
In (1), (x) is minimized if the feedback planu =(x) is
executed. Assuming L is positive denite and deterministic
(independent of nature's action, i.e., L = L(x;(x);O) >
0), it holds that (x
k
) =L(x
k
;(x
k
)) +E

k
[(x
k
+
k
)],
or more importantly
E

k
[(x
k+1
)]< (x
k
) (2)
B. Objective Function and Waypoint Location Optimization
LetH be the single objective function dened in (3). The
goal is to compute a waypoint-steering feedback policy _ p
i
=
u
i
that minimizesH.
H =
n
X
i=1
Z
Vi
W
s
2
jjq p
i
jj
2
(q)dq (3)
+
n
X
i=1
W
g
2
[(
pi 1
(p
i
))
2
+ (
pi+1
(p
i
))
2
]
Here,W
s
andW
g
reect the tradeoff between the compet-
ing objectives of steering waypoints to informative regions
vs. reducing path length. Further,V
i
is the V oronoi partition
of waypointp
i
. V oronoi partitions have been frequently used
in similar locational optimization problems [6], [16], [17]. (3)
is similar to the Lyapunov-like function candidate found in
[5], excluding the adaptation parameter.
The best physical interpretation ofH is that it denes a
spring-like potential energy so that virtual springs connect
neighboring waypoints. Similarly, virtual springs connect
waypoints to the informative center of mass of its respective
V oronoi partition. Standard gradient descent technique can-
not be used to locally minimize (3) due to the construction
of . Hence, we propose using the following continuous
feedback policy (4):
_ p
i
=u
i
=
K
i

i
[W
s
M
Vi
e
i
+W
g
(
pi 1
(p
i
))
^
h
pi 1
(p
i
) (4)
+W
g
(
pi+1
(p
i
))
^
h
pi+1
(p
i
)]
Here, M
Vi
=
R
Vi
W
s
(q)dq is the mass of the V oronoi
partition V
i
using the sensor function  as the density
function.e
i
=C
Vi
 p
i
is the vector difference of the V oronoi
partition centroid and the waypoint p
i
. C
Vi
=
L
V
i
M
V
i
, where
L
Vi
=
R
Vi
W
s
q(q)dq is the rst moment. The integrals
dened over the V oronoi partitions (e.g., M
Vi
and C
Vi
)
are well approximated by the Riemann sum of points on
the regular grid X
d
. The V oronoi partitions were therefore
approximated by calculating the nearest waypoint (i.e., the
nearest neighbor) of each x 2 X
d
using the k-nearest-
neighbor (KNN) algorithm. K
i
is a positive gain constant.
Also note that 
i
= M
Vi
+ 2W
g
is a normalization
parameter, and
^
h
pj
(p
i
) is the descent direction of 
pj
. (4)
has the property that if
^
h
pj
(p
i
) = r
pj
(p
i
) then (4) is
equivalent to normalized gradient descent ofH (3).
When computing
@
@pi
(
pj
(p
i
))
2
in (4), it is assumed
that the subscript p
j
is xed and hence
@
@pi
(
pj
(p
i
))
2
=
(2
pj
(p
i
))r
pj
(p
i
). Also, we assume
@
@pj
(
pj
(p
i
)) = 0
which explains the use of two terms in (3). The gradient
r
pj
is not well dened since the domain of  is X
d
.
Instead of using gradient descent, we will dene a descent
direction
^
h by averaging all possible outcomes  when
executing the feedback plan. It is reasonable to use either
the mode (5) or expected value (6):
^
h(x) :=
^
h
mode
(x) = arg max
2
Pr[jx;(x)] (5)
^
h(x) :=
^
h
mean
(x) =E[jx;(x)] (6)
However, verifying the desirable identity 
pj
(p
i
+
^
h)
?


pj
(p
i
) with  2 (0; 1] is a difcult task since  is
not convex with obstacles present. For example, we can-
not invoke Jensen's inequality to show that, for example,
(E[x + ])
?
 E[(x + )] < (x). It is possible to
construct (perhaps pathological) counter examples where this
desired inequality fails to hold. When calculating the descent
direction
^
h, bilinear spline interpolation is used.
C. Proposed Algorithm
A direct execution of the waypoint feedback policy in (4),
denoted as ICPS MDP algorithm, results in a rubber-band
like contraction of the waypoints wrapping around obstacles,
with ?attractor springs? pulling waypoints to the informative
regions. To avoid local minima, obstacles are ignored during
the computation of an initial informative coverage path. The
algorithm considers obstacles in later planning stages during
which it repairs the portions of the path that are invalidated
by the obstacles, and optimizes the path with respect to
the environmental effects that cause uncertainty in robot's
motion.
4743
Algorithm 1 COMPUTEINFORMATIVEPATH(X
d
;O;)
Require: A discrete grid X
d
, an obstacle regionO X
d
, and a
sensor function .
Ensure: An informative coverage path .
1: Run informative path shaping algorithm ICPS(X
d
;) [5] to
compute an informative coverage path that ignores obstacles
O.
2: Run FINDCOLLISIONFREEWAYPOINTS(,O) to nd collision-
free neighboring waypoints of the waypoints that are insideO.
3: Run the PBVI algorithm [13] to compute (p
i
;p
i
) of each
waypoint pi2. Update the informative coverage path  be-
tweenpi and its predecessorpi 1 and add additional waypoints
along the mode path connecting pi and pi 1.
4: Run ELIMINATEWAYPOINTS(;) to remove redundant (too
close to other waypoints) or uninteresting waypoints (cover a
region of the environment where little information is present).
5: Run ICPS MDP(;) algorithm to smooth the informative
coverage path.
6: Run ELIMINATEWAYPOINTS(;) to remove redundant or
uninteresting waypoints.
7: Run ICPS MDP(;) algorithm to smooth the informative
coverage path.
8: return .
Algorithm 2 ICPS MDP(;)
Require: An informative coverage path and a sensor function.
Ensure: An informative coverage path .
1: whilejjujj> do
2: for all pi2 do
3: Compute V oronoi-like partition Vi using k-nearest-
neighbor (KNN) algorithm for pi.
4: Run PBVI to generate (p
i
;p
i
).
5: Integrate the system dynamics of _ pi =ui =f(pi) using
(4) and the Euler approximation [13], i.e.p
k+1;i
=p
k;i
+
u
k;i
 t
k
6: end for
7: k k + 1
8: end while
9: return 
Coverage plan  is executed by starting at one waypoint
p
i 1
, and using the feedback plan 
pi
. Once the vehicle
reaches the goal state ofp
i
, then the planner follows the next
waypoint feedback plan
pi+1
. It is important to note that for
Alg. 4, waypoint statistics are correlated with their neighbors,
so eliminating too many waypoints at once may cause entire
sections of the path to disappear. We also typically assume
that q =r.
D. Calculating Plan Execution Success Probabilities
Calculating the probability of collision while executing
coverage plan  is a nontrivial task, because all possible
trajectories leaving from one waypoint p
i
to get to the next
waypoint p
i+1
must be considered. Given the MDP and its
solution, we dene a Markov Chain MC = (X
d
;T ) on X
d
with transition probabilities given by (x;(x)), dening
state transition matrix T = [T
i;j
], where T
i;j
= Pr[x
k+1
=
jjx
k
=i]. We further assume that  satises the property
that if x
i
2O[X
goal
, then T
i;j
= 
ij
, where 
ij
is the
Kronecker delta function. In other words, vehicles that enter
goal or obstacle locations are forever trapped. The stationary
Algorithm 3 FINDCOLLISIONFREEWAYPOINTS(;O)
Require: An informative coverage path , and an obstacle region
OX
d
.
Ensure: An informative coverage path .
1: ComputeOD by dilatingO using the convolution mask 133,
or a 3 3 matrix of ones.
2: for all pi2 do
3: if pi2OD then
4: Eliminate pi if the local direction of  does not change
more than 5 degrees, i.e., ifjij < 5

. Here cosi =
~ p
i+1;i 1
~ p
i;i 1
jj~ p
i+1;i 1
jjjj~ p
i;i 1
jj
and ~ p
i;j
= pi  pj is the vector
difference of pj and pi.
5: else
6: if9 an adjacent waypoint pj62OD then
7: Apply a variant of the bisection numerical method to
pushpi along the line segmentpi;pj the minimum dis-
tance untilpi62OD , or the length of the segment being
divided decreases below a user-specied threshold.
8: else
9: Search for a waypoint pj 62OD along the line seg-
ments pi;pi 1 and pi;pi+1 using the Van Der Corput
sequence [13] until the rst pj 62 OD is found or
the mesh of points searched decreases below a user-
specied threshold.
10: end if
11: if pj62OD is not found then
12: Eliminate pi.
13: end if
14: end if
15: end for
16: return .
Algorithm 4 ELIMINATEWAYPOINTS(;)
Require: An informative coverage path and a sensor function.
Ensure: An informative coverage path .
1: Calculate mass and area of each waypoint's pi2  V oronoi
partition [13] with respect to the sensor function .
2: Select q;r2f0; 1; 2;:::;jj  1g.
3: Sort the waypoints of the informative coverage path  in
ascending order with respect to their associated mass and area.
4: Keep any waypoint that exceeds theq
th
order mass statistic and
the r
th
order area statistic.
5: return .
distribution Y of T (satisfying Y = YT ) can be used to
calculate the probability of success of a coverage plan being
executed.Y is a probability mass function in the belief space
of X
d
, i.e., Y
(i)
= Pr[X =x
i
]8x
i
2X
d
. The eventfx
i
2
Og denotes that a collision occurred, while the eventfx
i
2
X
goal
g denotes a successful arrival at the goal waypoint.
GivenY , the probabilities of these events can be calculated.
We approximateY numerically by executing the xed point
method Y
k+1
= Y
k
T until it converges (T is sparse). Note
thatY exists but is not necessarily unique. However, we are
most concerned with the limiting distribution Y when Y
0
is
a delta distribution centered at the previous waypoint. P
(i)
succ
is the probability of reachingp
i+1
fromp
i
without collision
and P
succ
is the probability of successfully executing the
coverage plan , i.e., P
succ
=
Q
N
i=1
P
(i)
succ
.
4744
III. EXPERIMENTAL SETUP
A set of three distinct environments were created: ?Gaus-
sian bump grid?E
1
(see Fig. 2 and Fig. 4), ?trail fork?E
2
(see Fig. 5), and ?barricaded hot spots? E
3
(see Fig. 5).
These environments were augmented by inclusion of a wind
gust occupancy grid
~
E =Em = (;O;m) [18], where
m is a collection of Bernoulli random variables that dene
the probability of a gust of wind occurring from the north
(in the x direction) in a particular cell. In other words,
x
i
2 X
d
is assigned a particular m
i
2 m. We assume
that Pr[
k
jx
k
;u
k
;m
k
] can be more readily dened, and m
k
can be marginalized out yielding (x
k
;u
k
) using the law of
total probability (the distribution of m is given). This allows
us to localize the locations of high probability wind gusts
to particular regions in the environment, highlighting that
this induces local effects in the informative plan. For each
environment,E
a
,a2f1; 2; 3g, two different occupancy grids
m
0
and m
a
were used, yielding a total of 6 simulations
using augmented environments. In other words, the 6 envi-
ronments tested weref(E
a
;m
0
)g[f(E
a
;m
a
)g. Here, m
0
is
a uniform low probability wind gust occupancy grid, where
Pr[m
i
= 1] = 0:18i, and m
a
was tailored for its respective
environmentE
a
to have high probability wind gust regions
properly located to attempt to blow the vehicle into a given
obstacle.
To ease visualization purposes, Pr[m
i
= 1] is constrained
to be either 0.1 or 1. The locations where Pr[m
i
= 1] = 1 are
denoted by a green downward pointing triangle to indicate
the direction the wind is blowing.
For all simulation runs, the descent direction
^
h =
^
h
mode
was selected (5). Apart from the environment, simulation
parameters for all runs were identical, including the ini-
tial waypoint selection in Fig. 2(a). Obstacles were con-
structed such that even after obstacle dilation, the free space
X
D;free
=X
d
nO
D
remains fully connected.
IV. SIMULATION RESULTS
After executing the proposed algorithm, the resulting
locations of the waypoints for the environments ?Gaussian
bump grid? is shown in Fig. 4, while both ?trail fork? and
?barricaded hot spots? are in Fig. 5. The coordinate frame
follows the North-East-Down (NED) convention.
One important performance metric previously unspecied
in the informative path planning literature is the probability
of path execution success (conversely, probability of obstacle
collision during path execution) while executing the feedback
plans to traverse between waypoints. For each simulation, we
compare the vehicle's probability of success while executing
the specied coverage plan. We compare the waypoints
selected using the original algorithm ICPS proposed in [5]
to the ICPS MDP algorithm. Note that ICPS is a part of
ICPS MDP, so the coverage plans generated by the original
algorithm are shown in Figs. 4(a), 5(a), and 5(b). Since the
original ICPS algorithm has no knowledge of obstacles in
the environment, waypoints inside obstacles are eliminated,
and MDP-based feedback plans are generated to steer the
EAST (y) [m]
NORTH (x) [m]
10 20 30 40
10
20
30
40
(a) Waypoint locations after exe-
cuting ICPS.
(b) Wind blowing from north to
south.
Fig. 4. ?Gaussian bump grid? environment simulation results. This is the
same environment as shown in Fig. 2, contrasting the ICPS and ICPS MDP
simulation results. Notice here that the north wind present in the bottom
right in 4(b) causes the vehicle to move waypoints upwind to reduce the
probability of collision.
vehicle around obstacles when computing plan execution
success probabilities.
To test the robustness of the coverage plan, we also
incorporate uncertainty into the planner's estimate of 
so there is a mismatch between the environment and the
planner's model of the environment. We dene a new wind
occupancy grid whose parameters are a mixture distribution
of the true occupancy grid, and uniform noise: Pr[ ^ m
i
= 1] =
Pr[m
i
= 1] + (1 )
i
, where
i
is a continuous R.V . s.t.

i
Unif(0; 1) and we set  = 0:5.
Twenty wind occupancy grids ^ m for each simulation result
were drawn from 
i
, and success probability statistics were
calculated in Table I.
Trial wind 1) Gauss. 2) Trail 3) Hot
ICPS [5] [Psucc: ] high 88% 89% 95%
ICPS [5] [] high 0.027 0.019 0.016
ICPS MDP [Psucc: ] high 99.9% 94% 98%
ICPS MDP [] high 0.0013 0.019 0.0043
ICP [5] [Psucc: ] low 100% 100% 99.6%
ICP [5] [] low 10
 9
10
 9
0.014
ICPS MDP [Psucc: ] low 100% 100% 100%
ICPS MDP [] low 10
 15
10
 9
10
 13
TABLE I
PLAN EXECUTION SUCCESS PROBABILITIES FOR THE ENVIRONMENTS.
V. CONCLUSIONS
In this paper, we have introduced a planning algorithm
for computation of informative coverage plans for persistent
monitoring tasks with static obstacles. The algorithm morphs
an initial informative coverage path towards regions with
high information value, while avoiding obstacles and explic-
itly considering environmental effects that cause uncertainty
in a vehicle's motion. Simulation results show that the
proposed algorithm is robust to motion uncertainties and
hence reduces the probability of collision with obstacles in
the environment.
In future work, positioning uncertainty stemming from
sensor inaccuracies can be modeled by using a Partially
Observable MDP [18]. For this work, the sensor function
has been given a priori as a part of the environment. The
4745
EAST (y) [m]
NORTH (x) [m]
10 20 30 40
10
20
30
40
(a) ?Trail fork?: waypoint loca-
tions after executing ICPS.
EAST (y) [m]
NORTH (x) [m]
10 20 30 40
10
20
30
40
(b) ?Hot spots?: waypoint loca-
tions after executing ICPS.
EAST (y) [m]
NORTH (x) [m]
10 20 30 40
10
20
30
40
(c) ?Trail fork?: low occurrence of
wind.
EAST (y) [m]
NORTH (x) [m]
10 20 30 40
10
20
30
40
(d) ?Hot spots?: low occurrence of
wind.
EAST (y) [m]
NORTH (x) [m]
10 20 30 40
10
20
30
40
(e) ?Trail fork?: wind blowing
from north to south.
EAST (y) [m]
NORTH (x) [m]
10 20 30 40
10
20
30
40
(f) ?Hot spots?: wind blowing
from north to south.
Fig. 5. For ?Trail fork? simulation results: the waypoints near the wind
eld in the top right corner seems to work correctly and are pushed to the
wind gust boundary. Otherwise, wind effects seem to be negligible in this
environment. However, the planner does not seem to have larger clearances
for the lower obstacles. For ?Barricaded hot spots? simulation results: notice
what appears to be an extraneous traversal into the region in the top right of
both gures. This could be a consequence of the relative weightingWs ,Wg
of costs in (3). A further improvement of waypoint elimination heuristics
could reduce the number of waypoints in the bottleneck.
characterization of relevant sensor functions using onboard,
possibly noisy sensors selected for a particular mission
deserves further study.
ACKNOWLEDGMENTS
This work was performed in part at the Naval Re-
search Laboratory and was funded by the US Department
of Defense, Ofce of Naval Research, under grant num-
ber N0001413WX21045, Mobile Autonomous Navy Teams
for Information Surveillance and Search (MANTISS). S.K.
Gupta's participation in this research was supported by
National Science Foundation's Independent Research and
Development program. The authors would like to thank Keith
Sullivan and Thomas Apker at NRL for their insights, the
rest of the Laboratory for Autonomous Systems Research at
NRL, and the rest of the Simulation-Based System Design
Laboratory at UMD.
REFERENCES
[1] H. Choset, ?Coverage for Robotics - a Survey of Recent Results,?
Annals of Mathematics and Articial Intelligence, vol. 31, no. 1-4,
pp. 113?126, 2001.
[2] J. Binney and G. S. Sukhatme, ?Branch and Bound for Informative
Path Planning,? in IEEE International Conference on Robotics and
Automation (ICRA), 2012. IEEE, Saint Paul, MN, May 14-18, 2012,
pp. 2147?2154.
[3] D. Levine, B. Luders, and J. P. How, ?Information-Rich Path Planning
with General Constraints Using Rapidly-Exploring Random Trees,? in
AIAA Infotech Aerospace Conference, Atlanta, GA, 2010.
[4] S. Smith, M. Schwager, and D. Rus, ?Persistent Robotic Tasks: Mon-
itoring and Sweeping in Changing Environments,? IEEE Transactions
on Robotics, vol. 28, no. 2, pp. 410?426, 2012.
[5] D. E. Soltero, M. Schwager, and D. Rus, ?Generating Informative
Paths for Persistent Sensing in Unknown Environments,? in IEEE/RSJ
International Conference on Intelligent Robots and Systems (IROS),
2012. IEEE, Vilamoura, Algarve, October 7-12, 2012, pp. 2172?
2179.
[6] J. Cortes, S. Martinez, T. Karatas, and F. Bullo, ?Coverage Control
for Mobile Sensing Networks,? IEEE Transactions on Robotics and
Automation, vol. 20, no. 2, pp. 243?255, 2004.
[7] R. Graham and J. Cort« es, ?Adaptive Information Collection by Robotic
Sensor Networks for Spatial Estimation,? IEEE Transactions on Au-
tomatic Control, vol. 57, no. 6, pp. 1404?1419, 2012.
[8] B. J. Julian, M. Angermann, M. Schwager, and D. Rus, ?Distributed
Robotic Sensor Networks: An Information Theoretic Approach,? The
International Journal of Robotics Research, vol. 31, no. 10, pp. 1134?
1154, 2012.
[9] S. Carpin, D. Burch, and T. H. Chung, ?Searching for Multiple Targets
Using Probabilistic Quadtrees,? in IEEE/RSJ International Conference
on Intelligent Robots and Systems (IROS), 2011. IEEE, San Francisco,
CA, September, 25-30, 2011, pp. 4536?4543.
[10] G. Hollinger and S. Singh, ?Multi-Robot Coordination with Periodic
Connectivity,? in IEEE International Conference on Robotics and
Automation (ICRA), 2010. IEEE, Anchorage, AK, May 3-7, 2010,
pp. 4457?4462.
[11] A. Singh, A. Krause, C. Guestrin, and W. J. Kaiser, ?Efcient
Informative Sensing Using Multiple Robots,? Journal of Articial
Intelligence Research, vol. 34, no. 2, p. 707, 2009.
[12] C. T. Cunningham and R. S. Roberts, ?An Adaptive Path Planning
Algorithm for Cooperating Unmanned Air Vehicles,? in IEEE Inter-
national Conference on Robotics and Automation (ICRA), 2001, vol. 4.
IEEE, 2001, pp. 3981?3986.
[13] S. M. LaValle, Planning Algorithms. Cambridge University Press,
2006.
[14] A. Thakur, P. Svec, and S. K. Gupta, ?GPU Based Generation of
State Transition Models Using Simulations for Unmanned Sea Surface
Vehicle Trajectory Planning,? Robotics and Autonomous Systems,
V ol. 60, no. 12, pp. 1457?1471, 2012.
[15] P.

Svec, B. C. Shah, I. R. Bertaska, J. Alvarez, A. J. Sinisterra, K. von
Ellenrieder, M. Dhanak, and S. K. Gupta, ?Dynamics-Aware Target
Following for an Autonomous Surface Vehicle Operating Under COL-
REGS in Civilian Trafc,? in IEEE/RSJ International Conference on
Intelligent Robots and Systems (IROS'13), Tokyo, Japan, November
3-7, 2013, pp. 3871?3878.
[16] S. Salapaka, A. Khalak, and M. Dahleh, ?Constraints on Locational
Optimization Problems,? in IEEE Conference on Decision and Control
(CDC), 2003, vol. 2. IEEE, Maui, HI, December 9-12, 2003, pp.
1741?1746.
[17] L. C. Pimenta, M. Schwager, Q. Lindsey, V . Kumar, D. Rus, R. C.
Mesquita, and G. A. Pereira, ?Simultaneous Coverage and Tracking
(SCAT) of Moving Targets with Robot Networks,? in Algorithmic
Foundation of Robotics VIII. Springer, 2009, pp. 85?99.
[18] S. Thrun, W. Burgard, D. Fox et al., Probabilistic Robotics. MIT
Press Cambridge, 2005, vol. 1.
4746
