  
limin1985 
? 
Abstract— Current surgical tele-manipulators do not provide 
explicit haptic feedback during soft tissue palpation. Haptic 
information could improve the clinical outcomes significantly 
and help to detect hard inclusions within soft-tissue organs 
indicating potential abnormalities. However, system instability 
is often caught by direct force feedback. In this paper, a new 
approach to intra-operative tumor localization is introduced. A 
virtual-environment tissue model is created based on the 
reconstructed surface of a soft-tissue organ using a Kinect 
depth sensor and the organ’s stiffness distribution acquired 
during rolling indentation measurements. Palpation applied to 
this tissue model is haptically fed back to the user. In contrast to 
previous work, our method avoids the control issues inherent to 
systems that provide direct force feedback. We demonstrate the 
feasibility of this method by evaluating the performance of our 
tumor localization method on a soft tissue phantom containing 
buried stiff nodules. Results show that participants can identify 
the embedded tumors; the proposed method performed nearly 
as well as manual palpation.  
I. INTRODUCTION 
Palpation is a process where a clinician examines soft 
tissue organs during open surgery with their fingers to detect 
abnormalities beneath the surface [1]. Intra-operative 
palpation is a widely-used procedure to identify abnormal 
tissue regions [2]. Information of spatially distributed tissue 
stiffness is essential for palpation. Areas that are stiffer than 
the surrounding tissue are recognized as possible tumors [3]. 
During open surgery, which is carried out using a single 
large incision, intra-operative palpation is easily conducted 
by the surgeons using their hands. Robot-assisted Minimally 
Invasive Surgery (RMIS) has been widely applied in recent 
years. However, the physical contact between the surgeon 
and the soft tissue is cut off, which makes palpation and 
tumor identification difficult [4].  
Providing direct force feedback enables palpation via a 
surgical tele-manipulator [5]. However, most existing robotic 
surgical systems, such as da Vinci and Titan Medical 
Amadeus, do not provide haptic feedback. Only DLR 
(German Aerospace Center) has created a 7 DOF robotic 
system for surgery providing bimanual force feedback and 
 
M. Li, A. Faragasso, J. Konstantinova, V. Aminzadeh, L. D. Seneviratne 
and K. Althoefer are with the Department of  Informatics, Kings College 
London, U.K. ( e-mail: {min.m.li; angela.faragasso; jelizaveta.zirjakova; 
vahid.aminzadeh; lakmal.seneviratne; k.althoefer}@kcl.ac.uk). 
 L. D. Seneviratne is with College of Engineering, Khalifa University of 
Science, Technology and Research, Abu Dhabi, U.A.E. (e-mail: 
lakmal.seneviratne@kustar.ac.ae). 
P. Dasgupta is with MRC Centre for Transplantation, DTIMB and 
NIHR BRC, King’s College London (e-mail: prokar.dasgupta@kcl.ac.uk). 
3D vision [6]. Two input devices Sigma.7 are used at the 
master side for manipulation and force feedback. Bilateral 
tele-operation controllers are popular in multi-DOF haptic 
feedback surgery robot research [5], [7]. This approach 
makes use of a four-channel architecture for tele-operation 
control considering forces both from the master and slave, as 
well as the position difference between the master and the 
slave. However, with the increase of the system’s 
transparency, instability caused by jitters generated from 
small delays and errors in the system often leads to 
unacceptable oscillation at the master and the slave side 
during surgery. The trade-off between transparency 
(matching level of the feedback forces and the forces applied 
at the tool tip) and system stability is a limitation of direct 
force feedback [8].  
Alternatively, a graphical display of the organ’s stiffness 
distribution can be used to show the locations of tumors to 
surgeons [9-11]. Liu et al. [9] proposed a rolling indentation 
tissue probing approach to localize abnormalities during 
MIS; the stiffness distribution map of a soft tissue surface 
can be generated by exposing the tissue surface to 
continuous rolling indentation using a force-sensitive 
wheeled probe. However, a disadvantage of this method is 
that the colors of the resultant stiffness maps can only 
represent relative stiffness values [11]. Even if the magnitude 
of stiffness were provided, it is still difficult for surgeons to 
form an impression of the actual tissue stiffness at different 
points of the organ.  
Commonly, palpation simulators provide graphical 
feedback of the deformable tissue through computer graphics 
and force feedback via a haptic device. To generate haptic 
cues of virtual objects, motion tracking, collision detection 
between the virtual fingertip and the virtual objects, 
calculation of the reaction forces are required; relaying the 
resultant reaction forces to the user closes the loop to 
achieve a complete haptic feedback system. A deformable 
soft tissue model is often used to concurrently compute 
tissue deformation and reaction forces as a function of 
indentation depth and palpation velocity. Mahvash et al. [12] 
pointed out that if real-time intra-operative tissue models can 
be created, a force display could be based on this model 
rather than the on-line measured force. Thus, haptic 
palpation in RMIS can benefit from palpation simulation 
systems. There are some early attempts applying palpation 
simulation to intra-operative soft tissue tumor localization in 
RMIS by using estimated soft tissue parameters. For 
example, Khaled et al. [13] reconstructed virtual objects 
based on the results of real-time ultrasound elastography.  
A Novel Tumor Localization Method using Haptic Palpation Based 
on Soft Tissue Probing Data 
Min Li, Angela Faragasso, Jelizavata Konstantinova, Vahid Aminzadeh, Lakmal D. Seneviratne, 
Member, IEEE, Prokar Dasgupta, Kaspar Althoefer, Member, IEEE 
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 4188
  
In this paper, a novel tumor localization method 
providing force feedback utilizing real-time tissue models is 
introduced and validated. A tissue model is created in a 
virtual environment based on the reconstructed surface 
obtained using a Kinect depth sensor and the model’s 
stiffness distribution is acquired from rolling indentation 
experiments on a phantom tissue sample. With the generated 
tissue model, the user can explore the stiffness distribution 
independently of the real tissue. This method avoids the 
control issues linked to direct force feedback. Also, the user 
receives a sense of touch through force feedback instead of 
relying on relative stiffness differences values provided by a 
graphical display. The concept of this method is presented in 
Section II; Section III presents the process of the tissue 
model creation; Section IV depicts the feedback to the user; 
Section V shows human-subject palpation experiments on 
the tissue model using force feedbacks and tissue 
deformation visual feedback; Section VI draws out 
conclusions. 
II. METHOD CONCEPT 
Fig. 1 depicts the flow chart of the validation test of the 
concept of our method. First, a soft tissue model is generated 
from parameters of a tissue sample using a depth sensor and 
a rolling indentation probe. The tissue surface is 
reconstructed from the stereoscopic image acquired from the 
depth sensor. Then the reaction force is measured by using a 
force sensor attached on a rolling indentation probe. A 
rolling indentation trajectory with a certain indentation depth 
can be generated based on the reconstructed tissue surface 
coordinates. Next, a robot arm is programmed to conduct the 
rolling indentation following the trajectory. During the 
indentation probing, indentation depth/reaction force pairs 
are obtained enabling tissue stiffness distribution acquisition. 
The reconstructed tissue surface is used to ensure that the 
indentation depth during the rolling indentation is kept 
constant. A force distribution matrix can be obtained, which 
represents the tissue’s elastic modulus distribution at a given 
indentation depth; we assume that the investigated tissue is 
isotropic, homogeneous, and incompressible [14], [15]. A 
force distribution matrix can be obtained for each indentation 
depth; groups of indentation depth/force pairs at different 
tissue points can be generated. A soft tissue model is then 
established based on the reconstructed tissue surface and 
tissue stiffness distribution. A geometrical deformable soft 
tissue model is employed to visualize the tissue deformation. 
Unlike the commonly used mass spring based models in 
virtual reality-based simulations, the influence of the 
indenter diameter on tissue deformation is considered in this 
geometrical deformable soft tissue model. The force 
calculation is based on a look-up table and linear 
interpolation of measured indentation depth/force pairs 
during rolling indentation. Since the rolling friction is 
relatively low compared to the normal reaction force [9], the 
rolling friction is ignored, assuming that the contact between 
the indenter and soft tissue as “frictionless”. Thus, the virtual 
tissue can be palpated with real-time tissue deformation and 
force feedback. 
 
Figure 1.  Flowchart of tumor localization using a data-driven tissue model 
III. CREATION OF THE TISSUE MODEL 
A. Phantom Tissue 
A silicone phantom tissue (see Fig. 2) is used for the 
experimental study. A phantom tissue sample with a curved 
surface contains two embedded spherical nodules (A and B) 
at a depth of 3 mm, measured from the top of the nodules to 
the silicone surface. Cancerous formations are typically 
stiffer compared with healthy soft tissues [16]. According to 
the 2003 American joint committee on cancer staging, T1 
stage tumors are 2 cm or less in greatest dimension [17]. The 
phantom is fabricated using RTV6166 (TECHSIL Limited, 
UK) (ratio 4 : 6 and the viscosity 900 mPa?s). The nodules 
(15 mm in diameter) are made from RTV615 (TECHSIL 
Limited, UK) (ratio 10:1 and the viscosity 4000 mPa?s). 
 
Figure 2.  Phantom tissue sample 
B. Surface Reconstruction 
To obtain real-time intra-operative tissue models, tissue 
surface reconstruction is required. The objective is to 
provide a visualized anatomical reconstruction of the soft 
tissue surface for stiffness distribution acquisition and soft 
tissue model generation. 3D reconstruction is widely used in 
many fields including robotics, security, biomedical 
industries, virtual and augmented reality, and entertainment 
Nodule A 
Nodule B 
Soft Tissue 
Tissue Model 
Force Feedback 
Visualization of Soft Tissue 
Deformation 
User 
Surface Reconstruction 
Stiffness Distribution 
Acquisition 
User Provides Indentation 
and Trajectory 
4189
  
[18]. The target is to achieve satisfactory 3D tissue surface 
reconstruction results without heavy computational effort. 
Here, a Kinect depth sensor is used. The Kinect depth sensor 
has been used in many research projects to obtain real-time 
3D models of physical scenes. A comparison of the 3D 
reconstruction produced using the KinectFusion framework 
with ground truth data obtained from high-precision 3D 
scanner is given in [19] demonstrating that KinectFusion is a 
new low-cost solution to resolve object details with a 
minimum curvature of 10 mm.  
 
Figure 3.  Real-time 3D reconstruction and point cloud processing 
Figure 3 shows the real-time tissue surface reconstruction 
and point cloud processing. Firstly, a real-time 3D 
reconstruction of the scene was obtained using KinectFusion 
– this interactive system allowed us to create a single 
geometrically accurate, high-quality 3D model [20]. A hand-
held Kinect sensor was slowly moved around the phantom 
tissue sample covered by a piece of purple cloth, which was 
located on a planar table, at about 1 m distance. The 3D 
model of the scene obtained from the Kinect depth camera 
was then used to extract the point cloud. Only the point 
cloud representing the soft tissue surface and the planar table 
were selected manually cutting off the remaining part of the 
scene. The plane representing the planar table and the tissue 
surface were separated using a segmentation program with 
PCL (Point Cloud Library). The centroid of the points 
representing the surface is then used to translate the points; 
the normal of the table plane is used to rotate these points 
and make them parallel to the x-z plane. Afterwards, the 
eigenvectors of the covariance matrix are calculated by using 
a Principal Component Analysis (PCA) transformation, and 
those eigenvectors were used to rotate the side of the surface 
and make it parallel to the z axis. Linear interpolation is 
applied to regulate the points. Finally, the organ surface is 
reconstructed and displayed on the screen as 1500 small, 
distributed triangles with 31? 26 nodes using OpenGL in 
VC++. A validation of the tissue surface reconstruction 
result is provided in Section III C.  
C. Acquisition of Tissue Stiffness Distribution 
At a given and fixed indentation depth, the force 
distribution matrix obtained using a rolling indentation probe 
is effectively the tissue’s elastic modulus. The results of the 
tissue surface reconstruction (using the Kinect, as described 
above) allow us to maintain a constant indentation depth 
whilst scanning. A robot arm with a rolling indentation probe 
attached to its end-effecter is programmed to scan the tissue 
following trajectories maintaining a constant indentation 
distance from the tissue surface. Whilst the scanning, a set of 
force matrices are obtained by a force sensor attached to the 
rolling indentation.  
In this paper, an ATI Nano 17 force/torque sensor (SI-
12-0.12, resolution 0.003N with 16-bit data acquisition card) 
and a FANUC robot arm (M-6iB, FANUC Corporation, 
Japan) are used. The FANUC robot is controlled with 
FANUC R-J3iC controller (capable of computing the robot’s 
kinematics and dynamics in real time. A sequence of 
positions from the point cloud are passed into the controller 
via socket messaging and continuously updated. The 
controller passes the sequence to its trajectory generator 
which is set up to work in linear interpolation mode. In this 
mode of operation, the generated trajectory follows a 
Hermite interpolation with the following equation, 
) ) ( ) )(( (
) ) ( ) ( 2 )( (
) ) ( 2 ) ( 3 (
) ) ( 2 ) ( 3 1 ( ) (
3 3 2 2
) 1 (
3 3 2 2
) 1 (
3 3 2 2
) (
3 3 2 2
t t t t t t
t t t t t t t
t t t t t t
t t t t t t t
c i c i i e ci
c i c i ci i e
c i c i i e
c i c i ci
? ? ? ? ?
? ? ? ? ? ?
? ? ? ?
? ? ? ? ?
?
?
p p
p p
p
p p
?
?
,           (1) 
where p
ei
 and p
e(i-1)
 are two consecutive points passed to the 
trajectory generator, p
ci
 is the current location of the robot at 
the time of the receiving the next position p
ei 
and ? is a scalar 
which determine how strong should the motion of the robot 
align toward intermediate point. Adjusting scalar parameter 
? to a high value, the trajectory of the motion of the robot 
starting from p
ci
 is parallel to the vector p
e(i-1)
- p
ci
 and ends 
parallel to the vector p
ci
- p
e(i-1)
.  
Implementing this method ensures that the robot follows 
the points as they are passed to it. To avoid any discontinuity 
of the motion, which could result in varying coefficients of 
-0.1
-0.05
0
0.05
0.1
-0.1
-0.05
0
0.05
0.1
-20
-15
-10
-5
0
5
x 10
-3
z
x
y
-0.1 
0 
0.1 
0.2 
0.3 
-0.1 
0 
0.1 
0.2 
0.3 
0 
0.04 
  
  
Surface before PCA 
Surface after PCA 
Kinect 
Phantom Tissue 
Surface 
Kinect Fusion 
Point cloud 
After the Dominant 
Plane Elimination 
Rotation in x-z plane for 
alignment 
x 
z 
y 
Reconstructed surface in 
MS VC++ 2005 OpenGL 
environment 
 
Regulated x-z mesh and 
depth of y (represented by 
gray color) 
 
5 10 15 20 25 30
5
10
15
20
25
4190
  
friction or skipping points, the points are updated when the 
robot is in close vicinity of the last point. As a result, the 
point cloud can be followed with continuous motion. 
Parameter ? should be adjusted to reduce motion vibrations 
as much as possible. Empirical experiments demonstrate best 
results at ?=3.5.    
To correctly match the coordinate systems of the robot 
and the point cloud three points on the robot structure are 
measured. These points are origin (centroid of the surface) 
and one point in x and y directions. Based on these points, 
homogenous transformation matrices are created which 
transform the points of the point cloud into the robot 
coordinate frame. To validate the accuracy of the tissue 
surface reconstruction result, the robot was first programmed 
to follow the reconstructed tissue surface with an indentation 
depth of 0. Force data was recorded. The maximum force 
was 0.041 N. The average force was 0.009 N with a standard 
deviation of 0.008 N. The result demonstrates the indenter 
was barely touching the reconstructed surface – hence, 
following the curvature of the tissue surface accurately 
during the entire scan process. We conclude that the tissue 
surface reconstruction can be used for indentation depth 
control during indentation scans that aim at acquiring a 
tissue’s stiffness distribution. Three rolling indentation 
process were conducted with the indentation depths of 2 mm, 
4 mm and 6 mm. During the process, the soft tissue surface 
is lubricated. Normal reaction force data was recorded (see 
Fig. 4). From the force matrices, one can see that the two 
nodules, A and B, are easily recognizable in the color-coded 
representation of the force matrix – the two nodules show as 
high force peaks (distinct red and yellow areas in an 
otherwise blue (low value) force distribution.  
IV. FEEDBACK TO THE USER 
A. Visualization of Tissue Deformation 
Deformation of the virtual soft tissue during palpation is 
displayed in real time using a geometrical deformable soft 
tissue model (see Fig. 5), which was established based on 
predefined finite element modeling considering the influence 
of the indenter diameter. The details of this model are 
presented in [21].  
B. Force Feedback 
Force feedback is provided via a haptic device 
(PHANToM Omni from Sensable Technology Inc., see Fig. 
1) to enable the user to “palpate” the created tissue model by 
holding a stylus (described in Section III). The indenter 
position (P
0
, the blue sphere in Fig. 5) is acquired and 
compared with the soft tissue surface continuously. When the 
tissue surface is contacted by the indenter, the indentation 
depth is calculated using the distance between the indenter 
position (P
0
) and the nearest triangle planar on the mesh of 
the original tissue surface contour (vertices: P
1
, P
2
, P
3
). The 
unit normal vector of the planar n is acquired from (P
2
-
P
1
)?(P
3
-P
1
)/ ||(P
2
-P
1
)?(P
3
-P
1
)||, v is the vector from P
0
 to 
P
1
. This distance is |v?n|. According to the calculated 
indentation depth, the reaction forces are acquired from a 
look-up table and linear interpolation of measured tissue 
reaction force matrices of different indentation depths. When 
the force in the look-up table exceeds the max force (3.3 N) 
of PHANToM Omni, the force is set to be 3.3 N. Since the 
surface is lubricated during the rolling indentation process. 
The tangent force is very small compared with the normal 
force during the rolling indentation, so it is not fed back to 
the user. The direction of the normal reaction force (f
n
) is 
defined by a contact normal n. The force f
n
 is decomposed 
and converted into forces along x, y, z axes of the haptic 
device (see Fig. 6). Since the reaction force data acquired 
from rolling indentation with a constant velocity, the 
proposed haptic palpation approach assumes a constant 
palpation velocity along the tissue surface and the user needs 
to palpate with a fairly constant velocity during the 
experiments.  
V. PALPATION EXPERIMENTS 
A. Method 
An empirical study on the effectiveness of the proposed 
palpation method, where twenty participants were involved, 
was carried out (see Table I for the demographics of the 
involved participants). 
 
Figure 4.  Reaction force matrix at the indentation depth of (a) 2 mm, (b) 4 
mm and (c) 6 mm 
 
 
5 10 15
5
10
15
20
25
0.5
1
1.5
2
2.5
3
3.5
 
 
 
5 10 15
5
10
15
20
25
0.5
1
1.5
2
2.5
 
 
5 10 15
5
10
15
20
25
0
0.2
0.4
0.6
(a) 
(b) 
(c) 
0.8 N 
N 
N 
Nodule A 
Nodule B 
Nodule B 
Nodule A 
Nodule A 
Nodule B 
4191
  
 
Figure 5.  Visualization of tissue deformation: (a) geometrical deformable 
soft tissue model; (b) tissue deformation result  
 
Figure 6.  Force direction of haptic feedback  
TABLE I.  OVERVIEW OF DEMOGRAPHICS AND EXPERIENCE OF THE 
GROUP 
Item Detail 
Age range 19-42 
Average age 29.6 
Gender ?: 5; ?: 15 
Handedness R: 19; L: 1 
Palpation experience 1 
Engineering background 19 
VR simulator 0 
Two tests were conducted: manual palpation employing a 
silicone slab with embedded nodules and haptic palpation 
with force feedback using the soft tissue model generated 
based on the surface reconstruction and the stiffness 
distribution results (described in Section III). To avoid 
learning effect which might have biased the results in favor 
of the last test, the order of the two tests was balanced during 
the experiment. Before the manual palpation experiment, 
participants were asked to do a practice trial run palpating a 
transparent silicone phantom tissue with and without nodules 
inside. During the manual palpation experiment, participants 
were asked to manually palpate the silicone phantom tissue 
which was covered by a purple cloth hiding hard nodules 
buried inside the silicone phantom. The task of this 
experiment was to find the location of the buried nodules just 
employing the sense of touch. Before the haptic palpation 
test, participants were asked to do a practice run with hard 
nodules that were visible. During the haptic palpation 
experiment, participants were asked to palpate the virtual 
tissue with no hidden nodules and to pinpoint the found 
nodule positions.  
B. Results and Discussion 
During the two palpation experiments, all participants 
found the two embedded nodules (Nodule A: 100%; Nodule 
B: 100%). It is noted that one participant wrongly identified 
two additional regions as tissue regions where nodules were 
buried (see the yellow circles in Fig. 7). Localization 
accuracy is comparable between the haptic palpation and 
manual palpation. The average time of the manual palpation 
experiment was 29.15 s (Standard Error = 2.54 s) while the 
average time of the haptic palpation was 39.95 s (Standard 
Error = 4.18 s). A Mann-Whitney U-test [22] was conducted 
to compare the consumed time of these two methods. No 
significant difference was found (U = 133, p = 0.071 > 0.05). 
In this experiment, haptic palpation could be seen as efficient 
as manual palpation. 
 
Figure 7.  Wrongly recognized hard areas (two yellow circles)  
For this method to be employed in a real MIS setting, a 
smaller and sterilizable depth sensor or a binocular camera 
would need to be used instead of the Kinect. The two 
wrongly recognized nodule locations are both at the edges of 
the tissue model. The reason could be that the particular 
participant confused the changes of force caused by stiffness 
differences and the tissue texture. By just observing reaction 
force maps (like the one shown in Fig. 4), there is a risk of 
making mistakes in nodule identification and localization. In 
Fig. 4, there is an area with a relative high reaction force (see 
top right yellow area in Fig. 4 (a), (b) and (c)), which could 
be wrongly interpreted as a hard nodule if only the color 
coding of the shown force matrix was used in the analysis. In 
our human subject palpation experiments, users were able to 
detect the hard nodules correctly with the help of force 
feedback information. The reason for the slightly lower 
performance during the haptic palpation experiments 
compared to the manual palpation performance may be 
related to the limited tactile information experienced during 
the haptic feedback experiments. 
For the proposed 3D tissue surface reconstruction 
method to be employed in a real MIS setting, a smaller and 
sterilizable depth sensor or a binocular camera should be 
used instead of the Kinect. Although there is no official 
announcement, Microsoft is developing miniaturized Kinect 
depth sensor, which will be more suitable for the size 
requirements of MIS tools. Hopefully in the near future, it 
can be applied in a real MIS setting. In this proposed 
method, a flat table surface was used to work as a reference 
planar to segment and rotate the tissue surface and a centroid 
of tissue surface was used to register the reconstructed tissue 
Indenter 
Avatar 
P 0 
n 
f n 
f ny 
f nx 
y 
x 
(a) 
(b) 
Indenter 
Avatar 
4192
  
surface to the coordinate frame of the robot. In practice, the 
tissue will not be sitting on a planar surface in-vivo, but 
rather on and surrounded by other organs. The proposed 
method needs to be adapted to those conditions. Manually 
inserted markers or pins would be one solution. Attach the 
depth sensor to the surgical robot to unify the coordinate 
systems would be another solution. 
VI. CONCLUSIONS 
Providing direct force feedback to enable palpation via a 
surgical tele-manipulator can lead to system instability 
issues; using tissue stiffness distribution information 
provided by a graphical display it is difficult for surgeons to 
form a reliable impression of the actual tissue stiffness. To 
fill the research gap, an intra-operative tumor localization 
method providing force feedback utilizing real-time intra-
operative tissue models is introduced. Instead of using 
empirical tissue model parameters, the tissue model in this 
method represents the properties of investigated soft tissue. 
A validation test of the concept was conducted by evaluating 
the performance of the tumor localization on a soft tissue 
phantom containing buried stiff nodules. The proposed 
haptic palpation method performed well– although it was 
noted to be slower than manual palpation. The results 
revealed that although manual palpation was shown to be 
less time consuming, the two methods had no significant 
difference, concerning the nodule identification result. The 
proposed method avoids the control issues associated with 
direct force feedback. We demonstrated the potential of our 
palpation method in medical training, however, a lot of work 
and effort and user studies remain to show how that this 
technique can be efficiently used in a real medical training, 
RMIS and remotely guided open surgery. 
ACKNOWLEDGMENT 
The work described in this paper is partially funded by 
the Seventh Framework Programme of the European 
Commission under grant agreement 287728 in the 
framework of EU project STIFF-FLOP, by the China 
Scholarship Council, as well as by the National Institute for 
Health Research (NIHR) Biomedical Research Centre based 
at Guy's and St Thomas' NHS Foundation Trust and King's 
College London. The views expressed are those of the 
authors and not necessarily those of the NHS, the NIHR or 
the Department of Health. 
REFERENCES 
[1] T. R. Coles, D. Meglan, and N. W. John, “The Role of Haptics in 
Medical Training Simulators: A Survey of the State of the Art,” IEEE 
Trans. Haptics, vol. 4, no. 1, pp. 51–66, Jan. 2011. 
[2] M. Nakao, T. Kuroda, M. Komori, and H. Oyama, “Evaluation and 
user study of haptic simulator for learning palpation in cardiovascular 
surgery,” Int. Conf. Artif. Real. Telexistence, pp. 203–208, 2003. 
[3] G. De Gersem, “Reliable and enhanced stiffness perception in soft-
tissue telemanipulation,” Int. J. Rob. Res., vol. 24, no. 10, pp. 805–
822, Oct. 2005. 
[4] J. C. Gwilliam, Z. Pezzementi, E. Jantho, A. M. Okamura, and S. 
Hsiao, “Human vs. robotic tactile sensing: Detecting lumps in soft 
tissue,” 2010 IEEE Haptics Symp., pp. 21–28, Mar. 2010. 
[5] M. Tavakoli, A. Aziminejad, R. V Patel, and M. Moallem, “Methods 
and mechanisms for contact feedback in a robot-assisted minimally 
invasive environment.,” Surg. Endosc., vol. 20, no. 10, pp. 1570–
1579, Oct. 2006. 
[6] R. Konietschke, U. Hagn, M. Nickl, S. Jorg, A. Tobergte, G. Passig, 
U. Seibold, L. Le-Tien, B. Kubler, M. Groger, F. Frohlich, C. Rink, A. 
Albu-Schaffer, M. Grebenstein, T. Ortmaier, and G. Hirzinger, “The 
DLR MiroSurge - A robotic system for surgery,” in Proceedings of 
the IEEE International Conference on Robotics and Automation 
(2009), 2009, pp. 1589–1590. 
[7] H. Tanaka, K. Ohnishi, H. Nishi, T. Kawai, Y. Morikawa, S. Ozawa, 
and T. Furukawa, “Implementation of Bilateral Control System Based 
on Acceleration Control Using FPGA for Multi-DOF Haptic 
Endoscopic Surgery Robot,” IEEE Trans. Ind. Electron., vol. 56, no. 
3, pp. 618–627, 2009. 
[8] A. M. Okamura, “Haptic feedback in robot-assisted minimally 
invasive surgery,” Curr. Opin. Urol., vol. 19, no. 1, p. 102, 2009. 
[9] H. Liu, D. P. Noonan, B. J. Challacombe, P. Dasgupta, L. D. 
Seneviratne, and K. Althoefer, “Rolling mechanical imaging for tissue 
abnormality localization during minimally invasive surgery.,” IEEE 
Trans. Biomed. Eng., vol. 57, no. 2, pp. 404–14, Feb. 2010. 
[10] T. Yamamoto and N. Abolhassani, “Augmented reality and haptic 
interfaces for robot? assisted surgery,” Int. J. Med. Robot. Comput. 
Assist. Surg., vol. 8, no. November 2011, pp. 45–56, 2012. 
[11] A. P. Miller, W. J. Peine, J. S. Son, and M. D. Z. T. Hammoud, 
“Tactile imaging system for localizing Lung nodules during video 
assisted thoracoscopic surgery,” Proc. 2007 IEEE Int. Conf. Robot. 
Autom., pp. 2996–3001, Apr. 2007. 
[12] M. Mahvash, J. Gwilliam, R. Agarwal, B. Vagvolgyi, L.-M. Su, D. D. 
Yuh, and A. M. Okamura, “Force-Feedback Surgical Teleoperator: 
Controller Design and Palpation Experiments,” 2008 Symp. Haptic 
Interfaces Virtual Environ. Teleoperator Syst., no. Figure 1, pp. 465–
471, Mar. 2008. 
[13] W. Khaled, S. Reichling, O. T. Bruhns, H. Boese, M. Baumann, G. 
Monkman, S. Egersdoerfer, D. Klein, A. Tunayar, H. Freimuth, A. 
Lorenz, A. Pessavento, and H. Ermert, “Palpation imaging using a 
haptic system for virtual reality applications in medicine,” Stud. 
Health Technol. Inform., vol. 98, pp. 147–153, Jan. 2004. 
[14] H. Liu, J. Li, X. Song, L. D. Seneviratne, and K. Althoefer, “Rolling 
Indentation Probe for Tissue Abnormality Identification During 
Minimally Invasive Surgery,” IEEE Trans. Robot., vol. 27, no. 3, pp. 
450–460, 2011. 
[15] K. Sangpradit, H. Liu, L. D. Seneviratne, and K. A. Althoefer, “Tissue 
identification using inverse finite element analysis of rolling 
indentationof Rolling Indentation,” in IEEE International conference 
on Robotics and Automation ICRA, 2009, pp. 1250–1255. 
[16] P. Wellman and R. Howe, “Breast tissue stiffness in compression is 
correlated to histological diagnosis,” 1999. 
[17] W. a Woodward, E. a Strom, S. L. Tucker, M. D. McNeese, G. H. 
Perkins, N. R. Schechter, S. E. Singletary, R. L. Theriault, G. N. 
Hortobagyi, K. K. Hunt, and T. a Buchholz, “Changes in the 2003 
American Joint Committee on Cancer staging for breast cancer 
dramatically affect stage-specific survival.,” J. Clin. Oncol. Off. J. 
Am. Soc. Clin. Oncol., vol. 21, no. 17, pp. 3244–8, Sep. 2003. 
[18] G. Kordelas, “State-of-the-art Algorithms for Complete 3D Model 
Reconstruction,” in in Lecture Notes in Computer Science, 2010, pp. 
1–15. 
[19] S. Meister and S. Izadi, “When can we use KinectFusion for ground 
truth acquisition?,” in Workshop on Color-Depth Camera Fusion in 
Robotics, IROS, 2012, pp. 3–8. 
[20] S. Izadi, D. Kim, O. Hilliges, D. Molyneaux, R. Newcombe, P. Kohli, 
J. Shotton, S. Hodges, D. Freeman, A. Davison, and A. Fitzgibbon, 
“KinectFusion: Real-time 3D Reconstruction and Interaction Using a 
Moving Depth Camera,” in The ACM Symposium on User Interface 
Software and Technology (UIST), 2011, pp. 559–568. 
[21] M. Li, L. D. Seneviratne, P. Dasgupta, and K. A. Althoefer, “Virtual 
palpation system,” in International Conference on Intelligent Robots 
and Systems workshop “Learning and Interaction in Haptic Robots,” 
2012. 
[22] H. B. Mann and D. R. Whitney, “On a test of whether on of two 
random variables is stochastically larger than the other,” Ann. Math. 
Stat., vol. 18, no. 1, pp. 50–60, 1947.   
4193
