Coordination of a Nonholonomic Mobile Platform and an On-board
Manipulator
Yunyi Jia, Ning Xi and Erick Nieves
AbstractÑMobile manipulators provide more advantages
and ßexibility in a wide range of applications than standard
manipulators by introducing mobility. However, adding mobile
platforms to standard manipulators, especially nonholonomic
mobile platforms, introduces new challenges to the system
modeling and control. Most existing methods for mobile ma-
nipulators do not consider the performance difference between
the mobile platform and the manipulator and therefore cannot
handle the uncertain and unexpected events happened in both
the mobile platform and the manipulator. This paper introduces
a planning and control method in a perceptive reference
frame for a nonholonomic mobile manipulator to efÞciently
handle uncertain and unexpected events. The experimental
results on a nonholonomic mobile manipulator demonstrate the
effectiveness and advantages of the designed method.
I. INTRODUCTION
Mobile manipulators integrate the advantages of the mo-
bile platform and the manipulator and have been widely used
in many areas including industrial manufacturing, hazardous
material operations, domestic service, etc. [1-3]. The working
space of a standard manipulator can be enlarged by introduc-
ing a mobile platform, commonly a nonholonomic mobile
platform. However, this integration of two different systems
also introduces new challenges. First, the models for the
mobile platform and manipulator are different. The manipu-
lator is usually a holonomic system but the mobile platform
may be subject to nonholonomic constraints. A method is
required to incorporate the nonholonomic constraints during
the system modeling. Second, the integrated system is highly
redundant and the redundancy resolution scheme is required.
Third, from the view of practical implementation, even if
the above two theoretical problems are perfectly solved,
the control performance may still be affected by uncertain
and unexpected events in both the mobile platform and the
manipulator.
Many studies have been conducted on the modeling and
control of nonholonomic mobile manipulators. There are
commonly two ways to model the kinematic system with
nonholonomic constraints. One way is to directly add the
constraints to the velocity kinematic model [4][5]. Another
more efÞcient way is to model the system to explicitly entail
the admissible motions with respect to the nonholonomic
This research work is partially supported under U.S. Army Research
OfÞce Contract No. W911NF-11-D-0001, and U.S. Army Research OfÞce
Grant No. W911NF-09-1-0321 and W911NF-10-1-0358, and National Sci-
ence Foundation Award No. CNS-1320561 and IIS-1208390.
Yunyi Jia, Ning Xi and Erick Nieves are with the Department of
Electrical and Computer Engineering, Michigan State University, East
Lansing, MI 48824 USA (E-mails: jiayunyi@msu.edu, xin@egr.msu.edu,
nieveser@msu.edu).
constraints [6][7], which is also used in this paper. After
the model is obtained, the nonholonomic mobile manipulator
system is usually redundant for a given end-effector task
which usually has no more than six dimensions. Then, the
redundancy resolution methods for standard manipulators
can be extended to the nonholonomic mobile manipulator in-
cluding Extended Jacobian method [8], task priority method
[9], Reduced Gradient based method [10], Singularity-
Robust method [11], Damped Least-Squares Inverse Jacobian
method [12], etc. A task-space or end-effector space closed-
loop controller can then be incorporated into the redundancy
resolution schemes to make the robot track the desired end-
effector motions.
However, in practical implementation, the task-space
closed-loop controllers with redundancy resolution cannot
always guarantee the best performance of the end-effector
tracking because of the uncertain and unexpected events in
both the mobile platform and the manipulator. First, the
mobile platform and the manipulator have different struc-
ture characteristics and also work in completely different
environments. This results in different motion dynamics and
errors for the mobile platform and the manipulator. However,
the task-space controller is not aware of such differences.
This can affect the tracking performance of the end-effector.
In addition, either or both of the mobile platform and the
manipulator may be stopped by unexpected events such as
an obstacle. Since the task-space controller is not aware of
these issues as well, it will generate larger end-effector errors
and even lead to stability problems if no safety mechanisms
are designed ahead.
To address these problems, coordination between the mo-
bile platform and on-board manipulator is required. The
major contribution of this paper is to present a planning
and control method in a perceptive reference frame to online
coordinate a nonholonomic mobile platform and a manipu-
lator for the practical application. The method can handle
uncertain and unexpected events in both the mobile platform
and the manipulator. First of all, the kinematic model of
the nonholonomic mobile manipulator is derived. Based on
the model, traditional task-space kinematic control methods
with redundancy resolution are then introduced. By using a
perceptive reference, the traditional methods are converted
to online and closed-loop planning and control processes
driven by the system outputs. This makes the system be able
to be aware of uncertain and unexpected events and then
efÞciently handle them. Therefore, the performance of the
nonholonomic mobile manipulator can be signiÞcantly im-
proved including the end-effector tracking errors and system
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 4356
safety.
II. KINEMATICS OF THE NONHOLONOMIC MOBILE
MANIPULATOR
A. Kinematic Modeling
The nonholonomic mobile manipulator studied in this
paper contains a 4-wheel drive mobile platform and a 7-DOF
on-board manipulator as shown in Fig. 1. The coordinate
frames and variables are deÞned as below:
w
?
a
?
b
?
ee
?
x
y
z
Fig. 1. Nonholonomic Mobile Manipulator
¥ ?
w
: World reference frame;
¥ ?
a
: Manipulator base frame;
¥ ?
b
: Body attached frame at the horizontal center of
the mobile platform, which origin represents of the
abstraction of the mobile platform;
¥ ?
ee
: Frame Þxed at the end-effector center, which origin
represents the abstraction of the end-effector;
¥ r =[x
w
,y
w
,z
w
,O
w
,A
w
,T
w
]
T
: Generalized end-
effector position with respect to ?
W
;
¥ r
a
=[x
a
,y
a
,z
a
,O
a
,A
a
,T
a
]
T
: Generalized end-
effector position with respect to ?
a
;
¥ ø r
b
=[x
b
,y
b
,?
b
]
T
: Position and orientation of the mobile
platform with respect to ?
W
;
¥ r
b
=[d
b
,?
b
]
T
: Traveled distance and orientation of the
mobile platform with respect to ?
W
;
¥ ú r
b
=[v
b
,?
b
]
T
=[
ú
d
b
,
ú
?
b
]
T
: Longitudinal and turning
velocities of the mobile platform;
¥ q
a
=[q
1
,q
2
,q
3
,q
4
,q
5
,q
6
,q
7
]
T
: Joint variables of the
manipulator;
¥ u
b
=[u
l
,u
r
]
T
: Joint velocity of the mobile platform;
¥ u
a
=[u
1
,u
2
,u
3
,u
4
,u
5
,u
6
,u
7
]
T
: 7 Joint motor veloc-
ities of the manipulator;
¥ u =

u
b
u
a

T
: Complete motor velocities of the
mobile manipulator;
The forward kinematics of the 7-DOF manipulator with
respect to ?
a
can be obtained by
y
a
= h
a
(q
a
) (1)
Using the deÞnition ø r
b
=[x
b
,y
b
,?
b
]
T
and (1), the forward
kinematics of the mobile manipulator with respect to ?
w
can
be obtained by
r = h(ø r
b
,q
a
)
=ø r
b
+ T
w
a
(?
b
)h
a
(q
a
)
(2)
where T
w
a
(?
b
) is a transformation matrix which transfers
the manipulator base frame ?
a
to the frame whose origin
coincides with the origin of ?
b
and whose axes are parallel
to the axes of ?
w
. The only variable in the T
w
a
(?
b
) is ?
b
.
Through differentiation on both sides of (2), the velocity
kinematics can be obtained by
ú r =
¶h
¶ø rb
ú
ø r
b
+
¶h
¶qa
ú q
a
= J
b
ú
ø r
b
+J
a
ú q
a
(3)
The mobile platform is constrained by a nonholonomic
constraint described by
ú x
b
sin(?
b
)? ú y
b
cos(?
b
)=0 (4)
which implies that the mobile platform cannot have a ve-
locity along the lateral direction with respect to its body.
One way to handle this constraint is to attach the constraint
description to the velocity kinematic model by adding a new
row described by
0=

sin(?
b
) ?cos(?
b
)00
7?1


ú
ø r
b
ú q
a

(5)
Another more efÞcient way is to modify the kinematic
model to explicitly entail the admissible velocities of the
mobile platform with respect to its nonholonomic constraint.
The admissible velocities actually contain a longitudinal
velocity parallel to the mobile platform and an angular veloc-
ity for horizontally turning the mobile platform. Therefore,
deÞne these two admissible velocities by ú r
b
=[v
b
,?
b
]
T
and
we have
ú r = J
b
J
adm
b
ú r
b
+J
a
ú q
a
(6)
where J
adm
b
is the transformation matrix for the transforma-
tion from the admissible velocity space to the operational
velocity space, which is expressed by
J
adm
b
=
? ? sin(?
b
)0
cos(?
b
)0
01
? ? (7)
For both the mobile platform and the manipulator, the
ultimate outputs for kinematic control should be joint motor
velocities. For the manipulator, there is a one-to-one cor-
respondence between the joint motor velocities u
a
and the
joint variables q
a
.Sowehave
u
a
=ú q
a
(8)
For the mobile platform, there are four motors with two
mounted on both left and right sides, so it has four joint
motor velocities u
l1
,u
l2
,u
r1
and u
r2
. Because of the
special installation of these motors, considering no slippage
in longitudinal direction, it is required that the two motor
velocities on the same side must be identical, which is
described by
u
l1
= u
l2
u
r1
= u
r2
(9)
4357
For simplicity, use u
b
=[u
l
,u
r
]
T
to represent the motor
velocities on the left and right sides and the following
velocity kinematics can be obtained
ú r = J
b
J
adm
b
J
u
b
u
b
+J
a
u
a
=

J
b
J
adm
b
J
u
b
J
a


u
b
u
a

= J
m
u
(10)
where J
u
b
is a constant transformation matrix for transform-
ing u
b
to ú r
b
, which can be easily obtained based on the
dimension parameters of the mobile platform, and J
m
is the
Þnal Jacobian of the nonholonomic mobile manipulator.
B. Kinematic Control
In (10),u contains nine joint motor velocities of the mobile
platform and the manipulator. The end-effector velocity ú r is
usually a variable of no more than six dimensions. Therefore,
the mobile manipulator system is highly redundant. For a
given desired end-effector velocity ú r
d
, there exist many fea-
sible solutions of u to achieve it. The redundancy resolution
methods for standard manipulators can be extended to the
kinematic control of the nonholonomic mobile manipulator.
For a given end-effector velocity ú r, the formula of the most
commonly used kinematic control methods with redundancy
resolution can be expressed by
u = J
m
 
ú r +(I ?J
m
 
J
m
)u
0
(11)
where J
m
 
is the pseudoinverse of J
m
, I ? J
m
 
J
m
is the
orthogonal projection operator which projects the joint motor
velocity vector into the null space of J
m
, and u
0
is the
designed joint motor velocity for the secondary task. The Þrst
item is in the operational space and the goal is to achieve the
end-effector velocity. The second item is in the null space
and the goal is to satisfy some secondary tasks. It could be to
achieve a designed joint motor velocity or, more commonly,
to optimize a criterion that is related to the robot states.
Furthermore, when a desired trajectory is given by ú r
d
(t)
and r
d
(t), a task-space closed-loop controller [11][13] can
then be obtained by replacing ú r in controller using
ú r=ú r
d
(t)+K
r
(r
d
(t)?r
c
) (12)
where K
r
is a constant gain matrix and r
c
is the mea-
surement of current end-effector position. This closed-loop
design is adopted in most kinematic controllers of non-
holonomic mobile manipulators. However, the closed-loop
control in task space cannot always guarantee the best
performance of the system since there may exist some
uncertain and unexpected events in both the mobile platform
and the manipulator. When the joint motor velocities are
generated from the kinematic controller, they are sent to
the dynamic motor controllers of the mobile platform and
the manipulator separately. There usually exist two types of
uncertain and unexpected events in both the mobile platform
and the manipulator.
The Þrst type relates to uncertain events in the dynamics.
The manipulator is relatively light-weight and usually works
in a contact-free environment that has relatively small motor
disturbance. This leads to fast dynamics and small errors. In
contrast, the mobile platform is much heavier and works in
an unstructured environment where many unknown factors
can introduce large disturbances, such as the contact ground
condition or on-board manipulator motions. This leads the
mobile platform to slow dynamics and larger errors. These
differences, however, are never considered in the task-space
closed-loop controller. These problems will result in large
end-effector errors when the differences are obvious.
The second type of relates to unexpected events in both
robotic systems. When the mobile platform or manipulator is
stopped by unexpected events, such as an obstacle, only one
of them is movable in this situation. However, the task-space
kinematic controller is not aware of this and will continue
generating velocities for both the mobile platform and the
manipulator, one of which, however, can never be achieved.
This will lead to large errors of end-effector. Moreover, when
both the mobile platform and the manipulator are stopped,
The desired end-effector velocities and position trajectories
will still keep evolving because they are both functions of
time and the time never stops. This will also make the time-
based task-space kinematic controller continue to generate
larger and larger joint motor velocities as time increasing,
which will make the system unstable if no safety mechanisms
are designed ahead. This is because the desired end-effector
velocities and position trajectories are both functions of time
and will always keep evolving because the time never stops.
Therefore, in order to achieve the best possible perfor-
mance under these uncertain and unexpected events, coordi-
nated control between the mobile platform and the manipu-
lator and an automatic safety mechanism is required. These
two requirements can actually be achieved at the same time
through the planning and control in a perceptive reference
frame which is introduced in the next section.
III. COORDINATION OF THE NONHOLONOMIC MOBILE
MANIPULATOR
A. Planning and Control Theory in the Perceptive Reference
Frame
In traditional planning and control, the planning is usually
an open-loop process. The time variable is used as the motion
reference and the motion plan is parameterized by time
based on the deÞned tasks. Then, the planner generates the
desired instant output to the control system by plugging the
current referenced time into the time-based motion plan. All
uncertain and unexpected events are left to the control system
to handle. If these events are not considered in the action
plan, then the controller alone is not able to handle them.
This is especially true when it is working in an unstructured
environment. Therefore, it is very important to incorporate
the planning and control processes based on system output
measurement to handle these events and achieve the best
possible performance.
The planning and control in the perceptive reference frame
aims to handle uncertain and unexpected events in both
planning and control levels. The basic idea is to model the
4358
system planning and control based on a non-time reference
related to the physical system outputs instead of time t. The
new reference is named perceptive reference and usually
represented by s. Based on this idea, we have designed
the multi-robot coordination [14][15] and teleoperation [16]
in our previous work. In this paper, it is modiÞed and
extended to the coordinated control of the nonholonomic
mobile manipulator. The coordinated control mainly contains
three steps described as below.
B. Generation of Motion Plans
The desired motion of the end-effector is given by a human
operator using a spaceball. The spaceball can generate 6-
dimensional operational commands including 3-dimensional
translation and 3-dimensional rotation. Scaled sampled data
of these commands are used as the desired velocity of the
end-effector. Given a time-based desired trajectory ú r
d
(t),
deÞne the perceptive reference s as the distance that the end-
effector travels along the desired trajectory, the time-based
trajectory can be converted to a non-time based trajectory
parameterized by s: ú r
d
(s). Using the task-space closed-loop
kinematic control, the joint motor velocities of the mobile
manipulator, u, can be obtained
u = U(ú r
d
(s)) (13)
where u contain velocities of both the mobile platform
and the manipulator, u
b
and u
a
. Furthermore, the desired
velocities for the mobile platform and the manipulator, ú r
d
b
(s)
and ú r
d
a
(s), can be obtained by
ú r
d
b
(s)= J
u
b
U
b
(ú r
d
(s))
ú r
d
a
(s)= J
a
U
a
(ú r
d
(s))
(14)
where the functions U
b
and U
a
are decomposed from the
function U. From this relationship, given a desired trajectory
of the end-effector ú r
d
(s), we can Þnd its corresponding
desired trajectories of the mobile platform and the manip-
ulator using a chosen kinematic control method. They are
parameterized by s and represented by ú r
d
b
(s), r
d
b
(s), ú r
d
a
(s)
and r
d
a
(s).
C. Generation of Motion Reference for Coordinated Control
The goal is to minimize the end-effector errors and guaran-
tee the system safety under uncertain and unexpected events.
This can be achieved by the coordination which requires
that both the mobile platform and the manipulator work in
a planned manner to achieve the desired motion of the end-
effector. To be speciÞc, for a given point along the path of the
end-effector, both the mobile platform and the manipulator
should be in their desired positions corresponding to the
given point. To achieve this requirement, the perceptive
reference can be generated as following. When the tracking
performances of the mobile platform and the manipulator
differ because of uncertain events in the dynamics, e.g., one
tracks its desired motion slower than the other, the perceptive
reference could be designed to slow down the motion of the
faster one until the slower once catches up with it, such that
the end-effector errors can always be minimized. If one of
or both the mobile platform and the manipulator are stopped
by unexpected events, the perceptive reference could be
designed to stop both motions of the mobile platform and the
manipulator until the unexpected events are removed, such
that the safety of the system can be guaranteed. Therefore,
given the outputs of the mobile platform and the manipulator,
r
a
and r
b
, to achieve this coordination, the calculation of the
best perceptive reference can be designed as
s
?
=min{s
b
,s
a
}
s
b
=arg min
s


(r
d
b
(s)?r
b
)
T
W
b
(r
d
b
(s)?r
b
)

s
a
=arg min
s


(r
d
a
(s)?r
a
)
T
W
a
(r
d
a
(s)?r
a
)

(15)
where s
b
represents the motion tracking status of the mobile
platform and is calculated based on the mobile platform
outputs; s
a
represents the motion tracking status of the
manipulator and is calculated based on the manipulator
outputs; W
a
and W
b
are the weighting matrices to weigh
the coordination errors based on the speciÞc coordination
requirements.
D. Planning and Control for Coordination
Once the best perceptive reference is generated based on
the system output measurement, the planning for generating
the desired instantaneous inputs for the mobile platform
and the manipulator is achieved by simply plugging the
perceptive reference into their desired motion plans. The
joint motor velocities for the mobile manipulator can then
be designed by
u =

u
b
u
a

T
u
b
=(J
u
b
)
 

ú r
d
b
(s
?
)+k
b

r
d
b
(s
?
)?r
b

u
a
=(J
a
)
 

ú r
d
a
(s
?
)+k
a

r
d
a
(s
?
)?r
a

(16)
where k
b
and k
a
are positive constants. The new velocity
inputs are then passed to the dynamic motor controllers of
both the mobile platform and the manipulator for executions.
The planning and control for coordination in the perceptive
reference frame is schematically described as shown in
Fig. 2. The block of Motion Plan Generation generates the
motion plans described by s for both the mobile platform
and the manipulator based on the desired trajectory of the
end-effector. The system outputs are mapped to a best
perceptive reference s
?
which carries the current states of
both the mobile platform and the manipulator. The block
of Coordination Planner generates the desired instantaneous
inputs for the system based on the original motion plans
and the best perceptive reference s
?
. Then, the block of
Coordination Controller computes new joint motor velocities
to the dynamic motor controllers of both the mobile platform
and the manipulator to achieve the desired instantaneous
output. It is easily seen that, at a given instant of time, the
desired system inputs are functions of current system outputs,
which makes the planning a closed-loop process to be able
to handle some uncertain and unexpected events according
to the original motion plans.
4359
*
s
Motion Plan 
Generation 
Coordination 
Planner
Coordination 
Controller
Mobile 
Platform
Manipulator
Mobile platform 
motor controller
Manipulator 
motor controller
Mobile Manipulator
Perceptive
Reference
Motion plans
System output measurement
Desired 
instantaneous
inputs
Velocity input
System outputs
Motor measurement
System output measurement
Fig. 2. Planning and control for coordination in the perceptive reference frame
Notice that if there are no uncertain or unexpected events
in both the mobile platform and the manipulator, the planning
and control in the perceptive reference frame is equivalent to
the traditional task-level control methods. This is because the
motion plans for coordination are actually generated based
on the traditional task-level control method with redundancy
resolution. However, when uncertain or unexpected events
occur, the proposed planning and control method will take
effect and make the system have a better performance.
IV. EXPERIMENTAL RESULTS AND ANALYSIS
A. Experimental setup
In order to verify the effectiveness and advantages of
the proposed coordinated control method in the perceptive
reference frame, both traditional control method and pro-
posed method were implemented on a nonholonomic mobile
manipulator which was built at Michigan State University
(MSU). As shown in Fig. 3, the robot consists of a 4-wheel
Segway mobile platform and a 7-DOF Schunk manipulator.
The mobile platform, a heavy and rugged system with
slow dynamics and less accurate performance, moves on the
unstructured ground. In contrast, the manipulator, a light-
weight and precise system with fast dynamics and more
accurate performance, moves in a contact-free environment.
Notice that small errors of the mobile platform, in particular
the turning errors, will result in larger position errors of end-
effector.
B. Experimental Results of Coordinated Control
The Þrst experiment was to make the end-effector track a
straight-line trajectory along the y axis. The trajectory could
not be achieved by either the sole manipulator or the sole
mobile platform because the manipulator might be out of
reach and the mobile platform could not move in the lateral
direction due to the nonholonomic constraint. However, it
could be achieved by using the mobile platform and the
manipulator together. Both the traditional kinematic control
method [17] and the proposed method were implemented on
the robot system. The traditional method took maximizing
the manipulability index as the secondary task. The proposed
method was based on the same kinematic control method
Fig. 3. MSU nonholonomic mobile manipulator
but introduced the coordinated control in the perceptive
reference frame. Because the yaw angle tracking errors of the
mobile platform and the manipulator were most different, to
better demonstrate the effectiveness of the proposed method
without loss of generality, the yaw angle tracking error of
the end-effector were selected for the comparison.
Fig. 4 shows the errors of the traditional kinematic control
method and the proposed coordinated control method in the
upper plot and lower plot respectively. It can be seen that
both position and orientation errors of the proposed method
were always smaller than the traditional method. When
using the traditional method, in the beginning, the mobile
platform started much more slowly than the manipulator,
which caused a large error in the end-effector. During the
motion, the errors were also larger due to the different errors
of the mobile platform and the manipulator. In contrast, using
the proposed method, the errors were kept in a small range
for the entire time. When the obstacle stopped the mobile
platform at around 6.5 s, it made the perceptive reference
s
?
stop evolving and consequently caused the stop of both
the mobile platform and the manipulator. Therefore, the
error remained constant. At around 8 s when the obstacle
was removed, s
?
automatically started evolving and the
motions were automatically recovered. The entire process
was automatic and no replanning or resetting of the system
was required.
4360
Besides the straight-line motion, both methods were also
conducted for an arbitrary trajectory which was generated
through arbitrarily moving a space-ball joystick. Fig. 5 shows
the results of the traditional method and the proposed method
in the upper plot and lower plot respectively. It can be seen
that the errors of the former were much larger than the
latter. There were some large error segments in the traditional
control. This usually happened when large changes occurred
in the motion, e.g., large changes of velocity amplitude or
direction. This was mainly caused by different dynamics and
errors of the mobile platform and the manipulator. However,
using the proposed method, the errors were kept in a smaller
range for the entire process due to the coordination between
the mobile platform and the manipulator in the perceptive
reference frame.
0 2 4 6 8 10
?0.1
?0.05
0
0.05
0.1
time (s)
error of trad method (rad)
0 2 4 6 8 10
?0.04
?0.02
0
0.02
0.04
time (s)
error of proposed method (rad)
Fig. 4. Tracking errors for straight-line motion
0 10 20 30 40 50 60
?0.1
?0.05
0
0.05
0.1
time (s)
error of trad method (rad)
0 10 20 30 40 50 60
?0.04
?0.02
0
0.02
0.04
time (s)
error of proposed method (rad)
Fig. 5. Tracking errors for arbitrary motion
V. CONCLUSIONS
A new planning and control method for coordinated
control of a nonholonomic mobile manipulator has been
proposed in this paper. The method models the planning and
control based on the perceptive reference, which is related
to the system outputs. It makes the planning process become
closed-loop and online adaptively to the real-time system
outputs. The signiÞcance of the method is that it can handle
uncertain and unexpected events encountered by both the
mobile platform and the manipulator. The method provides a
mechanism to plan and control the robot system according to
real-time system outputs. For this reason, it can be extended
to many other robotic systems to achieve better performance
and handle more uncertain and unexpected events through
incorporating more information into the perceptive reference.
REFERENCES
[1] B. Bayle, M. Renaud and J.Y. Fourquet, ÓNonholonomic mobile ma-
nipulators: Kinematics, velocities and redundancies,Ó J. of Intelligent
and Robotic Systems, vol.32, no.1, pp.45-63, 2003.
[2] S. Soylu, B.J. Buckham, and R.P. Podhorodeski, ÓDexterous task-
priority based redundancy resolution for underwater-manipulator sys-
tems,Ó Trans. on Can. Soc. Mech. Eng., vol. 31, no. 4, pp. 519-533,
2007.
[3] Y. Jia, H. Wang, P. Strmer and N. Xi, ÓHuman/robot interaction
for human support system by using a mobile manipulator,Ó IEEE
Conference on Robotics and Biomimetics, 2010, pp. 190-195.
[4] H. Seraji ÓA uniÞed approach to motion control of mobile manipula-
tors,Ó Int. J. of Robotics Research, vol. 17, no. 2, pp. 107-118, 1998.
[5] F.G. Pin, K.A. Morgansen, F.A. Tulloch, C.J. Hacker and K.B. Gower,
ÓMotion planning for mobile manipulators with a non-holonomic
constraint using the FSP method,Ó J. of Robotic Systems, vol. 13,
no. 11, pp. 723-736, 1996.
[6] J.F. Gardner and S.A. Velinsky, ÓKinematics of mobile manipulators
and implications for design,Ó J. of Robotic Systems, vol. 17, no. 6,
pp. 309-320, 2000.
[7] J.Y. Fourquet, B. Bayle, and M. Renaud, ÓManipulability of wheeled
mobile manipulators: Application to motion generation,Ó Int. J. of
Robotics Research, vol. 22, no. 7-8, pp. 565-581, 2003.
[8] O. Egeland, ÓTask-space tracking with redundant manipulators,Ó IEEE
Trans. Robot. Automat., vol. 3, pp. 471-475, June 1997.
[9] A. Liegeois, ÓAutomatic supervisory control of conÞgurations and
behavior of multibody mechanisms,Ó IEEE Trans. on Systems, Man,
and Cybernetics, vol. 7, no. 6, pp. 868-871, 1977.
[10] A. De Luca and G. Oriolo, ÓThe reduced gradient method for solving
redundancy in robot arms,Ó Robotersysteme, vol. 7, no. 2, pp. 117-122,
1991.
[11] S. Chiaverini, ÓSingularity-robust task-priority redundancy resolution
for real-time kinematic control of robot manipulators,Ó IEEE Trans.
Robot. Automat., vol. 13, pp. 398-410, 1997.
[12] Y. Nakamura and H. Hanafusa, ÓInverse kinematic solutions with
singularity robustness for robot manipulator control,Ó Trans. ASME-J.
Dyna. Syst., Measure., Control, vol. 108, pp. 163-171, 1986.
[13] G Antonelli and S. Chiaverini, ÓFuzzy redundancy resolution and
motion coordination for underwater vehicle-manipulator systems,Ó
IEEE Trans. Fuzzy Syst., vol. 11, no. 1, pp. 109-120, 2003.
[14] N. Xi, T.J. Tarn and A.K. Bejczy, ÓIntelligent Planning and Control for
Multirobot coordination: An Event-Based Approach,Ó IEEE Transac-
tion On Robotics and Automation, vol. 12, no. 3, pp. 439-452, 1996.
[15] Y. Jia and N. Xi, ÓCoordinated Formation Control for Multi-Robot
Systems with Communication Constraints,Ó IEEE/ASME International
Conference on Advanced Intelligent Mechatronics, 2011, pp. 158-163.
[16] Y. Jia, N. Xi and J. Buether, ÓDesign of single-operator-multi-robot
teleoperation systems with random communication delay,Ó in Proceed-
ings of the IEEE/RSJ International Conference on Intelligent Robots
and Systems, 2011, pp. 171-176.
[17] H. Zhang, Y. Jia and N. Xi, ÓSensor-based redundancy resolution
for a nonholonomic mobile manipulator,Ó International Conference on
Intelligent Robots and Systems, 2012, pp. 5327-5332.
4361
