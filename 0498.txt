Simplifying Grasping Complexity through Generalization of
Kinaesthetically Learned Synergies
Giuseppe Cotugno
1
, Vishawanathan Mohan
2
, Kaspar Althoefer
1
, Thrishantha Nanayakkara
1
Abstract—There has been a growing enthusiasm to use
anthropomorphic hands of humanoid robots to manipulate
every-day objects and tools designed for humans. However,
multi-ﬁngered grasping imposes a formidable control challenge
due to the high dimensionality of the joint space and the
difﬁculty to form a functional grip on objects. We propose
a hybrid technique based on grasping synergies extracted from
kinaesthetic demonstrations on a given object with a primitive
geometry - a cuboid in this case - and passive kinematic
enveloping as a generalization technique. Experiments were
carried out on an iCub humanoid robot using everyday objects
such as a telephone receiver, a computer mouse, three white
board markers bundled together, a fencing handle, a compact
disc keep case, and a drinking glass. We prove that the
primitives extracted from kinaesthetic demonstrations on a
cuboid can be generalized across a majority of the above real
world objects.
I. INTRODUCTION
Recently, grasping based on synergies has attracted a
lot of enthusiasm among the robotics research community
[1]. Neuroscientiﬁc studies on human grasping have demon-
strated that the brain does not control the motion of the digits
individually, but rather as a whole [2], due to the very high
number of degrees of freedom (DoF) of the human hand
(23 in the simple model of [3]). In other words, the human
brain seems to solve the redundancy resolution problem by
commanding a group of muscles through combination of a
ﬁxed set of muscles synergies that are arranging the digits
in a suitable grasping posture. This concept can be modelled
mathematically through decomposing a given hand posture
into principal components using Principal Component Anal-
ysis (PCA). If applied to a human hand joint conﬁguration it
ispossibletoextractasetof primitivesor synergies,eachone
represented by a different eigenvector (eigenposture). Differ-
entprimitiveshaveastrongerorweakerroleindescribingthe
ﬁnal posture. This feature is expressed by the magnitude of
their associated eigenvalue - the higher the value is, the more
important the eigenposture is. Authors in [4] have suggested
that two or three synergies are sufﬁcient for describing a
grasping posture in humans, while adding more primitives
in the reconstruction accounts for ﬁner details related to the
object. Force applied on the object by each ﬁnger can also
be taken in consideration during grasping [5].
1
Giuseppe Cotugno, Kaspar Althoefer, Thrishantha Nanayakkara are
with the Centre for Robotics Research, School of Natural and Math-
ematical Sciences, King’s College London, Strand, WC2R 2LS, Lon-
don, United Kingdom [giuseppe.cotugno, k.althoefer,
thrish.antha] at kcl.ac.uk
2
VishwanathanMohaniswiththeRobotics,BrainandCognitiveSciences
Department, Istituto Italiano di Tecnologia, Via Morego 30, 16163, Genoa,
Italy vishwanathan.mohan at iit.it
Fig. 1. The iCub kinaesthetically learns to grasp three markers bundled
together while the left camera of the robot is recording the scene.
The original approach described in [2], does not take
into account the evolution of postures over time. To solve
this problem, Singular Value Decomposition (SVD) has
been performed on the human motion data while grasping
real objects to extract eigenpostures, eigenvalues, and time
modulationvectors[6].Suchvectorsareexplaininghoweach
posture evolves over time offering temporal information on
the role of each synergy in grasping.
Mechanical implementations of grasping synergies have
been extensively studied in robotics. Notable extension of
the initial implementations [7] are soft synergies [8] and
adaptive synergies [9]. Regardless of the design choices for
the hardware, a hand structurally designed to implement
a particular model of synergies is difﬁcult to revert to
alternative control strategies without additional complexity
in the hardware [10].
Synergies canalso be implemented at softwarelevel, with-
out the need of customizing hardware. In this case, the robot
canlearnsuchposturesfromhumandemonstrationsexecuted
in a way that enables future grasp analysis. Learning from
human demonstrations is a topic that has attracted attention
in the past. It is possible to perform demonstrations in many
different ways. Some are intrinsic to the robot joint space
- e.g. tele-operation or kinaesthetic teaching. Others rely
on observing extrinsic data provided by the motion of an
external body - e.g. motion capture or observational learning
[11]. Furthermore, the collected data must be ﬁtted into a
suitable model in order to ensure theirs repeatability, such
as dynamic motion primitives [12]. For a more detailed
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 5345
Fig. 2. Summary of the grasping algorithm. [A] Kinaesthetic demonstrations are collected from the joints of the robot. [B] De-noised data are decomposed
in orthogonal primitives, eigenvalues and time modulation vectors through SVD. [C] Time modulation vectors from different demonstrations are combined
through K-Means and spline interpolation. [D] The preshaping policy resulting from [B] and [C] is executed; Kinematic Enveloping is performed.
description of learning from demonstrations and its features,
the reader is referred to [13].
An example of learning from demonstration applied to
grasping synergies can be found in [14]. This approach relies
on motion capture of human actions. Since the human body
is more complex than robot kinematics, there is a substantial
kinematic mismatch between the body of the teacher and
the one of the robot. This problem is called the corre-
spondence problem [15], and it is not trivial to compensate
for such discrepancy. The reported technique employ PCA
as a decomposition approach. This mathematical method is
well established but it cannot take into account the postural
variability during the demonstration time line.
In this paper, we present a novel software implementation
of grasping synergies based on SVD [16] extracted from
kinaesthetic demonstrations. The algorithm beneﬁts from a
technique that combines different demonstrations using K-
Means clustering and spline interpolation. To improve the
generalization ability of the synergies, a technique to dy-
namically adjust the digits placement on different geometries
is illustrated (kinematic enveloping phase). The aim of this
work is to ﬁnd and explore answers in response to the
following scientiﬁc questions: 1) to what extent the proposed
method handles the inherent variability in the kinaesthetic
demonstrations, 2) how well do the synergies extracted from
demonstrations generalize on different objects, 3) how much
the enveloping phase can help generalizing the posture, and
4) which part of the grasping algorithm has more impact on
the performance.
II. LEARNING GRASPING SYNERGIES FROM
DEMONSTRATIONS
Since the focus of this work is on grasping, only the
9-ﬁnger joints are considered for the analysis. Reaching
and wrist orientation alignment is performed by the Passive
Motion Paradigm algorithm (PMP) [17].
A. Kinaesthetic Teaching Setup
Experimental data of kinaesthetic teaching were collected
from joint encoders in the arm (7 joints) and ﬁngers (9
joints), contact sensors at the ﬁngertips, and visual infor-
mation from the two cameras as illustrated in Fig. 2.A.
Kinaesthetic teaching was performed by a human operator
standing next to the robot. In each demonstration trial, the
operatorheldthehandsoftherobotwiththemotorsswitched
off, and guided them to perform a pick and place operation.
Objects were placed within an easily reachable workspace
of the robot.
The nine joints in the robot’s hand were organized as
follows: one joint controlling adduction/abduction of the
digits, three joints for the thumb, two for the index and
middle ﬁngers and one for the ring and pinky ﬁngers whose
motion is coupled. Each demonstration trial had a minimum
of 96 to a maximum of 156 data samples. In total eight trials
were performed on pick and place of a cuboid as a primitive
object.
B. Extraction of Synergies from Demonstrations
1) Data Preprocessing: The data recorded from the joints
of the hand have two trails of redundant stationary data
duringreachingtowardstheobjectandduringretrationtothe
home position. These redundnt data were automatically re-
moved using contact initiation and termination of the tactitle
sensors, in order to make the postural primitives accurately
represent the dynamic range of the grasping behavior. Then
we used a 3rd order Savitzky-Golay ﬁlter [18] with frame
size equal to 9 to remove high frequency artefacts in the
raw joint data generating an N ? M joint matrix J of
preprocessed data. In this case, N = 9 was the number of
joints in the hand, and M ? [96,97,98,··· ,156] was the
number of data samples in each demonstration trial.
2) Calculation of Synergies: This step is illustrated in
Fig. 2.B. Here, singular value decomposition was performed
on the preprocessed joint data in J in order to obtain three
matrices as given by
J =USV
T
(1)
where U is the N?N matrix of the eigenpostures, S is the
N?M matrixoftheeigenvalues,andV istheM?M matrix
of the temporal modulation coefﬁcients for each primitive
in U. In this context, matrix U represents N orthogonal
postural primitives of the hand that span the variability of
the corresponding grasping demonstration. Each element in
the diagonal matrix S represents the signiﬁcance of the
corresponding postural primitive. The higher the values, the
more the eigenposture contributes to the variability of the
digits. The columns v
i
in matrix V represent the scale of
temporal modulation of corresponding primitives in U.
In order to decide how many primitives to consider in the
analysis, the Root Mean Squared Error (RMSE) is evaluated.
5346
(a)
(b)
Fig. 3. Fig. 3(a) are RMS errors per trial. Each column shows the error on
a single joint, while each row shows the error using a different number of
primitives (from 1 to 9). Tables have been normalized to 35% to improve
visualization. Fig. 3(b) shows the distribution of mean RMS errors using a
different number of primitives.
The RMSE for each trial i is calculated for k = 1,2,··· ,9
primitives as given by
RMSE
(k)
i
=
s
[(U
(k)
S
(k)
V
(k)
T
)?J]
2
M
, (2)
where U
(k)
, S
(k)
and V
(k)
are the posture primitive
matrix, the signiﬁcance matrix, and the time modulation
matrix respectively, for k number of primitives, J is the
matrix of preprocessed joint data proﬁles, and M is the
number of samples recorded in trial i.
Fig. 3(a) shows the distribution of RMS errors over
trials for varying number of primitives for each joint. The
values have been normalized to the maximum of all trials.
By observing the errors, it can be concluded that a good
approximation could be obtained by considering two or
three primitives only. The maximum error among all trials
is 11.6% for two primitives and 9.5% for three primitives
(Fig. 3(b)). Those results are in line with the observations of
Santello et al. [4].
A comparison between the reconstructed joints and the
de-noised data can be observed in Fig. 4(a) and Fig. 4(b)
for two and three synergies employed respectively. It can be
noted that a higher number of synergies renders a preshaping
policy more similar to the original data, especially for some
joints.
3) Integration of Different Teaching Trials: This step is
illustrated in Fig. 2.C. Since eight demonstration trials have
been performed for grasping the same object, the problem
of abstracting them to one set of postural primitives and
(a)
(b)
Fig. 4. Comparison between de-noised joint values of trial 6 (continuous
line) and reconstructed ones (dashed line) using (a) two primitives and (b)
three primitives.
corresponding time modulation vectors has to be solved. We
combined the pre-processed joint data matrices of each trial
into one single matrix, and we applied SVD decomposition
on it. Concatenating joint matrices from different trials poses
the problem of separating the contribution of each sequence
for extracting common time modulation vectors. We solved
this problem of abstraction by performing K-Means clus-
tering [19] of the ensemble of v
i
, i = 1,2,3,··· ,8
vectors from the 8 demonstrations as shown in Fig. 5.
Centroids of clusters (milestones) are used as key points to
build interpolating cubic splines to reconstruct an abstracted
preshaping policy. We used the longest demonstration as a
guide to determine the number of clusters (K = 7) of the K-
means clustering algorithm. This resulted in a best ﬁt spline
per each eigenposture.
Thank to the orthogonality property of SVD, each com-
ponent of the v
i
matrices can be interpolated separately.
It is therefore possible to simplify a 9-dimensional control
algorithm to two or three independent spline interpolation
problems.
C. Kinematic Multi-ﬁngered Enveloping
The ﬁnal stage of grasping is the kinematic enveloping.
Postural primitives extracted from the SVD analysis and the
corresponding spline interpolations of the temporal modula-
5347
(a)
(b)
(c)
Fig. 5. Results of K-Means clustering on temporal modulation vectors.
Vectors v
i
5(a) i = 1, 5(b) i = 2, 5(c) i = 3] from different trials are
clustered independently in order to obtain a set of 7 key points for spline
interpolation. Cubic Spline interpolation from resulting milestones is shown
as black curve for each dimension.
tion coefﬁcients were used to compute the ﬁnal preshaping
grasp policy realtime. This step is summarized in Fig. 2.D.
Once the hand is preshaped by following the joint values
encoded in the grasp policy, each ﬁnger wraps around the
object trying to squeeze it. We used joint encoder readings
collected over a given time horizon (t
f
= 10 sec) to
detect the success of a grasping sequence. This enhances
the portability of the algorithm to different robotic platforms
that may or may not have tactile feedback on the ﬁngertips.
A digit is considered to be steady if:
d
i
2[f
i
(l)jh
i
<x
f
] (3)
Where d
i
is the total angular displacement of digit i, f
i
is the function regulating the motion of joint i, k is the
current number of encoder data samples, h
i
is the total
angular displacement of thei-th joint in a given time horizon
(t
f
=10 sec),x
f
is the threshold total angular displacement
to detect whether a signiﬁcant angular displacement has
occurred in each time horizon.
The execution ﬂow is resumed in algorithm 1. c
i
= 2:5

Algorithm 1: Kinematic Enveloping Algorithm
Data:
t - execution time [01) sec
h
i
- total displacement of joint i
f
i
- motion of joint i
l - number of iterations of the algorithm
x
f
- threshold deﬁning if the motion of a joint is
negligible
c
i
- constant increment of joint i
T - sampling time
t
f
- temporal horizon when stopping criteria is
evaluated
P - number of joints whose motion has been
detected as negligible
Jlim
i
- limit for joint i
begin
P =0;
for l =d
t
T
e;f
i
<Jlim
i
do
for i=[1J
n
] do
f
i
(l)=lc
i
;
h
i
(l)=
P
q=l
q=0
f
i
(q);
if l =d
t
f
T
e and h
i
(l)<x
f
then
P =P +1;
end
if P >=6 then
return true // Grasp successful
end
end
end
return false // Grasp unsuccessful
end
is the amount of angular increment of i-th joint in each
sampling step T = 1:6 sec. The increment c
i
has been
selected from the mechanical constraints of the robot to
ensure an observable motion due to the resolution of the
encoders. The time horizont
s
to detect a terminal condition,
is set to 10 seconds, while x
f
is set to 10

. The time
horizon t
f
and the threshold x
f
are the functions of the
increment and have been derived from tests on different
objects. If the number of stationary joints P >= 6 the
object is considered grasped. This number has been evaluated
experimentally, based on the assumption that at least three
digits are needed to grasp tightly [20] and that about two
joints are controlling a single ﬁnger. The quality of the grip
is validated experimentally as illustrated in next section.
III. EXPERIMENTAL EVALUATION
In this section, the proposed algorithm is validated on a
robot by grasping real-world objects. At ﬁrst the robotic
platform, iCub, is introduced. Secondly, the experimental
set-up and the validation criteria are described. Finally, the
results of the algorithm are discussed.
5348
Object
Name
No. of
Syner-
gies
Grade
of
stability
Duration
[sec]
Preshaping
time
[sec]
Enveloping
time
[sec]
3 4 78 35 43
2 3 92 37 55
Cuboid
?
3 4 133 30 103
2 4 89 26 63
1 3 111 30 81
Envl. Only 2 119 - 119
Cylinder
?
3 4 109 73 36
2 4 109 74 35
Receiver
1 2 109 74 35
Envl. Only 2 56 - 56
3 1 124 74 50
2 1 120 74 46
1 1 127 72 55
Envl. Only 1 48 - 48
CD Case
3 4 119 73 46
2 3 119 74 45
Markers
3 2 116 77 39
2 2 109 74 35
1 1 109 74 35
Mouse Envl. Only 0 4 - 4
3 0 111 73 38
Glass
3 3 122 77 45
Envl. Only 3 59 - 59
Handle
TABLE I
Summary of grasping experiments on the set of objects. (*) The time has
been evaluated using different parameters for the kinematic enveloping
phase (c
i
=1.0, tc =0.5), moreover the termination of the enveloping
was manual.
Fig. 6. Evolution of the grasp on the real robot using two primitives for
preshaping. The time reported in the ﬁrst picture takes into account the
required computation to start the algorithm. An example of execution can
be visualized in the accompanying video.
Index Description
Median
of Force
(N)
Standard
Deviation
of Force
(N)
4
The object is removed with a sig-
niﬁcant effort from the operator,
possibly using two hands and man-
ually opening the robot’s hand.
92.35 7.23
3
The object is removed with signif-
icant effort from the operator but
without interacting with the robot’s
hand.
51.59 5.88
2
The object is removed sliding it
from the robot’s hand applying dis-
creteeffortwithnointeractionwith
the robot’s hand.
15.81 1.48
1
The object is easily removed with
little effort and without interacting
with the robot’s hand.
4.9 1.86
0
The object is not grasped or is
falling while being picked up.
- -
TABLE II
Description of the ranking score for grip validation. The scores are
visually demonstrated in the accompanying video.
A. Description of Robotic Platform
The iCub is a 104 cm tall humanoid robot resembling
a 3.5 year old child [21] with 53 degrees of freedom in
total - including seven for each arm and nine for each hand.
The hands are actuated with a tendon driven system with
the motors located in the forearm (Faulhaber 1016M012G).
Encoders are based on hall sensors. The hands of the robot
are equipped with capacitive pressure sensors [22] that are
distributed on palms, ﬁngertips and the rest of the body.
Twelve taxels are allocated on the ﬁngertips, and detect the
contact with conductive material (such as metal or human
skin).
The robot, apart from the interface API that communicates
directly to the hardware, is operated through YARP [23],
an open-source robotic middleware that supports distributed
computation.
B. Experimental Setting
In order to validate the algorithm, several experiments
have been carried out with the iCub grasping different
objects. The objects used in the experiments are shown Table
I. The hand should be positioned at a maximum distance of 5
cm from the grasping point in order to manage a successful
grasp.
Afterwards, the algorithm is executed and the preshaping
is performed. Then the kinematic enveloping phase takes
place. Our technique differs from other methods [24] based
onknowncontactpoints,thereforetheconceptsofforce/form
closure [25] are not an appropriate method to validate the
stability of the grip using as the position of the contact
points is not known a priori. Instead, validation has been
carried out experimentally. Once the algorithm terminates,
the object is vertically lifted at about 22 · 10
?3
m/s
2
and
a human operator pulls the object from the robotic hand to
verify the stability of the grip (Table II). Each grip has been
ranked based on the force exerted by the human operator, it
5349
Fig. 7. Evolution of joint values for grasping a telephone receiver
using three synergies. (a) Evolution of the joints of the hand during the
preshape phase. (b) Evolution of the joints of the hand during the kinematic
envelopingphase.Theﬁngersareclosinglinearlyuntiltheobject’ssurfaceis
hit. Afterwards, the motion reaches a steady state and the grasp termination
is detected.
has been estimated experimentally using a 6 DoF force and
torque sensor (MINI40, ATI Technologies).
C. Experimental Validation and Discussion
In order to validate the robustness and generalization
power of our grasping technique, all objects in the set are
grasped with different numbers of synergies: three, two, one
or just with the kinematic enveloping.
To analyse whether different demonstrations are able to
produce a feasible preshaping policy, despite the variability
of the teaching trials, it is possible to observe the evolution
of a grasping sequence using just two primitives as in
Fig. 6. It can be observed that the conjunction of different
demonstrations executed on the same object - the cuboid
- produced a stable grasping policy. Thanks to the K-
Means clustering and the spline interpolation, it is possible
to combine different demonstrations in order to produce a
unique preshaping policy.
Fig. 7 shows the reconstructed evolution of the joint
anglesduringthegraspexecution,whilegraspingatelephone
receiverusingthreesynergies.AsexplainedinsectionII-B.3,
the preshaping follows a policy deﬁned from the extraction
ofsynergiesfromkinaestheticdata.Thereforeitsevolutionis
very similar across different objects. The enveloping phase,
however, differs from object to object. Fig. 6 displays a
typical evolution of grasping a telephone receiver has a
similar shape to many other objects, such as cuboids and the
cylinders. It can be clearly seen that, as deﬁned in section II-
C, the joints are linearly closing until the object is enveloped
with the ﬁngers reaching a steady state.
Table I summarizes the results of grasping the objects.
It can be seen that the telephone receiver, the markers, the
cylinder, the cuboid and even a complex shaped fencing
handle, are tightly grasped (see grade of stability in the third
column of Table I and Table II for the description of grades
of stability). The reason is that their geometries are similar
to the object used for learning and the thumb is placed on
the right position - ranked 4 to 3 on Table I. The computer
mouse is grasped but the grip is not tight - ranked 2 on Table
I.
The Compact Disc (CD) keep case was not successful
since its geometry differs from a standard cuboid and re-
quires a parallel grasp [26]. As the shape of the glass is
cylindrical,wewereinterestedintestingagraspwithsplayed
ﬁngers from the top. However, the grasp was unsuccessful
due to the very speciﬁc digit conﬁguration required.
Based on the experimental studies, we have found out that
misplacement of the yaw angle of the opposition joint of the
thumb (angle between the thumb and the index ﬁnger) is the
causeformostoffailures.Thisconclusionislogical,because
this degree of freedom in the primate thumb has given them
the skill to manipulate objects [27]. Other digits played a
more supportive role role in achieving a good grasp.
The experimental results given in Table I conﬁrm that
the difference between three and two postural primitives is
negligible. Both design choices perform comparatively well,
as the thumb opposition placement is similar. Using only one
synergy causes failures due to the very large dimensionality
reduction and its consequent reconstruction error. The thumb
is often misplaced leading to an unsuccessful grasp.
The enveloping phase has been proved to be very helpful
but not sufﬁcient to ﬁnalize the grasp. Unless the object
geometry is very simple, enveloping only may cause failures
due to the blind placement of the thumb on the object.
However, with a proper initial conﬁguration of digits after
pre-shaping phase, the enveloping helped to generalize even
for cases where the size of the object was smaller or the
geometry was slightly different from the original object used
to demonstrate grasping.
Among the two parts of the algorithm - preshaping and
enveloping - it can be seen that the second stage is generally
much faster than the ﬁrst. The reason is that the ﬁngers
move quickly and generally the enveloping is executed after
preshaping, so the number of iterations cannot be very large.
The preshaping phase, instead, is longer since it depends on
the number of sensor readings that, in general, can be very
large depending on the demonstration.
In the case of the cuboid, the overall time limited, since
the list of joints commands is short (about 48). Indeed,
due to mechanical constraints on the robot’s hand, a brief
pause is required between commands (1.5 seconds in our
experiments) to enforce the execution of the command. This
problem can be easily circumvented by sub-sampling the
policyobservingthegradientofeachjoint.Ifthederivativeis
notlargeenough,itcanbededucedthattherequestedmotion
is too ﬁne to be achieved and that set of joint commands can
be skipped in favour of larger values.
IV. CONCLUSIONS AND FUTURE WORK
This paper proposes a novel algorithm for grasping based
on synergies computed using the SVD on kinaesthetic teach-
ing data. The 9-dimensional joint space of the hand of
the iCub robot can be reduced to two or three postural
primitives that can be independently combined thank to the
orthogonality property of SVD. Data collected from different
trialscanbeintegratedthroughtheuseofK-Meansclustering
and spline interpolation producing a set of time modulated
5350
synergies for preshaping the hand. Experiments have shown
that the choice between two or three postural primitives does
not have a considerable impact on the ﬁnal quality of the
grasp.
To improve the generalization property of the preshaping,
the ﬁngers are being wrapped around the object until no
signiﬁcant motion is detected. This phase, called kinematic
enveloping, has shown to improve over the preshaping in
achieving a more general grip that is able to scale on the
target size and geometry of the object. Experimental results
show that enveloping in itself is not enough to ensure a safe
grip in all cases due to the blind placement of the thumb
opposition joint. This joint seems to have a pivotal role
on the generalization ability of a set of postural primitives
contributing in the preshaping phase.
The signiﬁcant advantage of the proposed technique relies
on the capability of SVD, K-Means clustering and spline in-
terpolationtocombinedifferentdemonstrationsintoaunique
preshapingpolicy,regardlessoftheirvariabilityamongtrials.
The kinematic enveloping only strengthen the generalization
ability of the preshaping policy by dynamically adapting the
ﬁngers to the geometry of the object at hand, and guarantees
a stable grasp on objects scaled with respect to the learned
one. Moreover, kinaesthetic teaching intrinsically solves the
correspondence problem, as the robot learns in its own joints
space. Employing this demonstration technique saves from
the burden of mapping the human kinematics as in other
approaches [7], [14].
In future work we will evaluate the algorithm on different
robotic hands in order to test how well the parameters
may scale on different kinematics and mechanical designs.
Furthermore, the algorithm will be tested on soft objects to
evaluate the deformation caused by the present enveloping
controller.
V. ACKNOWLEDGEMENTS
The research leading to these results has received fund-
ing from the European Community’s Seventh Framework
Programme (FP7/2007-2013) project DARWIN (Grant No:
FP7-270138). The authors would like to acknowledge the
contribution of each DARWIN partner and would like to
thank Dalia De Sanctis and Jacopo Zenzeri for their help
and support and Raffaello Bonghi for the insightful talks.
REFERENCES
[1] H. Mellmann and G. Cotugno, “Dynamic motion control: Adaptive
bimanual grasping for a humanoid robot,” Fundamenta Informaticae,
vol. 112, no. 1, pp. 89–101, 2011.
[2] M.Santello,M.Flanders,andJ.F.Soechting,“Posturalhandsynergies
fortooluse,” The Journal of Neuroscience,vol.18,no.23,pp.10105–
10115, 1998.
[3] M. Santello, G. Baud-Bovy, and H. Jrntell, “Neural bases of hand
synergies,” Frontiers in Computational Neuroscience, vol. 7, no. 23,
2013.
[4] M.Santello,M.Flanders,andJ.F.Soechting,“Patternsofhandmotion
during grasping and the inﬂuence of sensory guidance,” The Journal
of Neuroscience, vol. 22, no. 4, pp. 1426–1435, 2002.
[5] A. Jiang, J. Bimbo, S. Goulder, H. Liu, X. Song, P. Dasgupta,
K. Althoefer, and T. Nanayakkara, “Adaptive grip control on an
uncertain object,” in Intelligent Robots and Systems (IROS), 2012
IEEE/RSJ International Conference on, Oct 2012, pp. 1161–1166.
[6] C. Mason, J. Gomez, and T. Ebner, “Hand synergies during reach-to-
grasp,” Journal of Neurophysiology, vol. 86, no. 6, pp. 2896–2910,
2001.
[7] C. Brown and H. Asada, “Inter-ﬁnger coordination and postural
synergies in robot hands via mechanical implementation of principal
components analysis,” in Intelligent Robots and Systems, 2007. IROS
2007. IEEE/RSJ International Conference on, 2007, pp. 2877–2882.
[8] A. Bicchi, M. Gabiccini, and M. Santello, “Modelling natural and
artiﬁcial hands with synergies,” Philosophical Transactions of the
Royal Society B: Biological Sciences, vol. 366, no. 1581, pp. 3153–
3161, 2011.
[9] G. Grioli, M. Catalano, E. Silvestro, S. Tono, and A. Bicchi, “Adaptive
synergies: an approach to the design of under-actuated robotic hands,”
in Intelligent Robots and Systems (IROS), 2012 IEEE/RSJ Interna-
tional Conference on. IEEE, 2012, pp. 1251–1256.
[10] H. Yousef, M. Boukallel, and K. Althoefer, “Tactile sensing for
dexterous in-hand manipulation in robotics a review,” Sensors and
Actuators A: Physical, vol. 167, no. 2, pp. 171 – 187, 2011.
[11] K. Althoefer, B. Krekelberg, D. Husmeier, and L. Seneviratne, “Rein-
forcement learning in a rule-based navigator for robotic manipulators,”
Neurocomputing, vol. 37, no. 14, pp. 51 – 70, 2001.
[12] A. J. Ijspeert, J. Nakanishi, and S. Schaal, “Movement imitation
with nonlinear dynamical systems in humanoid robots,” in Robotics
and Automation, 2002. Proceedings. ICRA’02. IEEE International
Conference on, vol. 2. IEEE, 2002, pp. 1398–1403.
[13] B. D. Argall, S. Chernova, M. Veloso, and B. Browning, “A survey
of robot learning from demonstration,” Robotics and Autonomous
Systems, 2009.
[14] H.BenAmor,O.Kroemer,U.Hillenbrand,G.Neumann,andJ.Peters,
“Generalization of human grasping for multi-ﬁngered robot hands,” in
Intelligent Robots and Systems (IROS), 2012 IEEE/RSJ International
Conference on. IEEE, 2012, pp. 2043–2050.
[15] C. L. Nehaniv and K. Dautenhahn, “2 the correspondence problem,”
Imitation in animals and artifacts, p. 41, 2002.
[16] V. Klema and A. Laub, “The singular value decomposition: Its compu-
tation and some applications,” Automatic Control, IEEE Transactions
on, vol. 25, no. 2, pp. 164–176, 1980.
[17] V. Mohan and P. Morasso, “Passive motion paradigm: an alternative
to optimal control,” Frontiers in Neurorobotics, vol. 5, no. 4, 2011.
[18] A. Savitzky and M. J. E. Golay, “Smoothing and Differentiation of
Data by Simpliﬁed Least Squares Procedures,” Analytical Chemistry,
vol. 36, 1964.
[19] J. B. MacQueen, “Some methods for classiﬁcation and analysis of
multivariate observations,” in Proc. of the ﬁfth Berkeley Symposium on
Mathematical Statistics and Probability,L.M.L.CamandJ.Neyman,
Eds., vol. 1. University of California Press, 1967, pp. 281–297.
[20] E. Chinellato, R. Fisher, A. Morales, and A. Del Pobil, “Ranking
planar grasp conﬁgurations for a three-ﬁnger hand,” in Robotics
and Automation, 2003. Proceedings. ICRA ’03. IEEE International
Conference on, vol. 1, 2003, pp. 1133–1138 vol.1.
[21] G. Metta, L. Natale, F. Nori, G. Sandini, D. Vernon, L. Fadiga, C. von
Hofsten, K. Rosander, M. Lopes, J. Santos-Victor, A. Bernardino, and
L. Montesano, “The icub humanoid robot: An open-systems platform
for research in cognitive development,” Neural Networks, vol. 23, no.
8-9, pp. 1125–1134, 2010.
[22] G. Cannata, M. Maggiali, G. Metta, and G. Sandini, “An embedded
artiﬁcial skin for humanoid robots,” in Multisensor Fusion and Inte-
gration for Intelligent Systems, 2008. MFI 2008. IEEE International
Conference on, 2008, pp. 434 –438.
[23] P. Fitzpatrick, G. Metta, and L. Natale, “Towards long-lived robot
genes,” Robot. Auton. Syst., vol. 56, no. 1, pp. 29–45, 2008.
[24] B. Siciliano and O. Khatib, Springer handbook of robotics. Springer,
2008.
[25] A. Bicchi and V. Kumar, “Robotic grasping and contact: A review,”
in Robotics and Automation, 2000. Proceedings. ICRA’00. IEEE
International Conference on, vol. 1. IEEE, 2000, pp. 348–353.
[26] T. Feix, R. Pawlik, H. Schmiedmayer, J. Romero, and D. Kragic, “A
comprehensive grasp taxonomy,” in Robotics, Science and Systems:
Workshop on Understanding the Human Hand for Advancing Robotic
Manipulation, June 2009.
[27] M. W. Marzke and K. L. Wullstein, “Chimpanzee and human grips:
A new classiﬁcation with a focus on evolutionary morphology,”
International Journal of Primatology, vol. 17, no. 1, pp. 117–139,
1996.
5351
