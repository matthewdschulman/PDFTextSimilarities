Needle Localization Using Gabor Filtering in 2D Ultrasound Images
Mert Kaya and Ozkan Bebek
Abstract— In the percutaneous needle procedures using ul-
trasound (US) imaging, the needle should be detected precisely
to avoid damage to the tissue and to get the samples from the
appropriate site. Excessive artifacts and low resolution of the
US images make it difﬁcult to detect the needle and its tip. It is
possible to enhance the needle image using image processing;
and this work proposes a novel needle detection method in 2D
US images based on the Gabor ﬁlter. This method enhances
the needle outline while suppressing the other structures in the
image. First, the needle insertion angle is estimated and then
the needle trajectory is found with the RANSAC line estimator.
The experiments with three different phantoms showed that
the algorithm is robust and could work in percutaneous needle
procedures using US images.
I. INTRODUCTION
Percutaneous needle procedures, such as biopsy and drug
delivery, are commonly used in medical practices. Visibility
of the needle plays an important role in the success of
these procedures. Particularly in biopsies, if the needle is
misplaced, erroneous samples might be collected and organs
might be punctured leading to internal bleeding. In order to
prevent such failures, the trajectory of the needle has to be
predetermined and the needle tip should be tracked using
medical imaging techniques.
Magnetic resonance imaging (MRI) provides high quality
images, however custom needles are required for needle
tracking since the commonly used biopsy needles are ferro-
magnetic. Also, MRI does not provide enough workspace for
all operations. Computed Tomography (CT) and ﬂuoroscopy
imaging can be harmful due to increased dose of radiation.
In addition, similar to MRI, the workspace of CT is limited.
Using ultrasound (US) imaging, on the other hand, the needle
can be tracked with a very small probe, and US does not
have any known side effects. However, tracking the needle
can be challenging due to lower image quality. US images
contain undesirable artifacts and reverberation effects. Image
processing algorithms can help reduce these artifacts and
increase the visibility of the needle to track needle trajectory
and its tip. The following summarizes the work done on
developing needle localization algorithms.
Draper et al. [1] used variance mapping to discriminate
the needle from the background. They used user deﬁned
This work was supported by the Scientiﬁc and Technical Research
Council of Turkey (TUBITAK) under Grant No. 112E312.
Mert Kaya is with Department of Electrical and Electronics En-
gineering, Ozyegin University, Cekmekoy, 34794 Istanbul, Turkey
mert.kaya@ozyegin.edu.tr
Ozkan Bebek is with the Department of Mechanical Engi-
neering, Ozyegin University, Cekmekoy, 34794 Istanbul, Turkey
ozkan.bebek@ozyegin.edu.tr
thresholding technique and then principal component anal-
ysis (PCA) to localize needle axis and its tip. Ding et al.
[2] used fast implementation of Hough Transform based on
course-ﬁne search to segment needle in 2D US images. Their
approach decreased the computational time and can segment
the biopsy needle in real time.
Okazawa et al. [3] used Hough transform and coordinate
transform to localize curved needles under 2D US images.
Rough insertion angle was supplied by the user for needle
segmentation. Mathiassen et al. [4] used Okawaza’s needle
segmentation method. They measured the needle’s orienta-
tion and position using an optical tracking system. From
frame differences and sudden drops in image intensity, they
extracted the needle tip position in real time. Ayvaci et al.
[5] tracked the biopsy needle in 2D transrectal US images by
applying second order Gaussian Filter. Prior knowledge of
needle’s orientation and position, image background model,
and US probe stability were used to map the needle pixels
in the image.
Neshat et al [6] modeled curved needles with Bezier poly-
nomials. The coefﬁcients of the polynomial were estimated
using Radon Transform. In order to run the algorithm in
real time, they implemented their curved needle segmenta-
tion code on a GPU. Uhercik [7] used Frangi’s [8] vessel
segmentation algorithm to ﬁlter lines in 3D US images. The
axis of the needle was determined by a robust model ﬁtting
random sample consensus (RANSAC) algorithm. The needle
tip was determined according to the sudden drop in this axis.
Aboofezali [9] segmented curved needles in 3D US images
using anti isotropic ﬁlter. This process reduced speckles in
image and remaining speckles were reduced with a spatial
contrast enhancement ﬁlter. 3D images were projected to 2D
using ray casting and then Hough transform was applied to
detect the curvilinear needle.
Barva et al. [10] localized curvilinear objects in 3D US
images. 3D US images were converted to binary images
with empirically determined threshold values. To localize
the object, they performed least square curve ﬁtting to the
data obtained by Randomized RANSAC. Barva et al. [11]
localized metal electrode from 3D US images. They applied
thresholding and then model ﬁtting RANSAC was applied
to localize curved objects.
Novotny et al. [12] used passive markers to track the
surgical instrument. They implemented their algorithm on
a GPU, running in real time. They used a modiﬁed version
of the Radon transform to detect the projection of the surgi-
cal instrument’s shaft. Their GPU implementation detected
the surgical instrument in 31 ms, sufﬁcient for real time
tracking. Stoll et al. [13] used passive markers for tracking
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 4881
surgical instruments in 3D US images. Markers’ position
were computed from 3D US image then the position and
the orientation of the surgical instrument was determined.
Fronheiser et al. [14] tracked needle with 3D color doppler
US device. They vibrated the needle at high frequency with
a piezoelectric buzzer. RF and color doppler ﬁlters were used
to detect tip of surgical devices from US images.
Vrooijink et al. [15] tracked the needle in 3D using 2D US
images. They used a speciﬁc pattern created by the biopsy
needle in the US image known as the comet tail affect (CTA).
After thresholding and morphologic operations, they found
the centroid of the needle. A motorized needle insertion
device was used to provide position feedback and estimate
the pose of the needle tip. Chatelain et al. [16] tracked
needles in 3D US images. They detected needles from
volume intensity differences, then combined their detection
method with the RANSAC and Kalman ﬁlters to track the
needle more accurately.
In this study line ﬁltering is used to develop needle
localization algorithms. Speciﬁcally, the Gabor ﬁlter [17]
is applied to detect the needle, which has not been used
in needle localization studies with US imaging before. The
Gabor ﬁlter produces much better results compared to other
ﬁltering methods because it enhances the needle’s pixel
better.
II. GABOR LINE FILTERING ALGORITHM FOR NEEDLE
LOCALIZATION
Most of the needle detection algorithms are based on
the Frangi vesselness ﬁlter [8] or some empirically and
adaptively determined thresholding methods. Even though
the Frangi’s method is one of the most common methods for
segmenting vessels, it enhances all of the tubular structures in
2D and 3D US images. Therefore, it is difﬁcult to distinguish
needles from the other structures. The empirical and adaptive
thresholding methods, on the other hand, are also commonly
used to segment needles, however, the threshold value can
vary from image to image creating discontinuities in the
appearance of needle in the US image.
Due to these shortcomings of the commonly used methods,
we propose a new ﬁltering method based on the Gabor ﬁlter
to detect biopsy needles in 2D US images [17]. The main
difference between our ﬁltering method and the others’ is
that this ﬁlter enhances the tubular structures in the direction
of the needle insertion path ﬁltering out the orthogonal
structures. As a result, the needle pixels become brighter
compared to the image background and the needle stands
out. An imaging example using the proposed ﬁlter is shown
in Fig.1.
The Gabor Filter
The Gabor ﬁlter is widely used to identify ﬁngerprint
features in literature [18], and it is also used in anatomical
structure detections such as liver and retina [19], [20]. The
Gabor ﬁlter used in this research is adapted from [19], [20].
The method consists of three parts: (1) Gabor-based line
Fig. 1. 2D US image of the needle in the phantom gel. The image on the
left contains the original US data and the image on the right is the output
of the proposed Gabor ﬁlter.
Fig. 2. Flowchart of the proposed Gabor ﬁlter based needle localization
algorithm.
ﬁltering, (2) binarization, and (3) axis localization. Steps of
the ﬁltering method is shown in Fig. 2.
The 2D Gabor ﬁlter function in the spatial domain is the
multiplication of complex carrier sinusoid and 2D Gaussian
envelope. The 2D Gabor ﬁlter function in the spatial domain
is:
g(x;y) = exp
 
 
x
02
+y
02
2
2
!
exp
 
j

2
x
0


!
(1)
where
x
0
= x cos +y sin
y
0
=  x sin +y cos
 = 0:56
where  is the standard deviation value,  is the wave-
length of modulating sinusoid and is the orientation of the
Gabor ﬁlter.
e
jx
= cos(x) +j sin(x) (2)
Using (2), the 2D Gabor ﬁlter can be rewritten as:
Refg(x;y)g = exp( 
x
02
+y
02
2
2
) cos(2
x
0

) (3)
Imfg(x;y)g = exp( 
x
02
+y
02
2
2
) sin(2
x
0

)
The line ﬁltered image I
g
(x;y) is the convolution of the
input imageI(x;y) and the imaginary part of the Gabor ﬁlter
kernel Imfg(x;y)g as in (4).
I
g
(x;y) =I(x;y)Imfg(x;y)g (4)
4882
III. ESTIMATION OF NEEDLE INSERTION ANGLE
The Gabor ﬁlter is applied in accordance with the orien-
tation angle, . In order to localize the biopsy needle in US
images, the orientation of the ﬁlter has to be equal to the
insertion angle of the needle because the best appearance of
the needle and its tip can be obtained at this angle value.
Therefore, this ﬁltering angle is consistent with the needle
insertion angle. In Fig. 4, the Gabor ﬁlter is applied to the
same image by changing the orientation angle in increments
of 30

. This image bank shows that the needle visibility is
maximized when the ﬁlter orientation angle is almost equal
to the needle insertion angle, and the artifacts in the image
created by other structures are minimized.
The angle estimation is divided into two cases base on
prior knowledge. When frame sequences are used prior
knowledge is available for the frames; when a single frame
is used such data are not available. Two different techniques
are proposed below to estimate the needle insertion angles
for both cases.
1) Estimation of the Needle Insertion Angle from a single
US image: Estimating insertion angle value in an image is
quite complicated unless the angle is known a priori. We
developed a method based on the quadrants of cartesian
coordinate system to estimate the needle insertion angle in
2D US images. With this method, a rough estimate of the
insertion angle, , is chosen ﬁrst as shown in Fig. 3(b). If
the needle trajectory is similar to the trajectories as shown
in quadrants I and III, we choose the initial insertion angle,
, as 135

, and for the quadrants II and IV , we choose as
225

. After the initial assignment, the Gabor ﬁlter is applied
with the estimated insertion angle. The needle trajectory
becomes more clear and in the next step the RANSAC line
estimator is applied, and slope of the line, m, is found. The
exact insertion angle in terms of the Gabor ﬁlter coordinate
system,, can be found more precisely at this point and then
it can be used in the Gabor ﬁlter again to localize the biopsy
needle.
Due to the nature of how US images are collected, the
coordinate frames of the needle axis and the Gabor ﬁlter are
not positioned in the same direction, as shown in Fig. 3(a).
Using (5), the exact insertion angle value is expressed in
terms of the Gabor ﬁlter coordinate system.
 =+j tan
 1
(m)j 45

(5)
Steps of the needle insertion angle estimation is depicted
in Fig. 5 for two different types of gel phantom. First, raw
images are collected ((a) and (f)). Second, a rough estimate
of the insertion angle is chosen and the Gabor ﬁlter is applied
((b) and (g)). Next, the RANSAC line estimator is applied
to get the exact insertion angle,  ((c) and (h)). Finally, the
Gabor and the RANSAC are repeated to localize the needle
and its tip ((d-e) and (i-j)).
2) Estimation of the Needle Insertion Angle in Frame
Sequences: In US image sequences (videos), the needle
insertion angle can be determined at the beginning of nee-
dle penetration and can be assumed constant afterwards.
Fig. 3. The US and needle coordinate systems. (a) Angle is shown. (b)
Possible  angles are shown for the quadrants.
(a) =0

(b) =30

(c) =60

(d) =90

(e) =120

(f) =150

(g) =180

(h) =210

(i) =240

(j) =270

(k) =300

(l) =330

Fig. 4. The output of the Gabor ﬁlter bank using the proposed line ﬁlter.
The raw image in Fig.7(a) is used. The orientation angle, , is changed in
30

increments to show the ﬁltering effects.
Therefore, the needle insertion angle,, is determined before
ﬁltering is applied. The differences in close frames can be
used to estimate the insertion angle. In general, the image
acquisition speed of the US devices are 30 frames per second
(fps). Two images that are one second apart can be used for
angle estimation assuming that the displacement of the US
probe is zero at the beginning of the needle insertion and the
tissue (phantom) doesn’t move, as shown in (6).
I
n
=I[kn] I[k(n  1)] (6)
where I is the input image, I
n
is the difference image, k
is the frame step, and n = 1,2,3,... is the frame number.
This process generates a bank of binary images. The needle
insertion angle is updated as data are collected. Initially,
we used the least square method to detect the insertion
angle by ﬁtting a line to needle pixels. However, due to
the artifacts in the image differences, the error in the angle
estimation increased dramatically. We observed that the
needle pixels obtained from the frame difference images lie
in the maximum variance region. Therefore, the principal
component analysis is used to get the best insertion angle.
4883
(a) Raw Image with agar-
gelatine mixture
(b) Gabor with  = 225

(c) RANSAC line ﬁtting at
 = 225

(d) Gabor with  = 230:44

(e) RANSAC line ﬁtting at
 = 230:44

(f) Raw Image with agar (g) Gabor with  = 135

(h) RANSAC line ﬁtting (i) Gabor with  = 122:43

(j) RANSAC line ﬁtting
Fig. 5. The order for the needle insertion angle estimation and detection in 2D US images. (a) The raw image of the needle in agar-gelatin based phantom.
(b) Gabor ﬁlter applied with estimated insertion angle = 225

. (c) RANSAC to determine needle axis. (d) Gabor ﬁlter applied at exact insertion angle
 = 230:44

. (e) RANSAC line ﬁtting to localize the needle and its tip. (f) The raw image of the needle in agar based phantom. (g) Gabor ﬁlter applied
with estimated insertion angle  = 135

. (h) RANSAC to determine needle axis. (i) Gabor ﬁlter applied at exact insertion angle  = 122:43

. (e)
RANSAC line ﬁtting to localize the needle and its tip.
Then, covariance matrix of PCA is calculated as:
 =


2
xx

2
xy

2
yx

2
yy

(7)
where

2
xy
=
N
P
i=1
(x
i
   x)(y
i
   y)
N
(8)
andx
i
andy
i
are coordinates of the white pixels in the binary
image,  x and  y are the means of x
i
and y
i
, respectively,
and N is the number of the white pixels in the sum of
difference images. Then, the corresponding eigenvector in
this direction is:
 =


(1;1)

(1;2)

(2;1)

(2;2)

(9)
The angle of major principal axis,
m
, in this direction is:

m
=
 
  tan
 1

 

(2;1)

(1;1)

!
(10)
The needle insertion angle equals to the sum of the major
principal axis in this direction and . Since the result of
tan
 1
2 [ ;],  is added to 
m
for the Gabor ﬁlter to
work:
 =
m
+: (11)
Steps of the needle insertion angle estimation for frame
sequences is shown in Fig. 6. Two images that are 30 frames
apart in a sequence are chosen. These images are binarized
and their difference is obtained (Fig. 6(c)). Then, in order
to detect the needle insertion angle, Gabor ﬁlter followed by
RANSAC line ﬁtting is applied (Fig. 6(d-e)).
IV. IMAGE BINARIZATION
After the Gabor-based line ﬁltering, image binarization
is required for line ﬁtting. Binarization is achieved in three
steps: smoothing, thresholding, and removing small particles.
The steps are explained in detail below.
1) Median Filtering: After the Gabor-based line ﬁltering
is applied, the output image contains considerable noise (Fig.
7(b)), and the image should be smoothen for thresholding
operations. Therefore, a median ﬁlter is used to smoothen
the image and reduce the noise. 77 sized kernel was used
for images and for frame sequences. In addition, this median
ﬁlter enhances the needle edges. The output of the median
ﬁlter is shown in Fig. 7(c).
2) Automatic Thresholding: Thresholding is required to
get an outline of the needle but we observed that the thresh-
old value is not constant after the median ﬁlter is applied.
Therefore, an automatic thresholding method was needed. To
determine the threshold value, Otsu’s thresholding method
[21] was used. For difference image of close frames, the
automated thresholding value was used directly. However,
threshold value obtained by Otsu’s method can binarize
excessive number of pixels as foreground for single images
because of low intensity level of needle pixels and artifacts.
In this point, RANSAC algorithm can fail. In order to prevent
failure of RANSAC algorithm and increase the success rate
of the method, Otsu’s threshold value was multiplied with
a tuned constant which was selected between 2 and 4. As
shown Fig. 7(d) and Fig. 6(c), this method can successfully
distinguish the needle pixels.
3) MorphologicOperations: After automatic thresholding
operations, a 33 square shaped structuring element mor-
phologic erosion and dilation is applied. After thresholding,
the noise is reduced with morphologic erosion. Even though
morphologic erosion reduces the noise, it deteriorates the
4884
(a) Frame number = 96 (b) Frame number = 126 (c) Frame Difference Image (d) Gabor with  = 135:34

(e) RANSAC Line Fitting
Fig. 6. The order for the needle insertion angle estimation and detection in 2D US frame sequences. (a) and (b) are raw images of the needle in agar-based
phantom. (c) The difference image after the binarization process. Smoothing, thresholding, and morphologic operations are applied respectively. (d) Gabor
ﬁlter applied at estimated insertion angle,  = 135:34

. (e) The RANSAC line ﬁtting to localize the needle.
continuity of the needle. Morphologic dilation is applied in
order to enhance the needle structure, and improve the needle
continuity. The result of morphologic operations is shown in
Fig. 7(e).
(a) Raw Image with
agar phantom
(b) Line Filtering (c) Median Filtering
(d) Otsu Thresholding (e) Morphological Op-
erations
(f) Axis Localization
(g) ROI (h) Cropped image (i) Needle Tip Local-
ization
Fig. 7. (a) Raw image acquired from agar-based phantom, (b) Gabor ﬁlter
based line ﬁltering when=119

, (c) median ﬁltering, (d) thresholding with
Otsu’s method, (e) morphological erosion and dilation, (f) axis localization
with RANSAC, (g) region of interest (ROI) when N = 6, (h) ROI image,
and (i) localize needle axis and tip.
V. NEEDLE AXIS LOCALIZATION
A. Random sample consensus (RANSAC)
The needle direction is found using the RANSAC al-
gorithm which is a robust line estimator. In the proposed
algorithm, the Gabor ﬁlter enhances the needle in the US
images and decreases the continuity of the other structures.
Therefore, the RANSAC can effectively distinguish between
the needle outline and the more apparent needle image.
B. Region of Interest
After the needle trajectory was found, a region of interest
(ROI) was selected around the needle pixels to increase the
effectiveness of the needle tip detection. This also decreased
the computation time. The coordinates of the ROI was
calculated as:
width = x
2
 x
1
height = y
2
 y
1
length =
p
width
2
+height
2
(x
s
;y
s
) =

Nheight
2length
;
Nwidth
2length

(12)
(x
f
;y
f
) = (x
1
 x
s
;y
1
+y
s
)
(x
sec
;y
sec
) = (x
1
+x
s
;y
1
 y
s
)
(x
th
;y
th
) = (x
2
+x
s
;y
2
 y
s
)
(x
ft
;y
ft
) = (x
2
 x
s
;y
2
+y
s
)
where (x
1
;y
1
); (x
2
;y
2
) are coordinates of the needle tra-
jectory obtained by the RANSAC; (x
s
;y
s
) are transla-
tion distances according to the original coordinate position;
(x
f
;y
f
); (x
sec
;y
sec
); (x
th
;y
th
); and (x
ft
;y
ft
) are the
coordinates of the rectangular ROI;N is the thickness of the
ROI in terms of pixels. The ROI was depicted as a rotated
rectangle in Fig. 7(g).
C. Needle Tip Detection
The output of the binarized Gabor ﬁlter image was cropped
according to the ROI process explained above. The largest
chunk in this image is the needle and its sharp edge is the
needle tip. An intact needle outline is not always guaranteed
at the end of this process. In these cases the needle pixels
are seen as fragmented needles which makes it difﬁcult to
distinguish the needle from the other structures. To separate
the needle from the artifacts, the distances between the
divided groups were calculated. The chunk that is the farthest
from the others is the far end of the needle and sharp edge of
this outline is the needle tip. An example needle tip detection
is given in Fig. 7(i).
VI. EXPERIMENTS
A. Experimental Setup
1) The US Machine: The images were acquired using a
LOGIQ P5 2D US machine (General Electric, USA), with
a linear 2D US probe (11L, General Electric, USA). The
acquired images were 640 480 pixels.
2) Phantom: Three different types of phantoms were used
during the needle insertion experiments. These were gelatin-
based (1 L water + 80 g gelatin powder) (Fig. 1), agar-based
(1 L water + 20 g agar + 5 ml chlorhexidine) (Fig.5.a and
4885
Fig. 7.a), and gelatin and agar mixture (1 L water + 40 g
gelatin powder + 10 g agar + 2.5 ml chlorhexidine) (Fig.
5.f) phantoms. These phantoms were prepared according to
the recipe given in [22]. The phantoms were prepared and
let to rest eight hours before the experiments to eliminate
excessive air bubbles. In the experiments, 22 gauge biopsy
needles were used.
B. Experimental Results
1) Execution Time: The algorithm was implemented in
MATLAB and run on a 64-bit Window 7 workstation, which
has an Intel Xeon E5-2620 CPU running at 2 GHz and
32 GB of RAM. 164 US images were used in trials. The
image sizes were 640480 pixels. In all of the images, the
needle trajectory was localized successfully. The execution
time of the proposed line ﬁlter method for a single image
is 0.234 0.023 seconds (mean standard deviation). We
are expecting much faster execution times, about ﬁve folds
if the algorithm is implemented to run on a GPU.
2) Results: In this study, 149 single ultrasound images,
and 15 frame sequences were used to evaluate the algorithm.
Three different types of phantoms were used to check the al-
gorithms capability to detect the needles in different contrast
levels and images with excessive extraneous structures.
For each image, Gabor ﬁlter banks with 1

increments
were generated. With these images, the results of the initial
needle insertion angle estimation were checked. In all of
the images, the algorithm successfully detected the needle
insertion axis and the needle tip. During the experiments a
goniometer was used to measure the needle insertion angle
manually with respect to the upright held ultrasound probe.
Comparable angle measurement results were obtained from
the proposed algorithm.
In this study, by mimicking real tissues, phantoms were
used speciﬁcally to prove that the proposed method can work
in a variety of US images which have distinct backgrounds.
Both heterogenous and homogenous types of phantoms were
fabricated to perform the proposed method in different kinds
of mediums. In the fabrication process, cylindrical structures
made from latex and spherical glass balls in various sizes
placed inside the phantoms randomly. In addition, some of
the phantom gels were directly cooled. Hence, they contain
air bubbles. During the imaging, despeckle ﬁlters of the
US machine were closed. Therefore, the images contain
different types of artifacts, such as mirror and reverberation
artifacts. In the acquired images, needle was suppressed by
the artifacts. In many of the images, the intensity level of
needle pixels were very close to the image background, and
also; the needle was not seen as a complete structure. The
algorithm was able to detect and localize the biopsy needle in
all of the phantoms conﬁrming the robustness of the method.
REFERENCES
[1] K. J. Draper, C. C. Blake, L. Gowman, D. B. Downey, and A. Fenster,
“An algorithm for automatic needle localization in ultrasound-guided
breast biopsies,” MedicalPhysics, vol. 27, no. 8, pp. 1971–1979, 2000.
[2] M. Ding and A. Fenster, “A real-time biopsy needle segmentation
technique using hough transform,” Medical Physics, vol. 30, no. 8,
pp. 2222–2233, 2003.
[3] S. H. Okazawa, R. Ebrahimi, J. Chuang, R. N. Rohling, and S. E.
Salcudean, “Methods for segmenting curved needles in ultrasound
images,” Medical Image Analysis, vol. 10, no. 3, pp. 330 – 342, 2006.
[4] K. Mathiassen, D. Dall Alba, R. Muradore, P. Fiorini, and O. Elle,
“Real-time biopsy needle tip estimation in 2d ultrasound images,” in
Proceedings of the IEEE International Conference on Robotics and
Automation (ICRA), no. 2. IEEE Robotics and Automation Society,
May 2013, pp. 4348–4353.
[5] A. Ayvaci, P. Yan, S. Xu, S. Soatto, and J. Kruecker, “Biopsy needle
detection in transrectal ultrasound,” Computerized Medical Imaging
and Graphics, vol. 35, pp. 653 – 659, 2011.
[6] H. Neshat and R. Patel, “Real-time parametric curved needle seg-
mentation in 3d ultrasound images,” in Biomedical Robotics and
Biomechatronics, 2008. BioRob 2008. 2nd IEEE RAS EMBS Inter-
national Conference on, 2008, pp. 670–675.
[7] M. Uhercik, J. Kybic, C. Cachard, and H. Liebgott, “Line ﬁltering
for detection of microtools in 3d ultrasound data,” in Ultrasonics
Symposium (IUS), 2009 IEEE International, 2009, pp. 594–597.
[8] A. Frangi, W. Niessen, K. Vincken, and M. Viergever, “Multiscale
vessel enhancement ﬁltering,” in Medical Image Computing and
Computer-Assisted Interventation MICCAI98. Springer Berlin
Heidelberg, 1998, vol. 1496, pp. 130–137.
[9] M. Aboofazeli, P. Abolmaesumi, P. Mousavi, and G. Fichtinger, “A
new scheme for curved needle segmentation in three-dimensional
ultrasound images,” in Proceedings of the Sixth IEEE international
conference on Symposium on Biomedical Imaging: From Nano to
Macro, ser. ISBI’09, 2009, pp. 1067–1070.
[10] M. Barva, J. Kybic, J. Mari, C. Cachard, and V . Hvalac, “Automatic
localization of curvilinear object in 3d ultrasound images,” in SPIE
International Symposium Medical Imaging, San Diego, California,
USA, Feb 2005.
[11] ——, “Localizing metal electrode from 3d ultrasound data using r-
ransac and intensity priors,” in EMBEC’05, Prague, Czech Republic,
2005.
[12] P. M. Novotny, J. A. Stoll, N. V . Vasilyev, P. J. del Nido, P. E. Dupont,
and R. D. Howe, “Gpu based real-time instrument tracking with
three dimensional ultrasound,” in Proceedings of the 9th international
conference on Medical Image Computing and Computer-Assisted
Intervention - Volume Part I, 2006, pp. 58–65.
[13] J. Stoll, H. Ren, and P. Dupont, “Passive markers for tracking surgical
instruments in real-time 3-d ultrasound imaging,” Medical Imaging,
IEEE Transactions on, vol. 31, no. 3, pp. 563–575, 2012.
[14] M. Fronheiser, S. Idriss, P. Wolf, and S. Smith, “Vibrating interven-
tional device detection using real-time 3-d color doppler,” Ultrasonics,
Ferroelectrics and Frequency Control, IEEE Transactions on, 2008.
[15] G. Vrooijink, M. Abayazid, and S. Misra, “Real-time three-
dimensional ﬂexible needle tracking using two-dimensional ultra-
sound,” in Proceedings of the IEEE International Conference on
Robotics and Automation (ICRA), no. 2. IEEE Robotics and Au-
tomation Society, May 2013, pp. 1680–1685.
[16] P. Chatelain, A. Krupa, and M. Marchal, “Real-time needle detection
and tracking using a visually served 3d ultrasound probe,” in Proceed-
ingsoftheIEEEInternationalConferenceonRoboticsandAutomation
(ICRA), no. 2. IEEE Robotics and Automation Society, May 2013,
pp. 1668–1673.
[17] I. Fogel and D. Sagi, “Gabor ﬁlters as texture discriminator,” Biolog-
ical Cybernetics, vol. 61, no. 2, pp. 103–113, 1989.
[18] C.-J. Lee and S.-D. Wang, “Fingerprint feature extraction using gabor
ﬁlters,” Electronics Letters, vol. 35, no. 4, pp. 288–290, 1999.
[19] C. Vicas, M. Lupsor, R. Badea, and S. Nedevschi, “Detection of
anatomical structures on ultrasound liver images using gabor ﬁlters,”
in Automation Quality and Testing Robotics (AQTR), 2010 IEEE
International Conference on, vol. 2, 2010, pp. 1–5.
[20] R. Rangayyan, F. Oloumi, F. Oloumi, P. Eshghzadeh-Zanjani, and
F. Ayres, “Detection of blood vessels in the retina using gabor
ﬁlters,” in Electrical and Computer Engineering, 2007. CCECE 2007.
Canadian Conference on, 2007, pp. 717–720.
[21] N. Otsu, “A Threshold Selection Method from Gray-level Histograms,”
IEEE Transactions on Systems, Man and Cybernetics, vol. 9, no. 1,
pp. 62–66, 1979.
[22] J. W. Li, M. K. Karmakar, X. Li, W. H. Kwok, and W. D. N. Kee,
“Gelatin-agar lumbosacral spine phantom: A simple model for learning
the basic skills required to perform real-time sonographically guided
central neuraxial blocks,” Journal of Ultrasound in Medicine, vol. 30,
no. 2, pp. 263–272, 2011.
4886
