Learning Predictive Models of a Depth Camera & Manipulator
from Raw Execution Traces
Byron Boots Arunkumar Byravan Dieter Fox
Abstract—In this paper, we attack the problem of learn-
ing a predictive model of a depth camera and manipulator
directly from raw execution traces. While the problem of
learning manipulator models from visual and proprioceptive
data has been addressed before, existing techniques often rely
on assumptions about the structure of the robot or tracked
features in observation space. We make no such assumptions.
Instead, we formulate the problem as that of learning a high-
dimensional controlled stochastic process. We leverage recent
workonnonparametricpredictivestaterepresentationstolearn
a generative model of the depth camera and robotic arm
from sequences of uninterpreted actions and observations. We
perform several experiments in which we demonstrate that
our learned model can accurately predict future depth camera
observations in response to sequences of motor commands.
I. INTRODUCTION
One of the most fundamental challenges in robotics is
the general identiﬁcation problem [1]
1
: a robot, capable of
performing a set of actionsa 2 A and receiving observations
o 2 O, is placed in an unknown environment. The robot
has no interpretation for its actions or observations and no
knowledge of the structure of the environment (Fig. 1).
The problem is to program the robot to learn about its
observations, actions, and environment well enough to make
predictionsoffutureobservationsgivensequencesofactions.
In other words, the goal is to learn a generative model of the
observations directly from raw execution traces.
In this paper we investigate an instance of the general
identiﬁcationproblem:Arobotobservesamanipulatorunder
its control with a Kinect RGB-D camera. The goal is to
learn a generative model of RGB-D observations as the robot
controls its manipulator (Figure 2).
While the problem of learning manipulator models, or
body schemas, from visual and proprioceptive modalities
has been addressed before, existing techniques rely critically
on assumptions about the kinematic structure of the robot
and tracked features in observation space [2]–[5]. Here, we
address this problem in its most challenging instance: The
observations are streams of raw depth images (1.2 million
pixels), and the robot has no prior knowledge about what it
is controlling.
Byron Boots, Arunkumar Byravan, and Dieter Fox are with the Depart-
mentofComputerScienceandEngineering,UniversityofWashington,Seat-
tle, WA 98195 {bboots,barun,fox}@cs.washington.edu
This work was supported in part by ONR MURI grant number N00014-09-
1-1052 and by the National Science Foundation under contract NSF-NRI
1227234.
1
The general identiﬁcation problem was ﬁrst proposed by Ron Rivest in
1984 and originally called the Critter Problem
Uninterpreted 
Observations
Uninterpreted 
Actions
Unknown 
Environment
Unknown
Sensors
Unknown
Dynamics
Robot
o a
Fig. 1. The problem setup. The robot has access to uninterpreted streams
of continuous observations and actions. We do not make any assumptions
about the observations that the robot receives, the actions the robot can
execute, or the structure of the environment.
We approach this difﬁcult problem from a machine learn-
ing perspective. We dispense with problem-dependent geo-
metric and physical intuitions and instead model the senso-
rimotor data as a Predictive State Representation (PSR) [6],
[7], a general probabilistic modeling framework that can rep-
resent a wide variety of stochastic process models including
Kalmanﬁlters(KFs)[8],inputoutputhiddenMarkovmodels
(IO-HMMs) [9], [10], and nonparametric dynamical system
models [11].
The main contribution of our work is to show that a
recent nonparametric variant of PSRs, called Hilbert Space
Embeddings of PSRs, can learn a generative model of the
RGB-D camera and robotic arm directly from sequences
of uninterpreted actions and observations. This problem is
far more difﬁcult than the simulated problems explored
in previous PSR work [10], [12]–[14]. Additionally, the
manipulator used in our experiments has many additional
degrees of freedom compared to the systems considered in
recent work on bootstrapping in robotics [15]–[17].
Werunseveralexperimentsthatshowqualitativeexamples
of our learned model tracking the current state of the system
and predicting future RGB-D images given motor com-
mands. We also provide rigorous quantitative results which
demonstrate that our learned model is more accurate than
competing nonparametric methods at tracking and predicting
RGB-D observations given previously unseen sequences of
motor commands. To the best of our knowledge this is the
ﬁrstworktolearnamodelofadepthcameraandmanipulator
directly from raw execution traces.
II. RELATED WORK
Variations of the general identiﬁcation problem are central
to several ﬁelds of research, although the assumptions made
by different communities are often very different.
In the controls community, the problem of inferring the
unknown parameters of an input-output system is called
system identiﬁcation [18]–[20]. The system can be deter-
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 4021
0 1000
C.
D.
7-DOF
Example Motor Commands
A. B. RGB Depth
Joint 1
Joint 2
Joint 3
Joint 4
Joint 5
Joint 6
Joint 7
?1
0
1
Timesteps
Fig. 2. Observations and Actions. The robot receives sense data from
a Kinect RGB-D depth camera, but has no knowledge of the geometry
of the scene or the physics of the camera. The robot can control a 7–
degree-of-freedom Barrett WAM arm, but has no a priori knowledge of
the geometry, kinematics, or any aspects of the action space of the arm.
(A) An example 640? 480? 3 RGB image. (B) An example 640? 480 depth map. Darker indicates increased distance. Together, the RGB-
D observation vector has 1228800 elements. (C) The 7 degree-of-freedom
arm.Eachactionisacontinuous-valued7-dimensionalvector.(D)Examples
ofactionsexecuted:1000continuousmotorencodervaluesfromthetraining
data set. (See Section V for details)
ministic, stochastic, or combined. Usually, either the form
of the system (linear, bilinear, etc.), the state space, or the
dynamics are assumed to be known in advance. If the system
has a stochastic component, the noise is generally assumed
to be sampled from a Gaussian distribution.
The robotics community has typically approached the
problem of learning a generative model of sensor data, called
bootstrapping, from a deterministic viewpoint, focusing on
the geometry and kinematics of the observation and action
spaces. Proposed solutions have focused on the topology of
the environment [21], the manifold structure of observation
space [22], or diffeomorphisms that describe the effect of
taking actions [17]. Although these approaches have been
developed speciﬁcally for robotic systems, they often make
very strong assumptions about the form of (or lack of)
stochasticity, the observability of the state space, or the geo-
metric structure of the observations, actions, or environment.
The bootstrapping problem can also be viewed as an
extremeformofsystemidentiﬁcationorself-calibration[15].
And,overthelastseveralyears,substantialprogresshasbeen
made on these problems. For example: learning complex
nonlinear forward kinematics to predict the consequences of
actions [23], [24], or learning body schemas that integrate
the visual and proprioceptive modalities to discover the
kinematicstructureofarobot[2]–[4].Whilethesetechniques
are able to learn accurate models, they rely heavily on
assumptions about the kinematic structure of the robot and
tracked features in visual space.
In the machine learning community, where probabilistic
models play a central role, the identiﬁcation problem is typ-
ically concerned with learning the parameters of a controlled
stochastic process that generated the observations [11], [25],
[26]. Predictive State Representations (PSRs) [6], [7] are an
example of such a stochastic process model.
PSRs were originally developed in the reinforcement
learning community and explicitly designed to solve the
general identiﬁcation problem. They have several advantages
over previous approaches to bootstrapping in robotics. First,
PSRs are more expressive than methods like the Spatial
Semantic Hierarchy [21] and Diffeomorphism models of
sensorimotor cascades [17], and the theory behind PSRs
is mature: their subsumption of popular classes of latent
variable models is well understood [7]. Second, PSR models
are easy to learn. Popular latent variable models of stochastic
processes are often learned using heuristics such as Expecta-
tion Maximization (EM), which suffer from bad local optima
and slow convergence rates. Recent PSR learning algorithms
rely on spectral methods [10], [27] and kernel methods [11]
which are statistically consistent.
Unfortunately, evaluation of PSRs have long been re-
stricted to learning fairly simple “grid-world” type simulated
environments [10], [12]–[14], a fact which has lead to the
perception that PSRs are not ﬂexible enough, or that PSR
learning algorithms are not efﬁcient enough, to represent
high-dimensional raw sensorimotor data [17]. However, in
the last few years PSRs and PSR-like models have experi-
enced a marked resurgence as increasingly powerful learning
algorithms have been developed [10], [11], [27]–[29].
III. PREDICTIVE STATE REPRESENTATIONS
We begin by providing a brief overview of predictive
state representations [7], [10] which we use as a generic
framework for tackling the general identiﬁcation problem.
A. Predictive State
A PSR represents the state of a dynamical system as a set
of predictions of experiments or tests that can be performed
in the system. A test of length N is an ordered sequence of
future action-observations pairs ? = a
1
,o
1
,...a
N
,o
N
that
can be selected and observed at any time t.
A test ? i
is executed at time t if we intervene [30] to
select the sequence of actions speciﬁed by the test ? A
i
=
a
1
,...,a
N
.Atestissaidto succeed attimetifitisexecuted
andthesequenceofobservationsinthetest? O
i
= o
1
,...,o
N
matches the observations generated by the system. The
prediction for test i at time t is the probability of the test
succeeding given a history h
t
and given that we execute it:
2
P
?
? O
i,t
|? A
i,t
,h
t
?
(1)
2
For simplicity, we assume that all probabilities involving actions refer
to our PSR as controlled by an arbitrary blind or open-loop policy [31].
4022
ThekeyideabehindaPSRisthatifweknowtheexpected
outcomes of executing all possible tests, then we know
everything there is to know about the state of a dynamical
system [7]. In practice we will work with the predictions of
some set of tests. Let T ={? i
} be a set of d tests, then
s(h
t
)=
 
P
?
? O
i,t
|? A
i,t
,h
t
? 
d
i=1
(2)
is the prediction vector of success probabilities for the tests
? i
2 T given a history h
t
.
Knowingthesuccessprobabilitiesofsometestsmayallow
us to compute the success probabilities of other tests. That
is, given a test ? l
and a prediction vector s(h
t
), there may
exist a prediction function f
? l
such that P
?
? O
l
|? A
l
,h
t
?
=
f
? l
(s(h
t
)). In this case, we say s(h
t
) is a sufﬁcient statistic
forP
?
? O
l
|? A
l
,h
t
?
.A core set of tests is a set whose predic-
tion vector s(h
t
) is a sufﬁcient statistic for the predictions
of all tests ? l
at time t. Therefore, s(h
t
) is a state for a PSR.
B. Bayes Filtering
After taking action a and seeing observation o, we can
update the predictive state s(h
t
) to the state s(h
t+1
) using
Bayes’rule.ThekeyideaisthatthesetoffunctionsF allows
us to predict any test from our core set of tests.
The state update proceeds as follows: ﬁrst, we predict the
success of any core test ? i
prepended by an action a and an
observation o, which we call ao? i
, as a function of our core
test predictions s(h
t
):
P
?
? O
i,t+1
,o
t
=o|? A
i,t+1
,a
t
=a,h
t
?
= f
ao? i
(s(h
t
)) (3)
Second, we predict the likelihood of any observation o given
that we select action a (i.e., the test ao):
P[o
t
= o| a
t
= a,h
t
]= f
ao
(s(h
t
)) (4)
After executing action a and seeing observation o, Equa-
tions 3 and 4 allow us to ﬁnd the prediction for a core test
? i
from s(h
t
) using Bayes’ Rule:
s
i
(h
t+1
)=
f
ao? i
(s(h
t
))
f
ao
(s(h
t
))
(5)
This recursive application of Bayes’ rule to the predictive
belief state is an instance of a Bayes ﬁlter.
The predictive state and the Bayes’ rule state update
together provide a very general framework for modeling
dynamical systems. In the next section we show how a
recent variant of PSRs can be used to learn models of
dynamicalsystemswithhigh-dimensionalcontinuousactions
and observations.
IV. HILBERT SPACE EMBEDDINGS OF PSRS
PSRsgenerallyeitherassumesmalldiscretesetsofactions
A and observations O along with linear prediction func-
tions f
? 2 F [10], or if the actions and observations are
continuous, they assume Gaussian distributions and linear
functions [8]. Researchers have relied heavily on these as-
sumptionsinordertodevisecomputationallyandstatistically
efﬁcient learning algorithms. Unfortunately, such restrictions
can be particularly unsuitable for robotics applications.
Instead, we consider a recent generalization of PSRs for
continuous actions and observations called Hilbert Space
Embeddings of PSRs (HSE-PSRs) [11]. The essence of the
method is to represent probability distributions of tests, ob-
servations,andactionsaselementsinaHilbertspaceoffunc-
tions, deﬁned through a chosen kernel. The distributions are
learned nonparametrically from samples and no assumptions
are made about the shape of the underlying distributions.
This results in an extremely ﬂexible model. A HSE-PSR
is capable of modeling non-linear dynamics and estimating
multi-modal distributions for continuous or discrete random
variables without having to contend with problems such as
densityestimationandnumericalintegration.Duringﬁltering
these points are conceptually updated entirely in Hilbert
space using a kernel version of Bayes’ rule. In practice, the
“kernel trick” is leveraged to represent the state and required
operatorsimplicitlyandtomaintainastatevectorwithlength
proportional to the size of the training dataset.
In the following subsections, we provide a very brief
overview HSE-PSRs. We ask the reader to refer to [11] for
a more complete treatment.
A. Hilbert Space Embeddings of Distributions
Let F be a reproducing kernel Hilbert space (RKHS)
associated with kernel K
X
(x,x
0
)
def
=
?
  X
(x),  X
(x
0
)
?
F
for
x 2 X. Let P be the set of probability distributions on
X, and X be a random variable with distribution P 2 P.
Following Smola et al. [32], we deﬁne the mean map (or
the embedding) of P 2 P into RKHS F to be µ
X
def
=
E
?
  X
(X)
?
.A characteristic RKHS is one for which the
mean map is injective: that is, each distribution P has
a unique embedding [33]. This property holds for many
commonly used kernels including the Gaussian RBF kernel
when X =R
d
. Given i.i.d. observations x
t
, t=1...T, an
estimate of the mean map is:
ˆ µ
X
def
=
1
T
T
X
t=1
  X
(x
t
)=
1
T
? X
1
T
(6)
where ? X
def
=(  X
(x
1
),...,  X
(x
T
)) is the linear operator
which maps the tth unit vector of R
T
to   X
(x
t
).
Below, we’ll sometimes need to embed a joint distribution
P[X,Y]. It is natural to embedP[X,Y] into a tensor product
RKHS: let K
Y
(y,y
0
)=
?
  Y
(y),  Y
(y
0
)
?
G
be a kernel onY
with associated RKHS G. Then we write µ
XY
for the mean
map of P[X,Y] under the kernel K
XY
((x,y),(x
0
,y
0
))
def
=
K
X
(x,x
0
)K
Y
(y,y
0
) for the tensor product RKHS F ? G.
We also deﬁne the uncentered covariance operator C
XY
def
=
E
XY
?
  X
(X)?   Y
(Y)
?
. Both µ
XY
andC
XY
represent the
distributionP[X,Y]. One is deﬁned as an element ofF? G,
and the other as a linear operator from G to F, but they
are isomorphic under the standard identiﬁcation of these
spaces [34], so we abuse notation and write µ
XY
= C
XY
.
Given T i.i.d. pairs of observations (x
t
,y
t
), deﬁne ? X
=
 
  X
(x
1
),...,  X
(x
T
)
 
and ? Y
=
 
  Y
(y
1
),...,  Y
(y
T
)
 
.
Write ? ? for the adjoint of ? . Analogous to (6), we can
estimate
4023
b
C
XY
=
1
T
? X
? Y
? . (7)
B. Kernel Bayes’ Rule
We now deﬁne the kernel mean map implementation of
Bayes’ rule (called the Kernel Bayes’ Rule, or KBR). In
particular, we want the kernel analog of P[X |y,z]=
P[X,y| z]/P[y| z]. In deriving the kernel realization of
this rule we need the kernel mean representation of a condi-
tional joint probabilityP[X,Y | z]. Given Hilbert spacesF,
G,andHcorrespondingtotherandomvariablesX,Y,andZ
respectively, P[X,Y | z] can be represented as a mean map
µ
XY|z
def
= E
?
  X
(X)?   Y
(Y)| z
?
or the corresponding
operatorC
XY|z
. Under some assumptions [34], this operator
satisﬁes:
C
XY|z
= µ
XY|z
def
= C
(XY)Z
C
  1
ZZ
  (z) (8)
Here the operator C
(XY)Z
represents the covariance of the
random variable (X,Y) with the random variable Z.We
now deﬁne KBR in terms of conditional covariance opera-
tors [34]:
µ
X|y,z
=C
XY|z
C
  1
YY|z
  (y) (9)
To use KBR in practice, we need to estimate the
operators on the RKHS of (9) from data. Given
T i.i.d. triples (x
t
,y
t
,z
t
) from P[X,Y,Z], write ? X
=
 
  X
(x
1
),...,  X
(x
T
)
 
, ? Y
=
 
  Y
(y
1
),...,  Y
(y
T
)
 
, and
? Z
=
 
  Z
(z
1
),...,  Z
(z
T
)
 
. We can now estimate the
covariance operators
b
C
XY|z
and
b
C
YY|z
via Equation 8 and
then apply KBR via Equation 9. We express this process
with Gram matrices, using a ridge parameter   that goes to
zero at an appropriate rate with T [34]:
? z
= diag((G
Z,Z
+  TI)
  1
? Z
?   Z
(z)) (10)
c
W
X|Y,z
=? X
(? z
G
Y,Y
+  TI)
  1
? z
? Y
? (11)
b µ
X|y,z
=
c
W
X|Y,z
  Y
(y) (12)
where G
Y,Y
def
= ? Y
? ? Y
has (i,j)th entry K
Y
(y
i
,y
j
),
and G
Z,Z
def
= ? Z
? ? Z
has (i,j)th entry K
Z
(z
i
,z
j
). The
diagonal elements of ? z
weight the samples, encoding the
conditioning information from z.
C. Nonparametric Representation of PSRs
WenowuseHilbertspaceembeddingstorepresentpredic-
tive states and kernel Bayes’ rule to update the distributions
given a new action and observation.
1) Parameters: HSE-PSR models are represented non-
parametrically as Gram matrices of training data. Given
T +1 i.i.d. tuples of actions, observations, and histories
{(a
t
,o
t
,h
t
)}
T
t=1
generated by a controlled stochastic pro-
cess, we denote
? A
def
=
 
  A
(a
1
),...,  A
(a
T
)
 
(13)
? O
def
=
 
  O
(o
1
),...,  O
(o
T
)
 
(14)
along with Gram matrices G
A,A
= ? A
? ? A
and G
O,O
=
? O
? ? O
. We also deﬁne test embeddings
? T
def
=
 
  T
(h
1
),...,  T
(h
T
)
 
(15)
? T
0
def
=
 
  T
(h
2
),...,  T
(h
T+1
)
 
(16)
along with Gram matrices G
T,T
= ? T
? ? T
and G
T,T
0 =
? T
? ? T
0
. Here primes indicate tests shifted forward in time
by one step. The Gram matrices are the parameters for our
nonparametric dynamical system model. We will use them
below in order to create an initial feasible state as well as
update the state with KBR.
2) Estimating a Feasible State: We estimate an initial
feasible state S
? for the HSE-PSR as the mean map of the
stationary distributions of tests? T
? h? where
? h? =
1
T
1
T
(17)
Therefore,theinitialstateisthevector? h? withlengthequal
to the size of the training dataset.
3) Gram Matrix State Updates: Given a HSE-PSR state
? t
, kernel Bayes’ rule is applied to update state given a new
action and observation. Updating consists of several steps.
The ﬁrst step is extending the test distribution [11]. A
transition function which accomplishes this is computed
(G
T,T
+  TI)
  1
G
T,T
0. The transition is applied to the state
ˆ ? t
=(G
T,T
+  TI)
  1
G
T,T
0? t
(18)
resulting in a weight vector ˆ ? t
encodes the embeddings of
the extended test predictions at time t.
Given a diagonal matrix? t
= diag(ˆ ? t
), and a new action
a
t
, we can condition the embedded test predictions by right-
multiplying
? a
t
=? t
(G
A,A
+  TI)
  1
? A
?   A
(a
t
) (19)
The weight vector ? a
t
encodes the embeddings of the ex-
tended test predictions at time t given action a
t
.
Next, given a diagonal matrix? a
t
= diag(? a
t
), and a new
observation o
t
, we apply KBR to calculate the next state:
? ao
t
=(? a
t
G
O,O
+  TI)
  1
? a
t
? O
?   O
(o
t
) (20)
This completes the state update. The nonparametric state at
time t+1 is represented by the weight vector ? t+1
= ? ao
t
.
We can continue to ﬁlter on actions and observations by
recursively applying Eqs. 18–20.
V. MODELING A DEPTH CAMERA&MANIPULATOR
A. The Experimental Setup
In this work, we seek to enable a robotic system to
autonomously learn a generative model of RGB-D images
collected from a depth camera that observes the robot’s
manipulation space. Our robot consists of a Kinect depth
camera observing a Barrett WAM arm located approximately
1.5 meters away. The robot can execute actions and receive
observations at a rate of 30 frames per second.
Ateachpointintime,therobotexecutesamotorcommand
to each of the 7 active joints in the arm (see Figure 2(B)).
4024
A.
B.
Encoder Error (deg.)
Joint Position (deg.)
-1.0
-0.5
0.0
1.0
0.5
0 50 100 150
lower torque
higher torque
Fig. 3. Motor encoder and kinematic error. (A) Motor encoder error caused
by cable stretch in Joint 4 of the WAM arm. The motor encoder returns joint
position estimates that deviate from the true joint positions as a stochastic
function of torque. The higher the torque, the more the motor encoders err.
(B) The arm in four conﬁgurations. In each conﬁguration, the encoders and
forward kinematics erroneously predict the same hand pose. To show the
deviation, a ball is attached to the end effector. The center-to-center distance
between the two farthest ball positions is approximately 8 cm. (Figure in
(B) from [35])
For each joint, the motor command speciﬁes a desired
joint conﬁguration. The exact movement is a function of
the commanded target conﬁguration and the controller’s
estimate of the current joint position as provided by the
arm’s motor encoders. After executing a motor command,
the robot receives an RGB-D observation from the depth
camera. Each observation is a vectorized 640? 480? 3 pixel
RGB image and a time-aligned 640? 480 pixel depth map
(see Figure 2(A)).
If the motor encoders and RGB-D images were accurate
enough, then it would be possible to precisely specify a
generative model of the RGB-D images given the true
conﬁguration of the arm joints and known geometry and
kinematics. Unfortunately, this is not the case. Both the
actions and observations contain error due to unmodeled
physics in the arm’s movements, inaccuracies in the motor
encoders, and limitations of the depth camera.
An important example of unmodeled physics is cable
stretch. The WAM am is driven by cables which wind and
unwind as the arm moves. Under differing torques, the cables
are wound with differing tensions causing inaccuracies in the
joint angles reported by the motor encoders (Figure 3(A)).
Thisresultsinhysteresisinthereportedanglesandultimately
in inaccurate predictions of the arm’s location in 3D space
(Figure 3(B)).
Many of the factors contributing to inaccuracies in the
sensor and robot arm can be mitigated by building higher
precision parts. However, for many cheaper robots, at least
some form of error is likely to affect actions and observa-
tions. Modeling a robot as a stochastic process is a natural
framework for contending with these errors.
B. Learning the Model
1) Data Collection: The training data consisted of vec-
torized RGB-D observations in response to motor babbling:
we randomly moved the arm at different velocities to po-
sitions randomly sampled from a uniform distribution in
the 7D conﬁguration space (with some velocity and joint-
limit constraints). We collected a long execution trace of
30,000 actions and observations; or roughly 16 minutes of
data. This data was used as training data for our HSE-PSR
algorithm. A sequence of 2000 similarly collected actions
and observations were held out as test data.
This is a very large quantity of training data. Previous
work on learning HSE-PSRs learned models from ? 500
training data samples [11]. The quantity of training data was
kept low in these prior experiments due to the computational
complexity in learning, predicting, and ﬁltering, each of
whichisO(T
3
)inthenumberofsamples.Giventhephysical
complexity of the robot considered here, it would be very
difﬁcult to learn an accurate model from so few training
examples (500 samples is ? 15 seconds of data). To over-
come this problem, we use a standard trick for computing
a sparse representation of Hilbert space embeddings via an
incomplete Cholesky approximation [36], [37]. This reduced
the computational complexity of our state updates from an
intractable 30000
3
to a more reasonable 1000
3
.
2) State: The core component of our dynamical system
model is the predictive state. We model the robot with 1-step
tests. That is, each test is an action-observation pair ? =
a
1
,o
1
that can be executed and observed at each time t. The
state of the robot is, therefore, the probability distributions
of the next RGB-D images in response to motor commands:
P[o
t
| a
t
,h
t
].
The predictive distributions are represented nonparamet-
rically as Hilbert space embeddings. The Gram matrices
G
O,O
,G
A,A
,G
T,T
and G
T,T
0 were computed using Gaus-
sian RBF kernels and bandwidth parameters set by the
median of squared distance between training points (the
“median trick”) [28]. Finally, the initial state was set to the
stationary distribution of observations given our data collec-
tion policy: ? h? =
1
T
1
T
(Eq. 17). Given these parameters
and Eqs. 18–20, we can ﬁlter and predict observations from
our model.
3) Predicting: We have described above how to implicitly
maintain the PSR state nonparametrically as a set of weights
on training data. However, our ultimate goal is to make
predictions about future observations. We can do so with
mean embeddings: for example, given the extended state
ˆ ? t
(Eq. 18) at some history h
t
, we ﬁll in an action using
Eq. 19 to ﬁnd the mean embedding of the distribution of
observations:
µ
O|ht,at
=? O
? a
t
(21)
Once we have the embedding of the predictive distribution,
we have two options for efﬁciently computing a prediction.
4025
Expected Observation MAP Observation Actual Observation
Predicted Observations at Time t=195 Predicted Observations at Time t=930
Fig. 4. Example predictions from the learned HSE-PSR model. We can calculate the expected observation or the Maximum A Posteriori observation
from an embedding of the probability distribution over the next observation given that we take a speciﬁc action. The two columns on the left show the
two predictions after ﬁltering for 195 time steps. The two columns on the right show the two predictions after ﬁltering for 930 time steps. The bottom row
shows the actual observation. The expected observation is the weighted average of many images in the training data set. The MAP observation is the the
highest probability observation in the training data set. Both are able to predict the actual observation well.
We can either compute the maximum a posteri (MAP) obser-
vationfromtheembeddeddistributionorwecancomputethe
expected observation. The MAP observation is computed:
ˆ o = argmax
o
?
µ
O|h,a
,  O
(o)
?
However, the number of possible observations for our robot
isverylarge,sothismaximizationisnottractableinpractice;
instead, we approximate it by using the standard approach
of maximizing over all observations in the training set [11].
We can also compute the expectation of our embedded
distribution of observations. Since the mean embedding µ
X
satisﬁes E
X
[f(x)] = hf,µ
X
i for any f in our RKHS, we
can write ? i
(o
t
) for the function which extracts the ith
coordinate of an observation. If these coordinate projections
are in our RKHS, we can computeE[o
t
|h
t
,a
t
], the expected
observation, by computing the inner product
?
? i
,µ
O|ht,at
?
for all i. Examples of MAP and expected observations
calculated from embedded tests are shown in Figure 4.
VI. QUANTITATIVE RESULTS
We designed several experiments to illustrate the behavior
of the HSE-PSR and to rigorously evaluate the learned
model’s predictive accuracy. All evaluations are performed
on heldout data consisting of random trajectories that were
never observed in the training data.
Speciﬁcally, we studied the ﬁltering or tracking perfor-
mance of the model as the robot executes motor commands
and receives RGB-D observations. We also studied the
long-range predictive accuracy of the model in response to
sequences of motor commands.
Finally, we compared the learned HSE-PSR model to
several nonparametric function approximation methods for
mapping motor commands directly to observations. We show
thatthelearneddynamicalsystemmodelgreatlyoutperforms
the non-dynamic methods by learning to accurately track the
state of the robot.
A. Filtering Accuracy
First we studied the ﬁltering performance of the HSE-
PSR. As the learned model executes actions and receives
observations, the model’s prediction accuracy should in-
crease. Additionally, the process of ﬁltering should help to
overcome error in the reported joint angles and observations
(see Section V-A), leading to more accurate predictions than
models which do not take history into account.
To test this hypothesis, we performed ﬁltering over se-
quences of 100 actions and observations, comparing the pre-
dictive accuracy of the model as measured by mean squared
error (MSE) in the prediction of the next observation given
the current action. We then compared to a baseline provided
by kernel regression from motor commands to observations.
WetrainedkernelregressiononthesamedatasetastheHSE-
PSR and used Gaussian RBF kernels. The squared error of
the predictions was averaged over 1000 trials (Figure 5(A)).
As expected, the model quickly incorporates information
from the actions and observations to accurately track the
state of the system. 1-step predictions indicate that the model
4026
C.   Filtering (expected depth images)
t = 1 t = 2 t = 4 t = 8 t = 16
D.   Predicting (expected depth images)
A. B.
MSE
Filtering Error Long-range Prediction Error
x 10
4
x 10
4
10 20 30 40 50 60 70 80 90 100 10 20 30 40 50 60 70 80 90 100
1.5
2.5
3.5
1.5
2.5
3.5
t = 1 t = 2 t = 4 t = 8 t = 16
Kernel Regression
HSE-PSR
Kernel Regression
HSE-PSR
Fig. 5. Accuracy of the learned model. Mean Squared Error (MSE) is computed by taking the squared difference between predicted and true depth maps
(at the pixel level) for 1000 experiments. (A.) Filtering for 100 time steps starting from the stationary distribution. The graph shows the mean squared
error in the prediction of the next observation given that we take a speciﬁed action. The HSE-PSR model decreases its prediction error over time, and,
once it is accurately tracking the system, is able to substantially outperform kernel regression which does not model dynamics. (B.) Predicting forward
100 time steps. After ﬁltering, we used the learned model to predict 100 time steps into the future using only actions (no observations). The graph shows
the mean squared error of these predictions. Prediction error increases over time until the prediction accuracy is close to the accuracy of kernel regression.
This shows that long rang predictions are no worse than kernel regression and short term predictions are much more accurate. (C.) Example of ﬁltering:
The distribution of observations becomes more concentrated as the robot begins to accurately track its state. (D.) Example of long-range predictions: The
distribution of observations becomes more uniform as the robot’s uncertainty increases over time.
soundly outperforms kernel regression while tracking. An
example of expected depth maps during ﬁltering is shown
in Figure 5(C). The sharpening of the predicted images
indicates that the variance of the embedded distribution is
shrinking.
B. Long-range Prediction Accuracy
Next we consider the motivating problem of this paper:
Can we make accurate long range predictions of what
the depth camera will see given that the robot executes
a sequence of motor commands? We expect the predictive
performance of the model to degrade over time, but long
range prediction performance should not be worse than non-
parametric regression models which do not take history or
dynamics into account.
To test this hypothesis, we performed ﬁltering for 1000
different extents t
1
= 101,...,1100, and then predicted ob-
servations a further t
2
steps in the future, for t
2
=1,...,100,
using the given sequence of actions. We then averaged the
squared prediction error over all t
1
. Again, we compared to
kernel regression with Gaussian RBF kernels learned on the
training data set. The squared error of the predictions was
averaged over 1000 trials (Figure 5(B)).
The prediction accuracy of the learned model degrades
over time, as expected. However, the model continues to
produce predictions that are more accurate than kernel re-
gression at 100 time steps into the future. An example
of expected depth map during prediction is shown in Fig-
ure 5(D). The blurring of the expected images indicates that
the variance of the embedded distribution is growing.
C. MAP vs. Expectation
In the previous experiments we measured prediction accu-
racy by looking at the expected observation given the HSE-
PSR state. We then compared this prediction with the result
of kernel regression which can be interpreted as the expected
observation given a motor command.
It often makes sense to consider the MAP observation
instead of the expected observation. (For a visual compari-
son, see Figure 4). For example, if the predictive distribution
is multimodal, then the MAP observation may result in a
more accurate prediction. Or, if we require a visualization
of the predictions, then MAP observations may provide a
qualitatively better looking prediction.
We compared four methods, the expected and MAP ob-
servation from our model as computed by Section V-B.3, as
well as their nonparametric regression counterparts: kernel
regression and nearest neighbor regression. The results are
shown in Figure 6. First, the results indicate that the HSE-
PSR produces much better predictions than the nonparamet-
4027
0 MSE 8x10
4
Filtering (Expectation)
Filtering (MAP)
Kernel Regression
1-NN
Comparison of Different Approaches: 1-Step Prediction Error
Fig. 6. Comparison of nonparametric approaches to predicting RGB-
D images. Mean Squared Error (MSE) computed by taking the squared
difference between predicted and true depth maps (at the pixel level) for
1000 experiments.
ric regression approaches. This result is likely attributable to
inacuracies in the motor commands. Second, the expected
observations have higher predictive accuracy than MAP
observations. This is likely due to the fact that the action and
observationspacesarehigh-dimensionaland(approximately)
continuous. Since the MAP approaches are calculated with a
limited set of training samples, we cannot expect to always
have access to an observation in the training data set that is
very close to the observation that we wish to predict.
VII. CONCLUSION
In this paper we consider the problem of learning a
predictive model of a depth camera and manipular directly
from execution traces of RGB-D observations and motor
commands. We make as few assumptions about the system
as possible: the robot has no knowledge of its manipulator
and its goal is to predict raw observations. The fundamental
idea is to formulate the problem as learning a controlled
stochastic process and leverage recent work on Hilbert space
embeddings of predictive state representations in order to
learn the model. In real-world experiments, we showed that
our approach was able to handle high-dimensional data, to
learn complex nonlinear dynamics, and to overcome error
in the motor controller and depth camera to make accurate
predictions.
REFERENCES
[1] B. Kuipers, “The map-learning critter,” Tech. Rep., 1985.
[2] M. Hersch, E. L. Sauser, and A. Billard, “Online learning of the body
schema.” I. J. Humanoid Robotics, vol. 5, no. 2, pp. 161–181, 2008.
[3] J. Sturm, C. Plagemann, and W. Burgard, “Unsupervised body scheme
learning through self-perception.” in ICRA. IEEE, 2008, pp. 3328–
3333.
[4] ——, “Body schema learning for robotic manipulators from visual
self-perception,” Journal of Physiology-Paris, vol. 103, no. 3-5, pp.
220–231, Sept. 2009, neurorobotics.
[5] M.DeisenrothandD.Fox,“Learningtocontrolalow-costmanipulator
using data-efﬁcient reinforcement learning,” in Proc. of Robotics:
Science and Systems (RSS), 20e11.
[6] M. Littman, R. Sutton, and S. Singh, “Predictive representations of
state,” in Advances in Neural Information Processing Systems (NIPS),
2002.
[7] S. Singh, M. James, and M. Rudary, “Predictive state representations:
A new theory for modeling dynamical systems,” in Proc. UAI, 2004.
[8] M. Rudary, S. Singh, and D. Wingate, “Predictive linear-Gaussian
models of stochastic dynamical systems,” in Proc. UAI, 2005.
[9] Y. Bengio and P. Frasconi, “An Input Output HMM Architecture,” in
Advances in Neural Information Processing Systems, 1995.
[10] B. Boots, S. M. Siddiqi, and G. J. Gordon, “Closing the learning-
planning loop with predictive state representations,” in Proceedings of
Robotics: Science and Systems VI, 2010.
[11] B. Boots, A. Gretton, and G. J. Gordon, “Hilbert Space Embeddings
of Predictive State Representations,” in Proc. UAI, 2013.
[12] D. Wingate and S. Singh, “On discovery and learning of models with
predictive representations of state for agents with continuous actions
and observations,” in Proc. AAMAS, 2007.
[13] S. C. Ong, Y. Grinberg, and J. Pineau, “Mixed observability predictive
state representations,” 2013.
[14] W. L. Hamilton, M. M. Fard, and J. Pineau, “Modelling sparse
dynamical systems with compressed predictive state representations,”
in Proceedings of the 30th International Conference on Machine
Learning (ICML-13), S. Dasgupta and D. Mcallester, Eds., vol. 28,
no. 1. JMLR Workshop and Conference Proceedings, 2013, pp. 178–
186.
[15] A. Censi and R. M. Murray, “Bootstrapping bilinear models of robotic
sensorimotor cascades,” in Proceedings of the IEEE International
Conference on Robotics and Automation (ICRA), Shanghai, China,
May 2011.
[16] ——, “Bootstrapping sensorimotor cascades: a group-theoretic per-
spective,” in IEEE/RSJ International Conference on Intelligent Robots
and Systems (IROS), San Francisco, CA, September 2011.
[17] ——, “Learning diffeomorphism models of robotic sensorimotor
cascades,” in Proceedings of the IEEE International Conference on
Robotics and Automation (ICRA), Saint Paul, MN, May 2012.
[18] L. Ljung, System Identiﬁcation: Theory for the user, 2nd ed. Prentice
Hall, 1999.
[19] P. Van Overschee and B. De Moor, Subspace Identiﬁcation for Linear
Systems: Theory, Implementation, Applications. Kluwer, 1996.
[20] T. Katayama, Subspace Methods for System Identiﬁcation: A Realiza-
tion Approach. Springer, 2005.
[21] B. Kuipers, R. Browning, B. Gribble, M. Hewett, and E. Remolina,
“The spatial semantic hierarchy,” Artiﬁcial Intelligence, vol. 119, pp.
191–233, 2000.
[22] J. Modayil, “Discovering sensor space: Constructing spatial embed-
dings that explain sensor correlations,” in International Conference
on Development and Learning, 2010.
[23] A. M. Dearden and Y. Demiris, “Learning forward models for robots,”
in IJCAI, 2005, pp. 1440–1445.
[24] S.Ulbrich,V.Ruiz,T.Asfour,C. Torras,andR.Dillmann,“Kinematic
bzier maps,” IEEE Transactions on Systems, Man, and Cybernetics,
vol. 42, no. 4, pp. 1215–1230, 2012.
[25] H. Jaeger, “Observable operator models for discrete stochastic time
series,” Neural Computation, vol. 12, pp. 1371–1398, 2000.
[26] J. M. Wang, D. J. Fleet, and A. Hertzmann, “Gaussian process
dynamical models,” in In NIPS. MIT Press, 2006, pp. 1441–1448.
[27] B. Boots and G. Gordon, “An online spectral learning algorithm for
partially observable nonlinear dynamicalsystems,” in Proc. of the 25th
National Conference on Artiﬁcial Intelligence (AAAI-2011), 2011.
[28] L. Song, B. Boots, S. M. Siddiqi, G. J. Gordon, and A. J. Smola,
“Hilbert space embeddings of hidden Markov models,” in Proc. 27th
Intl. Conf. on Machine Learning (ICML), 2010.
[29] A. Anandkumar, R. Ge, D. Hsu, S. M. Kakade, and M. Telgarsky,
“Tensor decompositions for learning latent variable models,” CoRR,
vol. abs/1210.7559, 2012.
[30] J. Pearl, Causality: models, reasoning, and inference. Cambridge
University Press, 2000.
[31] M. Bowling, P. McCracken, M. James, J. Neufeld, and D. Wilkinson,
“Learning predictive state representations using non-blind policies,” in
Proc. ICML, 2006.
[32] A. Smola, A. Gretton, L. Song, and B. Sch¨ olkopf, “A Hilbert space
embedding for distributions,” in Algorithmic Learning Theory, ser.
Lecture Notes on Computer Science, E. Takimoto, Ed. Springer,
2007.
[33] B. Sriperumbudur, A. Gretton, K. Fukumizu, G. Lanckriet, and
B. Sch¨ olkopf, “Injective Hilbert space embeddings of probability
measures,” 2008.
[34] K. Fukumizu, L. Song, and A. Gretton, “Kernel bayes’ rule,” in
Advances in Neural Information Processing Systems 24, J. Shawe-
Taylor, R. Zemel, P. Bartlett, F. Pereira, and K. Weinberger, Eds.,
2011, pp. 1737–1745.
[35] M. Krainin, P. Henry, X. Ren, and D. Fox, “Manipulator and object
tracking for in-hand 3d object modeling,” Int. J. Rob. Res., vol. 30,
no. 11, pp. 1311–1327, Sept. 2011.
[36] J. Shawe-Taylor and N. Cristianini, Kernel Methods for Pattern
Analysis. New York, NY, USA: Cambridge University Press, 2004.
[37] S. Grunewalder, G. Lever, L. Baldassarre, M. Pontil, and A. Gretton,
“Modelling transition dynamics in MDPs with RKHS embeddings,”
CoRR, vol. abs/1206.4655, 2012.
4028
