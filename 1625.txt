Accurate In-Plane and Out-of-Plane Ultrasound-based Tracking of The
Discretely Actuated Steerable Cannula
Elif Ayvali and Jaydev P. Desai
Abstract— Discretely actuated steerable cannula is a multi-
degree-of-freedom hollow needle (cannula) that could poten-
tially be used in needle-based procedures to deliver therapeutic
and diagnostic tools to a target region through its hollow
inner core. Needle-based procedures are commonly performed
using intra-operative image guidance. 2D ultrasound is one of
the most commonly used imaging modalities in clinics. It is
portable, inexpensive and free of ionizing radiation. The success
of the needle-based procedures depends on accurate detection
of the needle. The accuracy of the out-of-plane detection, where
the ultrasound transducer is placed at a right angle to the long-
axis of the needle, depends on the ultrasound beam width. Finite
width of the ultrasound beam and uniform cross-section of the
needle introduce errors in tracking. The accuracy of in-plane
tracking depends on the tracking algorithm used and the spatial
resolution of the ultrasound transducer. This work presents a
method to quantify the ﬁnite ultrasound beam width and the
spatial accuracy of the transducer. An out-of-plane detection
method was implemented to locate the tip of the discretely
actuated steerable cannula. An in-plane tracking algorithm
based on optical ﬂow was also developed to obtain the shape of
a planar cannula. The algorithms and the methods developed
in this work are general and they can be extended to needles
having straight, curved and arbitrary shapes.
I. INTRODUCTION
Needle-based procedures require the guidance of the nee-
dle to a target region to deliver therapy or to remove tissue
samples for diagnosis. Needle insertion is commonly per-
formed using magnetic resonance imaging (MRI), computed
tomography (CT), ﬂuoroscopy or ultrasound guidance. The
success of image-guided procedures highly depends on the
ability to precisely locate the needle and the anatomical
structures. During needle insertion, needle deﬂection occurs
due to needle-tissue interaction which deviates the needle
from its insertion direction. Due to poor needle placement,
multiple insertion attempts at a single site are often made by
the physician. Furthermore, some sites are inaccessible using
straight-line trajectories due to the anatomical structures that
need to be avoided. There are many challenges in achieving
accurate targeting in needle-based procedures, and hence
there is no single solution to overcome these challenges.
Modeling needle-tissue interaction is an important step to
understand needle deﬂection. Needle deﬂection and tissue
deformation models were developed to estimate the needle
motion during insertion [3]. Externally manipulating the
This work was supported by the National Institutes of Health (NIH) grant
R01EB008713.
Elif Ayvali is with the Department of Mechanical Engineering, University
of Maryland, College Park, USA, 20742. eayvali@umd.edu
Jaydev P. Desai is with the Department of Mechanical Engineering, Uni-
versity of Maryland, College Park, USA, 20742. jaydev@umed.edu
tissue to push obstacles away from the insertion path [14]
or guiding the tumor towards the line of insertion of the
needle [10] are effective approaches to improve the targeting
accuracy. Robot-assisted needle insertion combined with
image guidance is promising to improve the accuracy of
the percutaneous procedures. The initial alignment of the
needle with the target can be achieved with robotic assistance
[4]. However, most of the targeting errors occur due to
needle deﬂection when the needle is inside the soft-tissue.
Manipulating the needle at the base provides limited control
over the needle trajectory after the insertion. In our previous
work, a multi-degree-of-freedom hollow needle (cannula)
was developed to account for the needle placement errors
once the needle is inside the soft-tissue [1]. The cannula is
composed of straight segments that are connected by shape
memory alloy (SMA) actuators at discrete locations along its
length. When the SMA actuators are heated using resistive
heating, they transform into an arc thereby generating joint
torques. To control the bending angle at each joint and
hence the tip of the cannula, two control approaches have
been explored. One approach is to measure the bending
angle or the tip position directly from the imaging modality.
The second approach is an indirect approach where the
strain of the SMA actuators is controlled by controlling the
temperature of the SMA actuator. The constitutive model of
the SMA relates the stress, strain and the temperature of the
SMA. This work is focused primarily on the detection of the
cannula in ultrasound-images for ultrasound-guided steering
of the cannula. We are interested in combining in-plane and
out-of-plane tracking of the cannula in the ultrasound images.
A. Ultrasound Image-based Tracking
Ultrasound is one of the most widely used imaging meth-
ods in medicine. Real-time ultrasound-based imaging can
easily be done at any probe position or orientation which
makes it attractive for instrument guidance in interventional
procedures. The main challenge with ultrasound guidance
in needle-based procedures is the artifacts produced by the
needle [8]. The artifacts result in missing boundaries, render-
ing various portions of the needle invisible. Needle visibility
depends on the alignment of the needle with the ultrasound
imaging plane. The needle tracking can be achieved in-plane
and out-of-plane. When the needle long axis and the needle
tip lie in the same plane with the ultrasound beam, the
tracking can be done in-plane. When the long axis of the
needle is perpendicular to the plane of the ultrasound beam,
the tracking is out-of-plane and only needle cross-section is
visible. The transducer and needle alignment can be achieved
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 5896
by sliding, tilting or rotating the transducer. Sliding the
transducer across the needle is the most commonly used
movement for aligning the ultrasound beam and the needle
tip. Rotation of the transducer is required when the needle
goes out of plane. There are many challenges in ultrasound-
based tracking. In the out-of-plane tracking, only the cross-
section is visible. Therefore, the shaft of the needle tip can
be mistaken for the needle tip. The ultrasound transducer
is usually placed at an angle with respect to the needle
insertion direction to visualize the needle tip [7], [5]. In
this approach, the detected cross-section can be the needle
shaft and the needle tip can be at a greater depth. The in-
plane tracking makes guidance easier since the entire needle
can be seen. The imaging width of the ultrasound probe
and the needle dimensions are commonly in mm scale. This
sometimes makes it hard to align the needle long axis with
the ultrasound beam.
B. Needle Detection and Image Analysis
Image analysis is widely applied to ultrasound images
to reduce noise and extract useful information about the
needle position. Extraction of lines, edges and curves is
a key step in image analysis. The goal in out-of-plane
tracking is to accurately detect the position of the needle tip
whereas in-plane tracking requires ﬁnding geometry speciﬁc
features of the needle. For a rigid needle, the feature to be
detected can be a line whereas detection of local or global
curvature may be required for a curved needle. The Radon
transform is a well-known tool for detecting parametrized
shapes in an image [6]. Radon transform was previously
used to determine parametrized shapes of a curved needle
[11]. Hough transform is commonly used to determine line
parameters such as slope and intersection points and can be
used to ﬁnd the brightest line in an image [7], [13].
Needle is usually the dominant line in the ultrasound
image. However, there might be gaps or other line artifacts
that belong to other structures. To reduce the noise and
detect the tip of the needle, thresholding or morphological
operations such as erosion and dilation are commonly applied
to the region of interest [12], [15]. Coating the needles with
an echogenic coating such as Echo-Coat
R 
(Angiotech Inc.)
improves needle visibility. There are commercially available
needles such as EchoBlock
R 
, EchoSti
R 
(Havel’s Inc.) that
have enhanced visibility compared to generic needles. Wrap-
ping passive markers around the needle tip is another way
of enhancing the needle shape in the ultrasound images [13].
One way to measure the location of the needle tip is to use
a magnetic tracker attached to the needle at the tip. The
tracker provides the relative position of the tip with respect
to the magnetic tracker’s base coordinate system. There are
commercial systems for ultrasound guided biopsy. Logiq E9
ultrasound platform (GE Healthcare Inc.) and SonixGPS (Ul-
trasonix Inc.) utilize a miniaturized electromagnetic sensor
for needle tracking. One of the sensors is embedded in the
tip of a biopsy needle and another one to an ultrasound
probe. The needle trajectory is displayed in real-time during
an entire procedure.
C. Overview
This work is focused on detection of the cannula in-
plane and out-of plane using ultrasound images. There are
two important considerations in ultrasound-based tracking
that are often overlooked. First, the ultrasound beam is
commonly assumed to be inﬁnitely thin. When the ultrasound
probe is perpendicular to the needle tip, the detected shape
is the cross-section of the needle. Since the geometry is
cylindrical, each cross-section gives a circle. Even though
the tip is accurately detected by the imaging algorithm,
the spatial accuracy is still limited by the ultrasound beam
width. Secondly, the spatial accuracy of the in-plane tracking
depends not only on the accuracy of the algorithm but also on
the resolution of the ultrasound transducer itself. These issues
are addressed in this work. The paper is organized as follows.
In Section II, the discretely actuated steerable cannula and
the experimental setup used for tracking are introduced. To
verify the in-plane tracking algorithm, a kinematic model of
the cannula is required. The kinematics is also introduced
in this section. In Section III, we demonstrate a method to
quantify the ultrasound beam width and spatial accuracy. To
detect the tip of the cannula, Hough circle transform was
implemented. The method presented in this section provides
a way to quantify and account for the error due to ﬁnite
ultrasound beam width. An in-plane detection algorithm
based on optical ﬂow was developed to obtain the shape of
the cannula. Finally, in Section IV we make some concluding
remarks.
II. MATERIALS AND METHODS
A. Discretely Actuated Steerable Cannula
The cannula is composed of three straight segments made
of polycarbonate with an inner diameter of 1.651 mm and
outer diameter of 3.175 mm. The length of each section
from the base to the tip is 3.8 cm, 2.5 cm, and 2.1 cm,
respectively. There are two slots along the length of each
straight segment and two antagonistic SMA actuators are
placed at each joint. The SMA actuators are 0.53 mm in
diameter and they are annealed in an arc shape. In this work,
all SMA actuators lie in a plane. Hence, the cannula moves in
a plane perpendicular to the location of the SMA actuators.
The joints are covered with non-conductive rubber sheath for
heat isolation and electrical insulation of the SMA actuators
inside soft-tissue. The schematic of the cannula is shown in
Fig. 1. There are 3 degrees-of-freedom (DOF): One DOF at
each joint and one insertion DOF. The conﬁguration of the
cannula in a plane can be described using Eq. 1.
x = L
1
+u+L
2
cos?
1
+L
3
cos? +r
1
sin?
1
+r
2
(sin?
2
cos?
1
?sin?
1
(1?cos?
2
))
y = L
2
sin?
1
+L
3
sin? +r
1
(1?cos?
1
)
+r
2
(sin?
1
sin?
2
+cos?
1
(1?cos?
2
))
? = ?
1
+?
2
(1)
The joint angles, ?
1
and ?
2
, are shown in Fig. 1. L
1
, L
2
,
L
3
are the lengths of the straight segments from base to
5897
Fig. 1. Schematic used for kinematic model of a 3-DOF planar cannula
tip. The position of the tip is given by (x,y) and ? is the
orientation of the tip. The radius of curvature of the joints
are given by r
1
and r
2
. The relation between the arc radius,
r, and joint angle, ?, is r = ?/? where ? is the length
of the SMA actuator between consecutive links. The three
equations representing the geometry of the cannula is solved
using a 4
th
order Runge-Kutta solver. The algorithm was
implemented in C++.
B. Experimental Setup
The experimental setup used for ultrasound guidance is
shown in Fig. 2. The frames are made of 1515 Lite fram-
ing material (80/20 Inc.). Two linear rail systems (Haydon
Motion Solutions) were mounted to the frame, and they are
used to control the ultrasound probe position in a plane.
The rails consist of a stepper motor (size 17 double stack
with 0.015875 mm per step resolution), a wedge style anti-
backlash nut, an optical encoder (US Digital E5S, 500 counts
per revolution), and 305 mm of total travel. The sliding
element of the rails that move along the long axis of the
rails have axial stability. However, it moves slightly when a
loading is applied along its width. Rail 2 is mounted across
the width of rail 1. To eliminate any horizontal movement
that might occur during operation, rail 2 was also constrained
using a guide rail that is attached on the frame. When rail
2 slides along the long axis of rail 1, it also slides along
the guide rail that provides additional support. There is a
DC motor ( Model 247858, Maxon Precision Motors, Inc.)
attached to the sliding element of rail 2, and its rotation
axis is centered along the center of the ultrasound probe.
Hence, the ultrasound probe has 3-DOF. The cannula is ﬁxed
between two plates that have a groove along their width. The
plates are attached to a vertical support that is attached to
the sliding element of rail 3. The height of the plates can be
adjusted using screws. The vertical position of the ultrasound
probe can also be adjusted prior to the experiments to make
sure the ultrasound probe is in contact with the tissue sample.
The arrows shown with dashed lines show the adjustment
direction for the cannula ﬁxture and the ultrasound ﬁxture.
The ultrasound system is a Philips Sonos 5500 ultrasound
console with a 3-11 MHz linear array transducer (Model 11-
3L). Matrox Morphis (Matrox Inc.) frame grabber is used to
grab frames in real time at 15 fps. The rails are controlled via
a TTL-compatible motor control unit (DCM 8028, Haydon
Motion Solutions) which directly drives the stepping motion
of the motor. The TTL-signals are generated using Arduino
UNO board at 500Hz and this frequency corresponds to 3.9
Fig. 2. Linear rail system used for ultrasound experiments
mm/s travel speed.
III. EXPERIMENTS AND RESULTS
This section presents the results of the out-of-plane tip
detection and in-plane tracking of the cannula inside tissue
phantom made of gelatin. For image analysis OpenCV
library was used [2]. The algorithms were implemented
in C++ on a Windows XP PC. In out-of-plane tracking,
the transducer is positioned at right angles to the cannula
insertion direction. The needle tip is found through image
analysis as the transducer slides over the cannula. In in-plane
tracking, the needle long axis is aligned with the ultrasound
beam. Hence, the whole needle is visible. The needle tip
position and orientation is obtained through image analysis.
The corresponding bending angle at each joint can then be
obtained using inverse kinematics.
A. Ultrasound Beam Width and Spatial Accuracy
To quantify the ultrasound beam-width, an object was
scanned with the transducer and images were recorded
with 0.127 mm increments. The physical dimension of the
imaging window of the transducer is 4.7 cm x 1 cm. When
the transducer is moved along the ‘a’ direction as shown in
Fig. 3, the scanned object starts to appear after the dashed
line. The object has maximum visibility when it is in the
middle of the imaging window. The visibility decreases once
the object passes beyond the center of the imaging window.
The object and its dimensions are shown in Fig. 4a. Initially
the transducer is away from the object and the object is not
visible. The object starts to be seen at 0.381 cm, and the
rectangular block disappears at 3.175cm. Fig. 4c shows the
ultrasound images of the object at various locations. The
rectangle block has 2.477 cm length and in the ultrasound
images it is visible for 2.794 cm (3.175-0.381). That means
the scanning width of the transducer is 0.317 cm (2.794-
2.477). Even though the physical width of the probe is 1 cm,
the effective imaging width is 0.317 cm. If an object with
length L is scanned by sliding the transducer over the object,
5898
Fig. 3. 11-3L Linear Array Transducer
the object will appear for L+0.317 cm. If the transducer is
used to track the tip of the cannula by placing the ultrasound
probe orthogonal to the insertion direction, the tip is visible
when the tip of the cannula is inside the 0.317 cm window.
This means that the tracking accuracy of the tip is within
0.317 cm when the transducer is used to locate the tip of
the cannula. The tip can be easily mistaken for the cannula
shaft. This observation is important yet commonly neglected
while assessing the accuracy of tracking the needle tip [12],
[15].
To determine the image quality and spatial resolution of
the transducer, the object shown in Fig.4a was scanned along
its width. The dimensions of the cross-section is given in
Fig. 4b. Fig. 4d shows several dimensions of the object
measured using the cursor in the ultrasound console. The
maximum error in dimensions was measured to be 0.015 cm.
This implies that the spatial accuracy of in-plane tracking is
limited by the spatial accuracy of the ultrasound.
Fig. 4. Ultrasound beam width and spatial resolution experiments: a) The
top view of the object that was scanned with the transducer, b) The front
view of the object that was scanned, c) the ultrasound images of the object at
different positions along the scanning axis, d) the dimensions of the object
that were measured using the ultrasound console. The dimensions are in
cm.
Fig. 5. The schematic of the experiment that was performed for out-of-
plane detection of the cannula tip
120 140 160 180
235
240
245
250
255
260
265
Frame number
Pixel coordinate
x , r= 8?10
y , r= 10?12
x , r= 10?12
y , r= 8?10
 0.6 mm
 2.54 mm
Fig. 6. The frames were recorded at 0.127 mm spacing. 20 frames
correspond to 2.54 mm displacement of the transducer. 5 pixels correspond
to 0.6 mm.
B. Out-of-plane Detection of the Cannula Tip
The ultrasound transducer is placed at right angles to the
cannula as demonstrated in Fig. 5. The imaging depth was
set to 8 cm. The initial position of the transducer is away
from the cannula tip such that the cannula cannot be seen
in ultrasound images. The transducer is moved towards the
cannula tip with 0.127 mm increments and a total number
of 185 ultrasound images were recorded. To detect the tip of
the cannula, Hough circle transform was implemented. The
ultrasound images were pre-processed using thresholding.
Downscaling, upscaling, dilation, and erosion operations fol-
lowed by blurring were applied recursively to obtain a clear
image that is free of any noise. A range of pixel values can
be speciﬁed to detect circles with a desired diameter. First the
circle radius was speciﬁed as 8-10 pixel which corresponds
to 3.074-3.842 mm diameter. A 10-12 pixel range was also
tested for comparison since the cannula diameter can be
larger in the ultrasound images due to artifacts. 10-12 pixel
range corresponds to 3.842-4.610 mm diameter. Fig. 6 show
the change in pixel coordinates of the detected circle as the
transducer slides over the cannula tip. The result shows
that both ranges give similar results and the ﬁrst circle was
detected at 117
th
frame in both cases. Hence, 8-10 pixel
range was used for detection of the tip. The ultrasound
images and their corresponding frame number and position
are given in Fig.7. The tip starts to appear at 75
th
frame
and the circle is detected after 42 frames (117-75). This
corresponds to 5.334 mm displacement of the transducer. The
5899
50 100 117 120
140 130 1 75 frame number
position (mm)
pre-processing
Hough circle
detection
6.350 12.700 14.859 15.240
17.780 16.510 0
9.525
 3 mm
x
y
Fig. 7. The images at the top are obtained through pre-processing to reduce noise and enhance needle tip visibility. The images are then input into the
Hough circle detection algorithm. The images at the bottom show the detected circles on the original ultrasound images.
length of the bevel-tip is 5.5 mm and the algorithm shows
great performance in accurate detection of the tip. Based on
the results of this study the following out-of-plane tracking
method is proposed. As the cannula is inserted into soft
tissue, the transducer will also move in the same direction.
The transducer can be commanded to move the same distance
as the insertion distance of the cannula. A better approach
would be to displace the transducer based on the estimated
position of the cannula tip. The transducer will also have a
6 mm sinusoidal motion (slightly larger than the bevel tip
length) around the cannula tip to scan the bevel tip length.
Therefore, the transducer will scan the whole bevel length
while tracking the cannula to accurately detect the position
of the tip. This approach accounts for the detection error due
to ﬁnite ultrasound beam width and the uniform cross-section
of the cannula.
C. In-plane Tracking of the Cannula
Lucas-Kanade optical ﬂow is a powerful algorithm for
motion detection. The algorithm uses sum-of-squared in-
tensity differences as measurements to minimize the errors
for each tracking and works with sub-pixel accuracy [9].
Optical ﬂow algorithm is based on the brightness constancy
assumption and hence it is sensitive to variation in brightness.
Image brightness is not very stable in ultrasound images. The
brightness of the whole image or certain regions (divided
in rows) can be adjusted and speckle can be minimized by
adjusting the settings on the ultrasound console. However,
there is variation in brightness due to the artifacts caused
by the cannula. Complete disappearance of tracked points
due to sudden brightness change is rare but the tracked
points can shift across pixels that have constant brightness.
When the tracked points shift across the cross-section of the
cannula due to pixels having similar brightness, it introduces
an error in the angle calculation. To eliminate this problem,
brightness variation of the tracked points in time should be
minimized. To achieve this, the boundaries of the cannula can
be enhanced using edge detection algorithms. An edge is de-
ﬁned by a discontinuity in gray-level values. Applying edge
detection algorithms directly proves to be not useful since the
artifacts of the cannula result in missing boundaries rendering
various portions of the cannula invisible. Pre-processing of
the images is necessary to reduce noise, brightness variation,
and missing boundaries.
The image is ﬁrst pre-processed using downsampling
followed by upsampling operation to reduce the amount of
noise and detail. Erosion, dilation and blurring operations are
also applied recursively to reduce brightness variation and
smoothen the image. The surface of the cannula facing the
transducer has higher brightness in ultrasound images which
makes edge detection useful. Sobel edge detection is applied
to detect the top surface of the cannula. Finally, a linear
blend operator is applied to the the ﬁnal image obtained
through Sobel edge detection and the original image. The
blend operator overlays both images, thus enhancing the
brightness of the top surface of the cannula on the original
image.
For testing of the algorithm, a video of a cannula insertion
experiment was recorded. The transducer was stationary and
the cannula was inserted into the gelatin. The joint angles
were varied randomly. The algorithm was tested on the
videos to optimize the parameters of the tracking algorithm.
Once the cannula is inside the imaging region, the tip of the
cannula and one point on the top surface of the distal link are
selected. A line is ﬁtted between the two points and the bend-
ing angle of the ﬁrst joint is obtained. The motion of the two
points are continuously tracked using the pyramidal Lucas-
Kanade optical ﬂow algorithm. Fig. 8 shows the comparison
of the optical ﬂow algorithm implemented on the original
image and the optical ﬂow algorithm implemented after
pre-processing and brightness enhancement. In the original
optical ﬂow algorithm with no brightness enhancement, the
second point is shifted down across the needle cross-section.
This shift results in error in the angle calculation. Fig. 9a
shows the ultrasound images after pre-processing and edge-
detection. A clean image is obtained and the upper surface
of the cannula is detected. Fig. 9b shows the cannula and the
kinematic model overlayed on the same image in real-time.
The optical ﬂow algorithm gives the pixel location of the
cannula tip position and orientation.
The in-plane tracking method presented in this section
can also be applied to rigid and curved needles as well
as needles with arbitrary shape. If the needle has a ﬁxed
curvature, the location of the two tracked points can be
used to calculate the curvature. For needles with an arbitrary
5900
Fig. 8. a) Original pyramidal Lucas-Kanade optical ﬂow algorithm, b)
Pyramidal Lucas-Kanade optical ﬂow algorithm with enhanced brightness.
The detected angle is 5.8137
?
in the original pyramidal Lucas-Kanade
optical ﬂow algorithm and 4.0205
?
in the pyramidal Lucas-Kanade optical
ﬂow algorithm with enhanced brightness.
a) b)
Fig. 9. a) After pre-processing and Sobel edge detection, the top surface
of the cannula is clearly resolved, b) The algorithm is initialized when the
cannula is straight and the kinematic model is overlayed on the ultrasound
images as the cannula moves inside gelatin.
shape, multiple points can be selected such that a point cloud
is formed on the top surface and the shape of the needle can
be reconstructed from the point cloud.
IV. CONCLUSIONS
The accuracy of the image-guided needle-based proce-
dures is highly dependent on the accurate detection of the
needle position. This work presented an in-plane detection
and an out-of-plane tracking algorithm for the discretely
actuated steerable cannula. While detecting the needle tip,
the ultrasound beam is generally assumed to be inﬁnitely
thin. Finite width of the ultrasound beam introduces tracking
errors. Uniform cross-section of the needle tip aggravates the
detection of the tip. The accuracy of the in-plane tracking
is limited by the spatial resolution of the transducer. The
method presented in this work provides a way to quantify
the ﬁnite ultrasound beam width and the spatial accuracy
of the ultrasound transducer. Hough circle transform was
used to detect the cross-section of the cannula and it was
demonstrated that the tip can be accurately detected. A
brightness enhancement technique was developed to alleviate
the brightness variation of the ultrasound images. This en-
abled using the pyramidal Lucas-Kanade algorithm to track
the cannula conﬁguration in-plane.
Our goal is to combine in-plane tracking and out-of-
plane tracking to steer the discretely actuated steerable
cannula in 3D. The methods and tools that are presented
in this work form the foundation required to achieve this
goal. In our previous work, we developed PWM (pulse
width modulation)-based temperature feedback and PWM-
based image feedback controllers to control the joint angles.
Motion planning algorithms were also developed to generate
a path between the entry point to the tissue and the target
point. In our future work, we will combine these tools and
do active ultrasound image-based tracking and control of the
cannula to execute trajectories that are obtained using the
motion planning algorithm.
REFERENCES
[1] E. Ayvali, C.P. Liang, M. Ho, Y . Chen, and J. P. Desai. Towards
a discretely actuated steerable cannula for diagnostic and therapeu-
tic procedures. The International Journal of Robotics Research,
31(5):588–603, 2012.
[2] G. Bradski. The opencv library. Dr. Dobb’s Journal of Software Tools,
2000.
[3] S.P. DiMaio and S.E. Salcudean. Needle steering and model-based
trajectory planning. In Medical Image Computing and Computer-
Assisted Intervention - MICCAI 2003, volume 2878, pages 33–40,
2003.
[4] G. Fichtinger, J.P. Fiene, C.W. Kennedy, G. Kronreif, I. Iordachita,
D.Y . Song, E. C. Burdette, and P. Kazanzides. Robotic assistance for
ultrasound-guided prostate brachytherapy. Medical Image Analysis,
12(5):535 – 545, 2008.
[5] R. H. Gottlieb, W. B. Robinette, D. J. Rubens, D. F. Hartley, P. J.
Fultz, and M. R. Violante. Coating agent permits improved visual-
ization of biopsy needles during sonography. American Journal of
Roentgenology, 171(6):1301–1302, 1998.
[6] C.L.L. Hendriks, M. van Ginkel, P.W. Verbeek, and L. J. van Vliet.
The generalized radon transform: Sampling, accuracy and memory
considerations. Pattern Recognition, 38(12):2494 – 2505, 2005.
[7] J. Hong1, T. Dohi1, M. Hashizume, K. Konishi, and N. Hata. An
ultrasound-driven needle-insertion robot for percutaneous cholecys-
tostomy. Physics in Medicine AND Biology, 49(3):441, 2000.
[8] J. Huang, J.K. Triedman, N.V . Vasilyev, Y . Suematsu, R.O. Cleve-
land, and Dupont P.E. Imaging artifacts of medical instruments in
ultrasound-guided interventions. J Ultrasound Med., 26(10):1303–22,
2007.
[9] B.D. Lucas and T. Kanade. An iterative image registration technique
with an application to stereo vision. In Proceedings of the international
joint conference on Artiﬁcial intelligence,, pages 674–679, 1981.
[10] V .G. Mallapragada, N. Sarkar, and T.K. Podder. Robot assisted real-
time tumor manipulation for breast biopsy. In IEEE International
Conference on Robotics and Automation(ICRA), pages 2515–2520,
2008.
[11] H.R.S. Neshat and R.V . Patel. Real-time parametric curved needle
segmentation in 3d ultrasound images. In 2nd IEEE RAS EMBS In-
ternational Conference on Biomedical Robotics and Biomechatronics
(BIOROB), pages 670–675, 2008.
[12] Z. Neubach and M. Shoham. Ultrasound-guided robot for ﬂexible
needle steering. IEEE Transactions on Biomedical Engineering,
57(4):799–805, 2010.
[13] P.M. Novotny, J. A. Stoll, N. V . Vasilyev, P. J. del Nido, P. E. Dupont,
T. E. Zickler, and R. D. Howe. Gpu based real-time instrument
tracking with three-dimensional ultrasound. Medical Image Analysis,
11(5):458 – 464, 2007.
[14] M Torabi, K. Hauser, R. Alterovitz, D. Vincent, and K. Goldberg.
Guiding medical needles using single-point tissue manipulation. In in
Proceedings of the IEEE International Conference on Robotics and
Automation, pages 2705–2710, 2009.
[15] G.J. Vrooijink, M. Abayazid, and S. Misra. Real-time three-
dimensional ﬂexible needle tracking using two-dimensional ultra-
sound. In Proceedings of the IEEE International Conference on
Robotics and Automation (ICRA), 2013.
5901
