A Method for Simplifying the Analysis of Leg-Based Visual Servoing of
Parallel Robots
Victor Rosenzveig
1,2
, S« ebastien Briot
1
, Philippe Martinet
1,2
, Erol
¬
Ozg¬ ur
3
, and Nicolas Bouton
3
AbstractÑ As the end-effector pose is an external property
of a parallel robot, it is natural to use exteroceptive sensors
to measure it in order to suppress inaccuracies coming from
modelling errors. Cameras offer this possibility. So, it is possible
to obtain higher accuracy than in the case of classic control
schemes (based on geometrical model).
In some cases, it is impossible to directly observe the end-
effector, but the leg directions can instead be used. In this
case, however, unusual results were recorded, namely: (i) the
possibility of controlling the robot by observing a number of
legs less than the total number of legs, and that (ii) in some
cases, the robot does not converge to the desired end-effector
pose, even if the observed leg directions did.
These results can be explained through the use of the hidden
robot concept, which is a tangible visualisation of the mapping
between the observed leg direction space (internal property)
and Cartesian space (external property). This hidden robot has
different assembly modes and singular conÞgurations from the
real robot, and it is a powerful tool to simplify the analysis of
the aforementioned mapping.
In this paper, the concept of hidden robot model is gener-
alised for any type of parallel robot controlled through visual
servoing based on observation of the leg directions.
Validation has been accomplished through experiments on a
Quattro robot with 4 dof.
I. INTRODUCTION
Compared to serial robots, parallel kinematic manipula-
tors [1] are stiffer and can reach higher speeds and accel-
erations [2]. However, their control is troublesome because
of the complex mechanical structure, highly coupled joint
motions and many other factors (e.g. clearances, assembly
errors, etc.) which degrade stability and accuracy.
Many research papers focus on the control of parallel
mechanisms (see [3] for a long list of references). It may
be possible to bypass the complex kinematic structure of the
robot and to apply a form of control which uses an external
sensor to estimate the pose of the end-effector, reducing the
stability and accuracy degradation mentioned earlier.
This work was supported by the French ANR project ARROW (ANR-
2011BS3-006-01), by the French ANR project EquipEx RobotEx (ANR-10-
EQPX-44) and by the European Union Program ÒComp« etitivit« e R« egionale
et Emploi 2007Ð2013Ó (FEDER Ð R« egion Auvergne).
The authors would like to thank Michel Coste from the Institut de
Recherche Math« ematique de Rennes (University of Rennes, France) for his
smart advices about the use of the B« ezout theorem and the deÞnition of the
Bohemian Dome.
1
V . Rosenzveig, S. Briot, and P. Martinet are with Institut de Recherches
en Communications et Cybern« etique de Nantes (IRCCyN), UMR CNRS
6597, Nantes, France
2
V . Rosenzveig and P. Martinet are with LUNAM University,
«
Ecole
Centrale de Nantes, Nantes, France
3
E.
¬
Ozg¬ ur and N. Bouton are with Institut Franc üais de M« ecanique
Avanc« ee (IFMA), Institut Pascal, UMR CNRS 6602, Clermont-Ferrand,
France
A proven approach for estimating the end-effector pose
is through the use of vision. The most common approach
consists of the direct observation of the end-effector pose [4],
[5], [6]. In some cases, however, it may prove difÞcult or
unwise to observe the end-effector of the robot, e.g. in the
case of a machine-tool. A substitute target for the observation
must then be chosen and an effective candidate for this
are the legs of the robot, which are usually designed with
slim and rectilinear rods [3]. When moving the object of
observation from the end-effector to the robot legs, the result
of the observation becomes a direct measure of an internal
property, i.e. the kinematic conÞguration of the robot. In
addition, as the information is acquired through an external
sensor, this technique allows to estimate indirectly the pose
of the end-effector from it (like it is done in [7]) which is
an external property.
An application of this technique was performed in [8]
where vision was used to derive a visual servoing scheme
based on the observation of a Gough-Stewart (GS) parallel
robot [9]. In that method, the leg directions were chosen
as visual primitives and control was derived based on their
reconstruction from the image. The approach was applied to
several types of robots, such as the Adept Quattro and other
robots of the same family [10], [11].
However, two unexpected results arose from the applica-
tion of this technique:
¥ It was possible to control the robot by observing a
number of legs fewer than the total number of legs.
This is surprising because in the case of standard control
schemes (actuator-based control), each actuated leg has
to be controlled in order to fully servo the robot (six legs
for the GS platform using actuators, instead of three legs
using vision; four legs for the Quattro using actuators,
instead of two legs using vision).
¥ In some cases, the robot did not converge to the desired
pose, even if all observed leg directions did. This was
surprising, since the whole idea of using an external
sensor is to get the exact position of the end-effector.
Not only were these two points inexplicable, but other
questions arose too, which were never answered. Such as:
¥ Are we sure there are no local minima (for which the
error in the observation space is non zero while the robot
platform cannot move [12]) in the Cartesian space?
¥ Are we sure that there is no singularity in the mapping
between the leg direction space and the Cartesian space?
Due to the unusual nature of this visual servoing technique,
all these points were left unanswered. It was clear that this
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 5720
behaviour was due to the mapping between Cartesian space
and the leg direction observation space, but at this time the
nature of the mapping was not understood and there were no
tools available to analyse correlation between the intrinsic
and extrinsic properties of the controller.
The answer came only recently, when two of the authors of
the present paper proposed the existence of a virtual robot
model ÒhiddenÓ within the controller. This robot presents
singular conÞgurations and assembly modes different from
the controlled robot, and it is this hidden robot whose
intrinsic and extrinsic properties are being used through the
observation of the real robotÕs leg directions.
This proposition was demonstrated in [13] where the
visual servoing of the leg directions of the GS platform was
proven to be equivalent to controlling the hidden 3ÐUPS
1
robot. A similar property has been shown for the control
of the Adept Quattro with only 3 translational degrees of
freedom (dof Ð a redundant version of the Quattro with
a rigid platform) for which another hidden robot model,
completely different from the one of the GS platform, has
been found [15].
In both cases, the hidden virtual robot is proven to be
a tangible visualisation of the mapping between the obser-
vation space and the real robot Cartesian space, correlating
the external and internal properties observed through vision.
Considering this hidden robot model, a minimal represen-
tation for the leg observation-based control of the studied
robots can be found, which makes it possible to answer the
previous questions.
Thus, the concept of hidden robot model, is the tool
able to analyse the intrinsic properties of some controllers
developed by the visual servoing community, without which
the behaviour of the controller cannot fully be explained.
Moreover, this concept shows that in some visual servoing
approaches, using only the extrinsic properties and stacking
several interaction matrices to derive a control scheme with-
out doing a deep analysis of the intrinsic properties of the
controller is clearly not enough. Further investigations are
required.
Therefore, in this paper, the generalization of the concept
of hidden robot model is presented and a general way to
Þnd the hidden robots corresponding to any kind of robot
architecture is explained. It will be shown that the concept
of hidden robot model is a powerful tool which correlates the
extrinsic and intrinsic properties observed through the visual
servoing of robots using leg direction observation and gives
useful insights about this kind of visual servoing technique.
Not only does the concept of hidden robot model answer
the unexplained results presented earlier, but also through
its use the singularity problem of the mapping between the
space of the observed robot links and the Cartesian space
can be addressed. Moreover, it is possible to give and certify
information, in a simpliÞed way, about the controllability of
the observed robots using the proposed controller.
1
In the following of the paper, R, P, U, S, ? will stand for passive
revolute, prismatic, universal, spherical and planar parallelogram joint [14],
respectively. If the letter is underlined, the joint is considered active.
u
i
Fixed
base
u
i
O
Moving
platform
Prox.
link
Parallelogram
x
i
y
i
z
i
(a) a RÐ{2ÐUS} leg (b) the Adept Quattro
C
4
C
1
C
2
C
3
D
1
D
2 ?
x
y
E
4
E
1
E
2
E
3
C
l
(c) Schematics of the
platform of the Quat-
tro
Fig. 1. Example of leg, robot, and platform for the Adept Quattro
II. RECALLS ON VISUAL SERVOING OF PARALLEL
ROBOTS USING LEG OBSERVATIONS
The proposed control approach was to servo the leg
directions
c
u
i
[8] (Fig. 1(a)). Some brief recalls on this type
of controller are done below.
A. Interaction matrix
Visual servoing is based on the so-called interaction matrix
L
T
[16] which relates the instantaneous relative motionT
c
=
c
?
c
?
c
?
s
between the camera and the scene, to the time
derivative of the vector s of all the visual primitives that are
used through:
ú s =L
T
(s)
T
c
(1)
where
c
?
c
and
c
?
s
are respectively the kinematic screw of the
camera and the scene, both expressed in R
c
, i.e. the camera
frame.
In the case where we want to directly control the leg
directions
c
u
i
, and if the camera is Þxed, (1) becomes:
c
ú u
i
=M
T
i
c
?
c
(2)
where M
T
i
is the interaction matrix for the leg i.
B. Control
For the visual servoing of a robot, one achieves ex-
ponential decay of an error e(s,s
d
) between the current
primitive vectors and the desired ones
d
using a proportional
linearizing and decoupling control scheme of the form:
T
c
=?
ö
L
T+
(s)
e(s,s
d
) (3)
where T
c
is used as a pseudo-control variable and the
superscript Ò+Ó corresponds to the matrix pseudo-inverse.
The visual primitives being unit vectors, it is theoretically
more elegant to use the geodesic error rather than the
standard vector difference. Consequently, the error grounding
the proposed control law will be:
e
i
=
c
u
i
?
c
u
di
(4)
where
c
u
di
is the desired value of
c
u
i
.
It can be proven that, for spatial parallel robots, matrices
M
i
are in general of rank 2 [8] (for planar parallel robots,
they are of rank 1). As a result, for spatial robots with more
than 2 dof, the observation of several independent legs is
necessary to control the end-effector pose. An interaction
5721
matrix M
T
can then obtained by stacking k matrices M
T
i
of k legs.
Finally, a control is chosen such thate, the vector stacking
the errors e
i
associated to of k legs (k = 3...6), decreases
exponentially, i.e. such that
ú e =??e (5)
Then, introducing L
T
i
= ?[
c
u
di
]
?
M
T
i
, where [
c
u
di
]
?
is
the cross product matrix associated with the vector
c
u
di
, the
combination of (4), (2) and (5) gives
c
?
c
=??L
T+
e (6)
where L
T
can be obtained by stacking the matrices L
T
i
of
k legs. The conditions for the rank deÞciency of matrixL
T
,
as well as the conditions that lead to local minima [12] of
the Eq. (6) are discussed in Section III.
This expression can be transformed into the control joint
velocities:
ú q =??
c
J
inv
L
T+
e (7)
where
c
J
inv
is the inverse Jacobian matrix of the robot
relating the end-effector twist to the actuator velocities, i.e.
c
J
invc
?
c
= ú q.
In the next Section, it is shown that such type of controller
involve the use of hidden robot models that can be studied
for analysing the controllability of parallel robots using the
proposed visual servoing approach.
III. THE CONCEPT OF HIDDEN ROBOT MODEL
The concept of hidden robot model has been Þrst intro-
duced in [13] for the visual servoing of the GS platform. In
this paper, it has been demonstrated that the leg direction
based visual servoing of such robots intrinsically involves
the appearance of a hidden robot model, which has assembly
modes and singularities different from the real robot. It was
shown that the concept of hidden robot model fully explains
the possible nonconvergence of the observed robot to the
desired Þnal pose and that it considerably simpliÞes the
singularity analysis of the mapping involved in the controller.
The concept of hidden robot model comes from the
following observation: in the classical control approach,
the encoders measure the motion of the actuator; in the
previously described control approach (Section II), the leg
directions or leg edges are observed. So, in a reciprocal
manner, one could wonder to what kind of virtual actuators
such observations correspond. The main objective of this
Section is to give a general answer to this question.
A. How to deÞne the legs of the hidden robots
Let us consider a general leg for a parallel robot in which
the direction u
i
of a segment is observed (Fig. 2(a) Ð in
this Þgure, the last segment is considered observed, but the
following explanations can be generalized to any segment
located in the leg chain).
In the general case, the unit vector u
i
can obviously be
parameterized by two independent coordinates, that can be
two angles, for example the angles ? and ? of Fig. 2(c)
deÞned such that cos? =xáv =yáw (wherev andw are
u
i
platform
base
A
0
A
1
A
2
A
n
A
n-1
A
n-2
passive joints
active joint
robot links
(a) A general robot leg
u
i
platform
base
A
0
A
1
A
2
A
n
A
n-1
A
n-2
passive
joints
active
joint
passive
PPP
chain
(b) its corresponding
hidden robot leg when
the vector u
i
is ob-
served
x
y
z
observed
direction
w
?
?
v
virtual
cardan
joint
v 
.
 
z=0
w 
.
 
z=0
u
i 
:
(c) Parameterization
of a unit vector u
i
with respect to a given
frame x, y and z
Fig. 2. A general robot leg and its corresponding hidden robot leg when
the vector u
i
is observed, and parametrization of said vector
deÞned such thatzáv =záw = 0) and cos? =uáx. Thus
? is the angle of the Þrst rotation of the link direction u
i
aroundz and ? is the angle of the second rotation aroundv.
It is well known that a U joint is able to orientate a link
aroud two orthogonal axes of rotation, such as z and v.
Thus U joints can be the virtual actuators with generalized
coordinates ? and ? we are looking for. Of course, other
solutions can exist, but U joints are the simplest ones.
If a U joint is the virtual actuator that makes the vector
u
i
move, it is obvious that:
¥ if the value ofu
i
is Þxed, the U joint coordinates? and
? must be constant, i.e. the actuator must be blocked,
¥ if the value of u
i
is changing, the U joint coordinates
? and ? must also vary.
As a result, to ensure the aforementioned properties for ?
and ? if u
i
is expressed in the base or camera frame (but
the problem is identical since the camera is considered Þxed
on the ground), vectorsx, y and z of Fig. 2(c) must be the
vectors deÞning the base or camera frame. Thus, in terms of
properties for the virtual actuator, this implies that the Þrst
U joint axis must be constant w.r.t. the base frame, i.e. the
U joint must be attached to a link performing a translation
w.r.t. the base frame
2
.
However, in most of the cases, the real leg architecture
is not composed of U joints attached on links performing
a translation w.r.t. the base frame. Thus, the architecture
of the hidden robot leg must be modiÞed w.r.t. the real
leg such as depicted in Fig. 2(b). The U joint must be
mounted on a passive kinematic chain composed of at most 3
orthogonal passive P joints that ensures that the link on which
is it attached performs a translation w.r.t. the base frame.
This passive chain is also linked to the segments before the
observed links so that they do not change their kinematic
properties in terms of motion. Note that:
¥ it is necessary to Þx the PPP chain on the preceeding leg
links because the information given by the vectorsu
i
is
not enough for rebuilding the full platform position and
orientation: it is also necessary to get information on
the location of the anchor point A
n?1
of the observed
2
In the case where the camera is not mounted on the frame but on a
moving link, the virtual U joint must be attached on a link performing a
translation w.r.t. the considered moving link.
5722
u
A
B
C
U joint
R joint
(a) A RU leg
u
PP
chain
A
B
C
U joint
mounted
on the PP
chain
R joint
(b) Virtual{RÐPP}ÐU
leg
Planar
parallelogram
(?) joint
u
A
B
C
U joint
mounted on 
the link BD
R joint E
D
(c) Virtual ?U leg
Fig. 3. An RU leg and two equivalent solutions for its hidden leg
segment [17]. This information is kept through the use
of the PPP chain Þxed on the Þrst segments;
¥ 3 P joints are only necessary if and only if the point
A
n?1
describes a motion in the 3D space; if not, the
number of P joints can be decreased: for example, in
the case of the GS platform presented in [13], the U
joint of the leg to control was located on the base, i.e.
there was no need to add passive P joints to keep the
orientation of its Þrst axis constant;
¥ when the vector u
i
is constrained to move in a plane
such as for planar legs, the virtual actuator becomes
an R joint which must be mounted on the passive PPP
chain (for the same reasons as mentioned previously).
For example, let us have a look at the RU leg with one
actuated R joint followed by a U joint of Fig. 3(a). Using
the previous approach, its virtual equivalent leg should be an
{RÐPP}ÐU leg (Fig. 3(b)), i.e. the U joint able to orientate
the vector u
i
is mounted on the top of a RÐPP chain that
can garantee that:
1) the link on which the U joint is attached performs a
translation w.r.t. the base frame,
2) the point C (i.e. the centre of the U joint) evolves on
a circle of radius l
AB
, like the real leg.
It should be noticed that, in several cases for robots with
a lower mobility (i.e. spatial robots with a number of dof
less than 6, or planar robots with a number of dof less than
3), the last joint that links the leg to the platform should be
changed so that, if the number of observed legs is inferior
to the number of real legs, the hidden robot keeps the same
number of controlled dof.
It should also be mentioned that we have presented above
the most general methodology that is possible to propose,
but it is not the most elegant way to proceed. In many cases,
a hidden robot leg architecture can be obtained such that less
modiÞcations w.r.t the real leg are achieved. For example, the
RÐPP chain of the hidden robot leg {RÐPP}ÐU (Fig. 3(b))
could be equivalently replaced by a planar parallelogram (?)
joint without changing the aforementioned properties of the
U virtual actuator (Fig. 3(c)), i.e. only one additional joint
is added for obtaining the hidden robot leg (note that we
consider that a ? joint, even if composed of several pairs,
can be seen as one single joint, as in [14]).
B. How to use the hidden robot models for analysing the
controllability of the servoed robots
The aim of this Section is to show how to use the
hidden robots for answering points 1 to 4 enumerated in the
introduction of the paper.
Point 1: the hidden robot model can be used to explain
why the observed robot which is composed of n legs can
be controlled using the observation of only m leg directions
(m < n) arbitrarily chosen among its n legs, and can also
help to choose the best set of legs to observe with respect to
some given performance indices.
For answering this point, let us consider a general parallel
robot composed of 6 legs (one actuator per leg) and having
six dof. Using the approach proposed in Section III-A, each
observed leg will lead to a modiÞed virtual leg with at least
one actuated U joint that has two degrees of actuation. For
controlling 6 dof, only 6 degrees of actuations are necessary,
i.e. three actuated U are enough. Thus, in a general case,
only three legs have to be observed to fully control the
platform dof.
Point 2: the hidden robot model can be used to prove that
there does not always exist a full diffeomorphism between the
Cartesian space and the leg direction space, but can also
bring solutions for avoiding to converge to a non desired
pose.
Here, the answer comes directly from the fact that the
real controlled robot may have a hidden robot model with
different geometric and kinematics properties. This means
that the hidden robot may have assembly modes and singular
conÞgurations different from those of the real robot. If the
initial and Þnal robot conÞgurations are not included in the
same aspect (i.e. a workspace area that is singularity-free
and bounded by singularities [2]), the robot wonÕt be able to
converge to the desired pose, but to a pose that corresponds
to another assembly mode that has the same leg directions
as the desired Þnal pose.
Point 3: the hidden robot model simpliÞes the singularity
analysis of the mapping between the leg direction space
and the Cartesian space by reducing the problem to the
singularity analysis of a new robot.
The interaction matrixM
T
involved in the controller gives
the value of
c
ú u as a function of
c
?
c
. Thus,M
T
is the inverse
Jacobian matrix of the hidden robot (and, consequently,
M
T+
is the hidden robot Jacobian matrix). Except in the case
of decoupled robots [18], [19], [20], the Jacobian matrices
of parallel robots are not free of singularities.
Thus,
¥ Þnding the condition for the rank-deÞciency of M
T
is
equivalent to Þnding the Type 2 (or parallel) singulari-
ties of the hidden robot [21],
¥ Þnding the condition for the rank-deÞciency ofM
T+
is
equivalent to Þnding the Type 1 (or serial) singularities
of the hidden robot [21].
Point 4: the hidden robot model can be used to certify that
the robot will not converge to local minima.
The robot could converge to local minima if the matrix
L
T+
of (6) is rank deÞcient. A necessary and sufÞcient
condition for the rank deÞciency of this matrix is that
5723
C
i1
Fixed
base
C
i2
u
i
Moving
platform Spatial
parallelogram
C
i
Planar
parallelogram
(a) a ?Ð{2ÐUU} leg
Fixed
base
Articulated
moving
platform
P
i
P
j
(b) the hidden robot model for the
Adept Quattro
A
i
u
i
Moving
platform
B
i
C
i
u
i
Actuated
U joint
B
i
C
i
S
i
Vertex space
of leg i
Free motion
of point B
i
C
i
D
i
D
i
l
AiBi
C
i 
:
(c) vertex space of point D
i
(pro-
jection of the ?Ð{2ÐUU} leg in a
vertical plane)
Fixed
base
P
i P
j
Uncontrolled
platform motion
       vertical slice of the
Bohemian Dome for a 
constant platform
orientation
C
j
Articulated
moving
platform
C
i 
:
(d) example of a Type 2 singularity
for a 2Ð?(2ÐUU) robot: the platform
gets an uncontrollable translation
Fig. 4. Example of leg and of hidden robot for the Quattro
the M
T+
is rank deÞcient, i.e. the hidden robot model
encounters a Type 1 singularity.
For illustrating this Section, let us present the fkp and
singularity analysis of the hidden robot model of the Quattro
with 4 dof (that can perform Schoenßies motions), when
controlled using leg direction observation. It must be men-
tionned that, in [15], the Quattro with rigid platform, i.e. with
3 translation dof, was studied. The kinematics of the hidden
robot for the version with 4 dof is completely different and
is the object of this Section.
The Quattro is made of 4 RÐ{2ÐUS} legs (see Fig. 1),
thus, following the previous approach, its equivalent hidden
robot will be made of ?Ð{2ÐUS} or ?Ð{2ÐUU} legs. As
such hidden robot legs have 2 degrees of actuation (the U
joint is fully actuated), only two legs have to be observed for
fully controlling the Quattro using leg direction observation.
However in this case, if the hidden robot has a 2Ð?Ð{2ÐUS}
architecture, the platform will have two uncontrolled dof.
This phenomenon disappears if ?Ð{2ÐUU} legs are used
in the hidden robot model (Fig. 4 Ð in this picture, the
articulated platform is simpliÞed for a clearer drawing, but
has indeed the kinematic architecture presented in Fig. 1(c)).
Forward kinematics and assembly modes. Without loss of
generality, let us consider that we analyse the 2Ð?Ð{2ÐUU}
robot depicted at Fig. 4(a). Looking at the vertex space of
each leg when the active U joints are Þxed, the points C
i
and D
i
are carrying out a circle C
i
of radius l
AiBi
centred
in S
i
(Fig. 4(c)).
The Quattro with 4 dof, and consequently its hidden robot
model, has a particularity: its platform is passively articulated
(Fig. 1(c)) so that its orientation with respect to the horizontal
plan xOy stays constant, while it can have one degree of
rotation around the z axis, i.e. point D
2
can describe a circle
C
l
located in the horizontal plane, centred in D
1
and with a
circle C
2 
:
vertex space of
the 2nd leg
coupler surface
(Bohemian Dome)
actuated
U joints
(on ? joints)
u
1
passive motions of
the ? joints
platform
P
l
S
1
S
1
D
1
A
1
B
1
C
1
(a) Coupler surface when leg 2 is discon-
nected
vertex space of
the 2nd leg
coupler surface
actuated
U joints
(on ? joints)
u
1
u
2
passive motions of
the ? joints
platform
(b) First set of possible assembly
modes
vertex space of
the 2nd leg
coupler surface
actuated
U joints
(on ? joints)
u
1
u
2
passive motions of
the ? joints
platform
(c) Second set of possible assembly
modes
Fig. 5. Solutions of the fkp for a 2Ð?Ð{2ÐUU} robot (in this example,
only 4 assembly modes exist)
radius l
D1D2
. For solving the forward kinematics, it is thus
necessary to virtually cut the platform at point D
2
and to
compute the coupler surface of point D
2
when it belongs
to leg 1. This coupler surface is the surface generated by
C
l
when it performs a circular translation along C
1
. Such a
surface is depicted in Fig. 5(a) and is called a Bohemian
Dome [22].
A Bohemian Dome is a quartic surface, i.e. an algebraic
surface of degree 4. When it intersects the vertical plane
P
l
containing the circle C
2
(i.e. vertex space of the second
leg), the obtained curve is a quartic curve (denoted at S
1
Ð Fig.5(a)). And using the B« ezout theorem [23], it can be
proven that, when the circle corresponding to the vertex
space of leg 2 intersects this quartic curve, there can exist
at most 8 intersection points, i.e. 8 assembly modes. Some
examples of assembly modes for the 2Ð?Ð{2ÐUU} robot
are depicted in Figs. 5(b) and 5(c).
Singular conÞgurations. For the 2Ð?Ð{2ÐUU} robot, Type
2 singularities appear when the planes P
i
and P
j
(whose
normal vectors are equal tov
?
i
andv
?
j
, resp.) are parallel. In
such cases, the circleC
2
is tangent to the Bohemian Dome at
their intersection point and the robot gains one uncontrollable
dof along this tangent (Fig. 4(d)). We must note here that
this can happen even when all four legs are being observed,
so in some situations, stacking the interaction matrices is not
a solution.
5724
C. Selection of the Controlled Legs
This Section has shown the importance of studying the
intrinsic properties of the controller that are directly related
to the choice of the stacked interaction matrices required
for computing the control law. Depending on the chosen
interaction matrices, i.e. on the choice of the observed legs,
the geometry of the hidden robot models will vary, as well as
its singularities and assembly modes. As singularities divide
the workspace into distinct aspects [2], it is necessary to
study the motion feasibility by selecting a set of legs that
can allow the robot displacement. Moreover, even if the
motion is feasible, if the robot goes close to a singularity,
the positioning error can considerably grow.
Therefore, it is necessary to Þnd the best set of legs
to observe in order to get the best performances of the
robot w.r.t. a desired task. For the sake of compactness,
the methodology for this will not be presented here, but the
reader is referred to [15] for more information on this.
In the next Section, all the presented theoretical results are
validated through experiments on the Adept Quattro [24].
IV. CASE STUDY
A. Description of the benchmark
In this Section, experiments are performed on the Adept
Quattro presented in the previous Section. The benchmark is
composed of (Fig. 6):
¥ an Adept Quattro robot bought by the Institut Pascal of
Clermont-Ferrand (France),
¥ a camera A VT Marlin F131B Þrewire IEEE1394 (lens:
3.6mm 1:1.6 1/2 inch for CCD camera), which is
mounted at the centre of the robot base so that all the
legs can be observed without any problems of occlusion
and whose intrinsic and extrinsic parameters have been
calibrated,
¥ a lighting system that provides an homogeneous lighting
to the scene,
¥ a computer that extracts the data coming from the
camera, computes the value of the leg directions u,
then calculates the robot actuator velocity ú q using the
controller of Section II-B and send the information to
the robot controller. Note that, in experiments, the value
of ? in the controller is Þxed to 0.2.
It must be mentioned we have deliberately decided to
use the minimal camera resolution and not to correct the
distortion of the captured image. The measurement noise on
the leg direction is thus of about 0.1 rad, but:
¥ such a high noise is interesting to show the controller
robustness to leg direction prediction errors,
¥ the noise is so high that, for analysing the robot accu-
racy and measuring the distance between the real and
nominal robot conÞgurations, we can directly record
and use the value of the platform pose predicted by the
Adept Quattro controller instead of using one external
measurement device (such as a laser tracker).
Visual based servoing Leg edge extraction
Adept Quattro controller
(with internal safeties)
Camera AVT
Marlin F131B
u
q
.
q Firewire
connexion
Computer
ViSP +
OpenCV
Leg model n
Firewire
connexion
q
.
Input
torques
Lighting
Fig. 6. Experimental bench
B. Experimental validations
Testing the convergence of the robot to the desired pose
In the Þrst set of experiments, the initial platform pose is
equal to {x = 0m,y = 0m,z = ?0.75m,? = 0rad} and
the Þnal desired platform pose is set to {x = ?0.2m,y =
0m,z =?0.56m,? = 0rad}. To go from the initial point to
the Þnal one, two sets of observed leg directions are tested:
{1,4} and {2,3}. For those two sets of legs, solving the
fkp of the hidden robot model of the Quattro presented in
Section III-B at the desired Þnal conÞguration of the robot,
gives four possible solutions each. For legs{1,4}, these are:
¥ {x =?0.2m,y = 0m,z =?0.56m,? = 0rad}
¥ {x =?0.2m,y = 0m,z =?0.909m,? = 0rad}
¥ {x = ?0.138m,y = 0.062m,z = ?1.019m,? =
0rad}
¥ {x =?0.138m,y = 0.062m,z =?0.45m,? = 0rad}
The solutions for legs {2,3} are:
¥ {x =?0.2m,y = 0m,z =?0.56m,? = 0rad}
¥ {x =?0.2m,y = 0m,z =?0.296m,? = 0rad}
¥ {x = ?0.262m,y = 0.062m,z = ?0.694m,? =
0rad}
¥ {x = ?0.262m,y = 0.062m,z = ?0.161m,? =
0rad}
The robot is asked to move from the initial conÞguration
to the Þnal one. Due to the presence of high measurement
noise, the robot can of course not converge to the Þnal desired
pose.
The results are illustrated in Figs. 7 and 8. It can be
seen that using legs {1,4}, not all legs tend to go to
zero, and indeed the Þnal attained pose will be P
f14
=
{x = ?0.11,y = 0.01,z = ?0.86,? = ?2.15rad}.
Simulations were run by adding the measurement noise to
the leg directions in the kinematic model [15] to determine
the uncertainty areas due to the aforementioned measurement
error corresponding to the Þnal attained position. The result-
ing tolerable errors in position and orientation were 0.11m
and 2.00rad, respectively. The fkp solution around P
f14
is
{x = ?0.2m,y = 0m,z = ?0.909m,? = 0rad}, so the
5725
Initial
platform
pose
Final
platform
pose
Desired
platform
pose
(a) top view of the platform
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0 10 20 30 40 50
Time (sec)
||e
i
||
Leg 3
Leg 1
Leg 4
Leg 2
(b) error norm on each leg ke
i
k
Fig. 7. Convergence of the robot when legs 1 and 4 are observed (desired
pose: {x = ?0.2,y =0,z = ?0.56,? =0}).
Initial
platform
pose
Final
platform
pose Desired
platform
pose
(a) top view of the platform
0 10 20 30 40 50
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
0.55
0.6
Time (sec)
||e
i
||
Leg 3
Leg 1
Leg 4
Leg 2
(b) error norm on each leg ke
i
k
Fig. 8. Convergence of the robot when legs 2 and 3 are observed (desired
pose: {x = ?0.2,y =0,z = ?0.56,? =0}).
robot does not converge to the desired pose, but to the second
fkp solution of its hidden robot model.
When observing legs {2,3}, all legs correctly tend to go
to zero, and the Þnal attained pose will be P
f23
= {x =
?0.12,y = 0.05,z = ?0.55,? = ?0.90rad}. After the
simulations, we obtain the associated uncertainty area of
this Þnal pose, characterised by tolerable errors of 0.23m
in position and 1.23rad in orientation. Around P
f23
can be
found the desired Þnal position, i.e. the Þrst fkp solution,
{x =?0.2m,y = 0m,z =?0.56m,? = 0rad}.
A second experiment is performed in which all legs
are observed. The initial platform pose is equal to {x =
0.05m,y = 0.05m,z = ?0.8m,? = 0rad} and the Þnal
desired platform pose is set to {x = 0.03m,y = 0.03m,z =
?0.59m,? = 0rad}. Solving the fkp of the hidden robot
model of the Quattro when all legs are observed at the desired
Þnal conÞguration of the robot, it can be proven that there
still exist two assembly modes which are:
¥ {x = 0.03m,y = 0.03m,z =?0.59m,? = 0rad}
¥ {x = 0.03m,y = 0.03m,z =?0.65m,? = 0rad}
Performing the motion, the robot arrived in the Þnal pose
P
f1234
= {x = 0.03m,y = 0.03m,z = ?0.72m,? =
0.05rad}.Even though all legs tend to go to zero, the robot
does not converge to the desired pose, but to the second
fkp solution. Indeed, when we perform the simulations to
determine the uncertainty area, we obtain tolerable errors
in position of 0.08m and orientation of 1.54rad, describing
a volume which contains the aforementioned fkp solution,
{x = 0.03m,y = 0.03m,z = ?0.65m,? = 0rad}.
The Þnal platform pose presents an error of 0.07m in
position error and 0.05rad in orientation w.r.t. this second
fkp solution. These results are illustrated in Fig. 9.
Initial
platform
pose
Final
platform
pose
Desired
platform
pose
(a) top view of the platform
2 4 6 8 10
0.01
0.02
0.03
0.04
0.05
0.06
0.07
0.08
0
Time (sec)
||e
i
||
Leg 3
Leg 1
Leg 4
Leg 2
(b) error norm on each leg ke
i
k
Fig. 9. Convergence of the robot when all legs are observed (desired pose:
{x= 0.03,y = 0.03,z = ?0.59,? =0}).
It should be mentioned that the plotted values of the error
norms are computed using the values of the leg directions
given by the Quattro controller.
All these experimental results conÞrm the presence of
the virtual robot hidden within the controller that must be
studied in order to avoid the convergence problems due to
inadequate stacking of interaction matrices.
Testing the importance of the selection of the observed
legs on the robot accuracy
To show the importance of the leg selection on the robot
accuracy, it is decided to control the robot displacement using
different sets of legs. Each experiment is run Þve times and
we present here the maximal values obtained on the position
and orientation error.
In the Þrst set of experiments, two different sets of legs
are observed: (i) legs {2,3} and (ii) legs {2,4}, going from
the initial pose {x = 0.02m,y = 0.1m,z = ?0.7m,? =
0rad} to the Þnal pose {x = ?0.2m,y = 0.01m,z =
?0.7m,? = 0rad}. When legs {2,3} are observed, the
Þnal pose accuracy shows a position error of 0.11m and
an orientation error of 0.06rad, while in the case of legs
{2,4}, the errors are 0.23m and 0.68rad, respectively. Thus
we obtain better accuracy when observing the Þrst set of
legs.
In the second set of experiments, the initial platform pose
is equal to{x = 0.05m,y = 0.05m,z =?0.8m,? = 0rad}
and the Þnal desired platform pose is set to{x = 0.03m,y =
0.03m,z =?0.65m,? = 0rad}. It is decided to control the
robot displacement using three different sets of legs: (i) legs
{1,4}, (i) legs {1,3,4} and (iii) all legs. In the Þrst case,
the Þnal platform pose is characterised by a 0.11m position
error and a 0.39rad orientation error. When observing three
legs, we obtain 0.09m error in position and 0.31 error in
orientation. And lastly with four legs we have a position error
of 0.07m and an orientation error of 0.05rad. These results
show that increasing the number of legs to be observed also
increases the accuracy of the platform.
All these experimental results conÞrm the necessity to
carefully select the set of legs to observe in order to obtain
the best accuracy possible. However, it must be recalled that,
even if observing all the legs lead to a better accuracy, this
result must not hide the fact that some convergence problems
can still appear, as shown previously.
5726
V. CONCLUSIONS
This paper has presented the Òhidden robot conceptÓ, a
tangible visualisation of the mapping between the observa-
tion space and Cartesian space of parallel robots controlled
through the use of leg direction-based visual servoing. This
robot, which has different assembly modes and singular
conÞgurations from the real robot, can be used as a tool
to simplify the analysis of the mapping between intrinsic
and extrinsic parameters acquired through vision. This tool
offers:
1) explanation why it is possible to fully control the real
robot by observing a number of legs which is less than
the number of total legs,
2) proof that there does not always exist a full diffeo-
morphism between the Cartesian space and the leg
direction space,
3) simpliÞed singularity analysis of the mapping between
the leg direction space and the Cartesian space by
reducing the problem to the singularity analysis of a
the new hidden robot,
4) knowledge about the existence of local minima and
certiÞcation whether the robot will or will not converge
to these, through the applciation of tools developed for
the singularity analysis of robots.
A general approach has been presented, which allows the
deÞnition of the hidden robot model corresponding to any
real parallel robot controlled via leg orientation-based visual
servoing. This method has been applied to the Adept Quattro,
followed by experiments which demonstrate the validity of
the theoretical developments.
Finally, in this paper, we only considered to observe the
leg direction u
i
, and not the leg edges in the image space,
as the leg edges are only used as a measure ofu
i
. However,
the problem is the same, except in the fact that we must
consider the singularity of the mapping between the edges
andu
i
, which appears when the cylinders are at inÞnity [17].
Thus, the concept of hidden robot model has been proven
to be a powerful tool, which brings mathematical tools
developed by the mechanical design community to aid in
the study of the correlation between intrinsic and extrinsic
properties of some controllers developed by the visual ser-
voing community. Also, not only has this tool simpliÞed
the analysis of the mapping between the Cartesian space
and observation space, but has also proven that using only
the extrinsic properties of the controller without doing the
analysis of the intrinsic ones is clearly not enough.
REFERENCES
[1] T. Leinonen, ÒTerminology for the theory of machines and mecha-
nisms,Ó Mechanism and Machine Theory, vol. 26, 1991.
[2] J. Merlet, Parallel Robots, 2nd ed. Springer, 2006.
[3] ÑÑ, 2012. [Online]. Available: www-sop.inria.fr/members/Jean-
Pierre.Merlet/merlet.html
[4] B. Espiau, F. Chaumette, and P. Rives, ÒA new approach to visual
servoing in robotics,Ó IEEE Transactions on Robotics and Automation,
vol. 8, no. 3, 1992.
[5] R. Horaud, F. Dornaika, and B. Espiau, ÒVisually guided object
grasping,Ó IEEE Transactions on Robotics and Automation, vol. 14,
no. 4, pp. 525Ð532, 1998.
[6] P. Martinet, J. Gallice, and D. Khadraoui, ÒVision based control law
using 3D visual features,Ó in Proceedings of the World Automation
Congress, WAC96, Robotics and Manufacturing Systems, vol. 3, Mont-
pellier, France, May 1996, pp. 497Ð502.
[7] E. Ozgur, N. Andreff, R. Dahmouche, and P. Martinet, ÒHigh speed
parallel kinematic manipulator state estimation from legs observation,Ó
in Proceedings of the IEEE/RSJ International Conference on Intelli-
gent Robots and Systems (IROS 2013), Tokyo Big Sight, Japan, 2013.
[8] N. Andreff, A. Marchadier, and P. Martinet, ÒVision-based control
of a Gough-Stewart parallel mechanism using legs observation,Ó in
Proceedings of the IEEE International Conference on Robotics and
Automation, ICRAÕ05, Barcelona, Spain, April 18-22 2005, pp. 2546Ð
2551.
[9] V . Gough and S. Whitehall, ÒUniversal tyre test machine,Ó in Proceed-
ings of the FISITA 9th International Technical Congress, May 1962,
pp. 117Ð317.
[10] E. Ozgur, N. Andreff, and P. Martinet, ÒDynamic control of the quattro
robot by the leg edgels,Ó in Proceedings of the IEEE International
Conference on Robotics and Automation, ICRA11, Shanghai, China,
May 9-13 2011.
[11] N. Andreff and P. Martinet, ÒVision-based kinematic modelling of
some parallel manipulators for control purposes,Ó in Proceedings of
EuCoMeS, the First European Conference on Mechanism Science,
Obergurgl, Austria, 2006.
[12] F. Chaumette, The Conßuence of Vision and Control, ser. LNCIS.
Springer-Verlag, 1998, no. 237, ch. Potential problems of stability and
convergence in image-based and position-based visual servoing, pp.
66Ð78.
[13] S. Briot and P. Martinet, ÒMinimal representation for the control of
Gough-Stewart platforms via leg observation considering a hidden
robot model,Ó in Proceedings of the 2013 IEEE International Confer-
ence on Robotics and Automation (ICRA 2013), Karlsruhe, Germany,
May, 6-10 2013.
[14] S. Caro, W. Khan, D. Pasini, and J. Angeles, ÒThe rule-based concep-
tual design of the architecture of serial schonßies-motion generators,Ó
Mechanism and Machine Theory, vol. 45, no. 2, pp. 251Ð260, 2010.
[15] V . Rosenzveig, S. Briot, and P. Martinet, ÒMinimal representation for
the control of the Adept Quattro with rigid platform via leg observation
considering a hidden robot model,Ó in Proceedings of the IEEE/RSJ
International Conference on Intelligent Robots and Systems (IROS
2013), Tokyo Big Sight, Japan, 2013.
[16] F. Chaumette, La commande des robots manipulateurs. Herm` es, 2002.
[17] N. Andreff, T. Dallej, and P. Martinet, ÒImage-based visual servoing
of gough-stewart parallel manipulators using legs observation,Ó Inter-
national Journal of Robotics Research, vol. 26, no. 7, pp. 677Ð687,
2007.
[18] M. Carricato and V . Parenti-Castelli, ÒSingularity-free fully-isotropic
translational parallel manipulators,Ó International Journal of Robotics
Research, vol. 21, no. 2, pp. 161Ð174, 2002.
[19] X. Kong and C. Gosselin, ÒA class of 3-dof translational parallel
manipulators with linear input-output equations,Ó in Proceedings of
the Workshop on Fundamental Issues and Future Research Directions
for Parallel Mechanisms and Manipulators, Qu« ebec City, QC, Canada,
October 2002, pp. 3Ð4.
[20] G. Gogu, ÒStructural synthesis of fully-isotropic translational parallel
robots via theory of linear transformations,Ó European Journal of
Mechanics. A/Solids, vol. 23, no. 6, pp. 1021Ð1039, 2004.
[21] C. Gosselin and J. Angeles, ÒSingularity analysis of closed-loop
kinematic chains,Ó IEEE Transactions on Robotics and Automation,
vol. 6, no. 3, pp. 281Ð290, 1990.
[22] M. Tale Masouleh, C. Gosselin, M. Husty, and D. Walter, ÒForward
kinematic problem of 5-RPUR parallel mechanisms (3T2R) with
identical limb structures,Ó Mechanism and Machine Theory, vol. 46,
pp. 945Ð959, 2011.
[23] E. B« ezout, Recherches sur le degr« e des « equations r« esultantes de
lÕ« evanouissement des inconnues. Histoire de lÕAcad« emie Royale des
Sciences, 1764.
[24] V . Nabat, M. de la O Rodriguez, O. Company, S. Krut, and F. Pierrot,
ÒPar4: very high speed parallel robot for pick-and-place,Ó in Proceed-
ings of the 2005 IEEE/RSJ International Conference on Intelligent
Robots and Systems (IROS 2005)., 2005.
5727
