Sparse learning for salient facial feature description*
Yue Zhao
1
and Jianbo Su
1
Abstract— High dimension of the features employed for face
recognition is the main reason to slow down the recogni-
tion speed. Additionally, selecting salient facial features has
signiﬁcant impact on the efﬁciency of face recognition. In
order to get the sparse and salient facial features, this paper
propose a new sparse learning approach for salient facial feature
description. This approach is to learn the feature evaluation
vector with the training samples composed of within- and
between-class distance vector sets. Then, the feature evaluation
vector is employed to construct a new model for salient facial
feature description. Experimental results show that the proposed
method achieves much better face recognition performance with
lower feature dimensionality.
I. INTRODUCTION
As a hot research area of artiﬁcial intelligence, face
recognitionhas generated wide applications including person
identiﬁcation [1], video surveillance [2], intelligent camera
[3]–[5], and so on. To achieve good face recognition results,
the key issue is to affordan efﬁcient facial feature descriptor.
In the past couple of years, many descriptors have been
presented for face recognition.A hybrid approach,Eigenface
[6], is proposed by M.Turk and A.Pentland. It produces
features by performingPrincipal ComponentAnalysis (PCA)
to local face regions independently [7]. Based on the theory
of Fisher Linear Discriminant Analysis (FLDA), Fisherface
[8] ﬁnds the optimal projector that maps the original data
into a low-dimensional feature space. This process follows
the restriction that the ratio of the trace of the between-class
scatter to the trace of the within-class scatter is maximized
[9]. Elastic Bunch Graph Matching (EBGM) [10] uses the
the Gabor ﬁlter responding in certain facial landmarks and
a graph describing the spatial relations of these landmarks
[11] to describe faces. Local Binary Pattern (LBP) is ﬁrstly
adopted to describe facial features by Ahonen et al. [12].
To describe the face feature more efﬁciently, Ahonen et
al. assign different weights to different regions based on
the psychology research. This leads to good results of face
recognition. A three-level operator, Local Ternary Patterns
(LTP), is proposed by Tan et al. [13]. LTP features are more
discriminant and less sensitive to noise. Guo et al. present
a hierarchical mutliscale LBP (HM-LBP) model [14] to dig
out useful information from those “non-uniform” patterns.
*This work was partially ﬁnancially supported by the Key Project of
National Natural Science Foundation ofChina(NSFC)undergrant60935001
1
Yue Zhao and Jianbo Su are both with Department of Automation,
Shanghai Jiao Tong University, and Key Laboratory of System Control and
Information Processing, Ministry of Education of China, Shanghai 200240
zhaoyue0609@sjtu.edu.cn; jbsu@sjtu.edu.cn
For face recognition, LTP, HM-LBP and the other region-
based features have achieved good results [13], [14]. How-
ever, they normally give rise to feature sets of high di-
mensionality, which essentially slows down the speed of
face recognition. In addition, they ignore the different con-
tributions of the features (a feature is an element of the
feature vector) in the same region, which leads to features
with different salience have the same importance for face
recognitionin one region. To get the sparse and salient facial
features, this paper propose a new sparse learning approach
for salient facial feature description based on our previous
work[15].Firstly, a facial featuretransformationis presented
to generate the training samples composed of within- and
between-class distance vector sets. Then, a sparse learning
approach is presented to learn the feature evaluation vector
withthetrainingsamples.Lastly,thefeatureevaluationvector
isemployedtoconstructanewmodelforsalientfacialfeature
description. As the sparse learning approach encourages the
sparsityatboththegroupandindividuallevels,thenewfacial
featuredescriptionmodelcan distinguishthe contributionsof
different dimensions of the features in the same region and
thus achieve dimensionality reduction.
The rest of the paper is organized as follows. Regional
facial feature descriptors are presented in Section II. Section
III describes the general facial feature description models.
In Section IV, a sparse learning approach is proposed to
evaluate the salience of the facial features. Then, the salient
facial feature description model is derived in Section V.
Extensive experiments results are employed to illustrate the
performanceof the proposedmethod in Section VI, followed
by the conclusions in Section VII.
II. REGIONAL FACIAL FEATURE DESCRIPTORS
Regional feature descriptors are the dominant descriptors
in face recognition, such as LTP [13] and HM-LBP [14].
A. LTP
The LBP operator takes a local neighborhoodaround each
pixel, thresholds the pixels of the neighborhood at the value
of the central pixel and uses the resulting binary-valued
image patch as a local image descriptor. LBPs threshold
exactly at the value of the central pixel, they tend to be
sensitivetonoise,speciallyinnear-uniformimageregions.So
LTP descriptor employs 3-valued codes to generate ternary
code. Suppose g
c
is the gray value of the center pixel of
the circular template, and g
e
is the gray value of the e
th
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 5565
neighborhood, where e=0,1,2,...,E?1. The original gray
level distribution of the these points T is:
T ={g
c
,g
0
,g
1
,...,g
E?1
}. (1)
The original gray level distribution can be described by the
joint difference distribution approximatively, which is:
T≈{g
0
?g
c
,g
1
?g
c
,...,g
E?1
?g
c
}. (2)
In order to achieve the variance with respect to the scaling
of the gray scale, LTP descriptor only considers the signs of
thedifferencesinsteadoftheirexactvalues.Thusthe original
gray level distribution T can be expressed by the following
equation:
T≈{s(g
0
?g
c
),s(g
1
?g
c
),...,s(g
E?1
?g
c
)}. (3)
The gray value of the neighborhoods in a zone of width ±t
aroundg
c
arequantizedto“0”.Onesabovethis arequantized
to “1” and ones below it to “-1”. This procedure can be
described by the following formula:
s(g
e
?g
c
)=
? ? ? 1 if g
e
?g
c
≥t
0 if |g
e
?g
c
|<t
?1 if g
e
?g
c
≤?t
e=0,1,2,...,E?1.
(4)
where t is a threshold speciﬁed manually. In this way, LTP
codes are more resistant to noise. Fig. 1 presents the LTP
encoding process. LTP descriptor also use the “uniform”
pattern to describe the texture pattern in a local area.
B. HM-LBP
LBP descriptor adopts “uniform” patterns to reduce the
number of binary patterns, which has been validated to play
animportantroleinfacerecognition[12]–[14].Incorporating
uniform idea, many patterns, which are not uniform patterns,
are clustered into a set of non-uniform patterns. By this
way, many discriminant but non-uniform patterns fail to
provide useful features, and the percentage of non-uniform
patterns increases as the radius increases, which leads to
muchinformationlost. DifferenttoLBP descriptor,HM-LBP
descriptorusesmanycirculartemplateswithdifferentsizesto
generate uniform pattern. After the LBP map of the biggest
radius for each pixel is gotten, the whole pixels are divided
into two groups: one group with the uniform pattern, and the
other with the non-uniform pattern. For the latter, another
circular template with a smaller radius will be employed to
extract the LBP patterns. The process will be stopped, if the
smallest radius has arisen. [14].
III. GENERAL FACIAL FEATURE DESCRIPTION MODELS
For face recognition, descriptors LTP and HM-LBP all
statistics the number of each uniform pattern in a local face
image area to obtain a set of histogram vectors, and then
concatenated them into a whole histogram vector as a facial
feature vector. The detailed procedures are as follows.
Fig. 1. The theories of LTP coding.
LTP andHM-LBP bothdivideaface imageintor different
regions: D
1
,D
2
,...,D
r
, then an m-dimensional histogram
vector is calculated for each region. Lastly, r histogram
vectors H[1],H[2],...,H[r] compose a 1?M feature vector
to describe the face image I:
H=[h
1
,...,h
j
,...,h
M
]
=[h
1
,...,h
m
  
H[1]
,h
m+1
,...,h
2m
  
H[2]
,...,h
(r?1)m+1
,...,h
rm
  
H[r]
],
(5)
where M =r?m, and h
j
is an element of the feature vector
H.
Eq. (5) is an unweighted facial feature description model,
and we simply call it as Unweighted Model. In this model,
each feature plays the same role.
As the psychophysical studies show that some facial
regions contain more useful information than others for
distinguishingdifferentpersons[2],Ahonenet al.[12]assign
different weights to different regions, but all the features in
the same region still have the same weight. We visualize the
region weights in Fig. 2. Based on this idea, we also assign
different weights to different regions in model (5), and then
get a regionweightedfacial featuredescriptionmodelshortly
named as Region Weighted Model, which can be described
as following:
K=[k
1
,...,k
j
,...,k
M
]
=[?
1
k
1
,...,?
1
k
m
  
K[1]
,?
2
k
m+1
,...,?
2
k
2m
  
K[2]
,...,
?
m
k
(r?1)m+1
,...,?
m
k
rm
  
K[r]
],
(6)
where K is the local feature vector, divided into
K[1],K[2],...,K[r], correspondingto ther regionsofthe face
image. k
j
is an element of the feature vector K. ?
m
is the
weight for all the features in the m
th
region.
Model (6) has considered different contributions of dif-
ferent facial regions, but it ignores the variety of feature
contributions in the same region.
IV. SALIENCE EVALUATION OF FACIAL FEATURES
A. Sample Sets Generation
For a face image dataset, LTP or HM-LBP descriptor is
adopted to extract feature vectors, which compose a feature
vectorset. Because each feature vectorhas not been assigned
5566
matrix S and feature evaluation vector ? into r sub-matrices
respectively, we have:
? ????? ????? S =[s
1
,...,s
m
  
S[1]
,s
m+1
,...,s
2m
  
S[2]
,...,s
(r?1)m+1
,...,s
rm
  
S[r]
]
? =[?
1
,...,?
m
  
?
T
[1]
,?
m+1
,...,?
2m
  
?
T
[2]
,...,?
(r?1)m+1
,...,?
rm
  
?
T
[r]
]
T
,
(12)
where s
m
is the m
th
column of S.
By introducing the group lasso scheme to the problem
(10), the following sparse minimization problem could be
formulated to get the solution of ?:
argmin
??R
M
L?
r
∑
?=1
S[?]?[?]
2
2
+?
r
∑
?=1
?[?]
2
, (13)
where S[?] denotes the?
th
groupof distance vectors,?[?] is
the corresponding feature evaluation vector of the ?
th
group
of features, and ·
2
is the Euclidean norm. Here ? > 0
is a complexity parameter which controls the amount of
shrinkage:the largerthe valueof? is, the greaterthe amount
of shrinkage could be. The solution of (13) can be obtained
with the method presented in [22]. As each element of the
feature evaluation vector must be nonnegative, the following
formula is used to update ?:
¯
?
j
=
	
?
j
if ?
j
>?
0 if ?
j
≤?,
(14)
where
¯
?
j
is the updated value of ?
j
, and ? >0 is a threshold
whichcontrolsthe dimensionalityof the facial featurevector.
The largerthe valueof? is, the smaller the dimensionalityof
the facial feature vector will be. Suppose the ﬁnal evaluating
indicator vector by updating ? is:
¯
? =[
¯
?
1
,...,
¯
?
j
,...,
¯
?
M
]
T
. (15)
As many elements of
¯
? are zeros, the correspondingfeatures
of these zero elements can be omitted directly, which greatly
reduces the facial feature dimensionality.
V. SALIENT FACIAL FEATURE DESCRIPTION MODEL
A new facial feature description model is obtained by
combining (15) and (5):
A=[a
1
,...,a
j
,...,a
M
]
=[
¯
?
1
?h
1
,...,
¯
?
j
?h
j
,...,
¯
?
M
?h
M
]
=[
¯
?
1
h
1
,...,
¯
?
m
h
m
  
A[1]
,
¯
?
m+1
h
m+1
,...,
¯
?
2m
h
2m
  
A[2]
,...,
¯
?
(r?1)m+1
h
(r?1)m+1
,...,
¯
?
rm
h
rm
  
A[r]
],
(16)
where A is a feature vector, and divided into A[1], A[2], ...,
A[r], corresponding to the r regions of the face image. Each
feature is afforded a weight to evaluate its contribution for
face recognition in model (16). Thus, this model is a feature
weighted facial feature description model, and we call it
Feature Weighted Model simply. As
¯
? assigns larger weights
to more salient features, model (16) is also a salient facial
feature description model.
VI. EXPERIMENTS
In this section, three facial feature description models:
Unweighted Model, Region Weighted Model and Feature
Weighted Model are employed to perform the experiments.
The region weights for Region Weighted Model are all the
sametothosein[12],whichcanbeseeninFig.2.Indifferent
databases, the region weights are ﬁxed. The feature weights
forFeatureWeightedModelaregeneratedautomaticallywith
the sparse learning approach described in Section IV, and
various in different databases. Two feature descriptors: LTP
[13]andHM-LBP[14]areadoptedforextractingtheoriginal
image features.
A. Data Description
Two face databases FERET [23] and CAS-PEAL-R1 [24]
are used in our experiments. FERET database is one of
the well-known face database, which contains ﬁve subsets
varying in lighting, ages and expressions. Experiments are
performed with the same gallery and probe sets speciﬁed by
the FERET evaluation protocol. 551 positive samples and
658,445 negative samples are employed to learn the feature
evaluation vector
¯
?. These positive and negative samples are
generated with all the training samples from the standard
FERET training set [23] and “subfc training set” [25].
Another famous face database is also applied to the ex-
periments. In this database, there are 30,900 images of 1,040
individualscontainingdifferentposes,expressions,andsoon.
The frontal images from subsets of accessory, background,
distance, expression, and aging are taken as probe sets and
normal gallery set in our experiments. 603 positive samples
and 200,196 negative samples generated by the standard
training set of CAS-PEAL-R1 database are used to learn the
feature evaluation vector
¯
?.
B. Results
The results of the three models: Unweighted Model, Re-
gionWeightedModelandFeatureWeightedModelaredrawn
inTables I,IIandFigs.4,5.FromTablesIandII,wecansee
thatFeatureWeightedModelachievesthehighestrecognition
rates on most of the subsets containing variations in lighting,
expressions, accessory, distance, background, and aging.
From the last column of Table I, we can see that for
each feature descriptor of LTP and HM-LBP, the average
recognition rate of Feature Weighted Model is obviously
better than Unweighted Model and Region Weighted Model.
Namely, Feature Weighted Model has the highest average
recognition rate.
5568
TABLE I
COMPARISONRESULTS OF DIFFERENT MODELS ON FERET DATABASE
Recognition rate (%) on the subset Average
Model Feature Dimensionality
fb fc dupI dupII recognition rate (%)
Unweighted Model [13] 5782 92.8 36.1 54.8 44.4 74.6
Region Weighted Model LTP 4602 96.0 61.9 59.1 50.4 80.2
Feature Weighted Model 800 97.3 80.4 61.6 47.4 83.7
Unweighted Model [14] 8575 94.2 48.5 65.2 56.8 80.1
Region Weighted Model HM-LBP 6825 97.4 75.3 68.8 64.1 85.6
Feature Weighted Model 2900 98.3 91.2 74.5 65.0 89.5
TABLE II
COMPARISONRESULTS OF DIFFERENT MODELS ON CAS-PEAL-R1DATABASE
Recognition rate (%) on the subset Average
Model Feature Dimensionality
Accessory Distance Background Expression Aging recognition rate (%)
Unweighted Model [13] 5782 61.4 96.9 83.9 88.4 81.8 72.3
Region Weighted Model LTP 4602 53.4 96.3 78.5 88.2 81.8 67.2
Feature Weighted Model 2000 70.5 97.5 86.9 93.3 86.4 79.5
Unweighted Model [14] 8575 75.9 97.5 99.4 89.1 87.9 82.6
Region Weighted Model HM-LBP 6825 66.6 97.8 99.5 88.7 89.4 77.5
Feature Weighted Model 2900 75.1 97.8 99.5 92.4 90.9 83.3
All the results show that Feature Weighted Model can
get the best performance on face recognition comparing to
the Unweighted Model and Region Weighted Model. This
is due to the fact that Feature Weighted Model not only
considers the contributions of different face regions, but also
can distinguish the contributions of different dimensions of
the features in the same region, which can represent the face
more precisely.
From Tables I and II, we can see that the feature vec-
tor generated by Feature Weighted Model has the lowest
dimensionality comparing with the feature vectors produced
by Unweighted Model and Region Weighted Model. This
indicates that Feature Weighted Model has the best sparsity
among the three models.
Figs. 4 and 5 present the relationship between feature
dimensionality and recognition rate generated by Feature
WeightedModelwithLTPandHM-LBPfeatures.Fromthese
two ﬁgures, Feature Weighted Model achieves satisfactory
performance with much lower feature dimensionality, which
shows that Feature Weighted Model can remarkably reduce
the feature dimensionality.
VII. CONCLUSIONS
Face recognition attracts more and more attention for
both wide applications and scientiﬁc challenges. This paper
focuses on constructing an efﬁcient facial feature description
model for face recognition, which can complete two goals:
(1) facial feature dimensionality reduction; (2) salient facial
feature selection. Thus, this paper proposes a new sparse
learning approach for salient facial feature description. The
proposed method ﬁrstly presents a facial feature transforma-
500 1000 1500 2000 2500 3000
0.2
0.4
0.6
0.8
1
Feature Dimensionality
Recognition Rate
fb fc dupI dupII
500 1000 1500 2000 2500 3000 3500 4000
0.2
0.4
0.6
0.8
1
Feature Dimensionality
Recognition Rate
fb fc dupI dupII
(a) 
(b) 
Fig. 4. Relationship between feature dimensionality and recognition rate
produced by Feature Weighted Model on FERET database: (a) with LTP
features; (b) with HM-LBP features.
tion to generate the training samples composed of within-
and between-class distance vector sets. Then, it proposes a
sparselearningapproachtolearnthefeatureevaluationvector
based on the training samples. Finally, the feature evaluation
5569
(a) 
(b) 
500 1000 1500 2000 2500 3000
0.4
0.5
0.6
0.7
0.8
0.9
1
Feature Dimensionality
Recognition Rate
Aging Accessory Background Distance Expression
500 1000 1500 2000 2500 3000 3500 4000
0.4
0.5
0.6
0.7
0.8
0.9
1
Feature Dimensionality
Recognition Rate
Aging Accessory Background Distance Expression
Fig. 5. Relationship between feature dimensionality and recognition rate
produced by Feature Weighted Model on CAS-PEAL-R1 database: (a) with
LTP features; (b) with HM-LBP features.
vectoris employedto constructanewmodelforsalientfacial
feature description.
Because the sparse learning approachencouragesthe spar-
sity at both groupand individuallevels, the proposedmethod
can greatly reduce the dimensionality of the facial feature
vector. As the feature evaluation vector can distinguish the
contributionsofdifferentfeaturesinthesameregion,thepro-
posedmethodcanrecognizethesalienceofdifferentfeatures.
Experimentalresults showthattheproposedmethodachieves
much better face recognition performance with lower feature
dimensionality. We really believe that the proposed method
can also be successfully used in object recognition, face
recognition, texture classiﬁcation, an so on.
REFERENCES
[1] A. Rice, P. J. Phillips, and A. O’Toole, “Variable use of the face and
body in person identiﬁcation,” Journal of Vision, vol. 13, no. 9, pp.
977–977, 2013.
[2] W. Zhao, R. Chellappa, P. J. Phillips, and A. Rosenfeld, “Face
recognition: a literature survey,” ACM Computing Surveys, vol. 35,
no. 4, pp. 399–458, 2003.
[3] C. Ye, T. Wu, Y. Chen, P. He, P. Xie, Y. Zhang, S. Teng, Y. Chen, and
P. Hsiung, “Smart video camera design–real-time automatic person
identiﬁcation,” in Advances in Intelligent Systems and Applications.
Springer, 2013, vol. 2, pp. 299–309.
[4] F. Huang and J. Su, “Face contour detection using geometric active
contours,” in Proceedings of World Congress on Intelligent Control
and Automation, vol. 3. IEEE, 2002, pp. 2090–2093.
[5] J. Dai, D. Liu, and J. Su, “Rapid eye localization based on projection
peak,” Pattern Recognition and Artiﬁcial Intelligence, vol. 4, 2009.
[6] M. Turk and A. Pentland, “Eigenfaces for recognition,” Journal of
Cognitive Neuroscience, vol. 3, no. 1, pp. 71–86, 1991.
[7] M. A. Turk and A. P. Pentland, “Face recognition using eigenfaces,”
in IEEE Conference on Computer Vision and Pattern Recognition
(CVPR). IEEE, 1991, pp. 586–591.
[8] P. Belhumeur, J. Hespanha, and D. Kriegman, “Eigenfaces vs. Fisher-
faces: recognition using class speciﬁc linear projection,” IEEE Trans-
actions on Pattern Analysis and Machine Intelligence, vol. 19, no. 7,
pp. 711–720, 1997.
[9] X. Jing, H. Wong, and D. Zhang, “Face recognition based on 2d
ﬁsherface approach,” Pattern Recognition, vol. 39, no. 4, pp. 707–710,
2006.
[10] L. Wiskott, J. Fellous, N. Kuiger, and C. von der Malsburg, “Face
recognition by elastic bunch graph matching,” IEEE Transactions on
Pattern Analysis andMachine Intelligence, vol.19,no. 7,pp.775–779,
1997.
[11] D. S. Bolme, “Elastic bunch graph matching,” Ph.D. dissertation,
Colorado State University, 2003.
[12] T. Ahonen, A. Hadid, and M. Pietikainen, “Face description with local
binary patterns: application to face recognition,” IEEE Transactions on
Pattern Analysis and Machine Intelligence, vol. 28, no. 12, pp. 2037–
2041, 2006.
[13] X. Tan and B. Triggs, “Enhanced local texture feature sets for face
recognition under difﬁcult lighting conditions,” IEEE Transactions on
Image Processing, vol. 19, no. 6, pp. 1635–1650, 2010.
[14] Z. Guo, L. Zhang, D. Zhang, and X. Mou, “Hierarchical multiscale
LBP for face and palmprint recognition,” in IEEE International Con-
ference on Image Processing (ICIP). IEEE, 2010, pp. 26–29.
[15] Y. Zhao and J. Su, “LBP-based hierarchical sparse patch learning for
face recognition,” in IEEE International Conference on Information
and Automation. IEEE, 2013, pp. 868–872.
[16] J. Friedman, T. Hastie, and R. Tibshirani, The elements of statistical
learning. Springer Series in Statistics, 2001.
[17] J. Han, M. Kamber, and J. Pei, Data mining: concepts and techniques.
Morgan kaufmann, 2006.
[18] Y. Eldar, P. Kuppinger, and H. Bolcskei, “Block-sparse signals: uncer-
tainty relations and efﬁcient recovery,” IEEE Transactions on Signal
Processing, vol. 58, no. 6, pp. 3042–3054, 2010.
[19] M. Stojnic, F. Parvaresh, and B. Hassibi, “On the reconstruction of
block-sparse signals with an optimal number of measurements,” IEEE
Transactions on Signal Processing, vol. 57, no. 8, pp. 3075–3085,
2009.
[20] M.YuanandY.Lin,“Model selection andestimation inregression with
grouped variables,” Journal of the Royal Statistical Society: Series B
(Statistical Methodology), vol. 68, no. 1, pp. 49–67, 2006.
[21] J. Friedman, T. Hastie, and R. Tibshirani, “A note on the group lasso
and a sparse group lasso,” Arxiv preprint arXiv:1001.0736, 2010.
[22] J. Liu and J. Ye, “Fast overlapping group lasso,” Arxiv preprint
arXiv:1009.0306, 2010.
[23] P. Phillips, H. Moon, S. Rizvi, and P. Rauss, “The FERET evaluation
methodology for face-recognition algorithms,” IEEE Transactions on
Pattern Analysis and Machine Intelligence, vol. 22, no. 10, pp. 1090–
1104, 2000.
[24] W. Gao, B. Cao, S. Shan, X. Chen, D. Zhou, X. Zhang, and D. Zhao,
“The cas-peal large-scale chinese face database and baseline evalua-
tions,” IEEE Transactions on Systems, Man, and Cybernetics, Part A:
Systems and Humans, vol. 38, no. 1, pp. 149–161, 2008.
[25] T. Ahonen, A. Hadid, and M. Pietik¨ ainen, “Face recognition with local
binary patterns,” in European Conferenceon Computer Vision (ECCV).
Springer, 2004, pp. 469–481.
5570
