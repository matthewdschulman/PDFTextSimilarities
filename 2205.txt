Agile Justin: An Upgraded Member of DLR’s Family of
Lightweight and Torque Controlled Humanoids
B. B¨ auml T. Hammer R. Wagner O. Birbach T. Gumpert F. Zhi U. Hillenbrand S. Beer W. Friedl J. Butterfass
I. ABSTRACT
This video presents the recent upgrades of the mobile
humanoid Agile Justin, bringing it closer to an ideal plat-
form for research in autonomous manipulation. Signiﬁcant
upgrades have been made in the ﬁelds of mechatronics,
3D sensors, tactile skin, massive GPGPU based computing
power, and software communication framework. In addition,
ﬁrst algorithms and two experimental scenarios are presented
that take advantage of these new capabilities.
Compared to other humanoid or two-armed robots like
iCub [1] or PR2 [2], Agile Justin provides a unique com-
bination of features: mechatronically it can perform highly
dynamic as well as dextrous tasks, it is equipped with a
multi-sensorial head for 3D modelling, a tactile skin with
high spatial and temporal resolution on its hands, a wireless
connection to a high performance GPGPU cluster, and a new
software framework for performant realtime communication
as well as higher level functional programming.
1) Mechatronics: Mechatronically the arms and mobile
platform are about 1.5 times faster and system can perform
well coordinated motions from the wheels to the ﬁngertips
with a time precision of 1ms over all 53 DOF. This allows
Agile Justin not only to catch a ball, as has been previously
shown [3], but even to throw it back again.
2) 3D perception: For advanced 3D perception an RGB-
D sensors has been integrated in the head and a wirelessly
coupled GPGPU cluster with 24000 cores runs a mapping
algorithm [4]. This allows the realtime generation of dense
3D models of the whole workspace with a resolution of 2mm.
Without ever transferring the models out of the GPGPU it
is used for optimization-based planning over all 22 DOF
of Justin’s torso and mobile platform [5]. The high-quality
models are also used as the basis for object recognition and
pose estimation. Thus, multiple hypotheses on the objects’
identity and pose are generated from the modeled scene
surfaces through pose clustering [6]. This hypothesis set is
evaluated and pruned by its match to occupied and free
model space.
3) Tactile Skin: The articulated hands have been equipped
with a sensitive tactile skin with a high spatial and temporal
resolution allowing, e.g., to precisely sense and control
the slippage of grasped objects. By processing the spatio-
temporal signal of the skin it is possible to discriminate
objects by their material – a skill which is esp. important
DLR Institute of Robotics and Mechatronics, M¨ unchnerstr. 20, 82234
Wessling, Germany, f berthold.baeuml@dlr.deg
Fig. 1. Agile Justin, an upgraded variant of its older sibling Rollin’Justin
[8].
when the objects would be indistinguishable from their 3D
shape alone. To do so, the robot compares the data obtained
by gently sweeping its ﬁngers over the object with previously
learned classes of spectral features.
4) Auto-Calibration: The multi-sensorial upper body is
calibrated completely automatically and without any external
tool in 5 min, resulting in intrinsic and extrinsic parameters
for the stereo cameras, RGB-D camera, IMU, joint elastici-
ties, and offsets [7].
5) Software Framework: The software architecture of
Agile Justin is based on our new robotic framework aRDx
(agile robot development next generation) [9] we developed
for research in mobile manipulation and robot learning on
complex and performant robotic systems.
The low level communication layer of aRDx is highly
performant and hard realtime capable. It outperforms other
robotics frameworks (e.g., ROS, see [9] for benchmarks)
and allows for detailed control of the quality-of-service and
optimally transports data packets for intra-process, inter-
process (zero-copy) as well as networked (copy once) com-
munication. This allows Agile Justin’s fast and deep sensor-
perception-planning-action loop to span multiple computers,
even including a GPGPU server cloud in a remote building,
with a timing precision in the millisecond range.
In aRDx, all higher level functionalities and abstractions
needed in a robotic framework as well as a more ﬂexible but
less performant communication layer are implemented in a
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 2562
modern higher level language of the Scheme/Lisp family, i.e.,
Racket [10]. Racket’s modern ”programmable programming
language” paradigm ideally ﬁts the need of implementing
various domain speciﬁc languages (DSLs) for efﬁciently
coping with the multiple domains in a complex robotics
application [11].
6) Experimental Scenarios: Two experimental scenarios
have been set up. The building of a scaffold structure
demands for dextrous as well as whole body manipulation.
The longterm vision is to enable the robot to not only
autonomously execute the task but to acquire the necessary
skills by autonomous learning. The ball playing bench-
mark [3] demands for fast 3D perception and dynamical
whole body motion planning.
II. SUMMARY
In summary, the upgrades make Agile Justin an almost
ideal platform for research in autonomous mobile manipula-
tion.
REFERENCES
[1] G. Metta, G. Sandini, D. Vernon, L. Natale, and F. Nori, “The icub
humanoid robot: an open platform for research in embodied cognition,”
in Proc. of the 8th Workshop on Performance Metrics for Intelligent
Systems, 2008.
[2] PR2 - personal robot 2. [Online]. Available:
http://www.willowgarage.com
[3] B. B¨ auml, F. Schmidt, T. Wimb¨ ock, O. Birbach, A. Dietrich, M. Fuchs,
W. Friedl, U. Frese, C. Borst, M. Grebenstein, O. Eiberger, and
G. Hirzinger, “Catching Flying Balls and Preparing Coffee: Humanoid
Rollin’Justin Performs Dynamic and Sensitive tasks,” in Proc. IEEE
International Conference on Robotics and Automation, 2011.
[4] R. Wagner, U. Frese, and B. B¨ auml, “Real-time dense multi-scale
workspace modeling on a humanoid robot,” in Proc. IEEE Interna-
tional Conference on Intelligent Robots and Systems, 2013.
[5] R. Wagner, B. B¨ auml, and U. Frese, “3d modeling, distance and
gradient computation for motion planning: A direct gpgpu approach,”
in Proc. IEEE International Conference on Robotics and Automation,
2013.
[6] U. Hillenbrand and A. Fuchs, “An experimental study of four variants
of pose clustering from dense range data,” Computer Vision and Image
Understanding, vol. 115, pp. 1427–1448, 2011.
[7] O. Birbach, B. B¨ auml, and U. Frese, “Automatic and self-contained
calibration of a multi-sensorial humanoid’s upper body,” inProc.IEEE
International Conference on Robotics and Automation, 2012.
[8] C. Borst, T. Wimb¨ ock, F. Schmidt, M. Fuchs, B. Brunner, F. Zacharias,
P. R. Giordano, R. Konietschke, W. Sepp, S. Fuchs, C. Rink, A. Albu-
Sch¨ affer, and G. Hirzinger, “Rollin’ Justin: Mobile Platform with
Variable Base,” in Proc. IEEE International Conference on Robotics
and Automation, 2009, pp. 1597–1598.
[9] T. Hammer and B. B¨ auml, “The highly performant and realtime
deterministic communication layer of the ardx software framework,”
in Proc. Int. Conf. on Advanced Robotics (ICAR), 2013.
[10] Racket. [Online]. Available: http://racket-lang.org
[11] B. B¨ auml, “One for (almost) all: Using a modern programmable
programming language in robotics,” in Proc. IEEE International
Conference on Robotics and Automation, Keynote of SDIR Workshop,
2013.
2563
