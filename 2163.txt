A Competitive Online Algorithm for Exploring a Solar Map
Patrick A. Plonski and V olkan Isler
Abstract— In this paper, we study the problem of quickly
building the 3D model of an outdoor environment from mea-
surements obtained by a robot equipped with a solar panel.
The robot knows the angle of the sun and the locations of
the objects in the environment. It does not know, however, the
height of the objects. For example, it might be possible to use
satellite images to obtain locations of trees in a ﬁeld but not
their heights.
In order to compute the height of an object, the robot must
ﬁnd the projection of the object’s highest point. This is where
the shadow of the object ends. The robot can ﬁnd it by tracing
the shadow (moving parallel to the sun) until the measurement
switches from shadow to sun or vice versa. The robot’s goal
is to compute the height of every object as quickly as possible
using only solar measurements.
We formulate this as an online optimization problem. The
optimal ofﬂine algorithm is given by the Traveling Salesman
path of the transition points. The robot does not know these
locations a priori. It must search for each of them. We present
an algorithm with the property that for n objects, our distance
traveled is guaranteed to be within a factor O(logn) of
this optimal ofﬂine tour. In addition to analytical proofs, we
demonstrate the algorithm with simulations using solar data
collected from ﬁeld experiments, and examine its performance
for uniformly distributed sites.
I. INTRODUCTION
Mobile outdoor robots have been shown to be useful
for a variety of exploration and environmental monitoring
applications. However, their long-term feasibility is often
constrained by limited battery life. A common approach used
to address this problem is the addition of solar photovoltaic
panels to the robot.
Previously the utility of solar-aware path planning has
been demonstrated. In [4] we constructed a solar map by
using only previous measurements of solar power associated
with positions. This method implicitly relied on having
densely sampled the relevant environment prior to the path
being planned.
In this work we address the exploration component neces-
sary to generate an accurate solar map. Any coverage pattern
or random walk will eventually explore everything, however
when a robot executes these strategies it might have to travel
a great distance. We would like some method to ensure that
we expend the least energy and time in the exploration step.
To this end, we use a quadtree-based exploration strategy
which uses observations of sun and shade to reﬁne its
estimate of the heights of shadow casting objects in the
environment. We demonstrate that this strategy obtains a
bounded worst-case competitive ratio between the distance
P. A. Plonski and V . Isler are with the Department of Computer Science
and Engineering, University of Minnesota, 200 Union Street SE, Minneapo-
lis MN 55455 USA. e-mail: {plonski, isler}@cs.umn.edu.
traveled using our exploration algorithm and the distance
traveled with the optimal algorithm. The bound is logarithmic
in the number of critical points that must be observed.
A. Related Work
Information about solar energy collected from the environ-
ment has been used to inform path planning for long term
missions. In open environments, such as in Antarctica [5]
or on the open ocean [6], the energy depends only on the
sun position. However the TEMPEST mission-level path
planner [7] uses the known position of the sun together with
known nearby terrain to perform raytracing and compute a
shadow map, which is then used to compute the net energy
of any potential path. Given that sensing the terrain in high
detail is a difﬁcult task, in [4] we examined the problem of
learning the solar map using only measurements of position
and solar current. This technique relied on having enough of
these measurements, spread out over the relevant positions.
In this work we look to ensure this is the case.
Analyzing an exploration strategy is challenging because
we don’t know what the environment looks like. A common
method in the literature is to look at the competitive ratio
between the online strategy and an optimal ofﬂine strategy
with full information. This allows us to reason about the
actual worst case environment to explore, instead of merely
making arguments on expectation. Some recent examples
of exploration strategies analyzed using competitive ratios
include [1], [2].
II. PROBLEM STATEMENT
We parameterize the problem of fully exploring the
shadow map as the following: We have n objects in our
environment with known position but unknown height. To be
able to claim that we have fully explored the environment,
we need to precisely determine each of thesen heights. From
the heights we will be able to obtain the shadow map for any
time of day. We know the angle of the sun at any moment
(see [3]), so to ﬁnd the height of an object it sufﬁces to ﬁnd
the length of its shadow. This is equivalent to ﬁnding the
critical point where a solar panel will switch from collecting
direct insolation to only collecting diffuse insolation. We call
these critical points sites {s
1
,s
2
,...,s
n
} = S. We assume
there are upper and lower bounds on the object heights,
so each site therefore lies on a known line segment. We
also assume that during the exploration step the sun does
not appreciably change position, thus all line segments are
parallel. Without loss of generality, therefore, we perform a
coordinate transform based on the angle of the sun. The x
positions of the sites, {s
x
1
,s
x
2
,...,s
x
n
} = S
x
, are known a
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 5766
Fig. 1: Here is an example of our problem setup. Each object
has known position on the plane but unknown height. To ﬁnd
the height the corresponding site in S must be visited. The
positions of S are unknown to the robot, however a bound
on the height of each object constrains its corresponding site
to lie on a line segment parallel to the sun.
priori, and it is only the y positions, {s
y
1
,s
y
2
,...,s
y
n
} =S
y
that are uncertain. However, there is an initial estimate of the
range that each s
y
i
lies in, denoted y
u
i
and y
?
i
for the upper
and lower limits, respectively. Without loss of generality,
?s
x
i
?S
x
,s
x
i
≥s
x
i?1
. See Figure 1 for an example problem
setup for an environment with three objects.
We assume our exploring robot r is a holonomic point
robot. We are primarily interested in the case wherer begins
outside the x range, so we ﬁx the initial x coordinate of r
at 0 and require that all S
x
are positive. As r explores the
environment, it learns more about the true positions of S.
We assume that walking farther away from an object than a
critical point will result in sun, and walking closer will result
in shade; (s
x
i
?S
x
) =r
x
, the robot learns whether s
y
i
or r
y
is greater, by measuring the solar insolation on its panel.
Our aim is to ﬁnd an algorithm for r that explores the
environment and visits all of S. We do not require that r
return back to the starting position; the mission ends when
the last site is visited. To judge the quality of our exploration
algorithm we do not assume any probability distribution but
rather consider the worst case competitive ratio between the
distance r travels when commanded by our algorithm,?(R),
and the distance r would travel were it commanded by an
optimal ofﬂine algorithm that simply solves the traveling
salesman path for the starting position of r and the true
positions of the sites. We denote the TSP solution as R
?
,
and we can formally state now that our goal is to minimize
the following competitive ratio:
C = max
S

?(R)
?(R
?
)

In this work we present an exploration algorithm for
r and demonstrate that its worst case competitive ratio is
logarithmic in the number of objects in the environment n.
III. X-SWEEP STRATEGY
Before we introduce our full algorithm we ﬁrst present a
basic na´ ıve strategy which has poor worst-case performance
but which we will later use as a subroutine. The X-Sweep
strategy simply visits all the input line segments in order
from lowest x-coordinate to highest. It goes to the closest
point on the segment ﬁrst and walks along it until it reaches
the site, then moves on until it has visited every site.
Clearly if there is not much difference between max(S
y
)
and min(S
y
), the X-Sweep Strategy will perform close to
optimal. However, it is easy to construct a situation where
X-Sweep performs poorly. Suppose the s
y
j
? S
y
alternate
between 0 and some large valuem, and furthermore suppose
d = x
n
?x
0
is very small compared with m. In this case
the optimal strategy cuts along y = 0, then cuts back along
y =m, with a total path length close tom. In comparison, X-
Sweep walks up and down the line segments and its total path
length is close to nm. Therefore the worst case competitive
ratio for X-Sweep is at least as bad as O(n).
IV. QUAD-EXPLORE STRATEGY
We saw that the X-Sweep strategy can have a competitive
ratio as bad asO(n). This is because it can backtrack very far
with each walk along a segment. To obtain a better bound we
need a method to balance walking along the segments with
cutting across the segments. One such method is our Quad-
Explore strategy: it cuts across segments when they are long
and executesX-sweep once the belief line segments are short
enough that performingX-sweep is guaranteed inexpensive.
A. Description
Here is the description of Quad-Explore.
First we consider the case where d = x
n
? x
1
=
max(Y
u
)?min(Y
?
). That is, the arena is square.
Quad-Explore is based on constructing a recursive
quadtree structure that we call Q. See Figure 2 for an
example of the structure of Q. The structure is constructed
as it is traversed, depth ﬁrst. Each nodeq
i
ofQ consists of a
square in the planeA(q
i
), a pointer to the parent, and pointers
to the possibly four children {c
1
,...} =C(q
i
),0≤|C|≤ 4.
Nodes are numbered as they are created, and q
0
corresponds
with the entire arena. In addition to Q the robot must
maintain knowledge about its position, and its belief Y
?
and Y
u
on the lowest and highest possible values for S
y
consistent with the initial belief and the online observations.
For eachq
i
the algorithm generates four candidate squares
{a
1
,a
2
,a
3
,a
4
} = A(q
i
) by evenly dividing A(q
i
). Those
candidate squares which contain sites will become associated
with new nodes that are children of q
i
, and control will be
passed to them, counter-clockwise, in turn, before returning
up to the parent of q
i
. We ﬁx the maximum depth of Q as
h(Q) = ?log
2
(n)? so that the edge length of a leaf square
is proportional to d/n. We execute a leaf strategy whenever
this depth is reached. Also, we execute the same leaf strategy
if at any time there is a q that only contains one site.
5767
Fig. 2: Here is an example Q constructed by Quad-Explore for an environment that has 8 sites. Q is shown here separated
by level but it is constructed in depth ﬁrst fashion, with children explored in counter-clockwise order from the upper right.
At each node it is determined which of the four candidate squares A contain sites; those that contain sites become squares
for children. If the square for a node only contains a single site the node executes the leaf strategy and creates no children.
This leaf strategy is also executed whenever the maximum depth h(Q) is reached.
Fig. 3: In the left of the ﬁgure is the Quad-Explore strategy for a node q
i
that is not a leaf. After performing the cut from
left to right it becomes clear that all sites in the node exist in a
1
anda
3
, the upper right and lower left candidate subsquares,
thus |C(q
i
)| = 2. Assuming that the next level is the maximum depth h(Q), each of the two children must perform the leaf
strategy, which is demonstrated in the right of of the ﬁgure. The leaf strategy for c
1
?C(q
i
) is performed right to left, and
it simply performs X-sweep and visits all of the sites in a
1
in turn.
See Figure 3 for an example of our strategy for a leaf node
and a non-leaf node.
The complete description of the actions commanded by
a leaf node q
i
is the following:
The leaf node actions are functionally almost identical to
performing the X-sweep strategy with A(q
i
) as the arena.
From the leftmost or rightmost border of A(q
i
), drive to a
point p on the line x = s
x
j
for whichever s
j
? A(q
i
) has
the least x distance from r
x
. The y value of p is selected
such that y
?
j
≤ p
y
≤ y
u
j
and the distance between p
y
and
r
y
is minimized. Then walk along the line segment of s
j
until s
j
is visited, and then move on to the next closest
s
x
k
|s
k
? A(q
i
). Repeat this process until every site in A(q
i
)
has been visited. Then pass control back to the parent by
visiting the intermediate y of A(q
i
) at the opposite x edge
from the start of r?q
i
.
The complete description of the actions commanded by
a non-leaf node q
i
is the following:
Perform a y-cut by driving r along the line segment that
splits the upper candidate subsquares{a
1
,a
2
}?A(q
i
) from
the lower ones {a
3
,a
4
}?A(q
i
). Adjust all Y
u
and Y
?
that
pass through the cut. It is clear at this point which ofA(q
i
)
contain sites, so associate these squares with children. For
child j, q
i
is responsible for delivering r to the middle y
of a
j
, at either the left edge or the right edge of a
j
(right
edge for a
1
and a
2
, left edge for a
3
and a
4
). Each child will
return control at the opposite side of its square. After the last
child returns control, q
i
passes control back to its parent by
returning r back to the ending point of the y-cut.
Now, consider the case where the arena is not square.
If the arena is longer than it is tall, we simply take any
square with edge length d that contains the initial belief line
segments as A(q
0
) in the algorithm.
If the arena is taller than it is long, we need to introduce
a special strategy only used by q
0
. The edge lengths of the
children of q
0
in this case are all d, so to remain consistent
the children are deﬁned as level 0 and the special q
0
is
deﬁned as level ?1.
The complete description of the actions commanded by
an initial q
0
that has a non-square corresponding region
is the following:
Perform the ﬁrst y-cut at y = 0 and adjustY based on the
observations. If afterwards there is any y
u
i
> d,y
u
i
? Y
u
,
perform the next y-cut at y = d. All cuts in q
0
will
occur at y = kd where k is an integer. The order of
cuts is: ﬁrst increment k until max(S
y
) is discovered, and
then decrement k from 0 until min(S
y
) is discovered. All
subsquares are bounded above and below by instances of
y =kd. When after any cut it becomes certain there is one or
more sites in a subsquare, a child is created for the subsquare
and control is passed to the child at the usual extreme x,
intermediate y position.
5768
1
2
3
4
5
6
7
Fig. 4: Here is an example of our level ?1 strategy when
max(S
y
)?min(S
y
) > d. The starting position (0,0) is on
the lower left and r follows the thick solid gray path, in the
order given by the arrows. When it is certain there is a site in
one of the subsquares a
i
?A(q
0
), a child is created for that
subsquare and control is passed to the child at the start of
the dashed gray line. Control is resumed by q
0
at the other
end of the dotted line.
See Figure 4 for the exploration procedure Quad-Explore
uses for an example input that is taller than it is long.
B. Analysis
Here we will prove that the worst case competitive ratioC
between the length of the robot path with our algorithm?(R)
and the length of the optimal ofﬂine shortest exploration path
?(R
?
) is upper bounded by k
c
log(n) where n is the number
of sites and k
c
is a constant.
We will prove this by showing that each node in Q does
work proportional to its edge length showing that the sum
of the edge lengths at each level in Q is linearly upper
bounded by ?(R
?
). The proof is completed by observing
that the number of levels in Q is logarithmic in n so if each
level does proportional work the total work is logarithmic.
First, we introduce some new notation: Denote the set of
all paths traveled by r while under control of q
i
as R(q
i
).
The sum of the lengths of these paths is ?(R(q
i
)), or, for
simplicity, ?(q
i
). Denote the number of sites contained in
A(q
i
) as n(q
i
). This means n(q
0
) = n the total number of
sites. Denote the depth of q
i
as h(q
i
), and denote the set of
all nodes in Q that are at depth h as Q
h
.
Lemma 1: There exists some constantk
1
such that for any
square non-leaf node q
i
?Q,
?(q
i
)≤k
1
d
2
h(qi)
.
Proof: Recall that the ﬁrst task in nodeq
i
is a cut which
is not longer than
d
2
h(q
i
)
.
Following the cut, q
i
needs to deliver r to up to ﬁve
more target positions (once for each child, and then once
for returning to the parent). Hence we can obtain the loose
upper bound k
1
≤ 6
√
2 because six targets are traveled to
along straight lines and no two points in the square can be
farther away than
√
2
d
2
h(q
i
)
.
Lemma 2: There exists some constantk
2
such that for any
leaf node q
i
?Q,
?(q
i
)≤k
2
n(q
i
)
d
2
h(qi)
.
Proof: In a leaf node the path of r is monotonic in x,
so the sum of all x components of R(q
i
) is upper bounded
by
d
2
h(q
i
)
. Recall that r in a leaf node seeks sites in a well-
deﬁned order. While seeking any site in A(q
i
), the path of
r is monotonic in y. The initial y value is intermediate, so
the y component while seeking the ﬁrst site can’t cost more
than half the edge length of A(q
i
). Similarly the ﬁnal step,
the return to intermediate y so that control can be passed
back to the parent, also cannot have y distance greater than
half the edge length. All other sites can require up to the
entire edge length. Therefore we can say the sum of all y
components ofR(q
i
) is upper bounded by
n(qi)d
2
h(q
i
)
. Combining
the x components and the y components we end up with a
worst case
?(q
i
)≤
(1+n(q
i
))d
2
h(qi)
≤
2n(q
i
)d
2
h(qi)
.
Therefore k
2
≤ 2.
Lemma 3: There exists some constant k
3
such that
?(Q
h
) =
X
qi?Q
h
?(q
i
)≤k
3
?(R
?
)
Proof: First, consider the case where h is not the
maximum depth h(Q) and it is not ?1. Denote the set of
squares associated with Q
h
as A(Q
h
). A(Q
h
) are a subset
from a grid with edge length
d
2
h
, and each ofA(Q
h
) contains
at least one site. Therefore R
?
must enter each of these
squares. Now consider the number of squares on the level
h grid R
?
enters, denoted |R
?
|
h
. If any path is divided into
segments of length
√
2
d
2
h
, each segment can enter at most 7
squares in the levelh grid (this case occurs when the segment
is diagonal across a grid square). Therefore,
|Q
h
|≤|R
?
|
h
≤ 7

?(R
?
)2
h
d
√
2

.
Any ofQ
h
that are leaf nodes must only contain one site,
because the depth is not the max depth so the leaf node
strategy is only executed when there is one site. Therefore
we can relate the number of nodes with the sum of the paths
in all the nodes at depth h as follows, using Lemmas 1 and
2, and deﬁning k
?
as max(k
1
,k
2
):
|Q
h
|k
?
d
2
h
≥?(Q
h
).
Putting this together with the bound on |Q
h
|, and using
5769
the fact that ?(R
?
)≥d, we have:
?(Q
h
)
2
h
d
≤k
?
|R
?
|
h
≤ 7k
?

1+
?(R
?
)2
h
d
√
2

?(Q
h
)≤ 7k
?

d
2
h
+
?(R
?
)
√
2

≤ 7k
?

?(R
?
)+
?(R
?
)
√
2

≤ 7k
?

1+1/
√
2

?(R
?
).
For k
?
≤ 6
√
2, this provides us with k
3
≤ 42(
√
2+1).
Now, consider the case where h is the maximum depth
h(Q). Since each site can exist in at most one node at a
given level, we can conclude from Lemma 2 that
?(Q
h
)≤k
2
d
2
h
X
qi?Q
h
n(q
i
)≤k
2
d
2
h
n.
Recall that we selected h(Q) = ?log
2
(n)? ≥ log
2
(n),
therefore ?(Q
h
)≤k
2
d≤k
2
?(R
?
).
Finally, consider the case where h =?1. The uppermost
y-cut will occur at y
u
c
= max

0,d
l
max(S
y
)
d
m
and the
lowermost will occur at y
?
c
= min

0,d
j
min(S
y
)
d
k
. The
maximum span between the upper and lower cut is therefore:
y
u
c
?y
?
c
≤ max(0,max(S
y
+d))?min(0,min(S
y
?d))
≤ 2d+?(R
?
)≤ 3?(R
?
)
And the maximum number of candidate subsquares for the
initial node is:
|A(q
0
)|≤

y
u
c
?y
?
c
d

≤

3?(R
?
)
d

≤
3?(R
?
)+d
d
≤
4?(R
?
)
d
Associate each candidate subsquare with the outer cut,
with greatest absolute value ofy. In this analysis, the actions
commanded by q
0
in any a
i
,a
i
? A(q
0
) are one cut, plus
the path walking up to the uppermost cut and walking back
down to the lowermost cut, plus deviation of half a square
edge to pass control to the child and another half a square
edge when control is returned from the child. This is a total
distance of not greater than 4d commanded by q
0
in any of
its candidate subsquares. To this we add another d for the
unafﬁliated ﬁrst cut at y = 0, and obtain the following:
?(R(q
0
))≤d+4d|A(q
0
)|≤d+4d
4?(R
?
)
d
≤d+16?(R
?
)≤ 17?(R
?
).
This concludes the proof for each of the three types of level.
The worst k
3
≤ 42(
√
2+1) occurs when 0≤h<h(Q).
Theorem 1: There exists some constant k
c
such that for
anyS,|S|≥ 2, a robot following the Quad-Explore strategy
and starting from r(0) = (0,0) will visit every site and
the total length of its path ?(R) will satisfy the following
competitive ratio:
?(R)
?(R
?
)
≤k
c
log(n).
Proof: Here is how we knowr will visit every site: The
square A(q
0
) contains every site. The union of subsquares
A(q
i
) contains all of the square A(q
i
) and thus every site in
A(q
i
). If q
i
has children, every square inA(q
i
) that contains
a site will become the square for a child, therefore the set
C(q
i
) will among it have responsibility for every site in
A(q
i
). If q
i
does not have children, it is a leaf node, and
the leaf node strategy ﬁnds every site in A(q
i
).
Here is how we bound the maximum length of ?R across
all possible inputs: Combining the maximum number of
levels 1+h(Q) = 1+?log
2
(n)? with the result of Lemma
3 we obtain:
?(R) =
1+h(Q)
X
h
?(Q
h
)
≤ (1+h(Q))k
3
?(R?)≤ (1+?log
2
(n)?)k
3
?(R?)
≤ (2+log
2
(n))k
3
?(R?)≤ 3k
3
log
2
(n)?(R?).
This provides an absolute worst case of:
k
c
≤ 126(
√
2+1)≤ 305.
However we expect that this constant is a very loose
estimate which can be improved by carefully considering
the different possible cases at each step.
V. SIMULATIONS
We examined the performance of X-Sweep and Quad-
Explore when exploring a real solar map constructed for the
McNamara Alumni Center at the University of Minnesota.
To do this we used our high density June 9, 2012 solar
data set from [4] to construct an approximate heightmap
consistent with all of the sun and shade rays measured.
Then we constructed our exploration problem by manually
ﬁxing 18 positions on the plane where the trees were rooted
(and 2 false positives that had height 0), and raytracing
from the known position of the sun at 16:23 CDT and
the constructed object heights. This procedure gave us S;
to obtain the initial y bounds we assumed a prior height
distribution between 0 and 60 meters. We simulated a robot
starting at the position of the bottom of the northwesternmost
tree, and executing bothX-Sweep and Quad-Explore. In our
Quad-Explore implementation we added a heuristic where
the length of each cut could be reduced when there was no
information to be gained by travelling farther.
See Figure 5 for a satellite image of the environment and
plots of the paths followed by X-Sweep and Quad-Explore.
The length of the X-Sweep exploration path was 390.35
meters, compared 644.19 for Quad-Explore. We can lower
bound ?(R
?
) with d, which was 39.44; thus our competitive
ratio was at most 16.33. X-Sweep performed well in this
case because the lines of similar trees ensured that sequential
critical points were not too far offset in the y direction.
To examine what happens when the problem size in-
creases, we also generated synthetic environments with sites
uniformly distributed in the unit square, and no initial infor-
mation about y coordinates. See Figure 6 for a chart of the
5770
Fig. 5: Top is a satellite image of the McNamara Alumni
Center, courtesy of Google Maps. Middle and bottom are
the paths followed by X-Sweep and Quad-Explore while
exploring the McNamara Alumni Center in simulation. X-
Sweep does well in this case because the critical points are
close together in the y-direction (for the rotated coordinate
frame). Quad-Explore carefully narrows down its belief for
the site positions before at the end walking a guaranteed
short distance down a particular line segment.
performance of X-Sweep and Quad-Explore as the number
of sites increases. We found that Quad-Explore had a slighly
higher constant factor but as the problem size grew the linear
term in X-Sweep came to dominate over the logarithmic
term in Quad-Explore.
Even though the theoretical performance of Quad-Explorer
is far superior to X-sweep, these simulations suggests that
X-sweep might be a better in some practical scenarios when
the number of sites to visit is not large.
VI. CONCLUSIONS
In this work we examined competitive strategies to explore
an unknown solar map. This exploration can provide the
information a solar-aware path planning algorithm needs to
plan an energy-minimizing path. We examined ﬁrst a simple
strategy X-sweep which has poor worst case competitive
performance ofO(n), and then a more sophisticated strategy
Quad-Explore which has superior asymptotic performance
 16 32 64 128 256 512
0
20
40
60
80
100
120
140
160
180
n
distance
 
 
X?sweep
Quad?Explore (standard)
Quad?Explore (reduced depth)
Fig. 6: A comparison of the distance traveled by three
exploration algorithms when exploring an increasing number
of sites uniformly distributed in the unit square, with no prior
y information. Each bar is the average of 10 random trials. In
addition to the X-sweep and Quad-Explore presented in this
paper, we also tested a variant of the latter with a reduced
maximum depth of?log
8
(n)? instead of the usual?log
2
(n)?.
of O(logn). We simulated both strategies on a real data
set and on a series of synthetic environments. We found
that X-sweep performs well in practice when the number of
sites to visit is not large, however Quad-Explore’s asymtotic
performance is superior for uniformly distributed sites.
The most direct avenue of further work on this topic is
improving the loose bound on the maximum competitive
ratio of Quad-Explore. Another future area of interest is ex-
amining the robustness of our algorithms to slightly violated
assumptions (such as a slightly moving sun, or a tree with
a narrow trunk that lets some light through near the ground
but not near the top). Finally, the general principles of Quad-
Explore are likely relevant for a variety of related but slightly
different sensing models, some of which might be useful for
solving different real-world exploration problems.
ACKNOWLEDGMENT
This material is based upon work supported by the Na-
tional Science Foundation under grant number 1111638.
REFERENCES
[1] S. P. Fekete, R. Klein, and A. N¨ uchter. Online searching with an
autonomous robot. Computational Geometry, 34(2):102–115, May
2006.
[2] R. Fleischer, T. Kamphans, R. Klein, E. Langetepe, and G. Trippen.
Competitive Online Approximation of the Optimal Search Ratio. SIAM
Journal on Computing, 38(3):881–898, Jan. 2008.
[3] D. Y . Goswami, F. Kreith, and J. F. Kreider. Principles of Solar
Engineering. Taylor & Francis, 2nd editio edition, 1999.
[4] P. A. Plonski, P. Tokekar, and V . Isler. Energy-efﬁcient path planning
for solar-powered mobile robots. Journal of Field Robotics, 30(4):583–
601, 2013.
[5] L. Ray, J. Lever, A. Streeter, and A. Price. Design and Power
Management of a Solar-Powered Cool Robot for Polar Instrument
Networks. Journal of Field Robotics, 24(7):581–599, 2007.
[6] C. Sauze and M. Neal. Long term power management in sailing robots.
In OCEANS, 2011 IEEE - Spain, pages 1 –8, june 2011.
[7] P. Tompkins, A. Stentz, and D. Wettergreen. Mission-level path plan-
ning and re-planning for rover exploration. Robotics and Autonomous
Systems, 54(2):174–183, 2006.
5771
