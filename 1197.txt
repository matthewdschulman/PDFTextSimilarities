  
? 
Abstract— Object handover is a basic task in many human-
robot interactive scenarios and therefore, it is important for 
assistive robots to be able to perform proper handovers. We 
previously designed a human-inspired grip-force-varying 
handover controller for a robot giver and showed on a Willow 
Garage PR2 robot that the controller yields human-like and 
human-preferred handovers. The PR2 robot had a non-
compliant fully-actuated gripper. However, recently, compliant 
underactuated grippers have been gaining more popularity. 
Although compliant underactuated grippers can provide more 
flexibility in manipulation, it is generally difficult to accurately 
measure and control the amount of applied grip force. In this 
paper, we present an implementation of the human-inspired 
handover controller on a Kawada Industries HRP4R robot, 
which has compliant underactuated hands, using joint position 
error measurement for estimating the amount of applied grip 
force. Through an experiment, we show that we are able to 
achieve safe, smooth, and intuitive robot-human handovers 
despite the lack of accurate grip force control on our robot.   
I. INTRODUCTION 
The development of assistive robots has seen a huge 
growth over the past decades. Unlike traditional robots which 
are built to work in isolated environments from humans, 
assistive robots are built with the intent of having them work 
alongside humans in various work places including factories, 
homes, and public facilities. Applications under development 
include intelligent factory assistants, homecare robots, 
hospital delivery robots, as well as astronaut robots [1]–[4].  
Working in cooperation with humans, assistive robots 
will have many direct interactions with their users. One 
routine task requiring direct interaction between the robot and 
its users that will frequently arise in many occasions is object 
handover (Figure 1). For example, a mechanic may ask a 
factory assistant to hand over a screwdriver, waiter robots 
may need to hand over drinks to customers, and a delivery 
robot may need to hand over packages to the recipients. 
Humans casually hand over various objects to each other 
numerous times in their daily lives. They rarely put in much 
thought when executing object handovers. Yet, without 
carefully planning for each handover, people in general 
complete each handover safely, efficiently, and smoothly. 
However, in contrast, most robots still have great difficulties 
handing over objects to people. Most robots require the user 
to follow specific procedures for object handover, and 
handovers between humans and robots still tend to be very 
mechanical. Since the ability to hand over objects is an 
 
 
essential skill for assistive robots and is crucial to enabling 
effective cooperation between humans and robots, there has 
been many efforts focusing on improving the human-robot 
interaction in object handovers. 
II. RELATED WORKS 
A.  Robot-Human Handovers 
Many existing studies have focused on various aspects 
of robot-human object handovers. Different methods have 
been proposed for indicating to the robot which object to hand 
over. Choi et al. proposed a method where motor-impaired 
patients use a laser pointer to identify the target object [5]. 
Ikai et al. proposed a method where users instruct the robot to 
handover an object using a predefined pointing hand gesture 
[6]. Others have studied how a robot should approach the 
person in preparation for a handover. Walters et al. found that 
when a person is seated, a frontal approach is disliked, since 
the robot may appear threatening, but is more acceptable 
when standing [7]. Shibata et al. and Huber et al. compared 
different reaching trajectories and they found that people 
prefer working with robots that use human-like (minimum-
jerk) trajectories [8], [9]. Cakmak et al. and Aleotti et al. 
studied how a robot should orient the object when handing it 
over [10], [11]. They found that when a robot uses an 
orientation that takes object affordance into account, 
participants gave a higher rating in terms of appropriateness 
and safety. 
In addition to the robot’s movement and posture, another 
important issue in object handover is how a robot, as the giver, 
can properly determine when to release the object during the 
actual transfer of the object to the receiver. Edsinger and 
Kemp used a simplistic approach where their robot releases 
Wesley P. Chan, Iori Kumagai, Shunichi Nozawa, Yohei Kakiuchi, Kei Okada, Masayuki Inaba 
Implementation of a Robot-Human Object Handover Controller on a 
Compliant Underactuated Hand Using Joint Position Error Measurements 
for Grip Force and Load Force Estimations* 
 
Figure 1. HRP4R handing over a bottled drink to a person. 
*Research supported by the Ministry of Education, Culture, Sports, 
Science, and Technology in Japan. 
The authors are with the Department of Information Science and Technology, 
University of Tokyo, Tokyo, Japan 113-8656 (phone: 3-5841-7416; fax: 3-
3818-0835; email: wesleyc, iori, nozawa, youhei, k-okada, inaba @jsk.t.u-
tokyo.ac.jp) 
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 1190
  
the object one second after reaching its arm out [12]. 
However, their study shows that in certain situations, people 
will simply let the robot drop the object. Bohren et al. 
programed their robot to release the object when the receiver 
pulls hard enough to displace the robot’s arm more than 1 cm 
[13]. This ensured that the robot does not drop the object 
accidentally, but required the receiver to pull very hard on the 
object [14]. To limit the amount of force required from the 
receiver, Choi et al. and Deyle et al. used a force/torque-based 
approach, where their robot releases when the force/torque at 
its fingers exceeded a threshold [2], [5]. While this approach 
ensures that the receiver can take the object without excessive 
force, it requires manual tuning of hardware-dependent 
thresholds (since finger lengths affect the resulting torque 
values) and makes it more susceptible to dropping the object 
due to unintentional collisions with the object or the arm. 
B.  Human-Human Handovers 
To bridge the performance gap between robot-human 
handovers and human-human handovers, we previously 
conducted a user study to investigate and characterize the 
force interaction in human-to-human handovers [15]. We 
discovered that during the object transfer phase of a handover, 
as the object load is gradually transferred from the giver to the 
receiver, the giver gradually decreases the applied grip force 
in response to the changing load force, such that an 
approximately linear relationship between the grip force and 
load force is observed. Furthermore, in order to ensure that 
the object is safely transferred to the receiver, the giver does 
not completely release his/her grip until a slight pull from the 
receiver is detected through the object. 
C.  Human-Inspired Handover Controller 
Following the human-human handover study, we 
designed a handover controller for a robot giver based on the 
discovered human grip force control strategy [16]. Our 
controller allows a robot giver to mimic a human’s behavior 
by gradually decreasing its grip force in response to the 
decreasing load force during a handover. In a user study 
comparing our controller design with existing constant grip 
force controller design, we showed that our controller results 
in better performance in terms of handover smoothness and 
intuitiveness. Furthermore, results also showed that our 
controller yields human-like and human-preferred handovers. 
D. Compliant Underactuated Grippers 
In the previous implementation of our handover 
controller, we used a Willow Garage PR2 robot, which has a 
non-compliant fully-actuated gripper. While such type of 
grippers allows full control of each finger joint and the robot 
to more easily compute and predict the gripper configuration 
when interacting with the physical environment, it may be 
difficult to grasp irregularly shaped objects. Therefore, as an 
alternative, researchers have begun to consider the use of 
compliant underactuated grippers [17], [18]. Such grippers 
can yield better performance on grasping various irregularly 
shaped objects as they are capable of passively conforming to 
the object’s shape. However, it is generally harder to control 
the applied grip force and the exact gripper configuration. 
With complaint underactuated grippers becoming more 
common, it would be important to enable robots equipped 
with such gripper to perform handovers effectively as well. 
The ability to properly control grip force is very important in 
object manipulation and thus in handovers [19], [20]. 
However, one challenge with compliant underactuated 
grippers is the difficulty in accurately measuring and 
controlling the amount of applied grip force since there are 
usually multiple oblique contacting surfaces during grasping. 
In this paper, we demonstrate the feasibility of achieving 
smooth robot-human handovers on a compliant underactuated 
gripper with the use of the controller presented in [16], despite 
the lack of accurate grip force control. We use a Kawada 
Industries HRP4R robot as our hardware platform (Figure 1). 
III. HANDOVER CONTROLLER DESIGN 
A.  Grip Force Control Function 
The handover controller we proposed in [16] is based on 
the grip force control strategy used by humans [15]. Figure 2 
shows the grip force control function of the handover 
controller. In the beginning of the handover, the robot 
supports the full load of the object, ? ??
, applying a grip force 
of ? ??
. As the receiver begins to take the object from the robot 
and the load force, ? ? , on the robot’s hand decreases, the 
controller decrease the applied grip force, ? ? , accordingly in 
a linear fashion. When the load force reaches zero, the 
controller continues to maintain a small non-zero amount of 
grip force, ? ??? . Once the controller detects a slight pull from 
the receiver, and the load force reaches a small negative value, 
? , the controller then releases the object completely. The zero-
load-grip-force, ? ??? , and the release-force-threshold, ? , are 
two tuneable parameters of the handover controller. In 
human-to-human handovers, ? ??? and ? are found to be 2.3 N 
± 1.7 N and 2.36% ± 4.16% of the object weight respectively 
[15]. Once the controller’s ? ??? and ? values have been 
chosen, the slope, ? , of the grip force control function, 
? ? ( ? ? ) , can be calculated as: 
 ? = 
? ??
? ? ??? ? ??
 (1) 
B.  Controller Flow Chart 
Figure 4 shows the flow chart for the handover 
controller. During a handover, the controller continually 
monitors the load force and computes the appropriate grip 
force according to ? ? ( ? ? ) . To prevent accidental drops due to 
collisions, the controller first checks to see if the acceleration 
of object is within a predetermined threshold, ? . If 
acceleration is within this threshold, the controller applies the 
computed ? ? . Else, the controller will continue to hold on to 
 
Figure 2. Grip force control function for a robot giver. During object transfer, 
the applied grip force, ? ? , is regulated according to the experienced load 
force, ? ? , in a linear fashion such that the grip force is gradually reduced as 
the load force decreases. The object is completely released after a slight 
upwards pulling force of |? | is sensed. (Figure from Chan et al. 2013 [16], 
axes relabeled for clarity.) 
1191
  
the object. Once the load force, ? ? , drops below the release-
force-threshold, ? , the controller then releases the object and 
the handover is completed. 
IV. PREVIOUS IMPLEMENTATION 
In a previous user study, we implemented our handover 
controller on a Willow Garage PR2 robot (Figure 3A) and 
verified that our controller produces smooth, safe, and 
human-preferred handovers [16]. Each arm of the PR2 robot 
is equipped with a two-fingered parallel gripper, and each 
fingertip is equipped with a force sensor array (Figure 3B). A 
3-axis accelerometer is also embedded in each gripper. The 
rigid fully-actuated gripper allowed us to have precise control 
over the grasp configuration and control the applied grip force 
with reasonable accuracy and precision. Our user study 
showed that even when the achieved ? ??? was around 4 N, 
and the |? | was around 10% of the object weight, our 
controller still produced handovers that are perceived as 
smooth and human-like.  
The use of rigid fully-actuated grippers does however 
have some limitations. Using a simple parallel gripper, it is 
very difficult to grasp and hold irregularly shaped objects or 
objects that do not have a set of parallel surfaces (For 
example, a triangular prism). Furthermore, certain object 
geometries may also cause high pressure concentration at the 
contact points due to small contact surface area between the 
gripper and the object (e.g., an egg or a cylindrical mug). This 
kind of pressure concentration imposes a risk of breaking the 
object during grasping [20]. In certain situations, attempting 
to grasp an object when a rigid non-compliant gripper is 
misaligned with the object may also cause failure. 
V. IMPLEMENTATION ON A COMPLIANT UNDERACTUATED 
HAND 
In contrast to rigid fully-actuated grippers, compliant 
underactuated grippers do not allow full control of the 
gripper’s configuration. It is also more difficult to control the 
applied grip force since there may be multiple oblique 
contacting surfaces with the object. However, compliant 
underactuated grippers can have better performance on 
grasping irregularly shaped objects since it can conform to the 
object’s geometry. With more compliant and underactuated 
grippers being developed, we can expect to see more assistive 
robots being equipped with such grippers. Therefore, it is 
important for such compliant underactuated grippers to be 
able to perform handovers effectively. In this section, we 
present the implementation of the controller described in 
Section III on a humanoid equipped with compliant 
underactuated hands, in the absence of grip force sensors. 
A. Hardware 
Our hardware platform is a Kawada Industries HRP4R 
robot (Figure 1). The HRP4R is equipped with a two-degree-
of-freedom hand on each arm. Figure 5A shows the hand in 
the opened position, with red dashed-lines indicating the joint 
axes. The thumb is composed of one rigid link and is actuated 
by one motor (joint_0), while the rest of the fingers are 
actuated together by another motor (joint _1). The fingers 
actuated by joint_1 are tendon driven. Each of these fingers is 
composed of three rigid links, and is compliant and 
underactuated. Figure 5B shows the hand in the closed 
position. To prevent grasped objects from easily slipping due 
to the smooth surface on HRP4R’s fingers, we attached rubber 
pads to the fingers to increase the surface friction of the hand. 
One major challenge is that HRP4R is not equipped with any 
force sensors on its arms and hands. It only provides encoder 
readings and estimated motor torque values based on current 
measurements for each joint. 
B. Load Force Estimation 
In our previous implementation on the PR2 robot [16], 
we used the estimated wrist torque for calculating the load 
force on the gripper. We modeled the PR2’s gripper and 
forearm as a simple two-link mechanism. By orienting the 
 
Figure 3. A - The PR2 robot used for our previous implementation of the 
handover controller (Figure from Chan et al. 2013 [15]). B - Parallel gripper 
of the PR2 robot. Each fingertip is equipped with an array of force sensors. 
 
Figure 4. Handover controller flow chart. (Figure from Chan et al. 2013 [16].) 
 
Figure 5. HRP4R's hand. A shows the hand in the opened configuration, with 
red dashed-lines showing the joint axes. B shows the hand in the closed 
configuration. 
1192
  
gripper parallel to the ground, the load force, ? ? , can be 
calculated using the definition of torque with the equation: 
 
? ? = 
? ? ? ? ? ? (2) 
where ? is the measured torque value, ? ? is an offset, and ? ? 
the distance from the wrist joint to the gripper tool center. 
For our current implementation on the HRP4R robot, we 
used the joint error measurement, ?? , instead to estimate the 
load force. The joint error measurement is defined as the 
difference between the commanded joint position and the 
actual position. Torque estimations based on current 
measurements tend to be noisy since they are affected by 
various undesirable characteristics of the motors (For 
example, gear friction). Joint positions, on the other hand, are 
measured by encodes and have much smoother 
measurements. As a result, the joint error measurement from 
HRP4R gives us a much more stable estimation of the load 
force. 
HRP4R uses PD control where joint torque output, ? ??? , 
is calculated as: 
 ? ??? = ??? + ? ? ? (3) 
where ? ? is the angular speed, and ? and ? are constants. 
Assuming that the robot’s joint has a sufficiently short 
response time, and that the handover is quasi-static, such that 
the actual joint torque is equal to ? ??? , and ? ? is near zero, the 
joint torque becomes approximately linear with respect to ?? . 
Thus, combining Equation (3) with Equation (2) and 
regrouping the constants, the load force on HRP4R’s hand can 
be estimated as: 
 ? ? = 
?? ? ??
?????? 
? 
(4) 
where ??
?????? is an offset, and ? is a constant with units 
rad/N, acting as a conversion factor. To determine ? , we 
placed an object weighing approximately 5 N in HRP4R’s 
hand, let it grasp onto the object, and recorded the resulting 
joint error measurement. We then set ? to be the measured 
joint error divided by 5 N.  
Initially, we attempted to use HRP4R’s wrist joint error 
measurement for estimating the load force. However, 
HRP4R’s wrist joint has very high friction and the joint error 
measurement does not really reflect the change in load force 
at the hand. Therefore, we used the elbow joint error 
measurement instead. This gives a larger moment arm and 
allows us to detect load force changes more easily. Thus, we 
re-write Equation (4) as: 
 ? ? ( ??
??
) = 
??
??
? ??
?? _?????? 
? 
(5) 
where ??
??
 is the elbow joint error, and ??
?? _?????? is the 
elbow joint error offset. Note that if the hand pose were 
changed, ? ? can still be calculated by taking into account the 
Jacobian and wrist joint states. For consistency, the hand pose 
was kept constant in our experiment, and thus ? ? simplifies to 
Equation (5). 
C. Grip Force Estimation 
For grasping the object, we fix the position of hand 
joint_0 at a near-closed position, and we control the amount 
of applied grip force by commanding the position of joint_1. 
To estimate the amount of applied grip force, we use the joint 
angle error measured at joint_1. When grasping the object in 
preparation for handover, we first place the object in 
HRP4R’s opened hand, and we gradually increase the 
commanded joint_1 position, while monitoring the joint error, 
??
? 1
. When ??
? 1
 exceeds a first threshold, 
??
?? ????? _? ???? ???? , we store the current joint angle as the 
contact angle, ? ??????? . The value of ??
??????? _? ???? ???? was 
manually selected to be as small as possible while remaining 
above the encoder noise, so that we do not detect false 
positives of object contact. We then continue to increase the 
commanded joint_1 position, until ??
? 1
 reaches a second 
threshold, ??
????? _? ???? ???? . The value of ??
????? _? ???? ???? 
was manually selected based on the object’s weight and 
coefficient of friction such that the robot applies a grasp force 
slightly above the slip threshold. Once ??
????? _? ???? ???? is 
reached, we store the current joint angle as the initial angle, 
? ? 1_? , and grasping is completed. 
We regulate the amount of applied grip force, ? ? , 
through controlling the commanded joint_1 position, ? ? 1
. We 
assumed a linear mapping between ? ? and ? ? 1
. During 
handover, the ? ? 1
 command is computed from the desired 
grip force, ? ? , according to: 
 ? ? 1
( ? ? ) = 
? ? 1_? ? ? ? 1_??? 
? ??
? ? + ? ? 1_??? (6) 
where ? ? 1_??? is the estimated joint_1 position at the zero grip 
force and is computed as: 
 ? ? 1_??? = ? ??????? ? ? ? 1_?????? (7) 
and ? ??
 is the initial grip force applied when the joint angle is 
at ? ? 1_? . We set the offset, ? ? 1_?????? , arbitrarily to be 1 degree 
and we estimated ? ??
 to be 10 N. The value for ? ??
 was 
estimated based on the theoretical minimum grip force 
required to prevent the object from slipping. While in reality, 
? ? may depend on higher powers and derivatives of ? ? 1
, our 
experiment will show that the approximation given by 
Equation (6) is sufficient for producing smooth handovers. 
D. Modified Handover Controller 
In our implementation on the HRP4R robot, we estimate 
the load force, ? ? , using the elbow joint error, ??
??
, and we 
control the grip force, ? ? , through commanding the finger 
joint angle, ? ? 1
. In other words, we are essentially controlling 
? ? 1
 according to ??
??
 (i.e., ? ? 1
= ? ? 1
( ??
??
) ). By substituting 
Equations (1), (5) and (6) in to the grip force control function 
? ? ( ? ? ) shown in Figure 2, we obtain: 
 
? ? 1
( ??
??
) =  
(
? ? 1
? ? ? ? 1
??? 
? ??
) (
? ??
? ? ??? ? ??
)(
??
??
? ??
??
?????? 
? ) 
+? ??? + ? ? 1_???
 
(8) 
which is a linear function in ??
??
. This shows that in this 
implementation, the controller is actually varying the position 
of the finger joint, ? ? 1
, according to the elbow joint error, 
??
??
, following a linear relationship. This means that while 
the resulting grip-force-to-load-force relation may not 
necessarily be linear, it should still be a monotonic one, 
assuming that the relationship between ? ? 1
 and ? ? , and the 
relationship between ??
??
 and ? ? are monotonic. 
1193
  
VI. EXPERIMENT 
A. Set Up and Procedure 
To validate our implementation, we conducted an 
experiment where HRP4R performed object handovers with 
a person. In the experiment, HRP4R handed over a plastic 
drink bottle (a common everyday object) to a subject. To be 
able to measure the load force experienced by the person 
(receiver), we attached an FTSens 6-axis force/torque sensor 
to the bottom of the drink bottle, and another plastic drink 
bottle at the other side of the force/torque sensor to serve as a 
handle to the robot. The total weight of the apparatus is 
approximately 4 N. During the experiment, in the beginning 
of the handover, the robot (giver) holds onto the handle by 
grasping it with its right hand, and the receiver stands in front 
of the robot. The robot begins the handover by reaching its 
right arm forward. Once the robot has completed its reach, the 
receiver then reaches his right hand over and takes the object. 
After object transfer, the receiver retracts his right arm, and 
the handover is completed. The participant was a healthy 22-
year-old male with no known sensory disorders. 
In the experiment, we first allowed the subject to 
perform four practice handovers with the robot to become 
familiarize with the experimental procedure. The subject then 
performed another four handovers where we collected the 
data for analysis. We set the parameters of the handover 
controller to be ? ??? = 2 N and ? = -0.4 N. 
B. Data Analysis 
From the measured receiver load force data, we extract 
the maximum excess receiver load force percentage, 
??? ? %, and object transfer time, ? ???????? . The maximum 
excess receiver load force, ???? , is defined as the maximum 
amount of receiver load force measured minus the weight of 
the object, and ???? % is ???? expressed as a percentage 
of the object weight. The ???? % measures how hard the 
receiver has to “pull” to take the object. The object transfer 
time is the total duration of the object transfer and is measured 
from when the receiver’s load force first rose above a 
threshold ?
1
, to when the receiver’s load force first settles to 
the weight of the object within a threshold, ?
2
. The thresholds 
?
1
 and ?
2
 are set to be 0.7 N. This value was chosen manually 
to be a small constant sufficiently greater than the observed 
noise in the load force measurements. We compare the 
???? % and the ? ???????? from the experiment with those 
measured in human-to-human handovers [15]. We also 
recorded the number successful handovers and the number 
failed handovers. 
C. Results 
Results from all four handover trials are shown in 
Figure 6. The measured ???? % and ? ???????? are 
summarized in Table 1. The average ???? % was measured 
to be 42.3% ± 15.0%, and the average ? ???????? was measured 
to be 462.7 ms ± 95.7 ms. The robot and the subject 
completed all handovers successfully, and there were no 
failed handovers. In all four trials, the bottle was safely 
handed over from the robot to the receiver. 
Table 1. Results from the handover experiment. 
 ? ??? % ? ???????? (ms) 
Trial 1 58.5 476.0 
Trial 2 50.8 586.0 
Trial 3 33.7 431.9 
Trial 4 26.0 357.9 
Average 42.3 ± 15.0 462.7 ± 95.7 
D. Discussion 
In our previous human-human handover study, we found 
that typical ? ???????? are in the order of 500 ms [15]. 
Comparing this with the value of 462.7 ms measured in our 
experiment, we see that our implementation on the HRP4R 
was able to achieve human-like object transfer times. Since 
object handover is a basic subtask that arises frequently in 
many higher-level tasks, it is important that robots are able to 
execute handovers promptly. If too much time is required to 
perform such basic subtasks, the efficiency of the higher-level 
task will be compromised. The results show that our 
implementation enables efficient robot-human handovers 
from an object transfer time standpoint. 
In handovers among humans, the ???? %, was found to 
be as low as around 2% [15]. In our previous implementation 
on the PR2 robot, we achieved a ???? % of 10.7% ± 11.4%, 
and according to the participants, the resulting handovers still 
felt smooth and human-like. The ???? % measured for the 
implementation on HRP4R was 42.3% ± 15.0%. While this 
value is quite higher, it still allowed all handovers to be 
completed successfully in the experiment. Our previous study 
showed that if a robot holds onto the object too long and the 
???? % exceeds ~40%-50%, the handover becomes 
unintuitive to users, and the handover will fail [16]. 
Participants would not naturally pull harder than ~40%-50% 
object weight without explicit instructions from the 
experimenter, and once the load force reaches ~40%-50%, 
participants will simply continue to hold onto the object or 
abort the handover. It appears that the resulting ???? % of 
our HRP4R implementation is just below the unintuitive 
threshold and still within the subject’s acceptance. Therefore, 
the resulting handovers were intuitive enough for the subject 
to successfully complete all handovers without any special 
instruction from the experimenter. 
The resulted ???? % was quite higher than we 
intended. Two causes for this are 1) the lack of accurate load 
force measurements, and 2) the lack of accurate grip force 
control. Due to the lack of force sensors on the HRP4R, it was 
impossible to obtain accurate load force and grip force 
measurements. We estimated the load force using elbow joint 
angle error, and therefore, the error in this estimation is likely 
to have caused HRP4R to release the object later than it 
should have. Similarly, we were only able to estimate and 
 
Figure 6. Receiver load force data measured in the handover experiment from 
all four trials. 
1194
  
regulate the applied grip force through measuring the finger 
joint angle error and commanding the finger joint position. 
The error in grip force control is also likely to have caused a 
delayed release of the object by HRP4R. These two hardware 
limitation related problems would be the cause of the high 
???? % observed in the experiment. With more 
sophisticated and accurate models of ? ? 1
( ? ? ) and ? ? ( ??
? ? ), 
one should be able to reduce the resulting ???? %. 
 Despite the hardware limitations, experiment results 
showed that our implementation was still able to yield 
handovers with transfer times similar to those of typical 
human-human handovers, and that the robot and the subject 
were able to safely and successfully complete all handovers. 
This shows that despite the lack of accurate load force sensing 
and grip force control on the compliant underactuated hand of 
HRP4R, we are still able to achieve time-efficient, safe, and 
intuitive handovers with our controller. 
VII. CONCLUSION 
We have presented an implementation of a robot-to-
human object handover controller, which we developed 
previously, on a compliant underactuated hand. Two great 
challenges in this implementation are the lack of sensors for 
load force measurements, and the lack of a means for accurate 
grip force control. We used simple linear models for 
estimating the load force from elbow joint angle error 
measurements and for estimating the applied grip force from 
finger joint angle error and position. Our experimental results 
showed that using this method, we were able to allow a robot 
with compliant underactuated hands to hand over an object to 
a person safely, intuitively, and in a timely manner.    In our 
future work, we wish to extend our studies to include more 
objects with different shape, size, and weight. We also plan 
on testing the use of our controller for robot-to-robot 
handovers. In this study, we tested our implementation with a 
human as the receiver, since humans are the target end users 
we had in mind. However, the receiver could also be a robot. 
In this use case, the controller would sever as an alternative 
means to setting up a network communication channel for 
coordinating object transfer between two independently 
controlled robots. 
REFERENCES 
[1] R. Wilcox, S. Nikolaidis, and J. Shah, “Optimization of Temporal 
Dynamics for Adaptive Human-Robot Interaction in Assembly 
Manufacturing,” in Proceedings of Robotics: Science and Systems 
Conference, 2012. 
[2] T. Deyle, H. Nguyen, M. S. Reynolds, and C. C. Kemp, “RFID-
Guided Robots for Pervasive Automation,” IEEE Pervasive Comput., 
vol. 9, no. 2, pp. 37–45, Apr. 2010. 
[3] W. Fung, Y. Leung, and M. Chow, “Development of a hospital 
service robot for transporting task,” in Proceedings of the 
International Conference on Robotics, Intelligent Systems and Signal 
Processing, 2003, pp. 628–633. 
[4] M. Diftler, J. Mehling, and M. Abdallah, “Robonaut 2 - the first 
humanoid robot in space,” in Proceedings of the International 
Conference on Robotics and Automation, 2011, pp. 2178–2183. 
[5] Y. S. Choi, T. Chen, A. Jain, C. Anderson, J. D. Glass, and C. C. 
Kemp, “Hand It Over or Set It Down: A User Study of Object 
Delivery with an Assistive Mobile Manipulator,” in Proceedings of 
the International Symposium on Robot and Human Interactive 
Communication, 2009, pp. 736–743. 
[6] T. Ikai, S. Kamitani, and M. Ohka, “Vision and Tactile Based Robot-
to-Human Object Handover,” in The 31th Annual Conference on 
Robotics Society of Japan, 2013, pp. 1G3–04. 
[7] M. L. Walters, K. Dautenhahn, S. N. Woods, and K. L. Koay, 
“Robotic Etiquette: Results from User Studies Involving a Fetch and 
Carry Task,” in Proceedings of the International Conference on 
Human-Robot Interaction, 2007, pp. 317–324. 
[8] S. Shibata, B. M. Sahbi, K. Tanaka, and A. Shimizu, “An Analysis of 
the Process of Handing Over an Object and its Application to Robot 
Motions,” in Proceedings of the International Conference on 
Systems, Man, and Cybernetics, 1997, pp. 64–69. 
[9] M. Huber, M. Rickert, A. Knoll, T. Brandt, and S. Glasauer, 
“Human-Robot Interaction in Handing-Over Tasks,” in Proceedings 
of the International Symposium on Robot and Human Interactive 
Communication, 2008, pp. 107–112. 
[10] M. Cakmak, S. S. Srinivasa, M. K. Lee, J. Forlizzi, and S. Kiesler, 
“Human Preferences for Robot-Human Hand-over Configurations,” 
in Proceedings of the International Conference on Intelligent Robots 
and Systems, 2011, pp. 1986–1993. 
[11] J. Aleotti, V. Micelli, and S. Caselli, “Comfortable Robot to Human 
Object Hand-Over,” pp. 771–776, 2012. 
[12] A. Edsinger and C. C. Kemp, “Human-Robot Interaction for 
Cooperative Manipulation: Handing Objects to One Another,” in 
Proceedings of the International Symposium on Robot and Human 
Interactive Communication, 2007, pp. 1167–1172. 
[13] J. Bohren, R. B. Rusu, E. G. Jones, E. Marder-Eppstein, C. 
Pantofaru, M. Wise, M. Lorenz, W. Meeussen, and S. Holzer, 
“Towards Autonomous Robotic Butlers: Lessons Learned with the 
PR2,” in Proceedings of the International Conference on Robotics 
and Automation, 2011, pp. 5568 – 5575. 
[14] Willow Garage, “Beer Me, Robot,” 2010. [Online]. Available: 
http://www.willowgarage.com/blog/2010/07/06/beer-me-robot. 
[Accessed: 13-Jul-2012]. 
[15] W. P. Chan, C. A. C. Parker, H. F. M. Van der Loos, and E. A. Croft, 
“Grip Forces and Load Forces in Handovers: Implications for 
Designing Human-Robot Handover Controllers,” in Proceedings of 
the 7th ACM/IEEE International Conference on Human-Robot 
Interaction, 2012, pp. 9–16. 
[16] W. P. Chan, C. A. C. Parker, H. F. M. Van der Loos, and E. A. Croft, 
“A Human-Inspired Object Handover Controller,” Int. J. Rob. Res., 
vol. 32, no. 8, pp. 971–983, 2013. 
[17] Willow Garage, “Willow Garage 2G Velo Gripper.” [Online]. 
Available: http://www.willowgarage.com/velo2g. [Accessed: 15-
Sep-2013]. 
[18] J. Schuurmans, R. Q. van der Linde, D. H. Plettenburg, and F. C. van 
der Helm, “Grasp force optimization in the design of an 
underactuated robotic hand,” IEEE 10th Int. Conf. Rehabil. Robot., 
pp. 776–782, 2007. 
[19] R. S. Johansson and J. R. Flanagan, “Coding and use of tactile 
signals from the fingertips in object manipulation tasks.,” Nat. Rev. 
Neurosci., vol. 10, no. 5, pp. 345–59, May 2009. 
[20] J. M. Romano, S. Member, and K. Hsiao, “Human-Inspired Robotic 
Grasp Control With Tactile Sensing,” Trans. Robot., vol. 27, no. 6, 
pp. 1067–1079, 2011.  
 
1195
