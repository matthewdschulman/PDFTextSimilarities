Information Merging in Multi-UA V Cooperative Search
Asif Khan, Evsen Yanmaz and Bernhard Rinner
1
Abstract— In this paper, we propose strategies for merging
occupancy probabilities of target existence in multi-UA V co-
operative search. The objective is to determine the impact of
cooperation and type of information exchange on search time
and detection errors. To this end, we assume that small-scale
UA Vs (e.g., quadrotors) with communication range limitations
move in a given search region following pre-deﬁned paths
to locate a single stationary target. Local occupancy grids
are used to represent target existence, to update its belief
with local observations and to merge information from other
UA Vs. Our merging strategies perform Bayes updates of the
occupancy probabilities while considering realistic limitations in
sensing, communication and UA V movement—all of which are
important for small-scale UA Vs. Our simulation results show
that information merging achieves a reduction in mission time
from 27% to 70% as the number of UA Vs grows from 2 to 5.
I. INTRODUCTION
The coordination of small-scale unmanned aerial vehicles
(UA Vs) for search operations, referred to as multi-UA V
cooperative search, is an emerging research area and is
applied in areas such as search & rescue [1], [2], disaster
management [3], forest ﬁre [4] and target detection [5].
Since search missions are typically time critical and span
a large geographical area, a single UA V is often not able
to complete the mission on time. A team of UA Vs provides
more resources and can therefore perform the search more
efﬁciently. However, cooperation among individual UA Vs is
necessary to operate as team.
Generally, in multi-UA V cooperative search each UA V
maintains a map of the search area (known as search map,
cognitive map or probability map) that serves as the UA V’s
knowledge base of the state of the search region. At the
beginning of the search mission, the initial map reﬂects
prior knowledge about the search region. As the UA V moves
around and observes some parts of the search region, the
corresponding parts of the map are updated to incorporate
the information gained by the UA V’s surveillance sensor. The
ultimate goal of each UA V is to gain as much information
as possible about potential target locations. The UA V must
therefore decide what information to send or receive to/from
other UA Vs, when to share information and how to utilize
the shared information to plan their movement actions in the
most effective way. These decisions are important as each
UA V is likely to perceive (parts of) the search region differ-
ently due to some deviations in the available information at
the UA Vs.
We can deﬁne multi-UA V cooperative search by three
components: (i) sensing the search region and updating the
1
The authors are with the Institute of Networked and Embedded Systems,
Alpen-Adria-Universit¨ at Klagenfurt, Austria.
search map by individual UA Vs, (ii) sharing local infor-
mation with each other, and (iii) making mutual decisions
about actions, e.g., where to move in the search region
to minimize the time of search. In this paper, we focus
on the ﬁrst two components and advance the state of the
art by a new approach of distributed information merging
considering limitations in sensing performance, information
exchange and connectivity. In the presented approach we do
not assume perfect sensing and consider detection and false
alarm probabilities for the surveillance sensors. We model the
search space by a discrete 2D map where each cell represents
the occupancy probability of a target. Whenever a new
observation is available, the UA V performs a Bayes update
for the corresponding occupancy probability in its local map.
By exchanging and merging local map information the team
of UA Vs is able to achieve a faster search mission and
an improved detection performance as compared to non-
cooperative search. Our key contributions include (i) a formal
system model for cooperative search considering limitations
in sensing, information exchange and network connectivity,
(ii) the introduction of resource-efﬁcient merging strategies
of information from multiple UA Vs and (iii) a detailed
comparison of the proposed strategies. Our simulation results
show that information merging achieves a reduction in mis-
sion time from 27% to 70% as the number of UA Vs grows
from 2 to 5.
The rest of the paper is organized as follows. Section II
discusses the related work in cooperative search. In Section
III, we introduce the problem formulation. Section IV de-
scribes our approach of information merging among UA Vs.
In Section V , we present and discuss the simulation results.
Section VI concludes the paper with a brief discussion.
II. RELATED WORK
In cooperative search, a team of UA Vs shares its local
information such as past trajectories, current position, (parts
of) the search map or planned movement actions of UA Vs.
The UA Vs then merge the information and coordinate their
actions to efﬁciently and effectively accomplish the search
mission. In centralized coordination, the merging and coor-
dination is either performed on a single UA V or a ground
station—both equipped with sufﬁcient computing equipment
and connected with all other UA Vs during the mission.
The team’s performance is highly sensitive to a failure
of the centralized node and communication limitations. In
distributed coordination, control, information merging and
decision making are distributed among the UA Vs. Distributed
coordination increases the robustness of the team, but in-
troduces control overhead and may lead to performance
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 European Union 3122
degradations due to decisions based on limited information.
We can classify existing multi-UA V search operations
into three approaches. The ﬁrst approach focuses on ef-
ﬁciently covering the search region, the second approach
concentrates on decentralized data fusion, and the third
approach is based on mutual decision making using shared
information. Essentially, all approaches require sharing of
some information among UA Vs, but the amount and type of
shared information varies. Similarly, decision-making can be
performed at the UA V level or the group level. Challenges for
all approaches include the representation of the search space,
the information merging as well as the various limitations of
the UA Vs such as physical maneuverability, sensing range,
ﬂight time and communication.
A. Efﬁcient area coverage based approaches
Initial work in multi-UA V cooperative search [6] focuses
on how to efﬁciently visit all cells of the search region multi-
ple times. This early work performs lookahead path planning
and considers maneuverability constraints of the UA Vs. Co-
ordination is limited to sharing position information of the
UA Vs and does not consider any sensor model. To increase
efﬁciency, this work is extended to reduce overlapping in
UA V paths by using artiﬁcial potential ﬁeld [7]. Neural
network, reinforcement learning [8], group dispersion pattern
[9], K-shortest path search [10], [11] and mixed integer linear
programming [12] have also been explored for efﬁcient area
coverage. Similarly, V oronoi partitioning [13], [14], [15],
[16] has also been used to restrict the movement of each
UA V to a speciﬁc partition to avoid overlaps in their paths.
In contrast to the previous approaches, [5] efﬁciently covers
the search region for detecting targets without storing the
history of visits. In all these approaches no merging of target
information in the individual search maps is performed.
B. Decentralized data fusion based approaches
Instead of sharing a centralized map and UA V motion
information for path planning, the UA Vs exchange sensor
observations and update their own search maps in this
approach [17]. The entries of the search map represent a
probability distribution of the target location. All UA Vs
update their probability map based on their own and shared
sensor observations using a Bayesian approach considering
a sensor model which only includes the sensor’s detection
probability. The UA Vs assume that the target is always
present in the search region and terminate the search mission
when the cumulative probability of target existence exceeds a
threshold [18], [19]. Probability of detection and probability
of false alarm have also been included in the sensor model
to reach a decision about the target existence or absence in
the search region [20], [21]. The decision strategy for each
approach differs and the performance depends on the prior
probability distribution about the target location. The goal is
to show how information on a single target location can be
maintained in a distributed manner between a team of UA Vs.
These approaches do not consider communication limitations
among the UA Vs.
C. Mutual decision making based approaches
As opposed to the previous approaches where the UA Vs
share data and each UA V individually decides what to do
next (passive coordination), mutual decision making based
approaches use active coordination, i.e., the UA Vs agree on
actions and mutually decide what to do next. An example
of this work is to search a target where UA Vs arrange
themselves to move in equally-spaced parallel tracks [22].
UA Vs exchange messages to maintain proper distance among
them in order to cover the whole search region uniformly.
Negotiation among UA Vs [23] is another approach that has
been used to reduce the uncertainty about the target existence
and to avoid covering the same area by multiple UA Vs
simultaneously. In a similar method, neighboring UA Vs ex-
change proposals and mutually decide using self-assessment
based decision making to cover a speciﬁc sub-region [24].
Coordination in UA Vs for the selection among a discrete
set of pre-computed trajectories [25] and the selection of
information to be shared [26] also involve limited mutual
decision making.
This paper introduces a generic framework for cooperative
multi-UA V search and compares different strategies for infor-
mation merging. The key differences to related work include
the consideration of limited communication and sensing as
well as the efﬁciency of the merging strategies in terms of
computation and memory requirements—all of which are
essential in small-scale UA Vs.
III. SYSTEM MODEL
We model the search region 
 as a rectangular ground
plane where a team of UA Vs search for a target of interest.
The search region is logically divided into C equally-sized,
disjoint cells, and each cell is identiﬁed by c = (x;y)
where x and y are the coordinates of its center. This two
dimensional grid of cells is used to maintain the occupancy
probability of target and therefore serves as our search map.
A target may be any object of interest a-priori deﬁned by
the user, e.g., a lost person or a ﬁre source in the forest,
and is assumed to occupy at most a single cell. A single
stationary target is either present or absent throughout the
entire search mission. The occupancy probability is modeled
as a Bernoulli distribution, i.e.,X
c
= 1 (a target is present in
cell c) with probability P
c
and X
c
= 0 (no target is present
in cell c ) with probability 1 P
c
. Deﬁnite knowledge about
target existence or absence in a speciﬁc cell c is represented
as P
c
= 1 or P
c
= 0, respectively. No knowledge about
target existence is thus represented as P
c
= 0:5.
There are N homogeneous UA Vs moving at a ﬁxed
altitude
1
above the search region and each UA V maintains
its own search map. At each time step the UA Vs can move
to a single distinct cell and take a single observation. For
sake of simplicity, we represent the location of a UA V
i
(i =
1; 2;:::;N) at time step t by the coordinates of the cell
in the search map c
i;t
= (x
i;t
;y
i;t
). We assume that each
1
This assumption is made for simplicity. The proposed strategies are
applicable to UA Vs with different altitudes as well.
3123
UA V is equipped with (i) a position sensor which facilitates
the UA V to know its location within the resolution of a
cell at any time; (ii) a surveillance sensor that is able to
cover the entire cell; (iii) a wireless communication unit
for exchanging information with other UA Vs in the team;
and (iv) a computing unit for performing local map updates.
The independent sensor observation by UA V
i
in cell c at
time step t is represented as O
i;c;t
. Two observation results
are deﬁned for each cell, i.e., O
i;c;t
= 0 or O
i;c;t
= 1.
However, we do not assume perfect sensing and represent the
sensor’s detection probability and false alarm probability by
the constant parametersp andq, respectively, i.e.,P (O
i;c;t
=
1jX
c
= 1) = p and P (O
i;c;t
= 1jX
c
= 0) = q, for all
cells and UA Vs. Whenever a UA V
i
visits a given cell c, the
information associated with that cell P
c
is updated in the
search map of UA V
i
based on its sensor observation and
prior probability in cell c.
The mobility of each UA V is discretized in time by
allowing the vehicle to make only decisions at discrete time
intervals, referred to as time steps. The mobility is also
discretized in space by only allowing the vehicle to move
to left, right, forward, backward or stay at the current cell
at each time step. This discretization of mobility in time
and space is well suited for small-scale, battery powered
quadrotor UA Vs. Currently, we assume predeﬁned paths for
the UA Vs to move, i.e., a sweep mobility model, and do not
bias the mobility of UA Vs by information gained during the
mission. We assume the wireless communication onboard
the UA Vs have range limitations. Thus, information can
only be exchanged when the UA Vs are within the speciﬁed
communication range. We further assume that there are no
delays or failures in communication once the UA Vs are
within this range. We ignore mutual decisions on UA V
movement, and hence concentrate on coordination in terms
of information sharing and merging, where the key is to
show how information of one UA V can be combined with
information from other UA Vs so that the team can work
together to locate the target more efﬁciently in terms of
mission time and location errors.
Primarily, each UA V updates its own search map using
its own sensor observations. Due to different UA V locations,
errors in the surveillance sensor, number of visits to a given
cell and especially limited communication range, the UA Vs
may have different probabilities of target existence for a
given cell. Individual probabilities by various UA Vs for a
given cell should be merged to calculate a probability that
best represents information about the target existence in that
cell. Utilizing the information from other team-mates a UA V
can improve the search in two ways: (i) by increasing its
observability of the search region by taking into consider-
ation other UA Vs’ observations and (ii) by improving its
knowledge in a given cell by merging probabilities in that
cell by other UA Vs. In the following section we discuss the
information merging strategies in more detail.
Uncoordinated 
Search Map Update 
Merge 
Information 
Update 
Search Map 
Coordinated Search Map Update 
O
i 
c
i 
Search map sent to 
other UAVs 
Search maps received 
from other UAVs 
Surveillance 
Sensor
 
Position 
Sensor
 
P
c
 ≥ B 
UAV 
Movement 
No 
Yes 
Inform other UAVs 
(Target found ) 
New cell 
Fig. 1. Information merging for multi-UA V cooperative search (process
within single UA V). Coordinated update depicted in the dashed box is not
deployed for the search strategies without merging.
IV. INFORMATION MERGING
As the mission starts, N UA Vs initialize their search
maps with P
i;c;0
= 0:5 for i = 1;:::;N and for all
c, which represents complete uncertainty or lack of prior
knowledge about the search region 
. Each UA V in the
team starts taking sensor observation at its current location.
Based on the sensor observation O
i;c;t
and prior probability
P
i;c;t 1
in the current cell c
i
, 8i, the UA Vs update the
occupancy probability to P
i;c;t
in their own search maps.
This uncoordinated map update by individual UA Vs depend
on the detection and false alarm probabilities of surveillance
sensor on board the UA Vs. Each UA V then broadcasts the
updated information to other UA Vs in the team. Depending
on the communication range, the UA Vs in the team now have
at most N values for the visited c
i
’s at time t. A merging
strategy takes into consideration all values corresponding to
c
i
that are visited at time t and determines a new occupancy
probability that best represents the existence of target at the
current cells of each UA V . Each UA V then moves to the next
cell in the search region according to its mobility model and
continues the merging process at the new cell. The process
is depicted in Fig. 1 which is executed by each UA V at every
time step. The search is ﬁnished when any of the N UA Vs
identiﬁes a cell c with P
c
 B, where B is a predeﬁned
detection threshold to stop the search.
Fig. 2 represents a small search region with a single target
and the local 4 4 search maps of three UA Vs having
unlimited communication. Fig. 3 shows the information
contents of UA V
1
after exchange of information with all
other UA Vs. Sharing and merging of information result in at
mostN cell updates in each individual search map. To avoid
confusion, we use the notation c
i
to represent location of
UA V
i
and P
i;cj
to represent occupancy probability of UA V
i
at the location of UA V
j
(j = 1; 2;:::;N). As indicated in
Fig. 1 there are two different updates performed by each UA V
at each time step: uncoordinated map update and coordinated
map merging. Uncoordinated map update requires only local
information and results in the ”uncoordinated” occupancy
probability. Coordinated map merging combines this local
uncoordinated probability with information from other UA Vs
and computes the actual probability P
i;ci
which is stored
in the search map. Obviously, when no information from
other UA Vs is available, coordinated map merging is not
3124
P
3,c
1 
P
3,c
2 
P
3,c
3 
P
1,c
1 
P
1,c
2 
P
1,c
3 
P
2,c
1 
P
2,c
2 
P
2,c
3 
1 
3 
2 
(a)        (b)            (c) 
(d) 
Fig. 2. Local 44 search maps of three UA Vs (a, b and c) and the search
region (d) marked with the UA Vs’ positions (dots) and the target position
(star).
P
1,c
1 
P
1,c
2 
P
1,c
3 
1 
3 
2 
Merge Merge 
Merge 
P
1,c 2 
P
2,c 2 
P
3,c 2 
P
1,c 1 
P
2,c 1 
P
3,c 1 
P
1,c 3 
P
2,c 3 
P
3,c 3 
Fig. 3. The coordinated map merging for UA V
1
having unlimited
communication.
possible and we simply use the uncoordinated occupancy
probability as new cell value.
2
In the following, we describe
the uncoordinated update and propose several strategies for
map merging in more detail.
A. Uncoordinated search map update
The probability in the current cell c is updated using
Bayesian rule [27], [16], which uses the sensor characteristics
(p and q), sensor observation O
i;c;t
and prior probability in
cell c. The Bayesian rule is given by
P
i;c;t
=
(
pPi;c;t 1
pPi;c;t 1 + q(1 Pi;c;t 1)
if O
i;c;t
= 1
(1 p)Pi;c;t 1
(1 p)Pi;c;t 1 + (1 q)(1 Pi;c;t 1)
if O
i;c;t
= 0
(1)
It can be shown from Eq. (1) that P
i;c;t
= 1 if P
i;c;0
= 1
and P
i;c;t
= 0 if P
i;c;0
= 0 for all t > 0. If p = 0, P
i;c;t
becomes 0 once UA V
i
gets a sensor observation equal to 1,
and will remain unchanged regardless of future observations.
We consider 0<P
i;c;0
< 1, 0<p< 1, and 0<q < 1.
B. Map merging
In this section, we propose four strategies to merge in-
formation from multiple UA Vs. We consider different types
2
For the sake of simplicity, we do not distinguish between uncoordinated
and merged occupancy probabilities throughout the remainder of this paper.
of information and communication limitations. We start
with unlimited communication and then elaborate on the
modiﬁcations required for efﬁcient implementation of each
strategy under limited range condition.
1) Belief update: Each UA V
i
computes the uncoordinated
occupancy probability for cell c
i
, stores it at its search map
and broadcasts the updated probability value to the other
UA Vs. All UA Vs which receive this information, overwrite
the previous probability value atc
i
in their own maps. Thus,
a UA V
i
receives updated information from other UA Vs and
updates its search map by
P
i;cj
=P
j;cj
(2)
where j = 1; 2;:::;N assuming that UA Vs don’t visit a cell
concurrently.
2) Average: Each UA V
i
computes the uncoordinated oc-
cupancy probability for cell c
i
, stores it at its search map
and broadcasts the updated probability value to the other
UA Vs. The UA Vs receiving this updated value for cell c
i
update their own maps depending on the previous value of
cell c
i
. UA V
j
overwrites the occupancy probability in cell
c
i
by the received value, if the previous probability value
is 0:5 and replaces it by the average of the values in its
own map and the received messages otherwise. UA V
i
has
to fully believe UA V
j
for a given cell, if only UA V
j
has
some information in that cell. Otherwise UA V
i
averages the
information contributed by itself and UA V
j
. UA V
i
updates
its map by
P
i;cj
=
(
P
j;cj
; if P
i;cj
= 0:5
1
n
P
n
k=1
P
k;cj
otherwise, (nN)
(3)
where n depends on the communication range. If the com-
munication range is limited, the probability values forc
j
may
differ in the local search maps due to updates at different time
steps (Section IV-C). In this casen is equal to the number of
UA Vs with different values for c
j
within the communication
range. If the communication range is unlimited, all UA Vs
(j6=i) have up-to-date knowledge for the probability value
in c
j
in their local search maps. Thus, we compute the
average only from the UA V currently observing c
j
and the
UA V
i
, i.e., n = 2.
3) Modiﬁed occupancy grid map merging: Integrating
occupancy grids [28] is a well-known technique used in
simultaneous localization and mapping (SLAM). We propose
a modiﬁed version of this strategy which better ﬁts to the
search process and include it as a comparison with the state-
of-the-art. The original merging rule is given as
P
iogm
ci
=
odds
ci
1 +odds
ci
(4)
odds
ci
=
n
Y
j=1
odds
j;ci
(5)
odds
j;ci
=
P
j;ci
1 P
j;ci
(6)
3125
TABLE I
MERGING OCCUPANCY PROBABILITIES IN A GIVEN CELL MULTIPLE
TIMES USING INTEGRATING OCCUPANCY GRIDS METHOD.
Time O
1;c
O
2;c
P
1;c
P
2;c
t
0
– – 0.5 0.5
t
1
1 (false alarm) – 0.9 0.9
t
2
– 0 (true negative) 0.9 0.9
whereP
iogm
ci
is the probability of occupancy atc
i
calculated
through integrating occupancy grid maps (OGMM)
3
.
In our cooperative search, we model the target existence
also as occupancy probability of a cell. The OGMM method
aims to reinforce cell values and thus reaches low or high
probability values very fast. This property supports quick
decision making but results in a considerable amount of
detection errors, if the repetitive observations include false
alarm and false negatives. Table I shows an example of this
problem for speciﬁc values ofp = 0:9 andq = 0:1, where at
timet
1
one UA V receives false alarm from its sensor and the
other UA V has no observation at cell c. The merging results
in updating both the maps at P
1;c
and P
2;c
with value 0.9.
At a later time t
2
, one of the UA Vs observes true negative
at cell c but merging of values brings no change in both
the maps. The probability of occupancy at c is now ﬁxed
to 0:9 and can not be reduced by even inﬁnite numbers of
correct observations in that cell. The detection of another
false alarm at c will further increase the value of P
c
leading
to exceeding the threshold value and terminating the search
with an erroneous result. Thus, integrating occupancy grid
maps in its original form is not suitable for cooperative
search scenario.
The effect of this problem can be reduced if we restrict the
output of the integrating occupancy grid technique to change
slowly. In order to do so, we combine the average value
of occupancy probabilities at c
i
and occupancy value using
integrating occupancy grids at c
i
by a weighted average.
P
ci
=v(P
avg
ci
) + (1 v)(P
iogm
ci
) (7)
where
P
avg
ci
=
1
n
n
X
j=1
P
j;ci
(8)
The weight v can be chosen based on the sensor parame-
ters and search constraints.
4) Sensed data sharing: Instead of sharing probability
values, the UA Vs can share their current locations and sensor
observations with each other. In this strategy, each UA V
keeps a record of sensor observations for each and every
cell in the search region and updates theP
c
iteratively based
on the total number and type of observations in cell c. The
strategy enables UA Vs to share full information but requires
more memory, computation power and bandwidth if surveil-
lance sensors are heterogeneous with different characteristics
3
This rule is adopted from SLAM where robots develop partial maps
using occupancy grids and integrate the partial occupancy grids at the end
of the SLAM process by using Eq. (4).
(p and q). The updated probability in cell c by a UA V can
be calculated by iteratively using Eq. (1) for all consecutive
observations from all UA Vs.
C. Communication range limitations
When the communication range is unlimited, the presented
strategies do not need to utilize the time index of a given
observation, since each UA V can hear the broadcast of
every other UA V at all times. However, in situations where
the communication range is limited, each UA V can only
communicate to UA Vs that are within its communication
range. This likely results in different probability maps at each
UA V and it is essential to correctly interpret the maps, e.g.,
to avoid double counting of observations in the sensed data
sharing strategy.
In order to maintain the timeliness of the occupancy
probabilities we introduce a simple time stamping mecha-
nism. Whenever a probability value is changed, we capture
the time stamp of this update. If this update is caused by
an observation of the cell, we capture the current time. If
this update is caused by merging cell values from different
UA Vs, we take the most recent time stamp among the
contributing cell values as new time stamp. The time stamps
are stored in the search maps and are exchanged together
with the probability values of the cells. Map merging is only
performed in those cells which have different time stamps
wrt. the neighboring UA Vs.
Observe that adding time stamps (i.e., history of obser-
vations) to the search map increases the information to
be exchanged and processed by the UA Vs. Therefore, the
performance of each strategy will depend on not only the
communication range but also the available bandwidth for
data transmission. The effect of bandwidth limitations on
cooperative search will be analyzed in future work.
D. Best case analysis for a single cell
Given the values of p, q and the threshold B, we can
calculate the minimum number of observations required in
cellc to satisfy the conditionP
c
B, if the target is present
in cell c. This condition is satisﬁed when all observations
taken at the target cell equal 1. According to Eq. (1), for a cell
c, the ﬁrst updated probability in case of positive observation
is given by,
P
1
=
pP
0
pP
0
+ q(1 P
0
)
(9)
where P
0
represents initial probability in cell c and is equal
to 0.5. Assume that target is present in cell c and each time
step the sensor generates positive observation O
c
= 1. The
iterative solution of this equation yields
P
m
=
pP
m 1
pP
m 1
+ q(1 P
m 1
)
(10)
P
m
=
p
m
P
0
p
m
P
0
+q
m
(1 P
0
)
(11)
where P
m
represents the updated value in cell c at m
th
observation. To ﬁnd the minimum number of observations
3126
0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4
2
2.5
3
3.5
4
4.5
5
5.5
6
6.5
7
q
No. of positive observations
 
 
p=0.8, B=0.99
p=0.85, B=0.99
p=0.9, B=0.99
p=0.8, B=0.99(m)
p=0.85, B=0.99(m)
p=0.9, B=0.99(m)
Fig. 4. Minimum number of observations required in a single cell to
satisfy condition PcB (corresponds to the best case, i.e., when a target
is present in the visited cell and the observation is equal to 1.)
such that, P
m
 B, we need to ﬁnd the value of m which
can be obtained by
m log

P
0
(1 B)
B(1 P
0
)

= log
q
p
(12)
Given the values of p, q, and B, Eq. (12) can be used
to estimate the minimum number of observations (P
m

B) required in a cell if there is a target. Fig. 4 shows the
analytical number of observations obtained using Eq. (12)
(represented withm in the legend) and simulation results. In
simulation results, we iteratively update the initial probability
of 0:5 and count the number of observations (that are always
positive) till the probability is equal to or greater than B.
V. SIMULATION RESULTS
To evaluate the effectiveness of our proposed merging
strategies, we simulate a search region of 10 10 cells with
a single stationary target located at (6; 7). We initialize the
location of upto N = 5 UA Vs at randomly selected cells
and consider a standard sweep model for the mobility of
UA Vs. We consider B = 0:99 which means the search is
ﬁnished if one of the UA Vs ﬁnds a cell c in its own map
with P
c
 0:99 and that cell is designated as location of the
target. If the result of search is a cell other than (6; 7), we
record a detection error. We perform simulations to compare
the results of our proposed strategies in case of no com-
munication, limited communication and full communication
among UA Vs. We use the communication range in terms of
cells and consider two UA Vs in range when the Euclidean
distance between them is less than or equal to the speciﬁed
communication range. All results are based on 1000 runs
of simulations and v = 0:7 in modiﬁed OGMM merging
strategy. We also present results for uncoordinated search,
where UA Vs only use their own observations to update their
maps as reference.
First, we consider full communication, where all UA Vs
can exchange information at each time step and evaluate
our strategies for various values of q and N. Fig. 5 and
Fig. 6 show the average number of time steps required and
the percentage of erroneous results versus the false alarm
0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4
0
100
200
300
400
500
600
q
Time Steps
 
 
Uncoordinated
Belief update
Average
Modified OGMM
Sensed data
0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4
0
10
20
30
40
50
60
q
Errors (%)
Fig. 5. The effect of increasing q on the search time (time steps) and
location errors with 2 UA Vs (p = 0:9, unlimited communication).
0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4
0
100
200
300
400
q
Time Steps
 
 
Uncoordinated
Belief update
Average
Modified OGMM
Sensed data
0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4
0
20
40
60
80
q
Errors (%)
Fig. 6. The effect of increasing q on the search time (time steps) and
location errors with 5 UA Vs (p = 0:9, unlimited communication).
rate q for 2 and 5 UA Vs, respectively. The ﬁgures show that
degrading the quality of the sensor (increasing the value of
q) increases the number of time steps to locate the target
in all strategies. Comparing the results in these ﬁgures, in
contrast to other strategies, the errors for the average strategy
reduces as the value of q increases. This reduction in errors
comes with a cost of overshoot in time steps. The repetitive
behavior or jumps in the plots are due to the fact that there
are a ﬁxed number of observations required to exceed the
threshold for certain ranges of q (as explained in Fig. 4). As
the value of q increases within a given range, the number of
false alarms increases but the number of steps required to
reach a decision remains constant. Having consecutive false
alarms in a cell will end up in an erroneous result. While
not presented here due to space limitations, decreasing the
value of p for ﬁxed value of q increases the number of time
steps required to terminate the search.
Second, we show the effect of increasing the number of
3127
1 2 3 4 5
0
100
200
300
400
No. of UAVs
Time Steps
 
 
Uncoordinated
Belief update
Average
Modified OGMM
Sensed data
1 2 3 4 5
0
10
20
30
No. of UAVs
Errors (%)
Fig. 7. The effect of increasing the number of UA Vs on the search time
and the location errors (p = 0:9;q = 0:2, unlimited communication).
UA Vs on our merging strategies with unlimited communi-
cation. Fig. 7 shows the effect of increasing the number of
UA Vs with ﬁxed values of p = 0:9 and q = 0:2 on the
search time. Note that increasing the number of UA Vs with
coordinated map updates is more efﬁcient than increasing the
number of UA Vs in uncoordinated search. It is evident from
Fig. 7 that sensed data merging and belief update require less
time to search the region but at the cost of higher location
errors. We can tune the value of v in the modiﬁed OGMM
strategy to obtain better results depending on the values of
p, q and the number of UA Vs.
Third, we evaluate our proposed strategies for limited
communication with ﬁxed values of p, q and the number
of UA Vs. Fig. 8 and Fig. 9 show the effect of increasing the
communication range on time steps required to terminate the
search and percentage of erroneous results for 2 and 5 UA Vs,
respectively. We show the results for no communication to
unlimited communication (in a 10 10 grid with communi-
cation range < 14). As the communication range increases,
the performance of these strategies converge to a point that
is consistent with the results of Fig. 7.
Finally, we show the percent gain for the various merging
strategies with respect to uncoordinated search in Table
II. We deﬁne the percent gain as ((T
u
  T
c
)=T
u
) 100,
where T
u
and T
c
represent time steps for uncoordinated and
coordinated search respectively. In general, the improvements
rise with increasing the number of UA Vs. In our simulations,
the minimum gain we can achieve for minimum number of
UA Vs (i.e., 2 UA Vs) is 27% and the maximum gain that we
can reach for maximum number of UA Vs (i.e., 5 UA Vs) is
70%. The improvement is also increasing with enlarging the
communication range but saturates once the communication
is stable. Note that when there is unlimited communication,
exchanging the probability maps (i.e., belief update) is sufﬁ-
cient to perform as good as sharing all observations. As the
communication range reduces, the improvements with belief
0 2 4 6 8 10 12 14
150
200
250
300
350
Communication Range (cells)
Time Steps
 
 
Uncoordinated
Belief update
Average
Modified OGMM
Sensed data
0 2 4 6 8 10 12 14
5
10
15
20
Communication Range (cells)
Errors (%)
Fig. 8. The effect of increasing the communication range on the search
time and the location errors (2 UA Vs, p = 0:9;q = 0:2).
0 2 4 6 8 10 12 14
50
100
150
200
250
Communication Range (cells)
Time Steps
 
 
Uncoordinated
Belief update
Average
Modified OGMM
Sensed data
0 2 4 6 8 10 12 14
0
10
20
30
Communication Range (cells)
Errors (%)
Fig. 9. The effect of increasing communication range on time steps (5
UA Vs, p = 0:9;q = 0:2).
update also reduce (from 70% to 41%) since the UA Vs meet
each other at different times and keep different maps, while
sharing observations still sustains high improvements. In this
case, increasing the number of UA Vs is also not sufﬁcient.
Therefore, under stringent communication, deployed merging
strategy needs to be chosen carefully.
VI. CONCLUSIONS
We presented merging strategies for information from
multiple UA Vs in a cooperative search scenario. We showed
that the proposed strategies enable cooperative search better
than uncooperative search even with pre-deﬁned and ﬁxed
path mobility of UA Vs. The strategies are well suited for
higher number of UA Vs as increasing the number of UA Vs
increases the gain (in terms of time and errors) compared to
uncooperative search. The improvement due to increase in
communication range saturates once the communication is
stable. Sharing of full information, as discussed in sensed
data sharing strategy, is efﬁcient time-wise but requires
3128
TABLE II
PERCENTAGE GAIN IN TERMS OF TIME STEPS WITH RESPECT TO UNCOORDINATED SEARCH (p = 0:9;q = 0:2)
Communication range = 2 (cells) Communication range = 6 (cells) Communication range = 14 (cells)
BU A VG MOGM SDS BU A VG MOGM SDS BU A VG MOGM SDS
N=2 15.6 -7.2 14.7 36.7 30.9 22.9 32.6 37.0 39.8 27.4 32.1 39.9
N=3 20.4 -2.1 16.2 48.0 50.6 14.5 36.8 52.3 54.5 23.1 33.1 52.0
N=4 39.6 5.8 28.7 67.6 64.0 23.9 51.3 68.6 63.5 25.6 43.8 64.8
N=5 41.6 8.0 29.7 70.9 70.0 40.0 61.1 69.5 69.4 37.0 57.8 69.8
BU=Belief update, A VG=Average, MOGM=Modiﬁed OGMM, SDS=Sensed data sharing
more resources. Other strategies are resource efﬁcient and
involve trade-off in time-to-search and number of errors.
We did not consider biasing the mobility of UA Vs and did
not plan cooperative paths based on information obtained
from sharing and merging which will be included in our
future research. We also plan to include the mobility of
target and communication bandwidth limitations in our future
publications.
ACKNOWLEDGEMENTS
This work was supported in part by the EACEA Agency
of the European Commission under EMJD ICE FPA n
o
2010-0012.The work has also been supported by the ERDF,
KWF, and BABEG under grant KWF-20214/24272/36084
(SINUS). It has been performed in the research cluster
Lakeside Labs.
REFERENCES
[1] S. Waharte, N. Trigoni, and S. J. Julier, “Coordinated search with a
swarm of UA Vs,” in Proceedings of the 6th Annual IEEE Communi-
cations Society Conference on Sensor, Mesh and Ad Hoc Communi-
cations and Networks, 2009.
[2] S. Waharte and N. Trigoni, “Supporting search and rescue operations
with UA Vs,” in Proceedings of International Symposium on Robots
and Security (ROBOSEC), 2010.
[3] M. Quaritsch, K. Kruggl, D. Wischounig-Strucl, S. Bhattacharya,
M. Shah, and B. Rinner, “Networked UA Vs as aerial sensor network
for disaster management applications,” Elektrotechnik und Informa-
tionstechnik, Special Issue on Wireless Sensor Networks, pp. 56–63,
2010.
[4] L. Merino, F. Caballero, J. M. de Dios, J. Ferruz, and A. Ollero,
“A cooperative perception system for multiple uavs: Application to
automatic detection of forest ﬁres,” Journal of Field Robotics, vol. 23,
pp. 165–184, 2006.
[5] E. Yanmaz and H. Guclu, “Stationary and mobile target detection
using mobile wireless sensor networks,” in Proceedings of the IEEE
Conference on Computer Communications, 2010, pp. 1–5.
[6] M. Flint, M. Polycarpou, and E. Fernandez-Gaucherand, “Cooperative
control for multiple autonomous UA V’s searching for targets,” in
Proceedings of 41st IEEE Conference on Decision and Control, 2002.
[7] Y . Yang, A. Minai, and M. Polycarpou, “Decentralized cooperative
search by networked UA Vs in an uncertain environment,” in Proceed-
ings of the American Control Conference, 2004, pp. 5558–5563.
[8] Y . Yang, M. Polycarpou, and A. A. Minai, “Multi-UA V cooperative
search using an opportunistic learning method,” ASME Journal of
Dynamic Systems, Measurement, and Control, vol. 129, no. 5, pp.
716–728, 2007.
[9] G. York and D. J. Pack, “Ground Target Detection Using Cooperative
Unmanned Aerial Systems,” Journal of Intelligent & Robotic Systems,
vol. 65, pp. 473–478, 2012.
[10] P. B. Sujit and D. Ghose, “Optimal uncertainty reduction search using
the k-shortest path algorithm,” in Proceedings of the 2003 American
Control Conference, 2003, pp. 3269–3274.
[11] P. B. Sujit and Ghose, “Multiple agent search of an unknown environ-
ment using game theoretical models,” in Proceedings of the American
Control Conference, 2004, pp. 5564–5569.
[12] E. J. Forsmo, E. I. G, T. I. Fossen, and T. A. Johansen, “Optimal
search mission with unmanned aerial vehicles using mixed integer
linear programming,” in Proceedings of IEEE Intl. Conference on
Unmanned Aircraft Systems (ICUAS), 2013, pp. 253–259.
[13] C. Lum, R. T. Rysdyk, and J. Vagners, “A search algorithm for teams
of heterogeneous agents with coverage guarantees,” AIAA Journal of
Aerospace Computing, Information, and Communication, vol. 7, pp.
1–31, 2010.
[14] K. R. Guruprasad and D. Ghose, “Automated multi-agent search using
centroidal voronoi conﬁguration,” IEEE Transactions on Automation
Science and Engineering, vol. 8, no. 2, pp. 420–423, 2011.
[15] M. Mirzaei, F. Shariﬁ, B. W. Gordon, C. A. Rabbath, and Y . M.
Zhang, “Cooperative multi-vehicle search and coverage problem in
uncertain environments,” in Proceedings of the 50th IEEE Conference
on Decision and Control and European Control Conference (CDC-
ECC), 2011.
[16] J. Hu, L. Xie, K.-Y . Lum, and J. Xu, “Multiagent information fusion
and cooperative control in target search,” IEEE Transactions on
Control Systems Technology, no. 99, pp. 1–13, 2012.
[17] F. Bourgault, T. Furukawa, and H. F. Durrant-Whyte, “Coordinated
Decentralized Search for a Lost Target in a Bayesian World,” in
Proceedings of the IEEE/RSJ Intl. Conference on Intelligent Robots
and Systems, 2003, pp. 48–53.
[18] F. Bourgault, T. Furukawa, and H. Durrant-Whyte, “Decentralized
Bayesian negotiation for cooperative search,” in Proceedings of
IEEE/RSJ Intl. Conference on Intelligent Robots and Systems, 2004,
pp. 2681–2686.
[19] T. Furukawa, F. Bourgault, B. Lavis, and H. F. Durrant-Whyte,
“Recursive Bayesian Search-and-Tracking Using coordinated UA Vs
for Lost Targets,” in Proceedings of IEEE Intl. Conference on Robotics
and Automation, 2006, pp. 2521–2526.
[20] T. Chung and J. Burdick, “Multi-agent probabilistic search in a
sequential decision-theoretic framework,” in Proceedings of the IEEE
Intl. Conference on Robotics and Automation, 2008, pp. 146–151.
[21] T. H. Chung and J. W. Burdick, “Analysis of search decision-making
using probabilistic search strategies,” IEEE Transactions on Robotics,
vol. 28, no. 1, pp. 132–144, 2012.
[22] P. Vincent and I. Rubin, “A framework and analysis for cooperative
search using UA V swarms,” in Proceedings of the 2004 ACM Sympo-
sium on Applied Computing, 2004, pp. 79–86.
[23] P. Sujit and D. Ghose, “Multiple UA V search using agent based nego-
tiation scheme,” in Proceedings of the American Control Conference,
2005, pp. 2995–3000.
[24] P. B. Sujit and D. Ghose, “Self assessment-based decision making
for multiagent cooperative search,” IEEE Transactions on Automation
Science and Engineering, vol. 8, pp. 705–719, 2011.
[25] D. Fave, F. Maria, Z. Xu, A. Rogers, and N. R. Jennings, “Decentral-
ized coordination of unmanned aerial vehicles for target search using
the max-sum algorithm,” in Proceedings of the AAMAS Workshop on
Agents in Real Time and Dynamic Environment, 2010, pp. 35–44.
[26] J. Berger and J. Happe, “Co-evolutionary search path planning under
constrained information-sharing for a cooperative unmanned aerial
vehicle team,” in Proceedings of the IEEE Congress on Evolutionary
Computation (CEC), 2010, pp. 1–8.
[27] M. Zhong and C. Cassandras, “Distributed coverage control and data
collection with mobile sensor networks,” in Proceedings of the IEEE
Conf. Decision Control, Dec 2010, pp. 5604–5609.
[28] W. Burgard, M. Moors, D. Fox, R. Simmons, and S. Thrun, “Col-
laborative multi-robot exploration,” in Proceedings of the IEEE Intl.
Conference on Robotics and Automation (ICRA), vol. 1, 2000, pp. 476
– 481.
3129
