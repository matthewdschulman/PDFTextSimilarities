Characterization and Compensation of XY Micropositioning Robots
using Vision and Pseudo-Periodic Encoded Patterns
Ning Tan, C´ edric Cl´ evy, Guillaume J. Laurent, Patrick Sandoz and Nicolas Chaillet
Abstract—Accuracy is an important issue for microrobotic
applications. High accuracy is usually a necessary condition
for reliable system performance. However there are many
sources of inaccuracy acting on the microrobotic systems.
Characterization and compensation enable reduction of the
systematic errors of the micropositioning stages and improve
the positioning accuracy. In this paper, we propose a novel
method based on vision and pseudo-periodic encoded patterns
to characterize the position-dependent errors along XY stages.
This method is particularly suitable for microscale motion
characterization thanks to its high range-to-resolution ratio
and avoidance of camera calibration. Based on look-up tables
andinterpolationtechniques,weperformcompensation andget
improved accuracy. The experimental results show an accuracy
improved by 84% for square tracking and by 68% for random
points reaching (respectively from 22 ?m to 3.5 ?m and from
22 ?m to 7 ?m).
I. INTRODUCTION
Micromanipulations, such as microassembly [1], bio-
logical micromanipulation [2], microdispensing [3] require
highly reliable and accurate operations. Considering many
factors (e.g., success rate, speed, and contamination), these
tasks usually rely on microrobotic systems with automatic
control instead of manual operation [5], [6]. Micromanipu-
lation platforms usually consist of one or several microrobots
comprising several micropositioning stages [7].
Off-the-shelf micropositioning stages have inherent imper-
fections that could be noticeable issues to achieve a microm-
eter accuracy. Manufacturers provide generally statistical
speciﬁcations such as positioning repeatability and sensor
resolution. Because some of imperfections are position-
dependent, these data are not sufﬁcient to ensure a good
accuracy of an end-effector attached to the stage. For in-
stance, for one of such stage mounted with a tip of 20 mm
length, the error could be around 3 ?m at the end-point
in the perpendicular direction of the motion due to yaw
deviation [11].
Moreover, micropositioning stages usually have limited
Degrees-of-Freedom (DoF) and the assembling of several
of them is required to meet speciﬁc needs. Tools such as
gripper or probe are also fastened onto the stages as end-
effector. These assemblies introduces geometric errors that
must be evaluated and compensated. For example, if the
These works have been funded by the Franche-Comt´ e r´ egion and OSEO,
and partially supported by the Labex ACTION project ANR-11-LABX-
01-01 and by the French RENATECH network through its FEMTO-ST
technological facility. We would like to acknowledge David Guibert for
technical support.
Authors are with the FEMTO-ST Institute, UFC-ENSMM-UTBM-
CNRS UMR 6174, Universit´ e de Franche-Comt´ e, Besanc ¸on 25000, France
cedric.clevy@femto-st.fr
perpendicularity error between two X and Y axes is 0.1

,
1 cm motion along Y could induce error about 17 ?m along
X which is signiﬁcant at the microscale.
To achieve motions of end-effector with improved accu-
racy, assembly errors and position-dependent errors must
be measured, quantiﬁed and compensated. This job requires
an exteroceptive sensor measuring the position of the end-
effector of the micromanipulation platform. However, ex-
teroceptive sensors that have at the same time nanometric
resolutions, millimeter ranges of measurement and multiple
direction of measurement are very rare [9].
For instance, position sensors such as interferometers that
have a high range-to-resolution ratio are generally bulky and
offer only one direction of measurement. Multi-direction of
measurement requires to combine several sensors, which is a
tough task because of the limited workspace and particularly
because it is difﬁcult to measure the position of the end-
effector when it is moving in another direction than the
measured one.
Vision is a rational alternative to measure the position
of the end-effector in several directions. However developed
methods such as blob detection [10], model-based tracking
[21] and phase-like correlation methods [14] have a limited
range of measurement because the object of interest has to
remain inside the ﬁeld-of-view. As a consequence, a trade-off
must be done between range and resolution.
In this paper, we propose a novel method of character-
ization using vision and pseudo-periodic encoded patterns.
A speciﬁc image processing enables high resolution and
long ranges in the two directions of the image plane. We
show on a case study that these features make pseudo-
periodic encoded patterns the ideal candidate to characterize
the motion behavior of microrobots. The case study is a
XY microrobotic structure using two micropositioning stages
because this kind of structure is very popular in microscale
applications [12], [13]. The second contribution of the paper
is the improving of the accuracy thanks to a compensated
driving based on look-up tables and interpolation techniques.
The remainder of this paper is organized as follows. Sec-
tion II introduces the visual measurement principle. Section
III presents the experimental setup including the microposi-
tioning stages and vision system. The errors characterization
of the XY micropositioning robot is presented in Section IV .
Section V details the compensation principle and experimen-
tal compensation results. Finally, we conclude the paper with
Section VI.
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 2819
x
coarse
x
fine
y
coarse
y
fine
x
y
Linear 
Feedback
Shift Register 
decryption
Camera image
Binary image
Fourier transform
Code extraction
Vertical modulation
Horizontal modulation
Phase computation for X
Phase computation for Y
Measurement 
combination
Fig. 1. Visual position measurement process (PPP algorithm).
II. VISUAL POSITION MEASUREMENT USING
PSEUDO-PERIODIC ENCODED PATTERNS
Most of high-resolution imaged-based motion-detection
algorithms rely on phase-like correlation methods. For ex-
ample, this kind of method has been implemented by Mod-
demeijer [14] reporting a resolution of 13.3 nm. The main
drawback of these correlation-like methods remains in the
useful ﬁeld-of-view. Those methods are feature dependent
so that the pattern has to remain inside the region of interest
to be analyzed thus limiting the range of measurement. To
overcome such a drawback, a technique based on pseudo-
periodic patterns has been proposed by different authors [15],
[16], [17].
In this paper, we propose to use a similar technique which
is based on an encryption of a binary code over a pseudo-
periodic pattern (PPP). The position is obtained by combin-
ing ﬁne and coarse measurements that are complementary
(cf. Fig. 1). The coding allows absolute but coarse coordinate
transformations of the image reference frame into actual
positions on the observed part of the pattern. In addition, the
pseudo-periodic pattern allows a high level of interpolation
through phase measurements that lead to subpixel resolution.
The coarse measurement is done by decrypting the distri-
bution of points missing in the periodic frame. Some dots are
missing and their distribution follows a codiﬁcation of the X
and Y orders of the dots. This codiﬁcation is based on Linear
Feedback Register Sequences (LFRS). Pose retrieval involves
complementary image processing to identify the location of
the missing points and thus to return the line and column
orders necessary to complete the ﬁne position provided by
phase computations.
The ﬁne measurement is performed after a 2D Fourier
transformation that aims to separate the different directions
of modulation of the pattern. The phase of the periodic
grid is then computed in both directions thanks to two
analysis functions. Given the phases (in rad) and the period
of the pattern (in meter), it is straightforward to calculate
the relative position of the pattern in the image reference
Fig. 2. Experimental setup of the XY microrobotic system, (a) general
view, (b) close view of the end-plateform, (c) microscope image of the
pattern.
frame. This process gives the position with typically subpixel
resolution of 10
 3
pixels but also with an indeterminacy
equal to the wavelength of the pattern.
Moreover as the period of the pattern is precisely known
(4 m in the present), the measurement is intrinsically self-
calibrated. There is no need to calibrate the imaging system.
More details about the algorithm and the fabrication of the
pattern can be found in [18].
Finally, in the present case, the measuring range is lim-
ited by the size of the pattern that is 9.5 mm for x-axis
and 4.2 mm for y-axis. The reproducibility of the visual
measurement has been experimentally evaluated and is better
than 10 nm [19].
III. CASE STUDY
Many micromanipulation systems work with mobile parts
that are guided based on friction principles. Their positioning
performances depend on the qualities of fabrication, plays,
2820
TABLE I
SPECIFICATIONS OF XY TRANSLATION STAGES IN DATASHEET
Stage PI M-111.1DG
Travel range 15 mm
Resolution 50 nm
Unidirectional repeatability 100 nm
Pitch angle deviation 150 ?rad
Yaw angle deviation 150 ?rad
Backlash 2 ?m
Thread pitch 0.4 mm
Driving mechanism Leadscrew
weight of the axes and so on. The micropositioning stages are
equipped with internal sensors and are individually closed-
loop controlled in actuation layer. But depending of the loca-
tion the sensors in the actuation chain, the feedback control
can not reject some sources of errors. Moreover, assemblies
errors can not be compensated using only proprioceptive
sensors.
In this paper, we choose an XY microrobotic structure as
a case study because this kind of structure is representative
for many systems commonly used in micromanipulation.
The pictures of the whole experimental setup and the end-
platform are shown in Fig. 2 (a) and (b). The system
consisting of two translation stages (XY) is mounted on a
anti-vibration table. The two translation stages are PI M-
111.1DG equipped with MercuryTM C-863 controllers. The
speciﬁcations of translation stages XY from the datasheets
is given in Table I.
The external measuring system for characterization con-
sists of a 1024768 video camera (A VT STINGRAY F-
125C), a microscope lens (Optem zoom 70XL), an objective
with 10 magniﬁcation and the pseudo-periodic pattern (Fig.
2 (c)). The upper goniometer (M-GON40-U) and lower
goniometer (M-GON40-L) are used for adjusting the par-
allelism between the pattern and the camera.
IV. CHARACTERIZATION OF
POSITION-DEPENDENT ERRORS
The position-dependent errors along axes are signiﬁcant
characteristics of the precise positioning stages. These errors
are due to the geometric nature of the axes. For macroscale
robotics, this type of errors is usually neglected in calibration
which mainly focuses on kinematic parameters identiﬁcation
or elastic deformation. However, these errors become signif-
icant at the microscale, especially for Cartesian microrobots.
The error curves are functions of axis coordinates, and
the functions are different from one axis to another, so
measurements of these errors for every axis are necessary.
The position-dependent errors are calculated by comparing
the measured positions (estimation of real positions) with the
targeted positions (positions to be reached). The designed
trajectories of measurement are 1-DoF straight lines, that is,
one stage is moving, while another stage is kept static.
As depicted in Fig. 3, each of the micropositioning stage is
controlled to reach appointed target coordinate x
T
, y
T
. The
#


$%


 
!
 
"""
 
!



$  %
 
'

$%
Fig. 3. Block diagram of characterization of position-dependent errors.
0 1000 2000 3000 4000 5000 6000 7000 8000 9000
?3
?2
?1
0
1
2
3
4
5
Coordinates of x?axis (?m)
Errors in x direction (?m)
 
 
forward
backward
Fig. 4. Errors (x
T
 xm ) in x direction when X stage is moving forwards
and backwards in one cycle.
camera captures the images of the pattern in the real positions
x
r
;y
r
. The images are processed subsequently with the PPP
algorithm so as to obtain measured coordinates x
m
and y
m
.
In the 9500 and 4200 ?m strokes, measurements are taken
with 5 ?m as step size and a total of 11403 data in X direction
and 5043 data in Y direction are obtained in 3 cycles (every
cycle corresponds to one forward and one backward motion).
Time spent on data acquisition is 9.5 hours.
According to the speciﬁcation, the driving mechanism of
the stage is leadscrew. So the errors along the axis could be
foreseen somehow based on the mechanical property. The
errors between x
T
and x
m
measured in one cycle is shown
in Fig. 4. It can be seen that errors vary cyclically. Such
behavior is reasonably assumed due to systematic turn-to-
turn nature inherent in the leadscrew. The thread pitch of
the stage is 400 ?m, so the cyclical error repeats with the
same period. We can also see that the periods of the errors in
forward and backward motions of the X stage are the same,
but the magnitudes are slightly different. The driving system
does not work symmetrically and makes a systematic error
between forward and backward motions that corresponds to
the backlash of 2 ?m as speciﬁed by the manufacturer.
Position-dependent errors appear not only in the driving
direction but also in the lateral direction. Fig. 5 shows this
coupling errors in y direction when only X stage is moving
forwards and backwards. It can be seen that the coupling
errors have the same period as the errors in driving direction.
Based on the characterized errors of all discrete targets
along each single axis, we have enough information for all
coordinates in 2-dimensional space.
We also used these measurements to calculate the po-
sitioning repeatability following ISO standard 9283 [20].
The objective is to get a lower bound of the accuracy
2821
0 1000 2000 3000 4000 5000 6000 7000 8000 9000
?5
?4
?3
?2
?1
0
1
2
3
Coordinates of x?axis (?m)
Errors in y direction (?m)
 
 
forward
backward
Fig. 5. Coupling errors (0 ym ) in y direction when X stage is moving
forwards and backwards in one cycle.
we could obtain with compensated driving. The positioning
repeatability is deﬁned by,
RP =

l + 3S
n 1
(1)
with,

l =
1
n
n
X
j=1
l
j
(2)
and,
S
n 1
=
v
u
u
t
1
n  1
n
X
j=1
(l
j
 

l)
2
(3)
 x
m
and  y
m
are the coordinates of the barycentre deﬁned
by  x
m
=
1
n
P
n
j=1
x
m;j
and  y
m
=
1
n
P
n
j=1
y
m;j
. l
j
is
the distance of the jth measure to the barycentre l
j
=
p
(x
m;j
   x)
2
+ (y
m;j
   y)
2
.
Fig. 6 shows the obtained repeatability along x for all
measuring points of X axis. The curve for Y direction
is similar. The repeatability is  1 ?m for most of the
measuring points except for two peaks. This result is larger
than expected from Table I. This is because of different ex-
perimental conditions between our conﬁguration and that of
speciﬁcation evaluation by the constructor. The performance
tests of PI company are indeed performed with less points
and maybe with a more precise temperature control. For our
case the ambient temperature drift was about 0.5

C for 9.5
hours. The conclusion of this calculation is that the residual
errors even after the best compensation should theoretically
not be better than this measured repeatability.
V. COMPENSATION OF POSITION-DEPENDENT
ERRORS
A. Compensation Principle
As mentioned before, we have characterized the position-
dependent errors of discrete coordinates along each axis. The
error at a given point contains two parts, the ﬁrst part induced
by X motion and the second part by Y motion. We deﬁne
0 2000 4000 6000 8000 10000
0
0.5
1
1.5
2
2.5
Coordinates of x?axis (?m)
Repeatability (?m)
Fig. 6. Positioning repeatability in x direction (forward motion).
f
xi
(x
T
) and f
yi
(y
T
) that denotes the errors component in i
direction when moving forward along x or y axis to target
x
T
or y
T
, and b
xi
(x
T
) and b
yi
(y
T
) that denotes the errors
component ini direction when moving backward alongx or
y axis to targetx
T
ory
T
. Each of these functions are based
on a look-up table that records the previous measurements.
Hence, targets might not be in the look-up table, the
errors at these targets neither. In this case, interpolation
techniques are required to calculate the unknown errors
(interpolated errors) based on the knowledge of known errors
(characterized errors). We used a linear interpolation thanks
to theinterp1 Matlab
r
function. Cubic spline interpolation
does not give signiﬁcant better results.
The schematic diagram (Fig. 7) shows the compensation
mechanism using the lookup table. Depending on the motion
direction (forward or backward) and the target coordinates,
the error components have various combinations. Taking
X stage as an example, ﬁrst the kth target position x
Tk
and its previous target x
Tk 1
are compared to identify
the direction of the the motion (forward or backward);
secondly, the program selects the corresponding errors from
the lookup table of X stage based on the information of
motion direction; ﬁnally these error components are summed
up to form the total errors. The aggregated errorsex(x
T
;y
T
)
and ey(x
T
;y
T
) along x and along y are expressed by the
following equations:
ex(x
T
;y
T
) =
2
4
f
xx
(x
T
)
or
b
xx
(x
T
)
3
5
+
x
(y
T
)+
2
4
f
yx
(y
T
)
or
b
yx
(y
T
)
3
5
; (4)
ey(x
T
;y
T
) =
2
4
f
xy
(x
T
)
or
b
xy
(x
T
)
3
5
+
2
4
f
yy
(y
T
)
or
b
yy
(y
T
)
3
5
: (5)
Due to the fact that the Y stage is not perfectly perpen-
dicular to the X stage, the errors in x direction should be
added by a bias 
x
(y
T
) depending on the y coordinate.
The compensation principle relies on that the errors at
the target points should be eliminated by adding the same
amplitude of errors to the input. The input of the XY stages is
2822




 !"#
!$"#





%&

	
	

"
"
"
"
""
""





%&

	
	




'

'

'
"
"

'



'


'
' 


'

 

"!$"#
Fig. 7. Schematic diagram of the errors combination mechanism for
compensation.







!
 



 
Fig. 8. Block diagram of compensation for position-dependent errors using
lookup table.
then deﬁned by the target trajectory minus the corresponding
geometric errors in the lookup table instead of the target
trajectory alone. The block diagram of the compensation
process is shown in Fig. 8.
B. Trajectories Tracking
The ﬁrst test is tracking of a square trajectory with com-
pensation of position-dependent errors using lookup table.
The planning trajectory is chosen with a size of 4000
 4000 ?m square spanning from coordinates 10 ?m to
4010 ?m. The square is divided into 4 segments: AB, BC,
CD, and DA (Fig. 9). The tracking performances with and
without (ex =exy = 0) compensation are shown in Fig. 10
(a) and (b). The accuracy (calculated following ISO standard
9283 [20]) is deﬁned by:
AP =
p
( x
m
 x
T
)
2
+ ( y
m
 y
T
)
2
(6)
Accuracy is about 22 ?m without compensation which
is mainly due to the perpendicularity error (BC and DA
segments) and a little bit position-dependent error (AB and
CD segments). After compensation, accuracy improves to
approximately 4 ?m (84% error reduction).
C. Random Points Positioning
To examine the positioning accuracy of arbitrary points
in the whole joint workspace experimentally, XY stages
are commanded to reach random coordinates. The input
targetsP
Ti
are coordinates of ten points which are generated
randomly. Table II shows the coordinates of the ten targets
deﬁned for the test. The XY stages are controlled to reach
the targetP
T1
,:::,P
T10
in sequence. From Fig. 11, we can
'
) *
 +


Fig. 9. Square trajectory (4 segments).
0 500 1000 1500 2000 2500 3000
0
5
10
15
20
25
Number of poses
Accuracy (?m)
 
 
without comp.
with comp.
B C D A A
(a) Accuracy in all poses of tracking a square
0
1000
2000
3000
4000
5000
0
2000
4000
6000
0
5
10
15
20
25
 
Coordinates in x axis (?m)
Coordinates in y axis (?m)
 
Accuracy (?m)
with comp.
without comp.
A
B
C
D
(b) 3D display of accuracy
Fig. 10. Accuracy of tracking square with and without compensation.
see that the positioning accuracy is improved from about
22 ?m to 7 ?m (68% reduction) by using the interpolated
compensation.
VI. CONCLUSIONS
Micropositioning stages are common components of the
microrobotic systems for applications at the microscale.
To achieve micrometer accuracy, errors in micropositioning
stages required to be compensated. In this paper, we em-
ployed an novel measuring system consisting of a regular
vision system observing a pseudo-periodic encoded pattern
to measure the motion behavior of the XY micropositioning
stages. This method is particularly suitable for microscale
2823
TABLE II
TABLE OF RANDOM TARGET COORDINATES
Targets x
T
(m) y
T
(m)
P
T1
3471 2311
P
T2
6044 3991
P
T3
3673 39
P
T4
5118 2738
P
T5
3643 2071
P
T6
8196 186
P
T7
1702 756
P
T8
3776 3815
P
T9
3903 1390
P
T10
1035 35
1 2 3 4 5 6 7 8 9 10
0
5
10
15
20
25
Number of test points (P
1
 to P
10
)
Accuracy (?m)
 
 
without comp.
with comp. & linear interp
with comp. & cubic spline interp
P P P P P P P P P P
Fig. 11. Positioning accuracy of random points with and without compen-
sation
motion characterization thanks to its high range-to-resolution
ratio and avoidance of camera calibration.
We characterized the position-dependent errors along XY
axes and perpendicularity error between them. Based on
the quantiﬁed errors, compensation is conducted through
building lookup tables and using linear interpolation. The
experimental validations of the compensation show notice-
able accuracy improvements despite the limited number
of training points. The positioning accuracy is improved
from 22 ?m to 3.5 ?m (84% reduction of inaccuracy) for
square tracking and from 22 ?m to 7 ?m (68% reduction of
inaccuracy) for random points reaching.
Beyond these experimental results on a XY structure,
the proposed method can be applied to other kind of mi-
crorobotic systems even having more degrees of freedom.
The PPP algorithm can be extended to measure the angular
position and also the out-of-plane motion (z direction) using
depth-from-focus approach [17].
REFERENCES
[1] K. Rabenorosoa, C. Cl´ evy, and P. Lutz “Active force control for robotic
micro-assembly: application to guiding tasks,” in IEEE International
Conference on Robotics and Automation, Anchorage, AK, USA, 2010.
[2] L. S. Mattos and D. G. Caldwell, “A fast and precise micropipette
positioning system based on continuous camera-robot recalibration
and visual servoing,” in IEEE International Conference on Automation
Science and Engineering, Bangalore, India, 2009.
[3] E. J. Grifﬁth and S. Akella, “Coordinating multiple droplets in planar
array digital microﬂuidic systems,” International Journal of Robotics
Research, vol. 24, no. 11, pp. 933-949, 2005.
[4] W. Park, C. R. Midgett, D. R. Madden, and G. S. Chirikjian, “A
stochastic kinematic model of class averaging in single-particle elec-
tron microscopy,” International Journal of Robotics Research, vol. 30,
no. 6, pp. 730-754, 2011.
[5] N. Chaillet and S. R´ egnier, Microrobotics for Micromanipulation.
Wiley-ISTE, 2010.
[6] K. Rabenorosoa, C. Cl´ evy, Q. Chen, and P. Lutz, “Study of
forces during micro-assembly tasks using two-sensing-ﬁngers gripper,”
IEEE/ASME Transactions on Mechatronics, vol. 17, no. 5, pp. 811-
821, 2012.
[7] A. N. Das, R. Murthy, D. O. Popa, and H. E. Stephanou, “A multi-
scale assembly and packaging system for manufacturing of complex
micro-nano devices,” IEEE Transactions on Automation Science and
Engineering, vol. 9, no. 1, pp. 160-170, 2012.
[8] D. O. Popa, R. Murthy, and A. N. Das, “M3-deterministic, multiscale,
multirobot platform for microsystems packaging: design and quasi-
static precision evaluation,” IEEE Transactions on Automation Science
and Engineering, vol. 6, no. 2, pp. 345-361, 2009.
[9] C. Cl´ evy, M. Rakotondrabe, and N. Chaillet, Signal Measurement and
Estimation Techniques for Micro and Nanotechnology. Springer, 2011.
[10] N. Tan, C. Cl´ evy, G. J. Laurent, and N. Chaillet, “Calibration and
validation of XY micropositioners with vision,” in IEEE/ASME
International Conference on Advanced Intelligent Mechatronics, Kach-
siung, Taiwan, 2012.
[11] N. Tan, C. Cl´ evy, and N. Chaillet, “Calibration of single-axis nanopo-
sitioning cell subjected to thermal disturbance,” in IEEE International
Conference on Robotics and Automation, Karlsruhe, Germany, 2013.
[12] Q. Xu, Y . Li, and N. Xi, “Design, fabrication, and visual servo
control of an XY parallel micromanipulator with piezo-actuation,”
IEEE Transactions on Automation Science and Engineering, vol. 6,
no. 4, pp. 710-719, 2009.
[13] Y . K. Yong, S. S. Aphale, and S. O. Reza Moheimani, “Design, iden-
tiﬁcation, and control of a ﬂexure-based XY stage for fast nanoscale
positioning,” IEEE Transactions on Nanotechnology, vol. 8, no. 1, pp.
46-54, 2009.
[14] R. Moddemeijer, “On the determination of the position of extrema of
sampled correlators”, Signal Processing, IEEE Transactions on, vol.
39, no. 1, pp 216-219, 1991.
[15] P. Masa, E. Franzi, C. Urban, “Nanometric resolution absolute position
encoders”, CSEM Scientiﬁc and Technical Report, pp. 1-3, 2008.
[16] D.B. Boyton, “Position encoder using statistically biased pseudoran-
dom sequence”, US Patent App. 10/399, 470, april 18
th
, 2003.
[17] P. Sandoz, R. Zeggari, L. Froehly, J.L. Pr´ etet, C. Mougin, “Position
referencing in optical microscopy thanks to sample holders with out-
of-focus encoded patterns”, Journal of Microscopy, vol. 225, pp. 293-
303, 2007.
[18] J.A. Galeano-Zea, P. Sandoz, E. Gaiffe, J.L. Pr´ etet, C. Mougin, C.,
“Pseudo-Periodic Encryption of Extended 2-D Surfaces for High
Accurate Recovery of any Random Zone by Vision”, International
Journal of Optomechatronics, vol. 4, no. 1, pp. 65-82, 2010.
[19] J.A. Galeano-Zea, P. Sandoz, E. Gaiffe, S. Launay, L. Robert, M.
Jacquot, F. Hirchaud, J.L. Pr´ etet, C. Mougin, “Position-referenced mi-
croscopy for live cell culture monitoring”, Biomedical optics express,
vol. 2, no. 5, 1307-1318 ,2011.
[20] Manipulating Industrial Robots Performance Criteria and Related Test
Methods, ISO 9283, 1998.
[21] B. Tamadazte, S. Demb´ el´ e and N. Le Fort-Piat, “CAD model-based
tracking and 3D visual-based control for MEMS microassembly”,
International Journal of Robotics Research, 29(11):1416-1434, 2010.
2824
