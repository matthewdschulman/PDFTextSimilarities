Stochastic Modeling, Control, and Veriﬁcation of Wild Bodies
Daniel Erik Gierl, Leonardo Bobadilla, Oscar Sanchez, and Steven M. LaValle
?
Abstract— This paper presents strategies for controlling
the distribution of large numbers of minimalist robots (ones
containing no sensors or computers). The strategies are
implemented by varying area, speed, gate length, or gate
conﬁguration in environments composed of regions connected
by gates and modelled by Continuous Time Markov chains.
We demonstrate the e?ectiveness and practical feasibility of
our strategies through physical experiments and simulation.
We use Continuous Stochastic Logic to verify high level
properties of our system and to evaluate the accuracy of our
model. Also, we prove that our model is accurate and that
our algorithms are e?cient with respect to the number of
regions and number of bodies.
I. Introduction
Robotics applications such as agriculture, environ-
mental monitoring, surveillance, and search and rescue
would beneﬁt from the deployment of large numbers of
robotsthatsolvetaskssuchasnavigation,patrolling,and
coverage[9],[25].However,thereareseveralfundamental
challenges that are present and need to be addressed
before the full potential of such applications can be
realized.Theseincludemodellingissues,suchasthecurse
of dimensionality, where the state space and associated
costs grow unacceptably as a function of the number of
bodies. Other issues involve costs, energy consumption,
ease of deployment, and robustness. Scaling issues are
especially problematic in the area of micro- and nano-
robotics, where very large numbers of bodies with little
sensing or actuation capabilities are involved [27].
Most strategies for solving robotics tasks have fol-
lowed a trend towards becoming more complex. They
require precise sensors, robust and reliable actuators,
complicated world models, high-bandwidth communi-
cation, and powerful computers and algorithms. This
complication is unsurprising given the nature of tech-
nological progress and the di?culty of the tasks related
to multiple robot deployments. On the other hand, no
proof exists to support the necessity of this complexity.
Althoughthese information-richstrategieshaveachieved
remarkable success, their resource intensive nature may
make them hard to scale.
Our motivation is to tackle multiple robot deployment
problems through a minimalist approach, where instead
of asking ourselves: what is the most complicated goal
we can achieve?, we ask ourselves: what is the least
?
DanielErikGierl,OscarSanchez, andStevenM.LaValleareat
the Motion Strategy Lab (MSL), in the Department of Computer
ScienceattheUniversityofIllinoisatUrbana-Champaign,Urbana,
IL 61801, USA gierl1,sanche14,lavalle@uiuc.edu.
LeonardoBobadillaisattheSchool ofComputingandInformation
SciencesatFloridaInternationalUniversity,Miami,FL33199,USA
bobadilla@cs.fiu.edu
(a) (b)
(c) (d)
Fig. 1. A sequence of images illustrating a control policy using
static gates inalarge(6m? 4m)environment composed of regions
separated by low brick walls, and connected by small static ramps.
Forty-ﬁve Weasel balls were used in this experiment (see Fig. 3
for details). Here the mixing process is demonstrated as all of the
bodies start in one region and are brought under control to the
distribution (2/9,1/9,4/9,2/9) (or (10,5,20,10) when normalized
to the number of bodies), clockwise from top-left. In (a) all the
bodies save one are still in region 0. In (b) they have begun to
disperse through the environment. In (c) they have reached the
distribution(12,4,21,8).Andin(d)thedistributionis(12,5,19,9).
Experiments starting in di?erent regions yield similar results.
technology (sensors, actuation, computation) we need to
achieve a goal? From a theoretical standpoint, this be-
comes a very interesting question that has been explored
by several authors [1], [8], [10], [12], [28].
One strategy explored is to build and use stochastic
models, due to the non-deterministic aspects underlying
many mobile robotics problems [16], [30]. Another strat-
egy is to take advantage of randomized motion in bodies
to solve tasks [11]. In these, control is exercised on the
behavioural conﬁguration space of the robot [29]. Our
methods build on previous work done on manipulating
robots by means of passive control [2]–[4]; we expand
and formalize such control using stochastic models. We
propose and demonstrate four di?erent means of control
for minimalist bodies using Continuous-Time Markov
chains (CTMCs) [7].
II. Preliminaries
A. Regions and Gates
Let G = (V,E) be a connected directed graph repre-
senting the environment where V, the regions, is a set of
disjoint closed subsets with ﬁnite boundaries inR
2
, and
E, the gates,is asetofedgesconnectingV betweentheir
boundaries (see Fig. 1). Each e = (i,j)? E represents
the collection of gates going from region i to region j.
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 549
B. Wild Bodies
Within this environment move wild bodies [4] having
no sensors, computers, or communication abilities, each
representedby its locationinsomev?V, its directionof
motion, and its bounded speed
1
. The body is actuated
su?ciently to induce wild behavior in v. We use the
deﬁnition for wild set forth in [3], in which a wild body
is one that, when placed into a bounded region r ?
R
2
, moves along a trajectory that strikes every open
intervalalongtheboundaryofrinﬁnitelyoftenininﬁnite
time.Thispropertyisrelatedtothenotionof topological
transitivity in dynamic billiards [14], [15], [17], [33].
As a result of this wild motion, the bodies move
randomly within the interiors of the regions of the
environment, making it di?cult to model the state of
the body inside of a region. Instead, we model the
state space as a n-dimensional vector ?, the distribution
of bodies across the regions of the environment. Our
notation is ? = (?
0
,?
1
,...,?
n
) for n =|V|, where ?
i
is
the proportion of bodies in region i; thus
X
i
?
i
=1.
C. Continuous Time Markov Chains
Transitions in this state space occur when a body
moves across an e?E. Such a transition along e= (i,j)
occurs at a rate R
ij
, corresponding to the parameter of
an exponential distribution from which the time spent
in the region before such a transition is made is drawn.
Given these transition rates, we model the system using
a Continuous-Time Markov chain (CTMC) C = (V,Q),
where Q:
Q
ij
=

R
ij
(i,j)?E
0 o/w
is the n?n instantaneous transition matrix. This can be
augmented to Q
?
by setting the diagonals to be minus
the sum of rates for their row, Q
?
ii
=?
X
j6=i
Q
ij
. From
this augmented form, the probability that a body is in
state j after time t after having started in state i is
P
ij
(t) where P(t)=e
tQ
?
. The limiting distribution is ?
?
satisfying ?Q
?
= 0, where
X
i
?
i
=1.
Ourresultscanbeextendedfromonebodytomultiple
bodies in a straight-forward way by assuming that the
bodies cover a small proportion of any region’s area and
that collisions between them do not disrupt signiﬁcantly
their rate w.r.t. the other bodies.
D. Problem Formulation
Nowthatwehaveformulatedourmodel,wecanbrieﬂy
state the problem: given a desired limiting distribution
? of bodies in an environment G, construct a control
policy ? expected to achieve ? using as few additional
resources as possible.
1
For our work here, each body is represented by apoint particle,
though in practice it need only be small with respect to the area
of the regions and the widths of the gates.
Therestofthepaperisorganizedasfollows.InSection
III, we show how Q can be found for an environment for
any goal distribution ?. In Section IV, we show how a Q
and some additional information about the environment
canbe usedtoconstructacontrolpolicy? toachievethe
limiting distribution of Q. Lastly, in Section V we use
Continuous Stochastic Logic (CSL) and a model checker
to construct probabilistic and temporal bounds for our
strategies based on Q.
III. Finding a Transition Matrix from an
Environment’s Connectivity and a Goal Distribution
Algorithm 1 takes a connected, undirected, anti-
reﬂexive graph G and a positive goal distribution ?,
and constructs an instantaneous transition matrix Q for
a CTMC whose limiting distribution is ?. The speed
of any particular chain’s convergence to the limiting
distribution is given by its transition matrix’s Second
LargestEigenvalueModulus (SLEM), in which the lower
the second largest eigenvalue is, the faster it converges
[5].
Algorithm 1 FindTransitionMatrix(G,?)
Input: G =(V,E){Graph of the environment}
Input: ?{Desired limiting distribution}
Output: Q{An instantaneous transition matrix}
1: Q
ij
?

?
j
(i,j)?E
0 o/w
Alternative algorithms for ﬁnding such Q exist, for
example using semi-deﬁnite programming [5], [6]. These
methods obtain the optimal solution, the Fastest Mixing
Markov Chain (FMMC), but we have chosen Algorithm
1 for simplicity.
Proposition1:AllQ suchthat
Qij
Qji
=
?j
?i
,i6=j,Q
ji
6=0
have limiting distribution ?.
Proof:
First, we augment Q to Q
?
by adding negative diago-
nals (see Sec. II). The limiting distribution ?
?
is deﬁned
as ?
?
Q
?
= 0,
X
i
?
?
i
= 1. By deﬁnition of the algorithm
above we have
?i?j,
Q
?
ij
Q
?
ji
=
?
j
?
i
?j?i,?
i
Q
?
ij
= ?
j
Q
?
ji
?j,
X
i6=j
?
i
Q
?
ij
=
X
k6=j
?
j
Q
?
jk
,
by breaking up the deﬁnition of the diagonal we get
?j,
X
i6=j
?
i
Q
?
ij
= ??
j
Q
?
jj
.
By moving over the negative diagonal that was added
during augmentation we get
?j,
X
i
?
i
Q
?
ij
= 0
?Q
?
= 0,
550
Fig. 2. An example labelled environment with ﬁve regions and
two gates between every connected pair of regions.
therefore, ? =?
?
.
For an example of the algorithm in practice, consider
the environment in Fig. 2. If we want the distribution
? = (0.1,0.2,0.3,0.3,0.1), we create the following Q:
Q=
?
?
?
?
?
?
0 0.2 0 0.3 0.1
0.1 0 0.3 0 0
0 0.2 0 0.3 0
0.1 0 0.3 0 0
0.1 0 0 0 0
?
?
?
?
?
?
This follows the intuition that the rates of transition
between two regions should be inversely proportional to
their desired distributions.
2
IV. Developing a Control Policy from a Transition
Matrix and other Environment Information
A. Modeling
To construct a control policy ? to gently inﬂuence the
motion of a body, ﬁrst we must construct a model for
how the body b moves through an environment G. This
motion is captured by the rate of transition R
ij
of b
between connected regions i and j. Due to the body’s
wild motion, at a point in time t, the body’s location in
region i is uniformly distributed as is its direction.
3
Let
Q
i
j
=
Qij
Qji
, m
i
j
=
Pr[m(eij)=open]
Pr[m(eji)=open]
, w
i
j
=
w(i)
w(j)
, a
i
j
=
a(i)
a(j)
,
and l
i
j
=
l(eij)
l(eji)
, in which l : E?R
+
is the length of a
gate along a region boundary, a : V ? R
+
is the area
of a region, w : V ? R
+
is the speed of a body in a
region, and m : E?{open,closed} is the conﬁguration
of the gate e = (i,j), in which open indicates that the
gate allows bodies from region i to j and closed not.
2
Notethatbecausetheratiosofvaluesareimportantandnotthe
values themselves, transpose-pairs of Q can be scaled by arbitrary
factors.ThealgorithmpresentedinSectionIVonlyusestherelative
ratios, so such scaling has no e?ect on the end control strategy.
3
Because the body’s motion inside a region is deterministic over
small intervals of time (up to bouncing o? region boundaries and
other bodies), for t
?
near t, this is not the case. As time progresses,
the body’s location and direction undergo topological mixing and
thus if they are sampled at su?ciently large intervals they appear
to be drawn from uniform random variables.
Proposition 2: The ratio of the rates is
R
ij
R
ji
=m
i
j
w
i
j
a
j
i
l
i
j
Proof:
We startwith the deﬁnition ofthe rate,andobservethat
all transitions must occur through gates, when they are
open.
R
ij
=Rate[b transitions from i to j]
=Rate[b transitions through e
ij
]
=Pr[m(e) =open]Rate[b hits e
ij
]
where Rate[] is the rate of an event per unit time, as the
unit time approaches zero. Since gates occupy portions
of region boundaries, we get
Rate[b hits e
ij
] =Rate[b hits boundary]
l(eij)
bnd(i)
.
The rate at which bodies hit the boundary is propor-
tional to their speed and the boundary length, and
inversely proportional to the region size, thus yielding
Rate[b hits boundary] =C
w(i)bnd(i)
a(i)
wherebnd:V ?R
+
isthelengthofaregion’sboundary,
and C?R is a constant factor. Thus we get
R
ij
=CPr[m(e
ij
)=open]
w(i)l(e
ij
)
a(i)
and ﬁnally as a ratio
R
ij
R
ji
=
Pr[m(e
ij
)=open]
Pr[m(e
ji
)=open]
w(i)
w(j)
a(j)
a(i)
l(e
ij
)
l(e
ji
)
R
ij
R
ji
= m
i
j
w
i
j
a
j
i
l
i
j
Given that the limiting distribution will be the goal
distributionsolongastheratio
Rij
Rji
=
Qij
Qji
ispreservedby
theimplementationof? ontoG(seeProofinSectionIII),
the control strategy can be implemented by adjusting
Pr(m(eij)=open)
Pr(m(eji)=open)
,
w(i)
w(j)
,
a(j)
a(i)
, or
l(eij)
l(eji)
. Combinations of
these factors can also be used (see Fig. 7), but for
simplicity we do not consider them here.
B. Control Policy
Construction of a control policy assumes a Q, and
knowledge of three of the following: area (a), gate
conﬁguration switching (m), speed (w), and gate length
(l). For area and speed control to be e?ective alone,
detailed balance must hold, for example, as when all
gates are symmetric with respect to their lengths and
conﬁgurations.
551
1) Area: Theﬁrstwaytocontrolthedistributionisby
modifying each region’s area, such that for region i, the
area is ?
area
(i) := ?
area
(j)Q
i
j
l
i
j
w
i
j
m
i
j
, for some adjacent
region j, the ﬁrst such region being given any constant
value. The order of this control policy evaluation is any
breadth-ﬁrst search of the environment. If all gates are
identical, this simpliﬁes to ?
area
(i):=?
i
w(i).
2) Length: The next means of control is by manipu-
lating the lengths of gates across the region boundaries,
in which the length of the sum of gates e = (i,j) is
?
length
(i,j) :=Q
i
j
m
j
i
a
j
i
w
j
i
.
3) Speed: Thethirdmeansofcontrolisoverthe speed
of the bodies in each region, in which for region i,
the speed is ?
speed
(i) := ?
speed
(j)Q
j
i
l
i
j
w
i
j
m
i
j
, for some
adjacent region j, the ﬁrst such region being given
any constant value. The order of this control policy
evaluationisanybreadth-ﬁrstsearchoftheenvironment.
If all gates are identical, this simpliﬁes to ?
speed
(i) :=
w(i)/?
i
.
Speed control can be implemented in mobile robots
by varying the motor power. In micro- or nano-robots
that move across voltage di?erentials, speed control can
be implemented by varying voltage.
4) Conﬁguration Switching: The last of the means of
control is over the probability that a gate from region
i to region j is conﬁgured to be open, ?
time
(i,j) :=
?
?
(i,j)
?
?
(i,j)+?
?
(j,i)
proportion of the time, in which ?
?
(i,j):=
Q
i
j
a
j
i
w
j
i
l
j
i
Gate conﬁguration control can be implemented by
opening and closing gates (e.g. a door).
These strategies can all be scaled by a constant and
remain correct, although the constant will e?ect the
speed at which the distribution of bodies approaches the
goal. Calculating time and length control are O(n
2
) in
time,inwhichnisthenumberofregions,andcalculating
area and speed control can be done in O(n) time.
C. Experimental Testing
Experimentsareusedtodemonstratethestrategy’sef-
fectiveness, using both a physical implementationas well
as in a simulator. The physical implementation consists
of Weasel Balls, a cheap ($4) toy for children and pets,
inside an environmentwhose regions are constructed out
of low brick walls and whose gates are either single-
conﬁgurationstatic gates whose conﬁgurationis open, or
controllable two-way gates whose conﬁguration is either
open or closed. See Fig. 3. These mechanisms are similar
to the ones presented in [2]. The simulation consisted
of polygonal regions in R
2
and bodies that implement
a simple approximation of Weasel Balls’ motion; they
travel along straight trajectories and bounce at random
angles o? of region boundaries [13]. See Fig. 7.
(a) (b)
(c) (d)
Fig. 3. (a) A static, one-way gate; (b) A dynamic, two-way gate;
(c) The inside of a Weasel Ball, which is 10cm in diameter; (d) A
physical environment with bodies. The walls of the environment
are composed of 9?9?28cm bricks.
(a) at 0s (b) at 36s
(c) at 102s (d) at 204s
Fig. 4. Control by means of area in a physical implementation.
One region is twice as large as the other, and are connected by two
equally large gates. Initially in (a) all bodies begin in the smaller
region. By (b) they are distributed half-and-half, by (c) they have
reached the goal distribution and it is maintained in (d).
(a) at 4s (b) at 48s
(c) at 224s (d) at 404s
Fig. 5. Control by means of gate length in a physical implemen-
tation. Two gates of the same length are pointing in one direction,
and asinglegate of the same sizeispointing in the other direction.
Initially in (a) all bodies begin in the left region. Again, by (b)
they are distributed half-and-half, by (c) it has reached the goal
distribution and it is maintained in (d).
552
(a) at 0s (b) at 18s
(c) at 30s (d) at 133s
Fig. 6. Control by means of the probability that a gate is in an
accepting conﬁguration through time, in a physical implementa-
tion. The gate alternates direction randomly such that the ratio of
probabilities is the desired ratio.
(a) at 4s (b) at 14s
(c) at 33s (d) at 49s
Fig.7. Controlbymeansofthespeedof100bodies,insimulation.
The control strategy here has to control for varying region sizes in
addition to the goal distribution.Across (a), (b), (c), and (d) there
isadecreasingerror(L-2distancebetween currentdistributionand
goal distribution) of 1.24, 0.60, 0.32, and 0.24 respectively.
In Figs. 4, 5, and 6, we demonstrate achieving a
distribution of ? = (1/3,2/3) across two regions by
means of controlling region area, gate length, and the
probability that a gate is accepting, respectively. In Fig.
7, we control the distribution across ﬁve regions using
a combination of area and speed control. Four physical
experiments were also run in a larger environment with
45 bodies; one of which is shown in Fig. 1. Additional
experiments were performed on a wide variety of envi-
ronments, starting distributions, and goal distributions
(see Fig. 8). Videos of these experiments and more can
be found at: http://users.cis.ﬁu.edu/?jabobadi/sc/.
D. Transition Sequence for Goal Distributions with Ze-
ros
In Section III, we speciﬁed that ? must be posi-
tive. Consider the case of the goal distribution ?
?
=
(0,.3,.2,.1,.4)for the environmentin Fig. 2. Our control
(a)
(b)
(c)
Fig.8. Graphs ofthe L-2distance between theactual distribution
and the goal distribution as a function of time. Di?erent colors
representdi?erentexperiments.(a)Convergencestartingfromeach
region (one of which is in Fig. 1) of a physical experiment; (b)
Convergence in simulation to a distribution proportional to their
area; (c) Convergence in simulation to a distribution inversely
proportional to their area
policy construction would divide by 0, and is thus
undeﬁned. In some cases (e.g. for the distribution ? =
(0.25,0.25,0.25,0.25,0))wecangetaroundthatproblem
by approximating ?c ? R
+
,c/0 := ∞, which would
correspond to a scenario in which bodies only move
out of regions with limiting distribution 0 and not
ever into them. However this does not work in the
case of our original ?
?
, since it would result in G’s
transition matrix ceasing to be an ergodic chain. The
limiting distribution of a non-ergodic Markov Chain is
a function of the initial distribution. Consider how an
initial distribution ?
0
= (0,0,0,0,1) would result in
the limiting distribution ?
?
= ?
0
, whereas any initial
distribution ?
0
= (0,a
1
,a
2
,a
3
,.4),
P
i
a
i
= .6 would
result in the limiting distribution ?
?
=?
?
, our goal.
Though Q cannot be constructed for impossible goal
distributions ?
?
, Qs can be constructed for an inﬁnite
sequence of possible, non-negative goal distributions
?
0
,?
1
,?
2
,..., lim
i?∞
?
i
= ?
?
. This subsequent sequence of
transitionmatricesQ
0
,Q
1
,Q
2
,...convergestoQandcan
be used to implement the otherwise unreachable control
policy.
The following practical heuristic is provided for the
initial element of the sequence ?
0
: the best ?
0
is the ini-
tialdistributionofthebodiesifknown,sinceconvergence
to ?
0
would then be instantaneous, or the distribution
corresponding to a random walk on G, because it has a
553
low SLEM and is easy to implement.
One of many possible ways to construct the full
sequence would be to linearly interpolate between the
initial distribution ?
0
and the impossible distribution
?
?
, where ?
n
=?
0
+(1?
1
n+1
)(?
?
??
0
) for n?N.
V. Finding Probabilistic Bounds on the Control
Strategy using Model Checking
In this section, we use a temporal logic and a model
checker to present techniques for verifying the limiting
distribution, calculating the average expected error, and
comparing the mixing rates of systems under the control
of the policy we presented. Additionally, we present
an analytical technique for quantifying the di?erence
between a body under wild motion and an ergodic body.
We are motivated by ongoing work uses temporal logic
in high-level control for motion planning problems [18]–
[21], [23], [24], [31]. In our work, we found continuous
stochastic logic (CSL) to be suitable for our needs.
The small subset of the syntax for CSL that we used
is
? =a| S
?p
[?]
(1)
in which a is a proposition, ?? {<,≤,>,≥}, and
p? [0,1] is a probability. In this syntax, ? are state
formulas, which are assertions about the model state.
The syntax S
?p
[?] asserts that the limiting probability
of ? satisﬁes? p. A complete and detailed deﬁnition,
syntax, semantics, and examples for CSL can be found
in [26]. The reader is encouragedto consult [26] for more
information.
We used the probabilistic temporal
model checker PRISM, described at
http://www.prismmodelchecker.org/ [22]. This program
takes a problem formulation and a list of propositions
to be checked, all formulated in an application speciﬁc
grammar, and evaluates the propositions e?ciently. Our
model’s state is the space of all distributions; it consists
of a variable for each region whose value indicates
the proportion of bodies in that region. Our model’s
transition scheme consists of a rate between two states
i and j proportional to R
ij
and the number of bodies
in i.
A. Steady State Veriﬁcation
We can use PRISM to verify properties about our
system, such as the limiting distribution. The limiting
distribution for region i in a single body model can
be found by evaluating the formula S[?
i
= 1].
4
This
is the proposition that, in the steady state, the body
can be found in that region. The results from PRISM
corroborate the proof provided in section IV. These
calculations are fast too, verifying for the environment
4
There are not probabilistic bounds on this or other formulas
here because S[?
i
= 1] = ?
?
i
s.t. S
≤?
?
i
[?
i
= 1] and S
≥?
?
i
[?
i
= 1].
Using PRISM, this can be calculated without a search.
Fig.9. TheL-2distancebetweentheexpectedlimitingdistribution
and the goal distribution as a function of the number of bodies in
the environment, for the environment in Fig. 1. Derived using the
CSL model checker PRISM.
in Fig. 1 in 0.005s on an Ubuntu 12.04 LTS install on a
Intel Core 2 Duo CPU with 4GB memory.
B. Average Error
The proofs and veriﬁcation provided thus far show
thattheexpecteddistributionunderthiscontrolstrategy
is the goal distribution. At any given time, the actual
distribution is probably not the goal one (and for some
goals, cannot be). We call this di?erence the error, and
is measured as the L-2 norm distance between ? and ?
?
:
h?,?
?
i
2
. The average error can be calculated as
X
?
Pr(?)h?,?
?
i
2
This computation can be expensive and complicated,
especiallythe enumerationofallpossiblestatesandtheir
probabilities. Fortunately PRISM can again be used to
simplify this process. PRISM allows costs to be assigned
to states that meet any proposition, and the cost is
accumulated over the time the system spends in the
state. Assigning a cost of the L-2 norm distance allows
the expected distance to be measured. Experimental
analysisshowsthattheerrortends tozeroasthenumber
of bodies increases.
5
Consider the environment shown in Fig. 1, whose
empirically observed error appears in Fig. 8 (a), and
whose expected error in the limiting distribution is
shown in Fig. 9. The model checker shows that for that
environment and the number of bodies used (45), the
average error of the limiting distribution is 11.35%. The
observedaverageerroris 25%;thus wecanconclude that
the discrepancies between our model and the physical
system accounts for 56% of the observed error. This
technique is generalized and can be applied to analyze
how closely any body’s motion approximates ergodicity,
and the description of a wild body set out in Section II.
C. Mixing Rates
InSectionIII, the SecondLargestEigenvalueModulus
(SLEM) is introduced as an analytical method for
5
Expected average error is invariant to the connectivity of the
environment, but does vary based on the goal distribution, the
number of agents, and the number of regions.
554
(a)
(b)
Fig. 10. Histograms of the time a body spent in two regions in
simulator. Region (a) is 50% larger than region (b). These clearly
demonstrate that the time spent in a region can be approximately
modeled as an exponential distribution whose parameter is pro-
portional to the region’s area. Such a distribution exists for each
gate (i,j)? E for the timespent in i before transitioningto j.The
parameter of this distribution is the rate R
ij
.
comparing the mixing rate of two transition matrices.
Using PRISM’srewards-basedpropertiesandthe reward
in Sec. V-B, the same can be done with PRISM. The
cumulative errorofa systemcanbe calculated,as canbe
theinstantaneouserrorwithPRISM.Sincetheserewards
are monotone decreasing, we can compare the mixing
rate of di?erent graph structures (in which the goal
distribution is keptconstant), and the mixing rateof dif-
ferent starting distributions (in which the topologies are
kept constant), by calculating either of these measures
for a given constant time. This comparison can then be
used to conduct a searchof the regionconnectivity space
or initial distribution space to ﬁnd the fastest-mixing
systems. This method is more powerful than using the
SLEM because it is sensitive to initial distributions.
VI. Discussion and Conclusions
In this work we present a methodology to control a
distribution of bodies by controlling the variables for
the 1) area of the regions, 2) length of the gates between
regions, 3) speed of the bodies in the regions, and 4) the
probability that a gate between two regions is open.
The results from the physical and simulated exper-
iments show that these control strategies are correct
and e?cient with respect to the number of regions and
numberbodiesbeingsubjecttocontrol.All ofthefactors
subject to control: the area of regions, the speed of
bodies within the regions, the sizes of the gates, and the
likelihood that a body can transition through a gate,
are shown to be relevant factors, and can be ignored
only where they are constant across the environment.
Other factors may exist that could inﬂuence the e?ect of
the control strategy; howeverany suchfactors must have
beenunintentionallyheldconstantacrossallexperiments
we conducted. Additionally, our core assumption that
the motion of wild bodies in such an environment can
be modeled by a CTMC is supported by experimental
evidence (see Fig. 10). This strategy is general enough
thatit canbe appliedto anyenvironmentthat meets the
assumptionslaidoutinSec.II,andanygoaldistribution.
Furthermore, the model checking techniques in Sec. V
can be used to analyze any strategy.
A. Signiﬁcance
The signiﬁcance of these results and this control
strategy can be limited by the assumptions made. The
assumption about the wildness of the robotic motion
turns out to be rather robust; in Fig. 10 we see that our
simulated bodies transition according to an exponential
distribution. We conducted additional experiments, in
which we manipulated the quality of the body’s motion
in simulation by adding varying degrees of systematic
wobble, skewed direction of travel, and acceleration
after inelastic collisions. In all cases the exponential
distribution was preserved, albeit with a scaled param-
eter. Additionally, in section V-B a metric is presented
for quantifying exactly how closely any robotic agent
approximates the wild motion our model assumes.
On the other hand, the a priori knowledge require-
ments about the environment, as well as the necessary
control over the environment to implement some of the
strategies, can limit certain applications. The power
in our approach is that it can be applied to a wide
variety of problems; the strategy is ignorant to the
numberofbodiesbeingcontrolled,ignoranttotheirstate
(region,location,speed,etc),andworksinanyconnected
controllable environment.
In practice, indoor environments lend themselves to
being easily broken up into regions and gates by rooms
and doors respectively. Whereas establishing control by
means of area or length modulation may be di?cult
or impossible in such environments, time control is
achievable merely by opening and closing one-way gates,
andspeedcontrolcanbeachievedbyvaryingthespeedof
a robot’s motors in each region [3]. For nanorobots that
swim according by control of voltage di?erentials, speed
can be adjusted with the voltage. Furthermore, time-
and speed-based control strategies also lend themselves
to being easily scaled down or up so that the fastest
speed or shortest duration are manageable.
Some potential applications would include many con-
tinuous maintenance operations, such as cleaning ﬂoors,
mowing lawns, picking up litter, gardening, inspecting
plants, and more. In these applications, the goal dis-
tributions may be proportional to their use, thereby
guaranteeing that services are provided proportionally
to their need. Areas under the heaviest use see the
most maintenance, but no areas are neglected. Where
environmental control is expensive, control could be im-
plemented within the robots themselves, distinguishing
between regions using simple sensors to tell where gates
555
appear (for example, changing ﬂoor coloration between
rooms).
B. Future Work
Most foreseeable future work, in keeping with the
goals of minimalism set out in Sec. I, would involve
reducing the severity of the assumptions the strategy
requires. For example, some of the information assumed
by our strategy, such as the area of regions and the
topology of the environment, could be approximated if
gates were capable of communicating with each other
as well as distinguishing between the bodies in the
environment. The topology can be learned by observing
which gates are reachable from each other (if a body
visits two gates in sequence, they must share a region).
Thebaseratesbetweenregions,takingintoaccounttheir
area, the speed within them, and the size of the gates
connecting them, can be calculated by approximating
how long an agent spends in a region i on averagebefore
transitioning through any given gate to region j. This
value corresponds to a(i)w(i)l(e
ij
) when m
i
j
= 1.
There may be more accurate models at the expense of
being more complicated [32]. However we believe that
CTMCs capture the phenomenon to a large enough
extent to make them useful models. Some future work
may involve exploring other modeling options.
Another areaof developmentfor future workwould be
to design robots whose motion best ﬁts the deﬁnition of
wild put forth in Sec. II. This measurable (see Sec. V-B)
development would improve mixing rates and decrease
average error, and its relation to ergodicity would make
it an interesting problem in its own right.
VII. Acknowledgements
This work was supported in part by NSF grant
0904501 (IIS Robotics), NSF grant 1035345 (CNS Cy-
berphysical Systems), DARPA SToMP grant HR0011-
05-1-0008, and MURI/ONR grant N00014-09-1-1052.
References
[1] M. Blum and D. Kozen. On the power of the compass (or,
why mazes are easier to search than graphs). In Proceedings
Annual Symposium on Foundations of Computer Science,
pages 132–142, 1978.
[2] L. Bobadilla, K. Gossman, and S. M. LaValle. Manipulating
ergodic bodies through gentle guidance. In Proceedings IEEE
Conference on Robot Motion and Control, 2011.
[3] L. Bobadilla, F. Martinez, E. Gobst, K. Gossman, and S. M.
LaValle. Controlling wild mobile robots using virtual gates
and discrete transitions. In American Control Conference,
2012.
[4] L. Bobadilla, O. Sanchez, J. Czarnowski, K. Gossman, and
S. M. LaValle. Controlling wild bodies using linear temporal
logic. In Proceedings Robotics: Science and Systems, 2011.
[5] S. Boyd, P. Diaconis, and L. Xiao. Fastest mixing markov
chain on a graph. SIAM Review, 46(4):667–689, 2004.
[6] Stephen Boyd. Convex optimization of graph laplacian
eigenvalues. In Proceedings oh the International Congress of
Mathematicians:Madrid,August22-30,2006:invitedlectures,
pages 1311–1320, 2006.
[7] Pierre Bremaud. Markov Chains: Gibbs Fields, Monte Carlo
Simulations, and Queues. Springer, 1991.
[8] J. F Canny and K. Y Goldberg. A RISC approach to sensing
andmanipulation. JournalofRoboticSystems,12(6):351–364,
1995.
[9] H. Choset, K. M. Lynch, S. Hutchinson, G. Kantor, W. Bur-
gard, L. E. Kavraki, and S. Thrun. Principles of Robot
Motion: Theory, Algorithms, and Implementations. MIT
Press, Cambridge, MA, 2005.
[10] B. Donald, J. Jennings, and D. Rus. Minimalism + dis-
tribution = supermodularity. Journal of Experimental &
Theoretical Artiﬁcial Intelligence, 9(2-3):293–321, 1997.
[11] M. A. Erdmann. Randomization in robot tasks. International
Journal of Robotics Research, 11(5):399–436, October 1992.
[12] M.A.ErdmannandM.T.Mason.Anexplorationofsensorless
manipulation. IEEETransactionsonRobotics&Automation,
4(4):369–379, August 1988.
[13] K. Gossman. Design of environments to control robotic
behavior, 2012.
[14] E.Gutkin. Billiardsinpolygons. PhysicaD,19:311–333,1986.
[15] E. Gutkin. Billiards in polygons: A survey of recent results.
Journal of Statistical Physics, 83(1/2):675–737, 1996.
[16] Maryam Kamgarpour, Sean Summers, and John Lygeros.
Control design forspeciﬁcations on stochastic hybrid systems.
In Proceedings of the 16th international conference on Hybrid
systems: computation and control, HSCC ’13, pages 303–312,
New York, NY, USA, 2013. ACM.
[17] S. Kerckho?, H. Masur, and J. Smillie. Ergodicity of billiard
ﬂows and quadratic di?erentials. Annals of Mathematics,
124(2):293–311, 1986.
[18] M. Kloetzer and C. Belta. Automatic deployment of dis-
tributed teams of robots from temporal logic motion speci-
ﬁcations. IEEE Transactions on Robotics and Automation,
26(1):48–61, 2010.
[19] H. Kress-Gazit, G. E. Fainekos, and G. J. Pappas. Temporal-
logic-based reactive mission and motion planning. IEEE
Transactions on Robotics and Automation, 25(6):1370–1381,
December 2009.
[20] H. Kress-Gazit, G.E. Fainekos, and G.J. Pappas. Temporal
logicmotion planningformobilerobots. In Proceedings IEEE
International Conference on Robotics and Automation, 2005.
[21] H. Kress-Gazit, G.E. Fainekos, and G.J. Pappas. Where’s
Waldo? sensor-based temporal logic motion planning. In
Proceedings IEEE International Conference on Robotics and
Automation, 2007.
[22] M. Kwiatkowska, G. Norman, and D. Parker. PRISM 4.0:
Veriﬁcationofprobabilisticreal-timesystems.InG.Gopalakr-
ishnan and S. Qadeer, editors, Proc. 23rd International Con-
ference on Computer Aided Veriﬁcation (CAV’11), volume
6806 of LNCS, pages 585–591. Springer, 2011.
[23] M. Lahijanian, J. Wasniewski, S. B. Andersson, and C. Belta.
Motion planning and control from temporal logic speciﬁca-
tions with probabilistic satisfaction guarantees. In Proceed-
ings IEEE International Conference on Robotics & Automa-
tion, pages 3227–3232, 2010.
[24] Morteza Lahijanian, Sean B Andersson, and Calin Belta.
Temporallogicmotionplanningandcontrolwithprobabilistic
satisfaction guarantees. Robotics, IEEE Transactions on,
28(2):396–409, 2012.
[25] S. M. LaValle. Planning Algorithms. Cambridge Uni-
versity Press, Cambridge, U.K., 2006. Also available at
http://planning.cs.uiuc.edu/.
[26] G. Norman M. Kwiatkowska and D. Parker. Stochastic
model checking. Lecture Notes in Computer Science (Tutorial
Volume), 4486:220–270, 2007.
[27] B.J. Nelson, L. Dong, and F. Arai. Micro/nanorobots. In
B. Siciliano and O. Khatib, editors, Springer Handbook of
Robotics. Springer-Verlag, 2008.
[28] J. M. O’Kane and S. M. LaValle. On comparing the power of
robots. International Journal of Robotics Research, 27(1):5–
23, 2008.
[29] D.A.Shell,C.V.Jones,andM.J.Mataric. Ergodicdynamics
by design: A route to predictable multirobot systems. In
Multi-Robot Systems: From Swarms to Intelligent Automata,
pages 291–297, 2005.
[30] S. Thrun, W. Burgard, and D. Fox. Probabilistic Robotics.
MIT Press, Cambridge, MA, 2005.
[31] Eric M Wol?, Ufuk Topcu, and Richard M Murray. Robust
control of uncertain markov decision processes with temporal
logic speciﬁcations. In Decision and Control (CDC), 2012
IEEE 51st Annual Conference on, pages 3372–3379. IEEE,
2012.
[32] A. I. Zeifman. Quasi-ergodicity for non-homogeneous
continuous-time markov chains. Journal of Applied Proba-
bility, 26(3):pp. 643–648, 1989.
[33] A.N. Zemlyakov and A.B. Katok. Topological transitivity of
billiards in polygons. Mathematical notes of the Academy of
Sciences of the USSR, 18(2):760–764, 1975.
556
