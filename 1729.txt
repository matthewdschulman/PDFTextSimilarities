Active Calibration and Its Applications on Micro-operating Platform
with Multiple Manipulators
Dengpeng Xing, De Xu, Haipeng Li, and Liyan Luo
Abstract— The microscope has characteristics of a planar
vision with small view ﬁeld and small view depth. For micro
operation systems with multiple manipulators, the handling of
irregular objects may lead to a nonorthogonal microscopic
system, which needs to focus on clear viewing interested
features, and it may also hardly locate the exact position and
posture of the robot arms. In view of these, this paper proposes
an active calibration method to compute image Jacobian matrix,
which maps from the relative motion of the manipulators
to the image coordination changes in the microscopes. We
also investigate the applications in micro operator positioning,
tracking for distributed systems, and movement optimization
in micro-assembly. Experiments are carried out on a micro-
assembly platform equipped with three microscopes and six
robot arms, and the results validate the effectiveness of the
proposed method.
I. INTRODUCTION
In recent years, micro-operation and micro-assembly have
been widely investigated [1], [2], which can greatly increase
the manufacturing quality and facilitate assembly with high
precision. Wason [3] used multiple coordinated probes for
micro-assembly with automated vision-guided. He developed
the capabilities required for construction of 3D structure us-
ing only planar micro fabricated parts. Rabenorosoa [4] used
a two-sensing-ﬁngers gripper to grasp planar microparts and
analyzed the lateral contact force which was estimated less
than 3mN. In Ref. [5], a hybrid micro-assembly technique
was reported to combine a robotic micro-manipulator and a
water droplet self-alignment.
Microscopic vision is the most important sensing for
micro-operation and attracts concerns in the community of
micro-operation. Chen [6] analyzed the characteristics of
macro and micro computer visions and proposed a fast
auto-focus algorithm based on depth from defocus. Our
previous work [7] analyzed the characteristics of monocular
microscope and the sensitive DoFs of the microscopic vision
system. A class of miniature vision sensors was proposed and
analyzed that enabled a wide ﬁeld-of-view within a small
form through a refractive optical design [8].
For microscopic vision, calibration is very important to
acquire the basic knowledge of how to control the ma-
nipulator precisely. For monocular and stereo microscopes,
different methods were applied in calibration. Pattern-based
[9] and motion-based [10] approaches are usually used for
monocular microscope. Cheah [11] presented a simple vision
based setpoint controller with adaptation to uncertainty in
Dengpeng Xing, De Xu, Haipeng Li, and Liyan Luo are with Institute
of Automation, Chinese Academy of Sciences, Beijing, China. (e-mail:
dengpeng.xing@ia.ac.cn)
depth information. In Ref. [10], broyden method was used to
estimate the image Jacobian matrix representing the relation
between the variations of image coordinates and Cartesian
planar coordinates. The two microscopic vision systems were
orthogonal in order to have three dimensional information of
the object. In our previous work, an active calibration method
was used to acquire monocular microscopic Jacobian matrix
and applied on assembly of micro-pipe and micro-sphere
[7]. To calibrate stereo microscope, Wang [12] estimated the
main parameters and rectiﬁcation parameters of an imaging
model using the symmetry and the differences between the
two optical paths of stereo microscopic vision system. In
Refs. [13], [14], a three dimensional positioning problem was
handled via considering the object model or the position of
the microscopic vision. Lee [15] experimentally determined
the Jacobian matrix by adding constant translational motions
to the actuators and acquiring the corresponding displace-
ments on the image plane.
To assemble or manipulate complex components requires
multiple robot arms with different grippers to work si-
multaneously in the small clear view of the microscopic
vision system. This may lead to placing some robot arms
in positions or postures that can not be exactly measured,
and therefore affect the precision of the micro-operation. To
handle irregular components under the supervision of the
microscopes may enforce to locate microscopes where the
interested features can be clearly viewed, and this commonly
results in a nonorthogonal microscopic vision system. In
these issues, how to precisely control the micro motion using
microscopic vision feedback is very important.
This paper uses an active approach to calibrate Jacobian
matrix to acquire the relationship between the relative motion
of the manipulators and the image coordination changes
in the microscopic vision system. This method allows any
placement of robot arms and microscopes, and provides high
precision and fast response. We apply it to micro manipulator
positioning, tracking for distributed systems, and motion
optimization in micro-assembly. To validate the effectiveness
of the proposed method, we conduct experiments on a micro-
assembly platform. This mechanism has a nonorthogonal
vision system incorporating three microscopes and six robot
arms, whose locations are not measured.
The rest of the paper is organized as follows. Section II
presents the active calibration method for a nonorthogonal
microscopic vision system and multiple robot arms whose
location are hardly measured. In Section III, applications are
addressed in the positioning, tracking of distributed systems,
and motion optimization. Experiments are carried out in the
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 5455
next section on our micro-assembly platform. The paper is
concluded in Section IV .
II. ACTIVE CALIBRATION
Compared with traditional vision system, microscope has
different characteristics which can be concluded as: 1) small
view depth, which may be at the levels of ten to hundred
microns; 2) small view ﬁeld, which is determined by the
magniﬁcation factor of the microscope lens and the size of
the camera’s sensing area; 3) neglectable lens distortion; 4)
planar vision; 5) adjusting platform to have clear images.
In view of the microscope characteristics, for a platform
with multiple manipulators designed to operate irregular and
complex objects of micro size, the microscopes need to be
placed at positions to be able to clearly observe interested
features. This usually leads to a nonorthogonal vision system.
For irregular object assembly, the robot arms may situate
in postures that can hardly be exactly measured. We need
a general method to map from the image plane of each
microscope to the Cartesian movement of each manipulator.
For any point, which is in the clear view area of the
studied microscope, in the end-effector of any manipulator,
the relative movements in Cartesian space have only a scale
to their position changes in the eye of the microscope. The
relation is
?
?
Du
i
Dv
i
Df
i
?
?
=
i
J
j
?
?
?
?
?
?
?
?
Dx
j
Dy
j
Dz
j
Da
j
Db
j
Dg
j
?
?
?
?
?
?
?
?
, (1)
where[Dx
j
,Dy
j
,Dz
j
,Da
j
,Db
j
,Dg
j
]
T
is the relative movement
of the j
th
manipulator, [Du
i
,Dv
i
,Df
i
]
T
is the image coor-
dination change in the i
th
microscope, [Du
i
,Dv
i
]
T
is the
coordination change of point features and Df
i
represents
the angle change of line features,
i
J
j
?R
3?6
is the image
Jacobian matrix of the j
th
manipulator in the i
th
microscope.
Since microscope has very small view depth and small
view ﬁeld, pattern-based calibration method which is widely
used in traditional vision system can not be suitable. Here we
use active calibration method. To solve the Jacobian matrix
in the above equation, the least square method is applied.
i
J
j
= A
i
B
T
j
(B
j
B
T
j
)
?1
, (2)
where
A
i
=
?
?
Du
i1
Du
i2
··· Du
in
Dv
i1
Dv
i2
··· Dv
in
Df
i1
Df
i2
··· Df
in
?
?
,
B
j
=
?
?
?
?
?
?
?
?
Dx
j1
Dx
j2
··· Dx
jn
Dy
j1
Dy
j2
··· Dy
jn
Dz
j1
Dz
j2
··· Dz
jn
Da
j1
Da
j2
··· Da
jn
Db
j1
Db
j2
··· Db
jn
Dg
j1
Dg
j2
··· Dg
jn
?
?
?
?
?
?
?
?
,
[Dx
jk
,Dy
jk
,Dz
k j
,Da
k j
,Db
k j
,Dg
jk
]
T
is the 3D movement vec-
tor of the j
th
arm in the k
th
step, [Du
ik
,Dv
ik
,Df
ik
]
T
represents
the image coordination change in the i
th
vision system in
the k
th
step, n is the total trials. Equation (2) has solution
if and only if matrix B is full rank; and since the matrix
B is a 6? n matrix, the sufﬁcient and necessary condition
to compute the Jacobian is n≥ 6, i.e., the active motions
include at least six steps. More recorded motions can improve
the calibration accuracy. The hand-eye calibration is also
achieved by applying action calibration.
A microscope is only sensitive to three DoFs: two transla-
tional motion in a plane vertical to the camera lens and one
rotational movement around the axis parallel to the camera
lens. So two cameras are at least required to determine the
exact motion without multiple solutions. Using the Jacobian
matrix, we can compute the corresponding manipulator mo-
tion given the required tasks in each individual camera. For
the j
th
arm, the expected manipulator movement is
?
?
?
?
?
?
?
?
Dx
j
Dy
j
Dz
j
Da
j
Db
j
Dg
j
?
?
?
?
?
?
?
?
=
?
?
?
1
J
j
.
.
.
m
J
j
?
?
?
†
?
?
?
?
?
?
?
?
?
?
?
Du
1
Dv
1
Df
1
.
.
.
Du
m
Dv
m
Df
m
?
?
?
?
?
?
?
?
?
?
?
, (3)
where J
j
= [
1
J
T
j
,··· ,
m
J
T
j
]
T
is the Jacobian matrix mapping
the j
th
robot arm motion to the image coordination changes
in the microscopic vision system,
†
means the pseudo-
inverse, and m is the number of microscopes. In practical
application, we can pick a part of speciﬁc features and form
a simpliﬁed equation, which is addressed in an experiment
example.
III. APPLICATIONS
A. Positioning for Platform with Multiple Micro Operators
After computing the Jacobian matrix of each robot manip-
ulator, we can directly use it to micro-operation. The control
system block diagram is shown in Fig. 1, which is separated
by the microscopic vision system and manipulator control
blocks. The vision system observes each manipulator, ﬁnds
interested features, and feedbacks the feature locations and
postures. With the expected states of each manipulator, the
Fig. 1. Control diagram using Jacobian for multiple robot arm.
5456
desired image coordination changes can be computed, which
are then multiplied with the corresponding pseudo-inverse
Jacobian matrix to acquire the expected motor movements.
These results can be fed into Controller to drive motors. The
controller is added for speciﬁc reasons: robust controllers
to make the moving robust, adaptive controllers to adapt
the environment, and commonly used time invariant PID
controller to eliminate overshooting, etc.
B. Tracking
For distributed robot systems, the motion of each manip-
ulator is determined by its own controller, not by a central
controller, and each subsystem has communications. If one
manipulator is expected to follow another one and the only
information got from outside is the leader’s motion command
of the next time step, the follower has to compute how to
move in order to catch up with the leader while still in
the clear view of the microscopic vision system. We can
determine the relationship between manipulators under the
clear vision of the i
th
microscope.
?
?
?
?
?
?
?
?
Dx
k
Dy
k
Dz
k
Da
k
Db
k
Dg
k
?
?
?
?
?
?
?
?
=(
i
J
T
k
i
J
k
)
?1i
J
T
k
i
J
j
?
?
?
?
?
?
?
?
Dx
j
Dy
j
Dz
j
Da
j
Db
j
Dg
j
?
?
?
?
?
?
?
?
, (4)
where [Dx
k
,Dy
k
,Dz
k
,Da
k
,Db
k
,Dg
k
]
T
is the k
th
manipulator
movements, [Dx
j
,Dy
j
,Dz
j
,Da
j
,Db
j
,Dg
j
]
T
is the j
th
manipu-
lator movements,
i
J
k
and
i
J
j
are the image Jacobian matrices
of the k
th
and j
th
manipulators in the i
th
microscopic vision
system. As discussed earlier, to acquire unique solutions
needs vision feedback information from two or more mi-
croscopes. The Jacobian matrix in the above equation needs
to be calibrated in an appropriate microscopic vision system.
If the system is reduced to three dimensional translation, two
microscopes at least is required. Speciﬁc controllers can also
be added in order to deal with possible overshooting and
detection errors.
C. Movement optimization
To manipulate two or more components, e.g., micro-
assembly, the traditional way is to manually design a trajecto-
ry for each manipulator, which executes its own command to
reach the desired state. But this is deﬁnitely not optimal, for
several reasons: 1) since some robot arms are not parallel to
the vision systems, the end effectors have different effort in
moving to keep the features still in the small clear view area
of the microscopic vision system; 2) usually the components
are irregular, and some arms are easy to drive and energy-
saving, while others are on the contrary. In some cases,
some manipulators easily move out of the clear view of
the microscopic vision system. All these rise difﬁculties
to manually tune the relative motion parameters. By using
optimization and incorporating Jacobian matrix is a useful
way to help the manipulator to determine where to go and
in what posture. This also improves the intelligence of the
micro-assembly.
We present a simple example to illustrate what this means,
as shown in Fig. 2. In the clear view of the microscope
k, two end effectors are initialized with certain angles and
the distance is [DP
i
,DP
j
] pixels. The optimized state is the
position that two objects are very close and vertical in this
camera’s eye. In order to generate the expected trajectory, at
least two microscope feedback should be used. We pick n
coordination changes in the microscopic vision system as the
image state, and the mapping relation between manipulators
and cameras is
?
?
?
?
?
?
?
?
Dx
i
Dy
i
Dz
i
Da
i
Db
i
Dg
i
?
?
?
?
?
?
?
?
=
v
J
†
i
?
?
?
?
?
DP
1
DP
2
.
.
.
DP
n
?
?
?
?
?
, (5)
where [DP
1
,DP
1
,··· ,DP
n
]
T
is the image coordination change
we pick from the vision system, and this vector corresponds
to the expected changes in camera’s eyes. n is the total
number of the expected image coordination change, and
when n is larger than the manipulator’s DoFs, redundant in-
formation is provided, which may lead to precision problem.
v
J
i
is the Jacobian matrix mapping the relative movement of
manipulator i to the picked feature changes in the vision
system.
To simplify the computation, we use an example of
assembling two components. For more parts handling, this
method can also be applied. We deﬁne DP
1
i
as the i
th
feature
change of the ﬁrst component, and DP
2
i
as of the second
one. The following equation separates the expected feature
coordination changes,
|DP
1
1
? DP
2
1
|= DP
1
,
.
.
.
|DP
1
n
? DP
2
n
|= DP
n
.
(6)
This equation also addresses the motion relationship between
the executing manipulators. We use the expected image co-
ordination change of one object as the optimization variable,
Fig. 2. Optimization process description.
5457
4
2
1
9
8 6
7
5
3
X
Y
Z
O
(a) schematic model (b) platform
The two subjects observed 
in the microscope 
(c) subject location
Fig. 3. The platform model for complex components assembly. 1-3 are microscopic vision systems, and 4-9 are robot arms.
and the above equation can compute the desired change of
the other object.
We deﬁne P=[P
1
,P
2
,··· ,P
n
]
T
, which is the position and
posture of interested features in corresponding cameras, and
deﬁne the clear area of the microscopic vision system as V,
which is the intersection set of the clear view area of each
microscope. Since each feature we picked should be clearly
viewed, the constraint for optimization is then set as P? V,
i.e. features never move out of the clear view of microscopes.
For the state slips out during optimization, a big punishment
is added into the cost function.
We deﬁne DX
i
= [Dx
i
,Dy
i
,Dz
i
,Da
i
,Db
i
,Dg
i
]
T
, which is
the relative movement of manipulator i, and deﬁne the
optimization criterion as a weighted sum squared on each
motor movement,
L= DX
T
1
RDX
1
+ DX
T
2
QDX
2
, (7)
where R?R
6?6
and Q?R
6?6
are the weight matrices. The
desired motion for each manipulator can then be optimized
by employing appropriate optimization tools.
IV. EXPERIMENTS
A. Platform System
The platform model is shown in Fig. 3. This machine has
6 robot arms and 3 microscopic vision systems, and has 34
DoFs totally. In the ﬁgure, the optic axes of the camera 1, 2,
and 3 are parallel with y-axis, z-axis, and x-axis, individually.
But the cameras are not strictly orthogonal; they can also
be placed at certain position so that interested features are
in their clear view. Each microscopic vision system has
3D micro translational DoFs, which can actively follow the
motion of interested features and increase the clear view
area of the microscope. The six robot arms are all equipped
with a macro translational rail, so they can share the small
micro working space without interference. The arm 6 has
a z-axis translational DoF and three rotational DoFs; and
the other arms all have three micro translational DoFs. The
arms 4, 5, and 8 have equipped with micro-force sensors and
a rotational mechanism to manually adjust the end effector’s
posture. The macro motion axes of the arm 6 and 8 are
approximately parallel with y-axis and x-axis, and the other
arms are just placed in order to facilitate assembly in the
micro space, according to the irregular objects they grip. We
have designed six manipulators in this platform in order to
facilitate assembling several subjects simultaneously.
B. Jacobian Results
We use the arm 5 as an example to testify the usefulness of
the proposed method. This arm has three micro translational
DoFs and horizontal cameras are used to form a microscopic
vision system. The equation (1) is then simpliﬁed as

Du
i
Dv
i

=
i
J
5
?
?
Dx
5
Dy
5
Dz
5
?
?
, (8)
where [u
i
,v
i
]
T
is the image coordination in the horizontal
cameras, i = 3 means in the view of the camera 3 which
is along x-axis and i = 1 is of the camera 1 which is
parallel with y-axis,[x
5
,y
5
,z
5
]
T
is the position vector of the
manipulator 5.
In this example, the equation (2) has solution if and only
if R(B)= 3, i.e, at least three steps of active motions of the
5
th
manipulator are required. This manipulator is actuated for
6 steps and the image coordination change of an interested
feature are recorded in each camera. Moving in the view area
of the camera 3, we have
3
B
5
=
"
1000 ?1000 0 0 0 0
0 0 1000 ?1000 0 0
0 0 0 0 1000 ?1000
#
mm,
3
A
5
=
h
223.1 ?223.0 ?225.8 225.7 8.2 ?8.2
7.4 ?7.4 ?4.5 4.5 ?318.2 319.1
i
pixels.
The Jacobian matrix of the manipulator 5 in the camera 3 is
then calculated as
3
J
5
=

0.2230 ?0.2258 0.0082
0.0074 ?0.0045 ?0.3187

.
Applying the same method results in the Jacobian matrix of
the manipulator 5 in the camera 1
1
J
5
=

?0.2301 ?0.2116 ?0.0033
0.0046 ?0.0049 ?0.3157

.
The manipulator has three DoFs while two cameras feed-
back four image coordination changes. Since the image
size of the two cameras is different, redundant feedback
5458
(a) in camera 1 (b) in camera 3
Fig. 4. The initial and desired states of the component gripped by the
manipulator 5.
information may result in incorrect positioning. According
to the characteristics of the platform, we only feedback
three observed states in this experiment, removing the ver-
tical change in the camera 3. The feedback state becomes
[Du
1
,Dv
1
,Du
3
]
T
, and the corresponding Jacobian matrix is
J
5
=
?
?
?0.2301 ?0.2116 ?0.0033
0.0046 ?0.0049 ?0.3157
0.2230 ?0.2258 0.0082
?
?
.
To testify the effectiveness of the Jacobian method, we
propose an example of alignment which is very common in
assembly. As shown in Fig. 4, the upper object is attached to
the gripper of the manipulator 5, while the lower one is ﬁxed
on the end effector of the robot arm 4. Figs. 4(a) and 4(b)
reﬂect the initial state of the end effector 5 (the red point
is the center of the upper object), and the desired state (100
pixels higher than the current center position of the lower
object) in the horizontal cameras. We use Jacobian matrix
to compute the expected motion and pick a PI controller to
drive motors. The results are shown in Fig. 5: the ﬁrst step
moves the distance about [316,?496,329]
T
pixels with the
error of [?4,4.7,?25]
T
pixels deviated from the expected
state. Starting from the second step, the errors of all the
picked features in the two cameras are less than 0.1 pixels,
in this example 0.5mm. The error ratio compared with the
moving distance is less than 0.04. This demonstrates that the
proposed method of using image Jacobian matrix has good
precision.
C. Tracking
As an example, we use the manipulator 5 to track end ef-
fector 4’s motion in the clear view of the horizontal cameras.
Since these two manipulators both have three translational
DoFs, the equation 4 is then simpliﬁed as
?
?
Dx
5
Dy
5
Dz
5
?
?
=(J
T
5
J
5
)
?1
J
T
5
J
4
?
?
Dx
4
Dy
4
Dz
4
?
?
. (9)
We can also compute the Jacobian matrix of the manipulator
4 in the clear view of the cameras 1 and 3 by taking 6 steps,
J
4
=
?
?
?0.221 ?0.223 0.006
?0.0025 0.0055 0.3165
?0.23 0.2235 ?0.0085
?
?
.
In this experiment, the manipulator 4 is actuated to move
in the distance of [?445.2,1.2,312.4]
T
motor pulse, whose
image is still in the clear view of the horizontal cameras,
and send this motion command to the manipulator 5. The
control system of this manipulator can calculate the motion
that is needed to follow the manipulator 4’s movement, by
using equation (9). After taking this step, the tracking error
is [3.1,?4.4,3.2]
T
pixels, and the error ratio compared with
the moving distance is less than 0.04.
D. Motion Optimization
We also use the manipulators 4 and 5 to test the effective-
ness of motion optimization. Since the manipulators only
have translational DoFs, this optimization is reduced to a
three dimensional problem. Suppose that the end effector
4 is on the upper-left side of 5, and the image distance
measured in the horizontal cameras is DP=[100,100,100]
T
pixels. Set the motion of the manipulator 4, DP
1
, as the
optimization variables, and the other manipulator’s motion
is restricted by equation 6. We set the weight matrix as
R= Q= I
3?3
in order to investigate the effect of robot arm’s
placement on image motion in microscope. SNOPT [16] is a
general purpose system for constrained optimization, using
sequential quadratic programming (SQP). We use it to ﬁnd
the optimal motion planning in this example.
TABLE I
THE OPTIMIZED CHANGES OF MANIPULATORS AS Q = I
3?3
.
Manipulator 4
image change [51.4,50.1,51.6]
T
pixels
motor movement [?229.2,0.8,156.4]
T
pulses
Manipulator 5
image change [48.6,49.9,48.4]
T
pixels
motor movement [3.5,223.5,154.7]
T
pulses
The optimized image coordination changes and motor
movements of each manipulator are displayed in Table I,
which show the difference of robot arm placement and its
effect. Since the two manipulators are placed in positions that
are almost symmetric along x-axis and on the same horizon
plane, the optimal results for the two manipulators are almost
equal (We can also explain this by comparing the elements
of Jacobian matrix of each manipulator). But for the robot
arms with different angles in the vision system, the results
will be different.
The weight matrix can be set different, for the cases
that some manipulators have difﬁculties in moving one or
more of their motors, or the operator hopes to drive some
manipulators as less as possible because of their delicate
end effectors, or some end effectors may easily go out of the
clear view of the vision system. In this example, we wish the
manipulator 5 to move less, especially upward motion. So the
weight matrix is set as R= I
3?3
and Q= diag(5,5,10). The
optimized results are changed to Table II. We can see that
the manipulator 5’s motion is much less, especially motion
along the z-axis.
5459
0 1 2 3 4 5 6
?50
0
50
100
150
200
250
300
350
steps
D u
1
 pixels
(a) Du
1
0 1 2 3 4 5 6
?50
0
50
100
150
200
250
300
350
steps
D v
1
 pixels
(b) Dv
1
0 1 2 3 4 5 6
?500
?400
?300
?200
?100
0
100
steps
D u
3
 pixels
(c) Du
3
Fig. 5. The image coordination error from the expected position.
TABLE II
THE OPTIMIZED RESULTS OF MANIPULATORS AS Q = diag(5,5,10).
Manipulator 4
image change [84.2,90.8,84]
T
pixels
motor movement [?374.4,1.2,283.8]
T
pulses
Manipulator 5
image change [15.8,9.2,16]
T
pixels
motor movement [1.2,73.1,28.1]
T
pulses
V. CONCLUSIONS
This paper proposes an active calibration method for micro
operation systems equipped with multiple robot manipu-
lators. The Jacobian matrix maps the relative movements
of manipulators to the image coordination changes in the
microscopic vision system. This method is especially suitable
for operating irregular objects, since the robot arms and
microscopes have to be located to clearly view the interested
features. We also investigate its applications in positioning,
tracking, and motion optimization. Experiments are carried
out on a micro-assembly platform equipped with three mi-
croscopes and six robot arms.
ACKNOWLEDGMENT
This work is supported by the Program for National Nature
Science Foundation of China (61305115, 61227804).
REFERENCES
[1] M. B. Cohn, K. F. Bohringer, J. M. Noworolski, et al., “Microassembly
technologies for MEMS”, Proc. SPIE: Conf. Micro. Dev. Comp, 1998,
pp. 2-16.
[2] M. Savia and H. N. Koivo, “Contact micromanipulation ? survey of
strategies”, IEEE/ASME Trans. Mechatron., vol. 14, no. 4, pp. 504-
514, 2009.
[3] J. D. Wason, J. T. Wen, J. J. Gorman, et al., “Automated multiprobe
microassembly using vision feedback”, IEEE Trans. Robot., vol. 28,
no. 5, pp. 1090-1103, 2012.
[4] K. Rabenorosoa, C. Clevy, Q. Chen, et al., “Study of forces during
microassembly tasks using two-sensing-ﬁngers grippers”, IEEE/ASME
Trans. Mechatron., vol. 17, no. 5, pp. 811-821, 2012.
[5] V . Sariola, M. Jaaskelainen, Q. Zhou, et al., “Hybrid microassembly
combinging robotics and water droplet self-alignment”, IEEE Trans.
Robot., vol. 26, no. 6, pp. 965-977, 2010.
[6] L. Chen, M. Wang, Z. Yang, et al., “Fast autofocus method for
microscopic computer vision”, Optic. Precis. Eng., vol. 18, no. 6, pp.
1361-1366, 2010.
[7] D. Xu, F. Li, Z. Zhang, et al., “Characteristic of monocular microscope
vision and its application on assembly of micro-pipe and micro-
sphere”, Chin. Contr. Conf., pp. 5758-5763, 2013.
[8] S. J. Koppal, I. Gkioulekas, T. Young, et al., “Towards wide-angle
micro vision sensors”, IEEE Trans. Pattern Anal. Mach. Intell., vol.
35, no. 12, pp. 2982-2996, 2013.
[9] M. Schroeck and T. Doiron, “Probing of two-dimensional grid patterns
by means of camera based image processing”, SPIE Int. Soc. Opt.
Eng., 2000, pp. 3966:9-17.
[10] X. Zeng, X. Huang, and M. Wang, “Micro-assembly of micro parts
using uncalibrated microscopes visual servoing method”, Inform. Tech.
J., vol. 7, no. 3, pp. 497-503, 2008.
[11] C. C. Cheah, C. Liu, and J. E. Slotine, “Adaptive Jacobian vision based
control for robots with uncertain depth information”, Automatica, vol.
46, no. 7, pp. 1228-1233, 2010.
[12] Y . Wang, D. Li, and C. Liu, “A sereoscopic imaging model and its
calibration of micro stereovision for 3D measurement”, Int. Conf.
Inform. Acquis., 2005, pp. 442-447.
[13] C. Cassier, A. Ferreira, and S. Hirai, “Combination of vision ser-
voing techniques and VR-based simulation for semi-autonomous mi-
croassembly workstation”, IEEE Int. Conf. Robot. Autom., 2002, pp.
1501-1506.
[14] A. Ferreira, C. Cassier, and S. Hirai, “Automatic microassembly
system assisted by vision servoing and virtual reality”, IEEE/ASME
Trans. Mechatron., vol. 9, no. 2, pp. 321-333, 2004.
[15] S. Lee, Y . Nakamura, K. Yamane, et al., “Image stabilization for in
vivo microscopy by high-speed visual feedback control”, IEEE Trans.
Robot., vol. 24, no. 1, pp. 45-54, 2008.
[16] P. E. Gill, W. Murray, and M. A. Saunders, “SNOPT: an SQP algorithm
for large-scale constrained optimization”, SIAM J. Optim., vol. 12, no.
4, pp. 979-1006, 2002.
5460
