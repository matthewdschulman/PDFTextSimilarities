The bench mover’s problem: minimum-time trajectories,
with cost for switching between controls
Yu-Han Lyu
1
Andrei Furtuna
2
Weifu Wang
3
Devin Balkcom
4
Abstract—Analytical results describing the optimal trajecto-
ries for general classes of robot systems have proven elusive,
in part because the optimal trajectories for a complex system
may not exist, or may be computed only numerically from
differentialequations.Thispaperstudiesasimpleroptimization
problem: ﬁnding an optimal sequence and optimal durations of
motion primitives (simple preprogrammed actions) to reach a
goal. By adding a ﬁxed cost for each switch between primitives,
we ensure that optimal trajectories exist and are well-behaved.
To demonstrate this approach, we prove some general re-
sults that geometrically characterize time-optimal trajectories
for rigid bodies in the plane with costly switches (allowing
comparison with previous analysis of optimal motion using
Pontryagin’s Maximum Principle), and also present a complete
analytical solution for a problem of moving a heavy park bench
by rotating the bench around each end point in sequence.
I. INTRODUCTION
Consider the following problem. A mover would like to
move a heavy park bench (modeled as a line segment) from
one location and orientation to another, as efﬁciently as
possible. Since the bench is heavy and there is only one
mover, the bench can only be moved by lifting one end and
rotating the bench around the end that is still on the ground,
with rotational velocity of±1. We wish to ﬁnd the sequence
of durations and directions of rotations that bring the bench
to the ﬁnal conﬁguration, while minimizing the total time of
the trajectory (computed as the sum of the absolute values
of the angles rotated through). This problem is very related
to the Reeds-Shepp problem [15] of ﬁnding the shortest path
for a steered car, but with only four discrete controls.
Unfortunately for the mover, the “optimal" trajectory to
move the bench straight forwards will require the mover to
runback andforthbetween endsofthebench inﬁnitely many
times, rotating the bench through an inﬁnitely small angle, a
phenomenonknownaschattering.We might therefore assign
some ﬁxed time cost or penalty to each switch of controls,
corresponding to the time it takes to run from one end of the
bench to the other.
The bench-mover’s problem is an example of a funda-
mental problem in robotics: ﬁnding trajectories that optimize
an objective function subject to constraints. For certain
simple models of mobile robots, including the well-known
1
Department of Computer Science, Dartmouth College, Hanover, NH
03755, USA yuhanlyu@cs.dartmouth.edu
2
Department of Computer Science, Dartmouth College, Hanover, NH
03755, USA andrei.furtuna@gmail.com
3
Department of Computer Science, Dartmouth College, Hanover, NH
03755, USA, weifu.wang.gr@dartmouth.edu
4
Department of Computer Science, Dartmouth College, Hanover, NH
03755, USA, devin@cs.dartmouth.edu
?4 ?3 ?2 ?1 0
?4
?3
?2
?1
0
1
k
3
heading (k
1
;k
2
)
H=!
initial configuration
goal configuration
left
right
Fig. 1: Optimal trajectory for initial conﬁguration
(?3,?3,π/4) with switching cost 1, where red arrow
represents the orientation of the bench. Green line denotes
the control line for this trajectory.
Dubins [10], [8] and Reeds-Shepp [15], [19], [18] cars,
optimal trajectories can be found analytically and explicitly.
Over the past decade, we and many other researchers (for
example, see [16], [6], [5], [7], [1], [17]) have tried vigor-
ously to extend and generalize techniques (typically based
on Pontryagin’s Maximum Principle [14]), with the goal of
achieving a more fundamental understanding of optimal mo-
tion for mobile robots with non-holonomic constraints. For
example, we have found strong results about minimum-time
trajectories for planar rigid bodies with linear constraints on
velocity and angular velocity [11].
However, extension to more satisfyingly general problems
has been elusive. Adding constraints on accelerations to
the model, or adding obstacles to the environment, leads
quickly to a formulation that resists solution using existing
techniques.
There seem to be two primary difﬁculties. The optimal
solutions might be described only by differential equations
that we may not integrate, or, even worse, the optimal
solutions may not exist. For example, Sussmann [19] showed
that perhaps the simplest extension of the Dubins model to
include bounds on angular acceleration leads to chattering:
the “best" trajectories require inﬁnitely many discontinu-
ous switches in control. Desaulniers showed that chattering
occurs with even the velocity-bounded model, if there are
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 106
obstacles in the environment [9].
This paper suggests an approach to dealing with both of
these difﬁculties. We limit the choice of controls to certain
primitives that may be integrated analytically (by design),
and we charge a cost for each switch. How should the
primitives be selected? In some cases, arguments about the
optimality of so-called ‘bang-bang’ controls may lead to
selection of a discrete set of consent controls. In other cases,
the design of the robot may suggest a set of primitives.
(This step is also required for modeling a system for the use
of either Non-holonomic PRM [12], RRT [13], and many
other general-purpose approaches to non-holonomic motion
planning.)
Pontryagin’sMaximumPrincipledoesnotappeartobethe
right tool for the motion primitive model of control. The set
of controls is discrete rather than continuous, and switching
costs make the cost function discontinuous with respect to
time.Wethereforesplittheproblemintotwoparts:adiscrete
problem of selecting the correct sequence of primitives, and
a continuous problem of ﬁnding the optimal duration. We
apply Karush-Kuhn-Tucker conditions [3] to ﬁnd necessary
conditions on trajectories with particular sequences of con-
trols.
We show that for a general class of problems in optimal
control, a non-zero cost for switching ensures that optimal
trajectories exist and are well-behaved. We also prove some
general results that geometrically characterize time-optimal
trajectories for rigid bodies in the plane with costly switches,
and ﬁnally present a complete analytical solution for the
park bench mover’s example problem described above. To
our knowledge, this is the ﬁrst exact solution for the opti-
mal trajectories for a mobile robot with a cost for control
switches, even though the model has been used implicitly in
motion-planning papers going as far back as 1991 [2].
II. EXISTENCE OF OPTIMAL TRAJECTORIES IN
COSTLY SWITCH MODEL
Furtuna’s Ph.D. thesis [11] proves that optimal trajectories
always exist for the bench-mover’s problem we will study in
this paper (as long as the switching cost is strictly greater
than zero), and in fact even for a much more general model
of trajectories composed of sequences of motion primitives
among obstacles. We brieﬂy consider this more general
model (which contains our current model as a special case),
and state the result.
Let Q be a closed set of collision free conﬁgurations. A
trajectory is a function F :Q?R
+
?Q that mapping from
an initial conﬁguration q
s
?Q and time t to a conﬁguration
in Q, where q
?
= F(q
s
,t) is the conﬁguration at time
t. When the initial conﬁguration is ﬁxed, a trajectory can
be determined by two sequences with the same length: a
sequence of controls, u, and a sequence of durations t. For a
trajectory determined by (u,t), we use q
i
(q
s
,u,t) to denote
the resulting conﬁguration after applying the ﬁrst i controls
on q
s
. We call a state q
?
reachable from q
s
if there exists
(u,t) with length n, such that q
n
(q,u,t) =q
?
. Let R(q) be
the set of reachable conﬁgurations from q.
For a control u ? U, the cost function c
u
(q,t) ≥ 0 is
a differentiable function representing the cost of applying
control u at conﬁguration q for duration t. For two controls
u,u
?
? U, the switching cost function C(u,u
?
) > 0 is a
function representing the cost of switching from u to u
?
.
Hence,foratrajectory (u,t),thecost is
∑
n
i=2
C(u
i?1
,u
i
)+
∑
n
i=1
c
ui
(q
i?1
(q
s
,u,t),t
i
).
Theorem 1: If the goal conﬁguration is in R(q
s
) and
R(q
s
) is a closed set, then there exists a minimum cost
trajectory from q
s
to the goal conﬁguration.
We sketch the proof. First upper-bound the number of
primitives required, using the fact that the goal is in R(q).
Now consider each ﬁxed trajectory structure (sequence of
primitives) separately; there are ﬁnitely many. For each
structure, construct a sequence of trajectories whose limit
is a trajectory with cost that is the inﬁmum of costs for tra-
jectoriesforthisstructure,andusingtheBolzano-Weierstrass
theorem show that this inﬁmum is actually a minimum.
(When there is no obstacles in the environment, existence
of trajectories is also implied by [4]. But the proof above is
simpler due to its restriction to rigid bodies in the plane, and
gives an explicit upper bound on the number of switches.)
III. RIGID BODIES IN THE PLANE
We specialize the model to consider the optimal motion of
rigid bodies in the plane with constant-velocity translations
or rotations; an ultimate goal of future work is to apply
similar techniques to more general models.
A. Model and Notation
We use (x,y,?) to denote a conﬁguration, and (v
x
,v
y
,?)
to denote a control: x and y velocities in a frame attached
to the body (robot frame), and angular velocity.
For a conﬁguration q
0
, if we apply a sequence of controls
u ? U
n
with a sequence of durations t ? R
n
+
, then the
result is a conﬁguration q(q
0
,u,t) ? SE(2), where q is a
continuous function that integrates the control over time in
the world frame and then adds q
0
to obtain the resulting
conﬁguration.
Let q
s
be the start conﬁguration and U be the set of
controls. A pair (u,t) is admissible if q(q
s
,u,t) = 0, and
its time is T(t) =
∑
i
t
i
. In addition to the time cost, there
is a cost associated with switching controls. The switching
costs can be modelled as a function C : U ?U ?R
+
that
depends on the control applied before and the control applied
after and the cost is always strictly larger than zero.
The problem is as follows: Given a start conﬁguration
q
s
, a ﬁnite control set U, and a cost function C, ﬁnd an
admissible (u,t) with the minimum sum of the time and
the switching costs. This problem can be modelled as a
mathematical optimization problem.
minimize
n
∑
i=1
t
i
+
n
∑
i=2
C(u
i?1
,u
i
)
subject to q(q
s
,u,t) = 0
t
i
≥ 0,u
i
?U (1)
107
Since function q integrates control over t, q is differentiable
with respect to t away from the boundary t
i
= 0.
B. Karush-Kuhn-Tucker conditions
Consider a non-linear optimization problem as follows
minimize f(x)
subject to q(x) = 0
g(x)≤ 0
x?R
n
,with f :R
n
?R, q :R
n
?R
m
,
and g :R
n
?R
p
differentiable.
For a solution ^ x, let the active set I(^ x) = {i : g
i
(^ x) =
0}. A solution ^ x satisﬁes linear independence constraint
qualiﬁcation (LICQ), if?q(^ x) and?g
i
(^ x),i?I are linearly
independent. (There are different types of constraint quali-
ﬁcation. Although LICQ is not the most general constraint
qualiﬁcation, LICQ sufﬁces for our bench-mover example.)
Karush-Kuhn-Tucker conditions [3] state: If ^ x is a local
minimum and satisﬁes LICQ, then there exists ??R
m
and
µ?R
p
, such that
1) ?f(^ x)+?·?q(^ x)+µ·?g(^ x) = 0.
2) µ≥ 0.
3) µ·g(^ x) = 0.
IV. NECESSARY CONDITIONS FOR RIGID BODIES
There are two sets of free variables, u and t. Since the
domain of u
i
is a ﬁnite set U and the domain of t
i
is R
+
,
formulation 1 is a mixed integer non-linear programming
problem, to which KKT conditions do not apply.
However,wecandecomposetheproblemintoseveralnon-
linear sub-problems. Each sub-problem has a ﬁxed control
sequence so that we only need to determine the optimal
duration for this control sequence. Consequently, each sub-
problem has only one set of free continuous variables. Since
for any given problem we may upper-bound the number of
controlsintheoptimaltrajectory,thereareonlyﬁnitelymany
sub-problems.
A. Fixed control sequence
Let u be a ﬁxed control sequence. Since the switching
cost
∑
n
i=2
C(u
i?1
,u
i
) in the objective function becomes a
constant, we remove that term from the objective function.
The resulting problem can be modelled as a mathematical
optimization problem.
minimize
n
∑
i=1
t
i
subject to q(q
s
,u,t) = 0
t
i
≥ 0 (2)
A solution t is regular if t satisﬁes LICQ. Since KKT
conditions hold only for regular solutions, we use KKT
conditions to prove properties of regular solutions and deal
with irregular solutions separately.
Let ? = (?
x
,?
y
, ?
?
) be the dual variables associated with
the equality constraints and let µ = (µ
1
,...,µ
n
) be the
dual variables associating with the inequality constraints. By
KKT, we can get the following condition.
?·?q(q
s
,u,t) =µ?1,
whereµ≥ 0 andµ·t = 0. Sinceq
s
andu are ﬁxed, function
q only depends on t.
Without loss of generality, we assume:
1) For all 1≤i<n, u
i
?=u
i+1
.
2) For optimal solutions t, t
i
> 0 for all 1≤i≤n.
If the ﬁrst assumption is violated, we can combine u
i
with u
i+1
. If the second assumption is violated, then we
can remove the controls u
i
with t
i
= 0, and the resulting
control sequence will be considered in another sub-problem.
Since t> 0, we have µ = 0 by the third KKT condition.
Now, we characterize properties of the velocity along an
optimal solution.
Lemma 1: For any ﬁxed control sequence u, an optimal
duration t
?
satisﬁes the following property: given the direc-
tion along which a particular translation control is applied at
some point t
0
, the possible directions (in the world frame)
of all other translation controls are determined, up to sign.
Proof: We have
?
x
∂q
x
∂t
?
i
+?
y
∂q
y
∂t
?
i
=?1. (3)
The partial derivatives are parallel to the direction of trans-
lation, so
?
x
_ x(t
0
)+?
y
_ y(t
0
) =?1. (4)
Since this equation holds for all translationsi, the property
follows immediately from properties of the dot product.
Lemma 2: For any ﬁxed control sequence u, an optimal
duration t
?
satisﬁes the following property: for a rotation
control at conﬁguration (x,y,?), we have
?
x
v
x
+?
y
v
y
+?(?
x
y??
y
x+?
?
) =?1.
Proof: For the i-th control, (v
x
,v
y
,?) at conﬁguration
(x,y,?), we have
∂q
x
∂t
?
i
=v
x
+y?,
∂q
y
∂t
?
i
=v
y
?x?,
∂q
?
∂t
?
i
=?
Thus, the ﬁrst KKT condition becomes
?1 =?
x
∂q
x
∂t
i
+?
y
∂q
y
∂t
i
+?
?
∂q
?
∂t
i
=?
x
(v
x
+y?)+?
y
(v
y
?x?)+?
?
?
=?
x
v
x
+?
y
v
y
+?(?
x
y??
y
x+?
?
)
Ifwemultiplyaconstant?H onbothsidesoftheequation
?
x
v
x
+?
y
v
y
+?(?
x
y??
y
x +?
?
) =?1, then we get the
following equation
k
1
v
x
+k
2
v
y
+?(k
1
y?k
2
x+k
3
) =H,
where k
1
= ??
x
H, k
2
= ??
y
H, and k
3
= ??
?
H. If
k
1
?= 0 or k
2
?= 0, since H can be chosen arbitrarily, we
can pick a positive H so that k
2
1
+k
2
2
= 1. Thus, combining
Lemma 1 and 2, we have the following theorem.
108
Theorem 2: For any ﬁxed control sequence u, any regular
optimal duration t
?
in the costly switch model satisﬁes the
following property: there exist constants H > 0, k
1
, k
2
,
and k
3
, such that for any control u
i
with the instantaneous
velocity (v
x
,v
y
,?) in the world frame when u
i
is applied at
conﬁguration (x,y,?), we have
k
1
v
x
+k
2
v
y
+?(k
1
y?k
2
x+k
3
) =H,
where k
2
1
+k
2
2
?{0,1}.
Interestingly, this central equation is the same as that
derived in [11] (using Pontryagin’s Maximum Principle) as
part of the necessary conditions for optimal trajectories for
rigidbodiestheplanewithlinearconstraintsonthevelocities
and no cost for switching. However, this condition is weaker:
it only applies to a particular control structure, and there is
no requirement thatH be maximized. This weaker condition
allows more “types" of optimal trajectory structures than for
the classic Dubins and Reeds-Shepp problems, depending
on the cost of switching. (Theorem 2 is implied by Blatt’s
indifference principle[4]; however, we still include the above
proof because it makes use only of simple KKT conditions.)
B. Control line interpretation
There is a nice geometric interpretation for Theorem 2
when k
2
1
+k
2
2
= 1, related to the control line interpretation
in[11].Wecandeﬁneacontrollineintheplanewithheading
(k
1
,k
2
) and distance k
3
from the origin; see Fig 1. The
term k
1
v
x
+k
2
v
y
becomes the translational velocity along
the vector (k
1
,k
2
) and the term k
1
y?k
2
x +k
3
becomes
the signed distance from the reference point to the control
line. By Corollary 1 in [11], when a rotation is applied, the
signed distance from the rotation center to the control line is
H/?.Similarly,whenatranslationisapplied,thedotproduct
between (k
1
,k
2
) and (v
x
,v
y
) must be H.
C. Whirl trajectories
In the case that k
1
= k
2
= 0, the KKT conditions tell
us relatively little: only that all angular velocities must be
equal. We call such trajectories whirl trajectories. In order
to compute an optimal whirl, we only consider a smaller
subclass of whirl trajectories, and show if an optimal whirl
exists, then an optimal trajectory of this constrained subclass
exists. Speciﬁcally, we consider two-stage trajectories:
1) The ﬁrst stage moves the last rotation center to the cor-
rect position in the goal conﬁguration in the minimum
time.
2) The second stage is a rotation around the last rotation
center until the goal conﬁguration is achieved.
Theorem 3: Among any ﬁxed control sequence u for
which all controls have the same angular velocity, the two-
stage trajectory has minimum cost.
Proof: Let T
1
and T
2
be the times corresponding to
the ﬁrst and the second stage respectively. Let T
f
be the
time for an optimal trajectory. Since T
f
is the time for an
optimal trajectory,T
f
≤T
1
+T
2
. Moreover, since an optimal
trajectory needs to place the last rotation center to the correct
position, T
f
≥T
1
. Since T
2
is strictly less than 2π, we have
T
f
≤ T
1
+ T
2
< T
f
+ 2π. For any two admissible whirl
trajectories, the difference of time between them must be a
multiple of 2π. Therefore, T
f
must equal T
1
+T
2
.
We now show how to ﬁnd the minimum-cost trajectory
required for the ﬁrst stage. We change the coordinate system
so that the last rotation center is at the origin. Then, the
duration for the ﬁrst stage is the solution to the following
mathematical optimization problem, where the functions q
?
x
and q
?
y
describe the motion of the last rotation center with
initial position q
?
s
.
minimize
n?1
∑
i=1
t
i
subject to q
?
x
(q
?
s
,u,t) = 0
q
?
y
(q
?
s
,u,t) = 0
t
i
≥ 0 (5)
By an argument similar to Lemmas 1, 2, and Theorem 2, we
have the following result.
Theorem 4: Regular optimal solutions to 5 must satisfy
the following property: there exist constants H
?
> 0, k
4
,
and k
5
, such that for any control u
i
with the instantaneous
velocity (v
x
,v
y
,?)intheworldframewhenu
i
for 1≤i<n
is applied at conﬁguration (x,y,?), we have
k
4
v
x
+k
5
v
y
+?(k
4
y?k
5
x) =H
?
,where k
2
4
+k
2
5
= 1.
Unfortunately, irregular solutions to 5 must still be con-
sidered during analysis of any particular system.
There is a geometric interpretation for two-stage trajec-
tories of this type. Deﬁne a whirl control line in the plane
heading (k
4
,k
5
)throughthelastrotationcenter.ByTheorem
4, all rotation centers except the last one should have the
same signed distance to this line, and are thus parallel to the
line.
V. BENCH MOVER’S PROBLEM
A general framework for ﬁnding optimal trajectories in the
costly switch model by using Theorem 2 is as follows:
1) Generate all possible control sequences of optimal
trajectories.
2) For each control sequence, determine the optimal du-
rations that reach the goal by using Theorem 2.
3) Output the best trajectory among the optimal trajecto-
ries founded in the previous step.
In general, identifying the control sequences of optimal
trajectories is difﬁcult and determining the optimal duration
for a ﬁxed control sequence is hard as well. However, for a
particular system, complete solution may be possible. We
will take the bench mover’s problem as an example to
demonstrate this framework.
A. Model and trajectory types
Consider a park bench with length 2. Letq
s
= (x
0
,y
0
,?
0
)
be the initial conﬁguration and (0,0,0) be the goal conﬁgu-
ration. Figure 1 gives an example with initial conﬁguration
(?3,?3,π/4). Let the reference point be the center of the
bench and it is (0, 0) in the robot frame. There are two
109
rotation centers: the left rotation center, (0, 1) in the robot
frame,andtherightrotationcenter,(0,-1)intherobotframe.
Let L be the set of controls containing l
+
= (1,0,1) and
l
?
= (?1,0,?1) corresponding the left rotation center. Let
R be the set of controls containing r
+
= (?1,0,1) and
r
?
= (1,0,?1) corresponding to the right rotation center.
The control set U =L?R. For two controls u,u
?
?U, the
cost of switching from u to u
?
is c.
Without loss of generality, we assume that the length of
the control sequence is at least three, since we can determine
optimal durations for a control sequence with length smaller
than three easily.
There are four broad types of trajectories:
1) Irregular: trajectories for which the gradients of the
constraints on the ﬁnal conﬁguration are linearly de-
pendent; KKT does not apply.
2) Whirl: trajectories for whichk
1
=k
2
= 0. All controls
in the trajectory must have the same angular velocity.
3) Alternating sign: the control sequence contains con-
trols alternating between l
+
and r
?
or alternating
between l
?
and r
+
.
4) Mixed: the control sequence contains controls alternat-
ing between L and R but not strictly alternating signs.
Our basic approach, given a starting conﬁguration, is to
compute an optimal trajectory of each of the four types,
and then to compare to ﬁnd the minimum. The following
sections will demonstrate how to ﬁnd an optimal trajectory
for each type. For computing optimal trajectories of types
3 and 4, an upper bound on the number of control actions
in the trajectory is required; this bound may be found by
considering the cost of the optimal whirl.
B. Irregular trajectories
If the gradients of the constraints on the ﬁnal conﬁgura-
tion are linearly dependent for some value of t satisfying
the constraints, we say that the corresponding trajectory is
irregular. Irregular trajectories may be optimal, and need not
satisfy the KKT conditions.
For the bench-mover’s problem, linear dependence of the
constraints only occurs for trajectories for which all rotation
centers lie on a line. This further implies that the distance
between ﬁrst and last rotation centers must be a multiple of
two.Itisstraightforwardtocomputetheoptimaltrajectoryof
this form geometrically. We sketch the procedure. First com-
pute the minimum-cost whirl (using the technique described
in the next section). Use this to upper bound a number of
circlesbetweenthestartandgoal,andenumerateallirregular
trajectories that do not reach the same conﬁguration twice.
C. Whirl trajectories
Since the analysis of whirls presented in the previous
section relies itself on a secondary application of KKT
conditions to a problem of optimal motion in the plane, we
must consider both regular whirls and irregular whirls. For
the case of regular whirls, all rotation centers except possibly
the last one are on the same line; see Fig. 2. We can also
see geometrically that for irregular whirls, the condition is
?1.5 ?1.0 ?0.5 0.0 0.5 1.0 1.5
?2.0
?1.5
?1.0
?0.5
0.0
0.5
1.0
1.5
2.0
initial configuration goal configuration
r
1
C
1
u
1
u
2
u
3
r
3
C
3
Fig. 2: Whirl trajectory with initial conﬁguration
(?0.5,0,π/2). All rotation centers except the last one
are on the same line. This is the optimal trajectory for this
initial conﬁguration with switching cost 1.
exactly the same. This section will show how this fact can
be used to identify the minimum-cost whirl.
Since the length of the bench is two and controls alternate
between L and R, for any two consecutive controls, the
distance between their rotation centers is two. Thus, when
the ﬁrst control and the last control are ﬁxed, in order to
reach the goal, there is only one choice of the length of the
control sequence. Hence, a whirl trajectory can be described
by its ﬁrst and last control. Since there are only four choices
for the ﬁrst control and each has two choices for the last
control, we can enumerate all possible pairs of ﬁrst and last
controls for whirl trajectories.
Fixtheﬁrstcontrolu
1
andthelastcontrolu
n
withrotation
centersr
1
andr
n
respectively. Since the last control is ﬁxed,
the second to the last control u
n?1
is also ﬁxed and its
rotation center r
n?1
should be on a circle C
n
centered at
r
n
with radius 2.
Since rotation centers r
i
, 1 ≤ i < n, are on the same
line, the distance L from r
1
to r
n?1
is determined in the
following way. Let D be the distance between the ﬁrst and
the last rotation centers. If u
1
= u
n
(u
1
?= u
n?1
), then L
is multiple of four plus 2. Otherwise, L is multiple of four.
Since the diameter of C is four and the difference between
any choices is multiple of four, L = 4?(D?4)/4?+2 when
u
1
=u
n
, L = 4?(D?2)/4? otherwise.
After we determine L, we can ﬁnd a circle C
1
centered
at r
1
with radius L. The circle C
1
intersects with C
n
at
most two points and these points are possible locations of
r
n?1
. When the location of r
n?1
is ﬁxed, the durations for
all controls can be determined easily.
D. Alternating sign trajectories
Since all angular velocities have the same absolute value,
all rotation centers must have equal distance to the control
110
line; see Fig. 1. An alternating sign trajectory can be de-
scribed by its ﬁrst control and the length of the sequence.
There are four choices of ﬁrst controlu
1
inU, and the parity
of n determines whether u
n
is the same as u
1
or not. We
will now show how to determine possible H values, control
lines, and durations based on u
1
and u
n
.
1) Determining H: Let r
1
and r
n
be the ﬁrst rotation
center and the last rotation center with distance D. If n is
odd, D = (2n? 2)
√
1?H
2
and H =
√
1?
D
2
4(n?1)
2
. In
this case, when D
2
≥ 4(n?1)
2
, the control line exists and
we can obtain a positive value of H ≤ 1. When n is even,
let X be (2n? 4)
√
1?H
2
, D
2
will be X
2
+
√
1?H
2
+
4. Consequently, D
2
= 4n(n? 2)(1?H
2
) + 4 and H =
√
1?
D
2
?4
4n(n?2)
. In this case, when D≥ 4 and D
2
≤ 4n(n?
2)+4 we can obtain a non-negative value of H ≤ 1.
2) Determining control lines: After we determine the
value of H, we want to determine the control line, which
is represented by a tuple (k
1
,k
2
,k
3
). Since k
2
1
+ k
2
2
= 1,
we can use (cos?,sin?) to represent (k
1
,k
2
). For one H
value, there are two possible control lines. We determine
(?,k
3
) in a similar way as in [11]. Let r
?
1x
=r
1x
u
1!
,r
?
1y
=
r
1y
u
1!
,r
?
nx
= r
nx
u
n!
, and r
?
ny
= r
ny
u
n!
. Let d
x
= r
?
1x
?
r
?
nx
and d
y
=r
?
1y
?r
?
ny
. Let (?,?) be (atan2(dx,dy),π/2)
if the ﬁrst control and the last control have the same angular
velocity; otherwise (atan2(d
?
x
,d
?
y
),acos(
H
√
d
?
x
2
+d
?
y
2
)), where
d
?
x
=r
?
nx
+d
x
/2 and d
?
y
=r
?
ny
+d
y
/2. Then, ? =??±?
and k
3
=
H+r
?
nx
sin??r
?
ny
cos?
un!
.
3) Determining durations: For a given control line L =
(k
1
,k
2
,k
3
) with a H value, we can determine the durations
as follows. For a given initial conﬁgurationq
0
with reference
point at p, we can determine the angle ? between the vector
p?r
1
and L. Then, we want to determine the location of
r
2
for u
2
. By theorem 2, all rotation centers have the same
distance H to L. For two consecutive rotation centers, their
distance must be 2, the length of the bench. Hence, the
angle ? between the vector r
2
? r
1
and L can only have
two possible values: asin(H) and π? asin(H) if u
1!
> 0,
otherwise π+asin(H) and 2π?asin(H). For a ﬁxed ?, we
can determine t
1
.
For u
2
, since we switch to u
2
at angle ? with respect to
L and u
3
=u
1
, we also can switch to u
3
immediately with
t
2
= 0. Since this null control will be examined by another
control sequence, we ignore this choice. Consequently, we
have only one choice of t
2
. Similarly, all controls u
2
to
u
n?1
have the same duration. This duration will be either
2acosH (if? ? [π/2,π/2]) or 2π?2acosH (otherwise). The
duration t
n
can be determined based on t
1
to t
n?1
based on
the constraint of reaching the goal conﬁguration.
E. Mixed trajectories
Consider a mixed trajectory that contains two consecutive
controls, u and u
?
, with the same angular velocity. By
Theorem 2, these two controls’ rotation centers, r and r
?
,
have equal distance to the control line, L, and are on the
same side of the control line. Hence, the line through r and
r
?
is parallel toL; see Fig. 3. Consequently, if there are three
?4 ?3 ?2 ?1 0 1
?1
0
1
2
3
Fig. 3: Mixed trajectory with initial conﬁguration
(?2.8,3.05,π/4). First two controls have the same
angular velocity and hence they are collinear and parallel to
the control line. This is the optimal trajectory for this initial
conﬁguration with switching cost 1.
consecutive controls with the same angular velocity, then the
duration of the second one must be π.
For a mixed trajectory, subsequences of controls with the
same angular velocity may appear anywhere in the control
sequence. However, it is always possible to rearrange the
controls in the control sequence without changing the cost,
such that the preﬁx of the control sequence has controls with
the same angular velocity and the sufﬁx has controls with
alternating angular velocity. Hence, we only consider control
sequences that can be decomposed into two parts in this way.
Letn be the length of the control sequence,n
w
<n be the
number of controls with the same sign, andm ben?n
w
. Let
D be the distance between the ﬁrst rotation center and the
last rotation center. Whenm is even,H satisﬁes|D?2(n
w
?
1)| = 2m
√
1?H
2
orD+2(n
w
?1) = 2m
√
1?H
2
.Hence,
H =
√
1?
(D?2(nw?1))
2
4m
2
or H =
√
1?
(D+2(nw?1))
2
4m
2
. We
can obtain at most two possible positive H ≤ 1 values.
When m is odd, H satisﬁes D
2
/4 = (m
2
?1)(1?H
2
)+
2m(n
w
? 1)
√
1?H
2
+n
2
w
? 2n
w
+ 2 or D
2
/4 = (m
2
?
1)(1?H
2
)?2m(n
w
?1)
√
1?H
2
+n
2
w
?2n
w
+2. Hence,
1?H
2
=|
?b±
√
b
2
?4ac
2a
|,wherea =m
2
?1,b = 2m(n
w
?1),
and c =n
2
w
?2n
w
+2. We can obtain at most two possible
positive H ≤ 1 values.
After we obtain H values, we can compute the control
line and durations by the method mentioned in the previous
section.
F. Mapping conﬁgurations to optimal trajectories
We implemented the solution described to solve the bench
mover’s problem, and used this implementation to sample
starting conﬁgurations and determine how optimal trajectory
structures and costs change with respect to different conﬁgu-
rations. We used initial conﬁgurations in [?7,?7]?[?7,?7]
111
(a) Switching cost 0.3 (b) Switching cost 0.4 (c) Switching cost 0.5
(d) Switch cost 1.0 (e) Switching cost 1.5 (f) Switching cost 2.0
Fig. 4: Synthesis
with initial orientation of zero, and six different values of
switching costs, to generate Figure 4.
We classify optimal trajectories by their ﬁrst control and
the parity of their lengths. We plot the mapping from initial
conﬁguration to trajectory category by using different colors
torepresentdifferenttrajectorycategories.Graycolorsrepre-
sent optimal trajectories with even length. Red, green, blue,
and yellow represent optimal trajectories with odd length.
Within each category, different colors represent different ﬁrst
controls.
Note that when the switching cost increases, the red/green
area grows, as optimal trajectories tend to use fewer controls,
changing the parity of the lengths of trajectories.
VI. CONCLUSIONS AND FUTURE WORK
Although the bench mover’s problem is artiﬁcial, and
a solution is perhaps of little practical use in itself, we
are motivated to study the problem because we believe it
highlights very central issues in the study of optimal control
and motion planning for robots. In particular, by analyzing
optimal sequences of motion primitives, we ensure that the
trajectories found may be described geometrically, without
recourse to numerical solutions of differential equations. By
adding a cost to switch between controls (perhaps not such
an unreasonable thing to do), we also ensure existence of
solutions that do not involve chattering.
At least two major challenges remain to apply our KKT-
based approach to a general model of optimal sequences of
motion primitives; such a model would include obstacles
and more complex control systems than the Reeds-Shepp
bench we studied. The ﬁrst challenge is irregular optimal
trajectories, for which KKT does not apply. For particular
simple systems, it is possible to exactly describe all irregular
trajectories (where constraints are redundant or dependent)
and analyze whether they may be optimal. It is not immedi-
atelyclearhowthisproblemmaybesolvedinamoregeneral
setting. The second challenge is the potential profusion of
optimal trajectory structures. For simple systems, the number
of structures is small; for more complicated systems, an
algorithm might potentially need to explore a number of
structures that is exponential in the number of primitive
actions along the path. We conjecture that exploration of
these discrete structures might be accomplished in an efﬁ-
cient order by a discrete search algorithm such as A*.
This work was supported in part by NSF grant IIS-
0643476, and we would also like to thank Vladimir Chernov
for insightful discussion, in particular leading to the proof of
Theorem 1.
REFERENCES
[1] Pankaj K. Agarwal, Therese Biedl, Sylvain Lazard, Steve Robbins,
Subhash Suri, and Sue Whitesides. Curvature-constrained shortest
paths in a convex polygon. In SIAM J. Comput, pages 392–401. ACM
Press, 1998.
[2] Jérîme Barraquand and Jean-Claude Latombe. Robot motion planning:
a distributed representation approach. ijrr, 10(6):628–649, Dec 1991.
[3] Mokhtar S. Bazaraa, Hanif D. Sherali, and C. M. Shetty. Nonlin-
ear Programming: Theory and Algorithms. Wiley-Interscience, 3rd
edition, May 2006.
[4] John M. Blatt. Optimal control with a cost of switching control. The
ANZIAM Journal, 19:316–332, 6 1976.
[5] H. R. Chitsaz. Geodesic problems for mobile robots. PhD thesis,
University of Illinois at Urbana-Champaign, 2008.
[6] Hamid Reza Chitsaz, Steven M. LaValle, Devin J. Balkcom, and
Matthew T. Mason. Minimum wheel-rotation paths for differential-
drive mobile robots. I. J. Robotic Res., 28(1):66–80, 2009.
[7] M. Chyba and T. Haberkorn. Designing efﬁcient trajectories for under-
water vehicles using geometric control theory. In 24rd International
Conference on Offshore Mechanics and Artic Engineering, Halkidiki,
Greece, 2005.
[8] E. J. Cockayne and G. W. C. Hall. Plane motion of a particle subject
to curvature constraints. SIAM Journal on Control, 13(1):197–220,
1975.
[9] Guy Desaulniers. On shortest paths for a car-like robot maneuvering
around obstacles. Robotics and Autonomous Systems, 17(3):139 – 148,
1996.
[10] L. E. Dubins. On curves of minimal length with a constraint on
average curvature, and with prescribed initial and terminal positions
and tangents. American Journal of Mathematics, 79(3):pp. 497–516,
1957.
[11] Andrei Furtuna. Minimum Time Kinematic Trajectories for Self-
Propelled Rigid Bodies in the Unobstructed Plane. PhD thesis,
Dartmouth College, June 2011.
[12] David Hsu, Robert Kindel, Jean-Claude Latombe, and Stephen M.
Rock. Randomized kinodynamic motion planning with moving obsta-
cles. I. J. Robotic Res., 21(3):233–256, 2002.
[13] Steven M. Lavalle. Rapidly-exploring random trees: A new tool for
path planning. Technical report, Computer Science Department, Iowa
State University, October 1998.
[14] L. S. Pontryagin, V. G. Boltyanskii, R. V. Gamkrelidze, and E. F.
Mishchenko. Mathematical Theory of Optimal Processes. John Wiley
& Sons Inc, January 1962.
[15] J. A. Reeds and L. A. Shepp. Optimal paths for a car that goes both
forwards and backwards. Paciﬁc Journal of Mathematics, 145(2):367–
393, 1990.
[16] David B. Reister and Francois G. Pin. Time-optimal trajectories for
mobile robots with two independently driven wheels. International
Journal of Robotics Research, 13(1):38–54, February 1994.
[17] Marc Renaud and Jean-Yves Fourquet. Minimum time motion of a
mobile robot with two independent acceleration-driven wheels. In
Proceedings of the 1997 IEEE International Conference on Robotics
and Automation, pages 2608–2613, 1997.
[18] P. Souères and J.-D. Boissonnat. Optimal trajectories for nonholo-
nomicmobilerobots. InJ.-P.Laumond,editor,RobotMotionPlanning
and Control, pages 93–170. Springer, 1998.
[19] Héctor J. Sussmann and Guoqing Tang. Shortest paths for the
Reeds-Shepp car: A worked out example of the use of geometric
techniques in nonlinear optimal control. Technical report, Department
of Mathematics, Rutgers University, 1991.
112
