Inverse Optimal Control for Differentially Flat Systems with
Application to Locomotion Modeling
Navid Aghasadeghi and Timothy Bretl
Abstract— Inverse optimal control is the problem of comput-
ing a cost function with respect to which observed trajectories
of a given dynamic system are optimal. In this paper, we
present a new formulation of this problem for the case where
the dynamic system is differentially ﬂat. We show that a
solution is easy to obtain in this case, in fact reducing to
ﬁnite-dimensional linear least-squares minimization. We also
show how to make this solution robust to model perturbation,
sampled data, and measurement noise, as well as provide a
recursive implementation for online learning. Finally, we apply
our new formulation of inverse optimal control to model human
locomotion during stair ascent. Given sparse observations of
human walkers, our model predicts joint angle trajectories
for novel stair heights that compare well to motion capture
data (R
2
= 0:97;RMSE = 1:95 degrees). These exemplar
trajectories are the basis for an automated method of tuning
controller parameters for lower-limb prosthetic devices that
extends to locomotion modes other than level ground walking.
I. INTRODUCTION
Inverse optimal control (IOC) is the problem of computing
a cost function with respect to which observed trajectories of
a given dynamic system are optimal. The cost function is then
a concise model of “expert” behavior that can be used as the
basis for imitation learning [1]. Applications of this approach
include learning aerobatic helicopter maneuvers [2], learning
skills like swinging a forehand with a humanoid robot [3],
complex manipulation on a robot arm [4], [5], and human
gesture learning [6].
Formulations of inverse optimal control vary depending
on the class of dynamic system under consideration. The
works [7], [8] develop IOC approaches for systems modeled
as Markov decision processes (MDP). Moreover, IOC ap-
proaches for non-linear continuous-time systems have been
developed for the deterministic [9] and stochastic [10] cases.
Many of these formulations lead to methods of solution that
are computationally complex, so recent work has focused on
taking advantage of special structure of the systems such as
linearly-solvable MDPs [11] .
In this paper, we introduce an approach to inverse optimal
control for the class of differentially ﬂat systems [12], [13].
For such systems, the deterministic non-linear optimal con-
trol problem can be equivalently written as an unconstrained
calculus of variations problem. We show that this equiva-
lence has ﬁve important consequences for the corresponding
inverse optimal control problem. First, we demonstrate that
N. Aghasadeghi is with the Department of Electrical and Computer
Engineering and T. Bretl is with the Department of Aerospace Engineering,
University of Illinois at Urbana-Champaign, Urbana, IL, 61801, USA
faghasad1,tbretlg@illinois.edu
the solution of the inverse optimal control problem becomes
“easy”, in fact reducing to ﬁnite-dimensional linear least-
squares minimization. Second, we precisely derive conditions
for unique estimation of the cost parameters given a set of
demonstrations and basis functions for the cost. Third, we
show that the problem of IOC for differentially ﬂat systems
does not explicitly depend on the dynamic equations, thus
leading to a robust estimation in the presence of model
perturbations. In this sense our algorithm is similar to model-
free IOC algorithms [10], [14]. Fourth, we demonstrate how
standard ﬁltering techniques can be applied to the problem
of IOC, to obtain better solutions in the presence of sampled
data and measurement noise. Fifth, a recursive version of
the IOC solution can be formulated for differentially ﬂat
systems, making this approach suitable for online robot
learning applications.
An important motivation for developing the proposed IOC
algorithm is to learn controllers for lower-limb prosthetic
devices. A common strategy for control of these devices
proceeds by breaking a gait cycle into four phases, and
by applying a proportional derivative (PD) feedback policy
within each phase [15]. A challenge in the application of this
controller is that it requires the choice of many parameters,
in particular 12 parameters for the knee joint. Currently
clinicians choose these parameters by trial and error for each
patient as noted in [15], [16]. This tuning process takes four
hours for each locomotion mode, for e.g. level ground walk-
ing or stair/ramp ascent. In fact different controllers need to
be tuned to provide locomotion for different inclinations of
stairs and ramps [16].
In [17] we proposed a framework for automatically learn-
ing prosthetic controller parameters customized to an indi-
vidual amputee for level ground walking. The proposed algo-
rithm made use of a set of exemplar outputs corresponding to
level walking, which have been shown to be invariant across
subjects. These invariant outputs correspond to outputs of a
ﬁve-link fully-actuated bipedal model, which is differentially
ﬂat [18]. We are interested in extending this method to
learning prosthetic controllers for other locomotion modes
such as ascending stairs and ramps of different inclinations.
However, a major challenge is that we need exemplar loco-
motion outputs corresponding to any desired inclination of
stair or ramp to use in the framework.
The proposed method of inverse optimal control exactly
overcomes this challenge. By applying this method to the
outputs of a ﬁve-link differentially ﬂat biped, we can produce
exemplar locomotion trajectories for stairs and ramps of
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
U.S. Government work not protected by
U.S. copyright
6018
different inclinations. These exemplar trajectories can then
immediately be used in the prosthetic learning framework
proposed in [17] to ﬁnd prosthetic controller parameters for
different modes of locomotion. The proposed method of IOC
based on differential ﬂatness is well-suited for this applica-
tion. Due to the efﬁciency and scalability of the algorithm,
we can learn cost functions composed of a large number of
features. The learned cost function is also expected to work
well for novel circumstances, due to the theoretical guaran-
tees on estimation of unique cost parameters. Furthermore,
the model-free nature of the algorithm is desirable since we
often have data corresponding to multiple subjects, where
the physical characteristics of the subjects, such as the mass
of their body segments are not exactly known. Using the
proposed method, we do not need to model these unknown
and complex physical dynamics of the subjects. In this paper,
we will describe how using sparse observations of stair ascent
we can learn an IOC model. Subsequently, we demonstrate
the power of the model in predicting locomotion outputs for
a novel stair height and verify the predictions by comparing
to motion captured data.
The remainder of the paper proceeds as follows. In sec-
tion II we discuss an existing formulation of IOC for deter-
ministic nonlinear systems. Theory of IOC for differentially
ﬂat systems is introduced in section III and is demonstrated
on a simulated system in section IV. Subsequently, we apply
the IOC method to model human stair ascent in section V
and we conclude in section VI.
II. EXISTING INVERSE OPTIMAL CONTROL
FORMULATION AND SOLUTION
Consider the following deterministic non-linear
continuous-time optimal control problem
min
x;u
Z
t
f
t0

T
(x;u)dt (1)
subject to _ x =f(x;u);
x(t
0
) =a;
x(t
f
) =b; (2)
where x2 R
n
represents the state of the system, u2 R
m
represents the inputs, f(x;u) :R
n+m
!R
n
represents the
system dynamics and t
0
;t
f
2 R
+
represent the initial and
ﬁnal time. The known basis functions (x;u) : R
nm
!
R
p
together with the cost parameters 

2 R
p
represent
a cost function to be minimized. Note that for simplicity
of presentation, additional state-input constraints on the
optimization (1) have not been included. However, both
the existing method of IOC, and the proposed method are
suitable for handling constraints, as we describe later.
A. Existing IOC Formulation
The problem of inverse optimal control for deterministic
nonlinear systems, as noted in [9], [19], is often posed as
ﬁnding the unknown cost parameters 

given observations
of the outputs y = h(x;u;:::;u
(j)
)2R
q
for a ﬁnite j, and
given known system dynamics _ x =f(x;u) and known basis
functions (x;u).
The existing formulation of this approach discussed in [9],
deﬁnes the following optimization to solve for the cost
parameter
arg min

Z
t
f
t0
jjy(t) y(t;)jj
2
dt; (3)
where the norm is often chosen to be an L
2
-norm. Here
y(t) is the observed output, andy(t;) is the solution to the
following optimal control problem
min
x;u
Z
t
f
t0

T
(x;u)dt (4)
subject to _ x =f(x;u);
x(t
0
) =a;x(t
f
) =b;
y(t;) =h(x;u;:::;u
(j)
):
B. Existing Solution Approach
An existing approach [9] to solving the optimization (3)-
(4) proceeds by iteratively solving the optimal control prob-
lem (4) and updating the estimate of. Thus in applications
where solving the optimal control problem is computation-
ally expensive, this iterative IOC approach is faced with a
computational bottleneck. Other approaches such as [19],
solve (3)-(4) by discretizing time and by forming a non-
linear program (NLP).
III. INVERSE OPTIMAL CONTROL FOR DIFFERENTIALLY
FLAT SYSTEMS
In this section, we introduce an IOC approach for the
class of differentially ﬂat systems. We ﬁrst discuss how by
focusing on the class of differentially ﬂat systems, we can
represent the optimal control problem (1) as an equivalent
unconstrained calculus of variation problem. Subsequently
for this class of systems, we introduce an alternative formu-
lation of the IOC problem that is based on minimizing the
extent to which ﬁrst-order necessary conditions of optimality
are violated.
A system is differentially ﬂat [12], [13] if all the states
x and inputs u can be obtained from the outputs without
integration. More precisely, a system is differentially ﬂat if
for outputs y =h(x;u;:::;u
(j)
)2R
m
there exists functions

x
and 
u
such that
x =
x
(y; _ y;:::;y
(k)
) (5)
u =
u
(y; _ y;:::;y
(k)
) (6)
for some ﬁnite k-th order time derivative of the outputs
denoted by y
(k)
. Note that for a system to be differentially
ﬂat, the number of outputs q should equal the number
of inputs m, i.e. the number of equations by which the
ordinary differential equation (ODE) _ x = f(x;u) is under-
determined. In this paper, we will use the terms differentially
ﬂat and ﬂat interchangeably. Some examples of ﬂat systems
include fully actuated Lagrangian systems such as a fully
actuated ﬁve-link biped, the car with N trailers, and a
kinematic chain [18].
6019
For such systems, the optimal control problem (1) is
equivalent to the following calculus of variation problem on
the ﬂat outputs as discussed in [20]–[22]
min
y;:::;y
(k)
Z
t
f
t0

T
(
x
(y;:::;y
(k)
);
u
(y;:::;y
(k)
))dt
(7)
subject to 
x
(y(t
0
);:::;y
(k)
(t
0
)) =a

x
(y(t
f
);:::;y
(k)
(t
f
)) =b:
Now the problem of inverse optimal control for ﬂat systems
is to ﬁnd the unknown parameters 

given the observed
ﬂat outputs y and known basis function (
x
(Y );
u
(Y )).
Here Y = [1;y; _ y;:::;y
(k)
]
T
denotes the outputs and their
higher order derivatives (we have also added the constant 1
to specify that the functions 
x
and 
u
can have constant
terms independent of the outputs). Note that since the opti-
mization (7) is no longer constrained by the dynamics, the
corresponding IOC problem does not explicitly depend on
the dynamic equations and only requires observations of the
ﬂat outputs.
A. Proposed IOC Formulation
In this section, we describe an alternative formulation of
the IOC problem based on our previous work [23], [24], for
the case where the system is differentially ﬂat. We proceed
by writing the Euler-Lagrange equations corresponding to
the ﬁrst order necessary conditions of optimality of (7) for
an unknown parameter  as follows

T
k
X
`=0
( 1)
`
d
`
dt
`
@
@y
(`)
1



x
(Y );
u
(Y )

= 0;
.
.
.

T
k
X
`=0
( 1)
`
d
`
dt
`
@
@y
(`)
m



x
(Y );
u
(Y )

= 0;
(where y
(0)
=y and
d
0
dt
0
y =y). We can write the necessary
conditions of optimality succinctly as

T
k
X
`=0
( 1)
`
d
`
dt
`

y
(`)


x
(Y );
u
(Y )

= 0 (8)
where 
z
(
x
(Y );
u
(Y )) denotes the Jacobian of
(
x
(Y );
u
(Y )) with respect to the vector z, and
y
(j)
= [y
(j)
1
;y
(j)
2
;:::;y
(j)
m
]
T
denotes thej-th derivative of the
vector of outputs y. We further deﬁne the residual function
r(;Y (t)) as
r(;Y (t)) =
T
k
X
`=0
( 1)
`
d
`
dt
`

y
(`)


x
(Y );
u
(Y )

To solve for the unknown parameters, we formulate the
IOC problem as minimizing the extent to which the ﬁrst
order necessary conditions of optimality are violated, i.e. by
minimizing the L
2
norm of the residual as follows
^
 = arg min

Z
t
f
t0





r(;Y (t))






2
dt (9)
subject to 
1
= 1:
This IOC formulation can equivalently be seen as a pa-
rameter estimation problem for the ODE equation (8) given
the observations Y . Different methods of ODE parameter
estimation have been developed using maximum likelihood
estimation [25] and least squares optimization [26]. The
optimization (9) corresponds to a least squares method for
ODE parameter estimation [26]. Also, note that since this
formulation relies on the ﬁrst-order necessary conditions of
optimality, our approach can also be applied to observed
locally optimal trajectories, similar to [27], while also en-
suring unique estimation of the cost parameters discussed in
section III-C.
Note that the constraint on the parameter vector  (here
on the ﬁrst element of the vector ) is required to ensure
that we ﬁnd a non-trivial solution, since otherwise the all
zero solution will minimize the objective. Also note that
the optimization (7) has the same solution if we scale the
cost by a positive number. Therefore, IOC in principle can
only ﬁnd 

up to a scaling. The inclusion of the constraint
thus ensures the possibility of having a unique solution. The
choice of the constraint 
1
= 1 requires domain knowledge.
However, the only domain knowledge necessary beforehand
is that
1
6= 0, and the exact value of
1
need not be known,
again because cost functions scaled by a positive number
lead to the same solution.
We should also note that additional constraints on the ﬂat
outputs can be added to optimization (7). Constraints that
impose additional necessary conditions of optimality as a
function of the unknown cost parameters can be incorporated
in the residual minimization. Otherwise if they are not
functions of the cost parameters, they will not change the
IOC optimization.
B. Proposed IOC Solution Approach based on Linear Least
Squares
In this section, we derive the least squares solution to
optimization (9). First we deﬁne
A
T
(Y (t)) =  
h
P
k
`=0
( 1)
` d
`
dt
`

y
(`)


x
(Y );
u
(Y )
i
2:p
,
and b
T
(Y (t)) =
h
P
k
`=0
( 1)
` d
`
dt
`

y
(`)


x
(Y );
u
(Y )
i
1
.
Here the notation
h
X
i
1
denotes the ﬁrst row of the matrix
X and
h
X
i
2:p
denotes the second through p-th rows of
the matrix X. Furthermore, we write 
T
= [1;
~

T
]. The
optimization (9) can equivalently be written as follows when
we replace the constraint 
1
= 1 in the objective
^
 = arg min
~

Z
t
f
t0
jjb(Y (t)) A(Y (t))
~
jj
2
dt (10)
6020
The minimization can be written as
min
~

Z
t
f
t0
(b
T
b  2
~

T
A
T
b +
~

T
A
T
A
~
)dt:
Differentiating the convex objective with respect to the
constant
~
 and equating to zero yields the equation

Z
t
f
t0
A
T
(Y (t))A(Y (t)) dt

^
 = (11)

Z
t
f
t0
A
T
(Y (t))b(Y (t)) dt

:
Equation (11), which is the continuous-time analog to the
discrete-time linear least squares solution, thus solves the
IOC problem in closed form. Note that standard Gaussian
elimination or LU decomposition techniques can be used to
ﬁnd numerically stable solutions to the equation (11). Also
note that if A
T
A is not bounded, we can get a bounded
signal by normalization [28]. Thus from now on without loss
of generality we will always assume A
T
A is bounded.
C. Properties of The Solution
To analyze the uniqueness of the solution, note that if
the matrix
R
t
f
t0
A
T
Adt is full rank, a unique estimate
^
 is
obtained. Also note that the true cost parameter 

satisﬁes
the necessary conditions of optimality (8), and therefore
guarantees the existence of a solution to the optimiza-
tion (10). Therefore when the matrix
R
t
f
t0
A
T
Adt is full rank
we can conclude that the unique estimate equals the true
cost parameter, i.e.
^
 = 

. In practice, one can check the
condition number of the matrix instead of the rank to evaluate
this condition.
D. Solution in the Presence of Noise and Sampled Data
Next, we will discuss two methods for computing an
estimate of the cost parameters when the observed outputs
are sampled and noisy. Both methods can lead to consistent
estimation of the cost parameter, and the choice of the
method depends on the application of interest. The ﬁrst
method will be based on spline-ﬁtting the observed outputs,
and the second method will make use of output ﬁltering.
1) Solution via Spline-Fitting: Consider observing sam-
pled noisy outputs. We model these observations as z(k)2
R
p
where k = 1;:::;N as follows
z(k) =y(t
k
) +
k
where t
0
t
1
:::t
N
t
f
(12)
and 
k
N(0; 
p
); 
p
> 0:
The problem of ﬁnding an estimate of the cost parameter
 in (8) can be considered as a parameter estimation prob-
lem for ODEs. An approach to parameter estimation using
sampled noisy observations [26] proceeds in two steps
1) Find a consistent nonparametric estimate of y(t),
which we denote by ~ y(t) and its derivatives ~ y
(n)
(t)
using observations z(k)
2) Use the continuous-time estimates of the outputs to
obtain an estimate of the unknown parameters
The problem of ﬁnding consistent nonparametric estimates
has been largely studied and it is shown that such estimates
can be constructed using splines and polynomial regression
approaches [29], among others. Moreover, consistent esti-
mates of the derivatives of y(t) can also be obtained by
differentiating ~ y(t) as described in [30].
Using the described two-step approach, it is shown [26]
that we can ﬁnd consistent estimates of the ODE parameters,
which correspond to cost parameters in our work.
2) Solution via Output Filtering: In solving the IOC
problem via optimization (10) we make use of higher order
derivatives (HOD) of the observed outputs y(t). Since we
often only observe y(t) and not its derivatives, we have to
rely on numerical differentiation methods to estimate these
HODs. This approach was used to do IOC via spline ﬁtting.
In this section we develop an alternative method of IOC
based on ﬁltering, which does not require computing HODs.
Note that the matrix A(Y (t)) and vector b(Y (t)) each have
entries that are functions of [y; _ y;:::;y
(r)
] up to some ﬁnite
derivative of order r. We proceed by ﬁltering the entries of
A(Y (t)) and b(Y (t)) using an r-th order stable ﬁlter
1
(s)
=
1
s
r
+
r 1
s
r 1
+ +
0
: (13)
We apply this ﬁlter to both sides of the necessary conditions
of optimality (8) as follows
1
(s)
Lfb(Y (t))g =
b
L
(s)
(s)
Y
L
(s)
1
(s)
LfA(Y (t))g
~
 =
A
L
(s)
(s)
Y
L
(s)
~

whereL represents the Laplace operator, and A
L
(s) and
b
L
(s) denote matrices of same size asA(Y (t)) andb(Y (t))
respectively. The entries of A
L
(s) and b
L
(s) are polyno-
mial functions of s, and satisfy equations A
L
(s)Y
L
(s) =
LfA(Y (t))g and b
L
(s)Y
L
(s) = Lfb(Y (t))g. Therefore,
using this approach, we can treat every entry of
A
L
(s)
(s)
and
b
L
(s)
(s)
as a ﬁlter that is being applied to the observed outputs,
and we eliminate the need for numerical computation of
derivatives. Moreover, we can use the well-established theory
of signal processing to design ﬁlters that can handle different
kinds of measurement noise. By deﬁning the ﬁlter outputs
~
b(t) =L
 1
f
b
L
(s)
(s)
Y
L
(s)g
~
A(t) =L
 1
f
A
L
(s)
(s)
Y
L
(s)g;
we can now write the following IOC optimization, which
can be solved as in (10)
^
 = arg min
~

Z
t
f
t0
jj
~
b(t) 
~
A(t)
~
jj
2
dt: (14)
To apply this method to sampled dataz(k) which are gen-
erated according to (12), with the assumption thatt
i
 t
i 1
=
t;8i, we can make use of the bilinear transformation [31]
s =
2
t
z 1
z+1
to convert the continuous-time ﬁlter to a discrete-
time ﬁlter.
6021
E. Recursive Solution
Real-time learning is an important topic in robotics,
since robots often encounter new situations and need to be
equipped with the ability to self-improve [32]. In this section,
we develop a recursive method of IOC for ﬂat systems.
This method will allow us to update the estimate of the
cost parameters upon receiving new observations without
resolving the complete IOC problem.
As we described, to solve IOC given dataY (s) from time
t
0
to t (i.e. t
0
st) we solve the following optimization
^
(t) = arg min
~

Z
t
t0
jjb(Y (s)) A(Y (s))
~
jj
2
ds:
To develop a recursive version of the IOC, we propose
minimizing the following objective with respect to
~

J(
~
) =
Z
t
t0
jjb(Y (s)) A(Y (s))
~
jj
2
ds
+
1
2
(
~
 
0
)
T
Q
0
(
~
 
0
);
where we have added an extra cost to penalize deviation
from some initial guess 
0
using a positive deﬁnite matrix
Q
0
> 0. Note that given multiple demonstrations, we can
solve the recursive IOC for the current demonstration, and
use the estimated cost parameter as an initial guess when
given the subsequent demonstration.
The objectiveJ(
~
) is convex in
~
 and we set the gradient
to zero to ﬁnd the following equation that solves for
^
 up to
time t
^
(t) =

Z
t
t0
A
T
Ads +Q
0

 1

Z
t
t0
A
T
bds +Q
0

0

:
We deﬁne the matrix P (t) as
P (t) :=

Z
t
t0
A
T
Ads +Q
0

 1
:
Note that P (t) is well deﬁned because A
T
A 0 and Q
0
>
0. To compute the cost parameter estimate
^
(t) recursively,
we obtain an expression for
_
P as
PP
 1
=I) 0 =
d
dt
(PP
 1
) =
_
PP
 1
+PA
T
A
)
_
P = PA
T
AP;
and subsequently obtain a differential equation for
^
 as
_
^
 =
_
P

Z
t
t0
A
T
bds +Q
0

0

+PA
T
b
= PA
T
AP

Z
t
t0
A
T
bds +Q
0

0

+PA
T
b
= PA
T
A
^
 +PA
T
b:
Thus the recursive IOC solution can be obtained from
_
^
 = PA
T
A
^
 +PA
T
b (15)
_
P = PA
T
AP:
Using theorem 4.3.2 in [28] we can show that the recursive
solution
^
(t) converges to a constant

, and if the matrix
A(t)
T
is persistently exciting, the solution converges to the
true cost parameter

. We sayA(t)
T
is persistently exciting
if for some 
0
;T
0
> 0 we have
Z
t+T0
t
A
T
(s)A(s)ds
0
T
0
I;8t:
IV. UNICYCLE EXAMPLE
In this section, we show how to apply the proposed IOC by
considering a unicycle example. We consider the following
optimal control problem
arg min
x;u;v
Z
t
f
t0

1
2
(x
1
(t) x

1
)
2
(16)
+

2
2
(x
2
(t) x

2
)
2
+

3
2
v
2
(t)dt;
subject to _ x(t) =
2
4
v(t) cos(x
3
(t))
v(t) sin(x
3
(t))
u(t)
3
5
x
1
(0) =a
1
;x
2
(0) =a
2
x
1
(1) =b
1
;x
2
(1) =b
2
:
Here x(t)2R
3
denotes the state of the unicycle at time t,
and u(t);v(t)2R denote the control inputs at time t. The
unknown cost parameters consist off
1
;
2
;
3
;x

1
;x

2
g. A
unicycle is differentially ﬂat [13] with ﬂat outputs y
1
(t) =
x
1
(t) and y
2
(t) = x
2
(t). Thus, the optimal control prob-
lem (16) can equivalently be written as
arg min
y1;y2
Z
t
f
t0

U
(y
1
(t); _ y
1
(t);y
2
(t); _ y
2
(t))dt = (17)
arg min
y1;y2
Z
t
f
t0
h

1
2
(y
1
(t) x

1
)
2
+

2
2
(y
2
(t) x

2
)
2
+

3
2
( _ y
2
1
(t) + _ y
2
2
(t))
i
dt
subject to y
1
(0) =a
1
;y
2
(0) =a
2
y
1
(1) =b
1
;y
2
(1) =b
2
:
To ﬁnd the cost parameters, we write the ﬁrst order
necessary conditions of optimality for (17) as follows

1
y
1
(t) 
1
x

1
 
3
 y
1
(t) = 0;

2
y
2
(t) 
2
x

2
 
3
 y
2
(t) = 0: (18)
We redeﬁne the unknown parameters as
~

1
= 
1
;
~

2
=

2
;
~

4
=  
1
x

1
and
~

5
=  
2
x

2
and we ﬁx 
3
= 1.
Now the necessary conditions of optimality are linear in the
unknowns
~

i
(although the original objective was nonlinear
in the parameters) and we can solve

Z
1
0
2
6
6
4
y
1
(t) 0
0 y
2
(t)
1 0
0 1
3
7
7
5

y
1
(t) 0 1 0
0 y
2
(t) 0 1

dt

^
 =

Z
1
0
2
6
6
4
y
1
(t) 0
0 y
2
(t)
1 0
0 1
3
7
7
5

 y
1
(t)
 y
2
(t)

dt

: (19)
6022
Now we consider the case that we only observe sampled
noisy observations z(k) and demonstrate the use of output
ﬁltering. The spline-ﬁtting approach can be applied in a
similar and straight-forward way as well. We proceed by
applying the following stable third-order ﬁlter
1
(s)
=
1
(s + 1)(s + 2)(s + 3)
to the Laplace transform of equations (18) to get
~

1
1
(s)
(Y
1
(s) y
1
(t
0
)) +
~

4
1
s(s)
=
s
2
(s)
Y
1
(s) 
s
(s)
y
1
(t
0
) 
1
(s)
_ y
1
(t
0
);
~

2
1
(s)
(Y
2
(s) y
2
(t
0
)) +
~

5
1
s(s)
=
s
2
(s)
Y
2
(s) 
s
(s)
y
2
(t
0
) 
1
(s)
_ y
2
(t
0
):
The four ﬁlters
1
s(s)
;
1
(s)
;
s
(s)
and
s
2
(s)
are converted
to discrete-time ﬁlters using the discussed bilinear trans-
formation. The IOC problem is then solved using the ﬁl-
tered outputs as described in Section III-D.2. A monte-
carlo simulation was performed using 300 different boundary
conditions and cost parameters that were uniformly randomly
generated. Each experiment was repeated with different noise
levels ranging from a signal-to-noise ratio (SNR) of 0 to 30.
Fig. 1 shows that as we expect, the estimated cost parameter
approaches its true value.
0 10 20 30
0
5
10
15
20
25
30
35
40
SNR (dB)
% Error in Cost Parameters
Fig. 1: IOC estimation error vs. SNR level
V. APPLICATION TO BIPEDAL LOCOMOTION AND
PROSTHETIC CONTROLLER DESIGN
In this section, we will use the proposed method of IOC
to obtain a model for human stair ascent, with application to
learning controllers for lower-limb prosthetic devices. These
devices are commonly controlled by impedance control. This
strategy breaks the gait cycle into four phases and uses a
PD feedback policy within each phase. Currently clinicians
choose the PD gains, which consist of 12 parameters for
the knee, through a time-consuming trial and error process.
In [17] we proposed a framework to automate this tuning pro-
cess for level walking. However, to extend this framework to
other locomotion modes, we need a model that can generate
exemplar locomotion trajectories, since such trajectories are
not always available. We overcome this challenge by learning
an IOC model capable of generating exemplar trajectories
corresponding to any desired stair height.
?
T1
?
S1
?
T2
?
S2
?
tr
Fig. 2: Five Link Biped Model
We will make use of a ﬁve link fully actuated biped
model shown in Fig. 2. Fully actuated mechanical systems
are known to be differentially ﬂat, with the joint angles as a
candidate for ﬂat outputs [33]. While this is a simple model,
we will demonstrate that through the use of the proposed
IOC algorithm it can learn and predict human locomotion
trajectories. To derive a model of locomotion based on IOC,
we make some design choices and will explain the motivation
for these choices below.
A. Elevation Angles Instead of Joint Angles
A major challenge in learning lower-limb prosthetic con-
trollers is that people with different physical characteristics
(such as height and weight) walk with different joint trajecto-
ries. In [17] we overcome this problem by utilizing elevation
angle trajectories as opposed to joint angles. These outputs
have shown to be invariant across different subjects [34]
and have been hypothesized to be controlled by the central
nervous system [35]. The angles are shown in Fig. 2 and can
be obtained from linear combination of joint angles, thus they
also form a set of ﬂat outputs. In Fig. 2 the subscripts T;S
andtr denote thigh, shank and torso. Also stance is denoted
by subscript 1 and swing by subscript 2.
B. Structure for the Cost Function
We model the cost for stair ascent as having a component
that is independent of the stair height, and a component that
is modulated by the stair height. We assume that the cost
component corresponding to the thigh is directly modulated
by the stair height, however, the cost component correspond-
ing to the shank is independent of the stair height, and the
shank angle is implicitly modulated through the thigh.
This cost structure is motivated by results in [36], [37]
that propose the existence of kinetic and kinematic synergies
between the shank and the thigh. Moreover, results in [38],
[39] suggest that the thigh is modulated in a feedforward
manner to produce different speeds and locomotion modes.
We learn a cost function 
L
composed of the summation
of the following parts for both stance and swing phases
6023
separately (We are omitting the stance and swing subscripts
i = 1; 2 for notational simplicity.)
 
1
(
S
;
T
) : representing the component of the cost
function capturing the relationship between the shank
(
S
) and thigh (
T
) elevation angles.
 
2
(
T
;h) : representing the component modulated by
the stair height h.
 
3
(
tr
) : representing the cost for the torso.
Next we describe the different features that the functions

1
;
2
and
3
are composed of weighted by cost parameters

i
.
1) Features Modeling Shank and Thigh Relationship: The
cost component 
1
equals the summation of the following
features:
 (
S
 
1
)
2
: denotes the cost of regulation of the shank
angle to a set point.
 
2
_ 
2
S
: denotes cost on angular velocity of the shank
 
3
_ 
2
T
: denotes cost on angular velocity of the thigh
 
4

S

T
+
5

S

2
T
+
6

2
S

T
: denotes monomial basis
functions modeling the relationship between the shank
and the thigh.
 
7
sin(
S
) +
8
cos(
S
) +
9
sin(
T
) +
10
cos(
T
) +
(
11
sin(
S
) + 
12
sin(
T
))
2
+ (
13
cos(
S
) +

14
cos(
T
))
2
: this feature corresponds to attractors
for foot position, and can be derived by expanding cost
on foot position regulation.
2) Features Modeling the Modulation of the Thigh: The
thigh angle has an additional cost component 
2
(
T
;h)
which is a function of the stair height as deﬁned below
 (
T
 
15
(h))
2
: denotes the cost of regulation of the
thigh angle to a set point.
3) Features Modeling the Torso: We deﬁne the following
features for the torso
 (
tr
 
16
)
2
: cost of regulation of torso to a set point.
 
17
_ 
2
tr
: denotes cost on angular velocity of the torso.
 
18
sin(
tr
) +
19
cos(
tr
) : denotes sinusoidal basis
functions.
Now given the discussed locomotion cost
L
=
1
+
2
+

3
we consider calculus of variation problem
min

S
;
T
;tr
Z
t
f
t0
e
 t
(
1
(
S
;
T
) +
2
(
T
;m) +
3
(
tr
;m))dt;
where e
 t
represents a discounting factor. We apply the
proposed method of IOC via cubic splines to solve for the
unknown cost parameters. The parameter
15
(h) for swing
is then varied to generate stair ascent trajectories for different
inclinations (for stance 
15
is independet of h).
C. Results and Predicting of Novel Stair Height
We use motion-captured data collected in [40] to learn an
IOC model. These trajectories correspond to average joint
trajectories of ten unimpaired subjects, climbing stairs at
minimum, medium and maximum heights. We used output
trajectories corresponding to the minimum and maximum
stair heights as observations. The proposed method of IOC is
then applied to estimate the cost parameters given these two
observations. To evaluate the performance of our estimated
cost, we evaluate how well we can predict the observed
trajectories in terms of R
2
and RMSE as seen in Fig. 3.
Moreover, the model predicted a novel stair height (medium),
and demonstrated a good ﬁt to motion capture data (R
2
=
0:97 and RMSE = 1:95 degrees.)
0 20 40 60 80 100
!20
0
20
40
60
Thigh Angle (°) Max Height , R
2
=0.99, RMSE=2.2°
Phase Time (%)
0 20 40 60 80 100
!60
!40
!20
0
Shank Angle (°) Max Height, R
2
= 0.97, RMSE= 3.2°
Phase Time (%)
0 20 40 60 80 100
!20
0
20
40
60
Thigh Angle (°) Min Height, R
2
= 0.99, RMSE= 0.91°
Phase Time (%)
0 20 40 60 80 100
!60
!40
!20
0
Shank Angle (°) Min Height, R
2
= 0.93, RMSE= 2.4°
Phase Time (%)
0 20 40 60 80 100
!20
0
20
40
60
Thigh Angle (°) Med Height, R
2
= 0.99, RMSE= 1.7°
Phase Time (%)
0 20 40 60 80 100
!60
!40
!20
0 Shank Angle (°) Med Height, R
2
= 0.95, RMSE= 2.2° 
Phase Time (%)
Fig. 3: Real (solid line) and Predicted (dashed line) stair
ascent trajectories. Swing is shown in blue and stance in
red. Quality of predictions is noted by R
2
and RMSE on
each plot. Data for max and min stair heights were used in
learning, and medium height was a novel prediction by IOC.
6024
VI. CONCLUSION
In this paper we introduced a new formulation of the
problem of inverse optimal control for the case where the
system is differentially ﬂat. We showed that IOC for this
class of systems has a number of desirable properties,
including an efﬁcient ﬁnite-dimensional linear least squares
solution, robustness with respect to model perturbations and
noise in sampled observations. We further demonstrated that
our approach can learn a model of stair ascent using sparse
data, and generate locomotion trajectories for novel stair
heights. Thus this model enables the automated tuning of
lower-limb prosthetic controllers for different locomotion
modes. The scalability and robustness of this approach, along
with its prediction power even with simple dynamic models,
opens the door for many exciting robotic applications.
VII. ACKNOWLEDGMENTS
The authors would like to thank Robert Riener and his
research group for kindly sharing their experimental data.
This work was supported by the National Institute of Neu-
rological Disorders and Stroke of the National Institutes of
Health under award #F31NS080618.
REFERENCES
[1] S. Schaal, “Is imitation learning the route to humanoid robots?” Trends
in cognitive sciences, vol. 3, no. 6, pp. 233–242, 1999.
[2] P. Abbeel, A. Coates, and A. Ng, “Autonomous helicopter aerobatics
through apprenticeship learning,” International Journal of Robotics
Research, vol. 29, no. 13, pp. 1608–1639, 2010.
[3] A. J. Ijspeert, J. Nakanishi, and S. Schaal, “Movement imitation
with nonlinear dynamical systems in humanoid robots,” in Robotics
and Automation, 2002. Proceedings. ICRA’02. IEEE International
Conference on, vol. 2. IEEE, 2002, pp. 1398–1403.
[4] F. Stulp, E. Theodorou, M. Kalakrishnan, P. Pastor, L. Righetti, and
S. Schaal, “Learning motion primitive goals for robust manipulation,”
in Intelligent Robots and Systems (IROS), 2011 IEEE/RSJ Interna-
tional Conference on. IEEE, 2011, pp. 325–331.
[5] E. Gribovskaya, S. M. Khansari-Zadeh, and A. Billard, “Learning non-
linear multivariate dynamics of motion in robotic manipulators,” The
International Journal of Robotics Research, vol. 30, no. 1, pp. 80–117,
2011.
[6] S. Calinon, F. D’halluin, E. L. Sauser, D. G. Caldwell, and A. G.
Billard, “Learning and reproduction of gestures by imitation,” Robotics
& Automation Magazine, IEEE, vol. 17, no. 2, pp. 44–54, 2010.
[7] P. Abbeel and A. Ng, “Apprenticeship learning via inverse rein-
forcement learning,” in Proceedings of the twenty-ﬁrst international
conference on Machine learning. ACM, 2004, p. 1.
[8] B. Ziebart, A. Maas, J. Bagnell, and A. Dey, “Maximum entropy
inverse reinforcement learning,” in Proc. AAAI, 2008, pp. 1433–1438.
[9] K. Mombaur, A. Truong, and J.-P. Laumond, “From human to
humanoid locomotion—an inverse optimal control approach,” Au-
tonomous Robots, vol. 28, no. 3, pp. 369–383, 04 2010.
[10] N. Aghasadeghi and T. Bretl, “Maximum entropy inverse reinforce-
ment learning in continuous state spaces with path integrals,” in
Intelligent Robots and Systems (IROS), 2011 IEEE/RSJ International
Conference on, 2011, pp. 1561–1566.
[11] K. Dvijotham and E. Todorov, “Inverse Optimal Control with Linearly-
Solvable MDPs,” in Proceedings of the Interntional Conference on
Machine Learning. Citeseer, 2010.
[12] M. Fliess, J. L´ evine, P. Martin, and P. Rouchon, “Flatness and defect of
non-linear systems: introductory theory and examples,” International
journal of control, vol. 61, no. 6, pp. 1327–1361, 1995.
[13] R. M. Murray, M. Rathinam, and W. Sluis, “Differential ﬂatness
of mechanical control systems: A catalog of prototype systems,” in
ASME International Mechanical Engineering Congress and Exposi-
tion. Citeseer, 1995.
[14] A. Boularias, J. Kober, and J. Peters, “Relative entropy inverse
reinforcement learning,” in International Conference on Artiﬁcial
Intelligence and Statistics, 2011, pp. 182–189.
[15] F. Sup, A. Bohara, and M. Goldfarb, “Design and control of a pow-
ered transfemoral prosthesis,” The International journal of robotics
research, vol. 27, no. 2, pp. 263–273, 2008.
[16] F. Sup, H. A. Varol, and M. Goldfarb, “Upslope walking with a pow-
ered knee and ankle prosthesis: initial results with an amputee subject,”
Neural Systems and Rehabilitation Engineering, IEEE Transactions
on, vol. 19, no. 1, pp. 71–78, 2011.
[17] N. Aghasadeghi, H. Zhao, L. J. Hargrove, A. D. Ames, E. J. Perreault,
and T. Bretl, “Learning impedance controller parameters for lower-
limb prostheses,” in Intelligent Robots and Systems (IROS), 2013
IEEE/RSJ International Conference on, accepted, 2013.
[18] R. M. Murray, “Nonlinear control of mechanical systems: A lagrangian
perspective,” Annual Reviews in Control, vol. 21, pp. 31–42, 1997.
[19] K. Hatz, J. P. Schloder, and H. G. Bock, “Estimating parameters in
optimal control problems,” SIAM Journal on Scientiﬁc Computing,
vol. 34, no. 3, pp. A1707–A1728, 2012.
[20] S. Agrawal and N. Faiz, “Optimization of a class of nonlinear dynamic
systems: new efﬁcient method without lagrange multipliers,” Journal
of optimization theory and applications, vol. 97, no. 1, pp. 11–28,
1998.
[21] R. Mahadevan, S. K. Agrawal, and F. J. Doyle, “Differential ﬂatness
based nonlinear predictive control of fed-batch bioreactors,” Control
Engineering Practice, vol. 9, no. 8, pp. 889–899, 2001.
[22] J. Oldenburg and W. Marquardt, “Flatness and higher order differ-
ential model representations in dynamic optimization,” Computers &
chemical engineering, vol. 26, no. 3, pp. 385–400, 2002.
[23] N. Aghasadeghi, A. Long, and T. Bretl, “Inverse optimal control for a
hybrid dynamical system with impacts,” in Robotics and Automation
(ICRA), 2012 IEEE/RSJ International Conference on. IEEE, 2012.
[24] M. Johnson, N. Aghasadeghi, and T. Brelt, “Inverse optimal control
for deterministic continuos-time non-linear systems,” in Decision and
Control, 2013. Proceedings of the 52nd IEEE Conference on, accepted.
IEEE, 2013.
[25] J. Ramsay, G. Hooker, D. Campbell, and J. Cao, “Parameter estimation
for differential equations: a generalized smoothing approach,” Journal
of the Royal Statistical Society: Series B (Statistical Methodology),
vol. 69, no. 5, pp. 741–796, 2007.
[26] N. Brunel, “Parameter estimation of odes via nonparametric estima-
tors,” Electronic Journal of Statistics, vol. 2, pp. 1242–1267, 2008.
[27] S. Levine and V . Koltun, “Continuous inverse optimal control with
locally optimal examples,” arXiv preprint arXiv:1206.4617, 2012.
[28] P. A. Ioannou and J. Sun, Robust adaptive control. Courier Dover
Publications, 2012.
[29] A. Berlinet and C. Thomas-Agnan, Reproducing kernel Hilbert spaces
in probability and statistics. Kluwer Academic Boston, 2004.
[30] S. Zhou and D. Wolfe, “On derivative estimation in spline regression,”
Statistica Sinica, vol. 10, no. 1, pp. 93–108, 2000.
[31] A. V . Oppenheim, R. W. Schafer, J. R. Buck et al., Discrete-time signal
processing. Prentice Hall Upper Saddle River, 1999, vol. 5.
[32] S. Schaal, C. G. Atkeson, and S. Vijayakumar, “Scalable techniques
from nonparametric statistics for real time robot learning,” Applied
Intelligence, vol. 17, no. 1, pp. 49–60, 2002.
[33] P. Martin, R. M. Murray, P. Rouchon et al., “Flat systems,” 1997.
[34] N. A. Borghese, L. Bianchi, and F. Lacquaniti, “Kinematic determi-
nants of human locomotion.” The Journal of physiology, vol. 494, no.
Pt 3, pp. 863–879, 1996.
[35] F. Lacquaniti, R. Grasso, and M. Zago, “Motor patterns in walking,”
Physiology, vol. 14, no. 4, pp. 168–174, 1999.
[36] D. A. Winter, Biomechanics and motor control of human gait: normal,
elderly and pathological, 1991.
[37] Y . P. Ivanenko, A. d’Avella, R. E. Poppele, and F. Lacquaniti, “On
the origin of planar covariation of elevation angles during human
locomotion,” Journal of neurophysiology, vol. 99, no. 4, pp. 1890–
1898, 2008.
[38] M. Daley, G. Felix, and A. Biewener, “Running stability is enhanced
by a proximo-distal gradient in joint neuromechanical control,” Jour-
nal of Experimental Biology, vol. 210, no. 3, pp. 383–394, 2007.
[39] M. MacKay-Lyons, “Central pattern generation of locomotion: a
review of the evidence,” Physical Therapy, vol. 82, no. 1, pp. 69–
83, 2002.
[40] R. Riener, M. Rabuffetti, and C. Frigo, “Stair ascent and descent at
different inclinations,” Gait & posture, vol. 15, no. 1, pp. 32–44, 2002.
6025
