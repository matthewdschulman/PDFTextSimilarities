Gaussian Belief Space Planning with Discontinuities in Sensing Domains
Sachin Patil, Yan Duan, John Schulman, Ken Goldberg, Pieter Abbeel
Abstract— Discontinuities in sensing domains are common
when planning for many robotic navigation and manipulation
tasks. For cameras and 3D sensors, discontinuities may be
inherent in sensor ﬁeld of view or may change over time
due to occlusions that are created by moving obstructions
and movements of the sensor. The associated gaps in sensor
information due to missing measurements pose a challenge for
belief space and related optimization-based planning methods
since there is no gradient information when the system state
is outside the sensing domain. We address this in a belief
space context by considering the signed distance to the sensing
region. We smooth out sensing discontinuities by assuming that
measurements can be obtained outside the sensing region with
noise levels depending on a sigmoid function of the signed dis-
tance. We sequentially improve the continuous approximation
by increasing the sigmoid slope over an outer loop to ﬁnd
plans that cope with sensor discontinuities. We also incorporate
the information contained in not obtaining a measurement
about the state during execution by appropriately truncating
the Gaussian belief state. We present results in simulation for
tasks with uncertainty involving navigation of mobile robots and
reaching tasks with planar robot arms. Experiments suggest
that the approach can be used to cope with discontinuities in
sensing domains by effectively re-planning during execution.
I. INTRODUCTION
Our work is motivated by the desire to facilitate reliable,
autonomous robotic manipulation and navigation tasks. For
autonomous operation, robots use sensors to obtain mea-
surements about their state and the state of the environ-
ment they are operating in. Commonly used sensors such
as cameras, laser range ﬁnders, and depth sensors have a
limited range of sensing, outside of which no measurements
or noisy, unusable measurements are obtained. Occlusions
due to robot geometry or objects in the environment may
also be responsible for missing measurements. These factors
induce discontinuities in sensing domains that can introduce
considerable uncertainty during autonomous task execution.
Consider, for instance, a robot, such as Willow Garage’s
PR2 robot, that is equipped with an on-board camera and
depth sensor and is trying to autonomously perform a grasp-
ing and manipulation task. The limited ﬁeld of view of these
sensors and occlusions due to the robot arm obstructing the
view while trying to grasp an object lead to missing mea-
surements that can introduce uncertainty in task execution. A
common workaround is to carefully engineer how the sensors
are positioned and how the arms are moved such that the
object is in the ﬁeld of view of the sensors. Ideally, however,
the robot itself should be capable of planning about its sensor
The authors are with the Department of Electrical Engineering and Com-
puter Science at the University of California at Berkeley, USA. fsachinpatil,
dementrock, joschu, goldberg, pabbeelg@berkeley.edu
(a) Problem setup (b) State space plan (c) Our approach
(d) (e) (f)
Fig. 1. Belief space planning with sensing discontinuity: Comparison of
plans generated by state space and belief space methods for a point robot
moving in a 2D light-dark domain adapted from Platt et al. [18] (Sec. VI-A).
(a) The robot’s start position (upper-left corner), initial uncertainty (ellipse),
and desired target (bottom left corner) are shown in yellow. The robot only
obtains a measurement of its position when it is in the sensing domain (the
white rectangular region on the right hand side). (b) State-space planning
[23] generates a locally-optimal trajectory straight toward the target, un-
aware of the sensing zone, so cannot reduce uncertainty (initial and ﬁnal
uncertainty shown). (c-f) Belief space planning using our approach computes
a trajectory that ﬁrst visits the sensing domain to reduce uncertainty before
headings towards the target. To address the discontinuity in sensing domain,
our algorithm solves a sequence of optimization problems that begin with
(d) a very relaxed (continuous) sigmoid approximation to the step function,
gradually reducing the relaxation (e,f) toward the actual (discontinuous) step
function. The resulting plan shown in (f) is more robust than the plan in (b)
or (d), as detailed in Sec. VI. The beliefs as computed using the continuous
approximation (red) and the true beliefs (yellow), are shown.
and arm motions in a way that it can succeed even in the
presence of uncertainty.
We address the problem of computing locally-optimal
trajectories in belief space, given that measurements may not
be obtained during execution due to factors such as limited
ﬁeld of view of sensors and occlusions. We adopt a trajectory
optimization framework for belief space planning, which has
shown promise in terms of scaling to higher dimensional
belief spaces [3], [23], [15]. Incorporating sensing disconti-
nuities in this optimization framework is challenging since
when no measurements are obtained, there is no gradient
information to guide the optimization to regions where valid
measurements could be obtained.
To handle the discrete transition between a sensor provid-
ing a measurement versus not providing a measurement, we
solve a sequence of optimization problems. Each problem is
a continuous sigmoid approximation of the discontinuities in
the sensing domain [6], and we sequentially improve the ap-
proximation till the true sensing discontinuity is represented
within a user-deﬁned tolerance (Fig. 1). This approach of
continuously deforming an easier problem into the given hard
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
U.S. Government work not protected by
U.S. copyright
6483
problem, while solving a family of deformed problems, is
referred to as an homotopy approach in optimization [29].
Our proposed approach handles limited sensing regions
and occlusions within the same framework by considering
the signed distance to the valid sensing region. Valid mea-
surements are obtained if the expected state of the robot
or other objects is within the valid sensing region, thus
corresponding to a negative signed distance, and obtaining
no measurements corresponds to a positive signed distance.
It is important to note that since measurements obtained
during execution are not known a priori, we revise the plan
according to the revised expected state of the system using
the model predictive control (MPC) paradigm [21] of re-
planning after every time step. During execution, there is
information contained in not obtaining a measurement about
the state, which is incorporated by appropriately truncating
the Gaussian belief state with respect to the boundary of the
valid sensing region [17].
We present results in simulation for tasks involving navi-
gation of mobile robots in environments with limited sensing
regions and for a planar articulated arm performing a reach-
ing task under uncertainty. Our experiments suggest that this
approach can be used to re-plan for model predictive control
to cope with discontinuities in sensing domains.
II. RELATED WORK
Research efforts have focused on solving POMDPs involv-
ing discrete state, action, and/or observation spaces using
approximate value iteration [19], [14] but these approaches
do not currently scale to continuous state, action, and
observation spaces that arise in robotic manipulation and
navigation. Recently, extensions have been proposed to con-
tinuous spaces [1] but these methods may not be suitable for
online planning. Kaelbling et al. [12] proposed an integrated
hierarchical planning framework that combines discrete and
continuous planning by relying upon a regression-based
planner. Factors such as the limited ﬁeld of view of sensors
and occlusions are encoded in this framework using user-
deﬁned task primitives.
As a result, a large subset of prior work has focused on
computing locally optimal solutions for problems involving
robot navigation and manipulation using sampling-based
motion planners or optimization-based methods. Sampling-
based planners [20], [4], [9], [10] can directly incorporate
parametric and nonparametric belief representations and dis-
continuities in sensing domains due to limited sensor ﬁeld
of view or occlusions but these methods do not currently
scale to higher dimensional belief spaces. Optimization-
based methods [8], [18], [27], [15] use a parametric Gaussian
belief state representation and use continuous dynamics and
measurement models that provide gradient information to
the optimization. We consider an extension to optimization-
based methods to handle sensing discontinuities and occlu-
sions by iteratively solving a series of problems that better
approximate the true problem.
Vitus and Tomlin [28] considered the problem of placing
sensors in the environment to minimize the uncertainty in
the state of the robot along a pre-planned trajectory using
numerical optimization. We use a similar relaxation method
as theirs to incorporate sensing discontinuities in a numerical
optimization framework. In our work, we use a belief space
planning formulation that could be used to plan locally-
optimal trajectories for both the robot and deployed sensors.
We also consider heterogeneous sensors and anisotropic
sensing regions induced due to factors such as the limited
ﬁeld of view of sensors or occlusions.
Prior work in the domain of active perception and sensing
[2] has considered the effect of discontinuities in sensing
domains in decision making under uncertainty. We refer the
reader to an extensive survey of developments in this ﬁeld
by Chen et al. [7]. Active perception addresses the question
of where to position sensors and how to make decisions
for next actions, in order to maximize information gain and
minimize cost. Most approaches in this domain assume that
the location of the sensors is known with certainty. The belief
space formulation used in this work is capable of jointly
planning motions for the robot and sensors under uncertainty.
The domain of active exploration considers motion plan-
ning for a mobile robot to minimize uncertainty in the
location of sensed objects in the environment. Proposed
approaches relax the stochastic planning problem to make
it computationally tractable. For instance, a small set of
actions and one-step lookahead (myopic) planning is con-
sidered [25], a reinforcement learning approach based on
a discretized state and action space is evaluated [13], and
active policy search for approximately solving the underlying
POMDP has also been explored [16]. In contrast, our work
uses a belief space planning formulation that optimizes over
the entire belief state.
III. PRELIMINARIES AND OBJECTIVE
State space system: Letx = [
x
R
x
O
] be the system state that
is comprised of the state x
R
of the robot and the state x
O
of other relevant objects in the environment. Let u = [
u
R
u
O
]
denote the combined control input applied to the system and
z = [
z
R
z
O
] be the vector of measurements obtained about the
system state using sensors.
We assume we are given a discrete-time stochastic dynam-
ics model that describes how the system state evolves and a
measurement model that relates the obtained measurements
to the state, given here in state-transition notation:
x
t+1
=f(x
t
;u
t
;q
t
); q
t
N (0;I); (1)
z
t
=h(x
t
;r
t
); r
t
N (0;I); (2)
where we assume that the state space trajectory is discretized
into` time intervals of equal duration,q
t
is the process noise
andr
t
is the measurement noise that is assumed to be drawn,
without loss of generality, from a Gaussian distribution with
zero mean and unit variance and can be scaled appropriately
to be state and control input dependent within the functions
f and h, respectively.
Due to discontinuities in the sensing domain, some of the
dimensions of the measurement vectorz
t
at time stept can-
not be measured using sensors. To quantify this phenomenon,
6484
we deﬁne a binary vector 
t
2R
dim[z]
, where the i
th
entry
in the vector
i
t
takes the value 1 if a measurement of thei
th
dimension of z
t
is obtained at time step t and a value of 0
if no measurement is obtained due to discontinuities in the
sensing domain. We formalize the relationship between the
i
t
variables and valid sensing domains in which measurements
can be obtained, in Sec. IV.
Belief system: We consider a Gaussian parameterization
of the probability distribution over the state, also known as
the belief. Speciﬁcally, the belief state b
t
=

xt
vec[
p
t]

is
a vector comprised of the mean state x
t
and the columns
of the principal square root
p

t
of the covariance 
t
of a
Gaussian distribution N(x
t
; 
t
). We only include the lower
(or equivalently, upper) triangular entries of
p

t
to eliminate
redundancy in the belief state.
We assume that the initial belief b
0
=

x0
vec[
p
0]

is
given. Given a current belief b
t
, a control input u
t
, and a
measurement z
t+1
, the belief state evolves using a Kalman
ﬁlter (such as an extended Kalman ﬁlter) and is a stochastic
process [27]. However, inspired by Platt et al. [18], we make
the assumption that the maximum likelihood observation is
obtained at each time step. This eliminates the stochasticity
from the belief dynamics to make it suitable for trajectory
optimization using sequential quadratic programming (SQP)
[3], [23]. The deterministic belief dynamics are given by:
^
b
t+1
=g(
^
b
t
; ^ u
t
) =
"
^ x
t+1
vec[
q

 
t+1
 K
t
H
t

 
t+1
]
#
; (3a)
^ x
t+1
=f(^ x
t
; ^ u
t
;0); 
 
t+1
=A
t
p

t
(A
t
p

t
)
T
+Q
t
Q
T
t
; (3b)
A
t
=
@f
@x
(^ x
t
; ^ u
t
;0); Q
t
=
@f
@q
(^ x
t
; ^ u
t
;0); (3c)
H
t
=
@h
@x
(^ x
t+1
;0); R
t
=
@h
@r
(^ x
t+1
;0); (3d)
K
t
= 
 
t+1
H
T
t

t+1
(
t+1
H
t

 
t+1
H
T
t

t+1
+R
t
R
T
t
)
 1

t+1
: (3e)
Here, 
t+1
= diag[
T
t+1
] is a diagonal matrix comprised
of entries of the binary vector 
t+1
corresponding to which
dimensions of the maximum likelihood observation z
t+1
=
h(^ x
t+1
;0) can be measured. Note that the Kalman gain
matrix in Eq. (3e) differs from the standard EKF formulation
[26] and is a generalization of the formulation considered by
Sinopoli et. al. [24], where a single binary value is used to
indicate if the entire measurement vectorz is obtained or not
1
. An alternative formulation using an extended information
ﬁlter (EIF) [26] can also be used to incorporate entries of
the binary vector in the update of the belief state [28].
Objective: Our goal is to plan trajectories in belief space
that will minimize uncertainty during task execution. In
general, objectives that are functions of means and covari-
ances can be considered. We formulate this as a nonlinear
optimization problem which minimizes a user-deﬁned cost
function that encodes minimization of uncertainty in the
system state while satisfying task-speciﬁc constraints.
For notational convenience, we concatenate the belief
states and control inputs for all time steps 0t` to form
1
A derivation, omitted due to space constraints, is available here:http:
//rll.berkeley.edu/beliefopt/
^
B = [
^
b
0
:::
^
b
`
] and
^
U = [^ u
0
::: ^ u
` 1
] that parameterize a
nominal belief space trajectory such that
^
b
t+1
=g(
^
b
t
; ^ u
t
).
The optimization problem is then formally stated as:
min
^
B;
^
U
C(
^
B;
^
U) (4a)
s: t:
0t<`
^
b
t+1
=g(
^
b
t
; ^ u
t
); ^ x
`
2X
target
;
^ x
t
2X
feasible
; ^ u
t
2U
feasible
(4b)
where C(
^
B;
^
U) is a cost function encoding the objective,
^ x
`
2 X
target
constrains the ﬁnal estimate of the system
state ^ x
`
to lie in the desired target region X
target
, ^ u
t
2
U
feasible
constrains the control input ^ u
t
to lie in the set of
feasible control inputsU
feasible
, and ^ x
t
2X
feasible
constrains
the state ^ x
t
to lie in the set of feasible states X
feasible
.
In our experiments, we use a cost function of the form
C(
^
B;
^
U) =
P
`
t=0
tr[M
t
^

t
] +
P
` 1
t=0
^ u
T
t
N
t
^ u
t
that encodes
the objective of minimizing uncertainty (minimizing the trace
of the covariance
^

t
) while penalizing the control effort, but
the cost function can also include problem-speciﬁc additional
terms. The matrices M
t
 0 and N
t
 0 are positive semi-
deﬁnite cost matrices that weigh the contributions of the
two cost terms. The optimization is initialized with a belief
trajectory

B = [

b
0
:::

b
`
] and

U = [ u
0
:::  u
` 1
].
The optimization formulation is general enough to include
other constraints such as probabilistic collision avoidance
with obstacles in belief space [15] but we do not consider
obstacles in this work for the sake of clarity.
IV. TRAJECTORY OPTIMIZATION WITH SENSING
DISCONTINUITIES
The general optimization problem given in Eq. (4) involves
binary entries in the Kalman gain matrix in Eq. (3e). One
alternative would be to include the binary entries in the
Kalman gain matrix in Eq. (3e) in the optimization formula-
tion. This leads to a binary nonlinear program, solving which
is known to be at least NP-hard [5]. Directly considering
the binary entries in a continuous nonlinear optimization
formulation is challenging because when a measurement
cannot be obtained, there is no local gradient information
that would guide the optimization towards sensing regions
where measurements could be obtained.
We use an approximation of the entries in
t
using sigmoid
functions to map them to a value in the range [0; 1], and
this approximation is successively improved till the values
of entries in 
t
arrive within a user-deﬁned threshold of the
true binary values. We use sequential quadratic programming
(SQP) [3], [23] to iteratively solve each nonlinear optimiza-
tion problem with continuous approximations.
To consider a continuous approximation to the original
problem, we ﬁrst examine the relationship between the binary
entries and whether valid measurements can be obtained. Let
 denote the valid sensing region associated with a given
sensor. As shown in Fig. 2, the valid sensing region depends
on factors such as the limited ﬁeld of view of the sensor and
presence of other objects within the ﬁeld of view that might
occlude portions of the sensing region. If the expected system
state ^ x
t
lies within the valid sensing region, a measurement
6485
(a) sd(ˆ x
t
, ?)> 0 (b) sd(ˆ x
t
, ?)< 0
pˆ x t
Outside ﬁeld of view Inside ﬁeld of view
ˆ n
ˆ n
?
pˆ x t
(c) sd(ˆ x
t
, ?)> 0
pˆ x t
Occluded view
ˆ n
(d) sd(ˆ x
t
, ?)< 0
Unoccluded view
pˆ x t
ˆ n
? ? ?
Occluder
Fig. 2. Relationship between measurements and signed distance to valid
sensing region: (a) The expected position p
^ x
t
of the robot or object lies
outside the ﬁeld of view  (shown in yellow) of a sensor, corresponding to a
positive signed distance, where no measurements are obtained. The normal
vector ^ n indicates the direction of closest approach. (b) A negative value
of the signed distance corresponds to a valid measurement being obtained.
(c,d) The ﬁeld of view is partially blocked by an occluder object (shown
in gray). Even though the expected position of the robot or object is within
the triangular ﬁeld of view, it is still outside (or inside) the valid sensing
region corresponding to a positive (or negative) signed distance.
is obtained, and no measurement is obtained if it does not
lie in the valid sensing region.
This relationship is formalized using the notion of signed
distance sd(^ x
t
; ) in the workspace between the expected
state ^ x
t
of the system and the valid sensing region , as
shown in Fig. 2. The signed distance here corresponds to the
minimum translation distance required to bring the expected
system state ^ x
t
inside the valid sensing region  from the
outside (Fig. 2(a,c)) or push it outside the valid sensing
region from the inside (Fig. 2(b,d)).
Each binary entry 
i
t
= 1(sd(^ x
t
; ) < 0);i =
f1;:::; dim[z]g then takes the value 1 when a measurement
is obtained, i.e., when the signed distance to the valid
sensing region is negative, and a value of 0 when the signed
distance is positive, corresponding to when no measurement
is obtained (Fig. 3). Inspired by [6], [28], we approximate
the indicator function with a sigmoid function as:

i
t
=1(sd(^ x
t
; )< 0)

i
t
() = 1 
1
1 + exp( sd(^ x
t
; ))
; (5)
where  is a parameter that governs the degree of ap-
proximation of the indicator function 1(sd(^ x
t
; ) < 0),
especially near the origin (Fig. 3). Increasing the value of
is equivalent to scaling the measurement noise levels outside
the sensing region as a function of the signed distance.
Note that the valid sensing region corresponding to 
i
t
is
determined by the sensor that is responsible for measuring
the i
th
dimension of the measurement vector z
t
. Using Eq.
(5), we replace all occurrences of 
t
in Eq. (3e) with 
t
().
sd(ˆ x
t
, ?)
?
i
t
=1(sd(ˆ x
t
, ?)< 0)
0
1
0
sd(ˆ x
t
, ?
s
)
1
0
?
i
t
(?) = 1?
1
1+exp(??·sd(ˆ xt,?))
? = 1
? = 3
? = 9
? = 27
0
Fig. 3. Continuous approximation of 
i
t
using sigmoid functions.
Alg. 1 outlines the steps involved in SQP-based opti-
mization [3], [23] for belief space planning with sensing
discontinuities. In particular, we sequentially solve a series
of continuous approximations to the true problem, obtained
by increasing the value of the parameter , starting from a
user-deﬁned constant 
init
, by a constant factor k (lines [2-
10] in Alg. 1). We used k = 3 for all our experiments. We
update the trajectory initialization [

B;

U] after each update
to seed the optimization. The algorithm converges when the
entries of 
0:`
are within a user-speciﬁed tolerance  of the
true binary values computed using Eq. (5).
V. EXECUTION
It is important to note that we only compute the signed
distance to the valid sensing region with respect to the
expected state ^ x
t
for deciding if a measurement will be
obtained or not. We compute this expected state based on the
maximum likelihood observation assumption [18]. However,
the expected state may not remain the same during execution
after updating the belief state based on actual measurements.
To account for the deviation in the expected state, we follow
the model predictive control (MPC) paradigm [21] of re-
planning after every time step. This has been demonstrated
to be an effective way of performing feedback control to
remain robust to large perturbations, provided one can re-
plan sufﬁciently fast.
Alg. 1 outlines the steps involved in executing the tra-
jectory by re-planning after every time step following a
model predictive control paradigm. At each time step , we
solve a belief space planning problem, as described in Sec.
IV (lines [2-10]). We then select the ﬁrst control input  u

from the sequence of control inputs

U
:` 1
computed by the
optimization (line 11) and apply the actuation commands to
the system. We then obtain a measurement z
+1
and use it
to update the belief state

b
+1
=
  x+1
vec[
p
+1]

using the
extended Kalman ﬁlter (EKF) as (line 12):
 x
+1
=f( x

;  u

;0) +K
t
(z
+1
 h(f( x

;  u

;0);0); (6a)
p

+1
=
q

 
t+1
 K
t
H
t

 
t+1
; (6b)
where 
 
t+1
;K
t
; and H
t
are computed using Eq. (3). The
Kalman gain matrixK
t
from Eq. (3e) contains binary entries
corresponding to if a measurement is obtained or not and it
automatically disregards subsets of the obtained measure-
mentz
+1
that do not constitute a valid measurement in the
Kalman update (Eq. (6a)).
In the event that a measurement should have been obtained
based on the estimated system state  x
+1
but no measure-
ment is obtained during execution, the system can infer that
the real system state is not present within the valid sensing
region. We incorporate this information during execution by
appropriately truncating the Gaussian belief state against the
boundary of the valid sensing region.
Truncating the belief state (line 13): We use the
method of Patil et al. [17] to locally convexify the re-
gion of the workspace not spanned by the valid sensing
region, i.e., represent the complement of the valid sensing
region as a conjunction of linear inequality constraints as
T
k
i=0
a
T
i
x
+1
 b
i
. For each constraint, we apply an
afﬁne transformation x
i
+1
= a
T
i
x
+1
to transform the
6486
Algorithm 1 Belief space planning with sensing discontinuities (MPC paradigm)
Inputs:

B
0:`
= [

b
0
:::

b
`
];

U
0:` 1
= [ u
0
:::  u
` 1
]: Belief space trajectory initialization
`: Number of time intervals
Cost and constraint deﬁnitions (Eq. (4))
Parameters:
: Approximation parameter for relaxing discrete sensing constraints
k: Coefﬁcient to control rate of increase of 
: Execution time step (0`)
: Convergence tolerance parameter
Variables:
^
B
0:`
= [
^
b
0
:::
^
b
`
];
^
U
0:` 1
= [^ u
0
::: ^ u
` 1
]: Optimization variables

0:`
: Binary vector to track value of continuous approximation for convergence criterion
1: for  = 0;:::;`  1 do . Re-planning loop following the MPC paradigm
2:  
init
3: while 
:`
not within  tolerance of true binary valuesf0; 1g do
4: Reset trust region size and penalty coefﬁcient . [23]
5: [
^
B
:`
;
^
U
:` 1
] SQP-based optimization of approximation given [

B
:`
;

U
:` 1
] . [23]
6:  k . -update to increase noise outside sensing region
7:
^
b
t+1
=g(
^
b
t
; ^ u
t
) 8 t =;:::;`  1 . Integrate belief trajectory after -update
8: Update 
:`
 
:`
() . Eq. (5)
9: [

B
:`
;

U
:` 1
] [
^
B
:`
;
^
U
:` 1
] . Update trajectory initialization
10: end while
11: Execute  u

12: Obtain measurement and update

b
+1
using EKF . Eq. (6a)
13: Truncate

b
+1
w.r.t sensing region boundary
14: Update sensing regions for all sensors
15:

b
t+1
=g(

b
t
;  u
t
) 8 t = + 1;:::;`  1 . Integrate belief trajectory after Kalman update
. using previously optimized control inputs

U
+1:` 1
16: end for
belief state N (^ x
+1
; 
+1
) to a 1D Gaussian x
i
+1

N (a
T
i
 x
+1
;a
T
i

+1
a
i
) along an axis normal to the con-
straint. The problem now reduces to truncating the 1D
Gaussian distribution at an upper bound given byx
i
+1
=b
i
to give ~ x
i
+1
N (
i
;
2
i
) [11]. We estimate the truncated
belief state based on the truncated 1D Gaussian distribution
~ x
i
+1
N (
i
;
2
i
) [17]. We truncate the belief state

b
+1
with respect to each of the k constraints in a sequential
manner and then accumulate the effect of truncation over
all the constraints.
Updating the sensing regions (line 14): We update the
valid sensing region for the sensors after execution at each
time step. This step is necessary for sensors with a limited
ﬁeld of view, e.g., cameras or depth sensors, where the ﬁeld
of view might be blocked due to an occluder object that
might move during execution. We perform a convex decom-
position of the valid sensing region and check for occlusions.
For instance, for a camera-like sensor, we project beams
outward from the camera and truncate these beams with
respect to occluder geometry. The convex decomposition
facilitates signed distance computation and determination of
constraints along the sensing region boundary for truncating
the belief. We note that other decomposition methods such
as voxel grids or geometric methods can also be used.
VI. EXPERIMENTS
A. Navigation: Mobile robots
Point robot: We consider a point robot navigating in a
light-dark environment with a sensing discontinuity, adapted
from Platt et al. [18] (Fig. 1). The robot is able to obtain
reliable measurements about its state in the light region of
the environment, but gets no measurements if it is in the dark
region. We assume the following stochastic dynamics model
f and measurement model h:
x
t+1
=x
t
+u dt +S
x
q
t
(7a)
z
t
=x
t
+S
z
r
t
; (7b)
where the state x = [x;y]
T
2 R
2
consists of the position
of the robot, control input u = [v
x
;v
y
]
T
2 R
2
consists of
the robot’s velocity, dt = 1 is the duration of a time step,
and S
x
= 0:1I and S
z
= 0:01I are constant matrices
that scale the process noise q
t
and measurement noise r
t
,
respectively. The initial mean position is x
0
= [0; 4]
T
and
initial covariance is 
0
= 0:5I, and the target position is at
[0; 0]
T
. The boundary of the light region is located atx = 5.
Fig. 1 shows that a state space planner [23] computes a
straight line trajectory to the target, resulting in considerable
ﬁnal uncertainty. Belief space planning with a single contin-
uous approximation ( = 1) (Fig. 1(d)) plans a trajectory
6487
(a) Execution without truncation
(b) Execution with truncation
Fig. 4. Effect of belief state truncation during execution: The execution
trace so far (dashed green line), current plan (solid red line), and current
beliefs (yellow ellipses) are shown. The desired target is at the bottom left
corner (yellow dot). (a) Without truncating the Gaussian belief state, the
robot thinks it is in the light region where it can get measurements but it is
actually still in the dark region. As a result, the robot starts heading back,
resulting in a larger targeting error at the ﬁnal time step. This results from
the fact that the plan is computed starting from the expected state and not the
true state, which is unknown during execution. (b) With truncation, at the
same time step as (a), the belief is updated by truncating against boundary
of light region and the robot estimates that it has not yet arrived in the
light region. At the next step, the robot then performs a different action and
moves into the light region for reducing uncertainty. Over 100 simulated
executions, the robot reaches the light region in 64% of the executions
without truncation and 100% of the executions with truncation. The state
estimation during execution is more accurate with truncation, resulting in
plans with reduced ﬁnal targeting error.
towards the light region but the robot fails to reach it, while
our approach results in the robot reaching the light region
before heading to the target with reduced uncertainty (Fig.
1(c)). Fig. 4 shows the effects of truncation on the Gaussian
belief state during execution. Our experiments indicate that
considering truncation reduces the ﬁnal uncertainty at the
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
20% 80% 140% 200% 260% 320% 380% 440% 500%
Distance to target (m) 
Noise level (% of input process and measurement noise) 
State space
Continuous belief space
Our approach w/o truncation
Our approach w/ truncation
Fig. 5. Comparison of the targeting error using simulated executions
with artiﬁcially added noise and re-planning after every time step for four
approaches: (i) state space planning, (ii) belief space planning with a single
continuous approximation (? = 1), (iii) our approach without truncation,
and (iv) our approach with truncation of the belief state. We varied the
scaling of the process and measurement noise variances considered in Eq.
(7) from 20% to 500% and considered the average distance to the target (in
m) over 100 simulated executions for each noise level. Our approach with
truncation of the Gaussian belief state results in the lowest error because
it is able to consistently lead the robot to the light region to reduce the
uncertainty. The rate of increase in the targeting error as the noise level
increases is similar for all approaches since the initial state uncertainty is
much larger than the considered process and measurement noise.
(a) Problem setup (b) Static objects (c) Moving objects
Fig. 6. Composite belief space planning for robots and objects in
the environment: We consider a nonholonomic car-like robot with an on-
board stereo camera sensor that is oriented in the direction in which the
car is heading. The ﬁeld of view of the camera is visualized in white. The
robot localizes itself by detecting objects in the environment, whose initial
positions are very uncertain (position and uncertainty shown in green). This
is an example of belief space planning applied to active exploration. (a) A
state space planner plans a trajectory that results in considerable uncertainty
at the target. (b) When the objects are static, our approach ﬁnds a trajectory
such that the car orients itself to place the objects in its ﬁeld of view and then
reaches the target, thereby reducing uncertainty in both the robot state and
state of the objects. (c) The objects are now allowed to move. Our approach
ﬁnds a trajectory for the robot and the objects such that the visibility of the
objects is maximized in the ﬁeld of view of the camera. The ﬁnal uncertainty
in car state and object positions reduces further. It is interesting to note that
the ﬁnal positions of the objects are close to each other since the uncertainty
in the robot state and object states is correlated (just as in the simultaneous
localization and mapping problem [26]).
target. Fig. 5 shows the results of evaluation of different
approaches in terms of the ﬁnal error at the target, using
simulated executions with artiﬁcially added noise and re-
planning after every time step. Our approach with truncated
belief states outperforms other approaches that do not ac-
count for sensing discontinuities or do not truncate the belief
state during execution.
Nonholonomic car-like robot: We consider a nonholo-
nomic car-like robot navigating in an environment. The car
is equipped with an on-board stereo camera sensor that is
oriented in the direction  in which the car is heading and
the car is able to localize itself by detecting objects in the
environment, whose initial positions are uncertain (Fig. 6(a)).
(i) Static objects: This is an example of belief space
planning applied to the active exploration setting. We assume
the following stochastic dynamics modelf and measurement
model h:
x
t+1
= [x
t
+v
t
dt cos(
t
); y
t
+v
t
dt sin(
t
);

t
+v
t
dt tan(
t
)=d; x
1
t
; y
1
t
; x
2
t
; y
2
t
]
T
+S
x
q
t
(8a)
z
t
= [x
1
t
 x
t
; y
1
t
 y
t
;x
2
t
 x
t
; y
2
t
 y
t
]
T
+S
z
r
t
; (8b)
where the system statex = [
x
R
x
O
]2R
7
comprises of the state
x
R
= [x;y;]
T
2 R
3
of the robot containing its position
[x;y]
T
and its orientation , and the state of the objects
x
O
= [x
1
;y
1
;x
2
;y
2
]
T
2R
4
consists of the positions of the
two objects. The control input u = [;v]
T
2R
2
applied to
the system consists of the robot’s steering wheel angle and
speed v. Here, dt is the time step duration, d is the length
of the car-like robot, and S
x
and S
z
are constant matrices
that scale the process noise q
t
and measurement noise r
t
,
respectively. Fig. 6(b) shows the planned trajectory for the
car, in which the car orients itself in a such a way that it
places the objects in the camera ﬁeld of view, to reduce the
overall uncertainty in the state of both robot and objects.
(ii) Moving objects: This is an example of composite be-
lief space planning for both the robot and moving objects (or
6488
sensors) in the environment. The object motion is assumed to
be holonomic. We assume the following stochastic dynamics
and measurement models:
x
t+1
= [x
t
+v
t
dt cos(
t
); y
t
+v
t
dt sin(
t
); 
t
+v
t
dt tan(
t
)=d;
x
1
t
+v
1
x
dt; y
1
t
+v
1
y
dt; x
2
t
+v
2
x
dt; y
2
t
+v
2
y
dt]
T
+S
x
q
t
(9a)
z
t
= [x
1
t
 x
t
; y
1
t
 y
t
;x
2
t
 x
t
; y
2
t
 y
t
]
T
+S
z
r
t
; (9b)
where the composite control input is now given by u =
[;v;v
1
x
;v
1
y
;v
2
x
;v
2
y
]
T
2R
6
, where [v
k
x
;v
k
y
]; k = 1; 2, is the
speed of thek
th
object. Fig. 6(c) shows the planned trajectory
for the car and the objects, such that the visibility of the
objects in the camera ﬁeld of view is always maximized.
Since the uncertainty in the robot state and object states
is correlated [26], the objects move close to each other to
minimize the overall uncertainty in the system state.
B. Reaching Task: Planar three-link manipulator
We consider the case of a planar three-link manipulator
with a stereo camera mounted at its base. The objective is to
try to grasp a static object whose position is very uncertain,
on account of the robot arm occluding the object in the
camera ﬁeld of view. We consider the following two cases:
(a) Problem setup (b) State space
plan
(c) Execution
(intermediate)
(d) Execution
(ﬁnal time step)
Fig. 7. Reaching task under uncertainty (static camera): We consider
a three-link manipulator trying to grasp an object whose position is very
uncertain, on account of the robot arm occluding the object in the camera
ﬁeld of view. The camera is looking towards top of ﬁgure and is ﬁxed.
The visible region in white is the part of the camera view frustum that is
visible and the rest is occluded by the robot arm. The estimated position
of the object is shown in yellow with very large uncertainty. The actual
position of object is shown in green. (b) A state space planner computes
a trajectory to estimated position of object but fails because the object is
not present there. (c) An intermediate time step is shown during execution
with re-planning. The robot ﬁrst reaches the initial estimated position of the
object, discovers nothing there but truncates the belief of the object position
with respect to the sensing region. Traces of the updated estimated object
position and truncated belief is shown in yellow. (d) The robot discovers
the object during execution and is able to successfully grasp it.
(i) Static camera: The camera is assumed to be static and
oriented as shown in Fig. 7(a). We assume the following
stochastic dynamics and measurement models:
x
t+1
= [
1
t
+!
1
t
dt;
2
t
+!
2
t
dt;
3
t
+!
3
t
dt;x
t
;y
t
]
T
+S
x
q
t
(10a)
z
t
= [
1
t
;
2
t
;
3
t
;x
t
 x
c
; y
t
 y
c
]
T
+S
z
r
t
; (10b)
where the state x = [
1
;
2
;
3
;x;y]
T
2R
5
consists of the
joint angles of the manipulator [
1
;
2
;
3
]
T
and the position
[x;y]
T
of the object it is trying to grasp, the control input
u = [!
1
;!
2
;!
3
]
T
2 R
3
consists of the angular speeds at
each of the joints of the arm, and [x
c
;y
c
]
T
is the position of
the camera base. Fig. 7 shows the traces of how the estimated
object position and belief state are updated during execution
using truncation to account for the fact that no measurements
are obtained when a measurement should have been obtained
based on the estimated position of the object. The valid
sensing region is also updated after each time step. The
manipulator is able to successfully grasp the object during
execution by accounting for the limited ﬁeld of view of the
camera and occlusions due to the arm.
(a) State space plan (b) Execution
(intermediate)
(c) Execution (ﬁnal
time step)
Fig. 8. Reaching task under uncertainty (rotating camera): The
camera is now allowed to rotate about an axis (coming out of the page).
The estimated position of the object is shown in yellow with very large
uncertainty. The actual position of object is shown in green. (a) A state
space planner computes a trajectory to estimated position of object but fails
because the object is not present there. (b) An intermediate time step is
shown during execution with re-planning. The robot ﬁrst reaches the initial
estimated position of the object, discovers nothing there but truncates the
belief of the object position with respect to the sensing region corresponding
to the new orientation of the camera. Traces of the updated estimated object
position and truncated belief is shown in yellow. (c) The robot discovers
the object during execution by rotating the camera at the base and is able
to successfully grasp it.
(ii) Moving camera: The camera can now rotate about
its axis (Fig. 7(a)). We assume the following stochastic
dynamics and measurement models:
x
t+1
= [
1
t
+!
1
t
dt;
2
t
+!
2
t
dt;
3
t
+!
3
t
dt;

camera
t
+!
camera
t
dt;x
t
;y
t
]
T
+S
x
q
t
(11a)
z
t
= [
1
t
;
2
t
;
3
t
;
camera
t
;x
t
 x
c
; y
t
 y
c
]
T
+S
z
r
t
;
(11b)
where the system statex now includes the camera orientation

camera
and the control input includes the angular speed of
rotation at the camera base !
camera
. Fig. 8(b) shows the
traces of how the estimated object position and belief state
are updated during execution using truncation against the
valid sensing region corresponding to the camera orientation.
The manipulator is able to successfully grasp the object
during execution by simultaneously planning for both the
manipulator and the camera.
C. Performance Evaluation
We analyzed the performance of our approach on each
of the scenarios described above. The computation time
depends on the number of optimization variables, which
depends on the dimension of the belief state, control input,
and the number of time steps used to discretize the trajectory.
The computation time also depends on how many calls to
the SQP solver (line 23 in Alg. 1) are made depending on
the complexity of the problem. For instance, the planning
problem for the nonholonomic car-like robot is difﬁcult to
solve because of the nonholonomic constraints on the car
motion and the measurement model used. Note that the total
execution time for execution is substantially faster than the
number of time steps multiplied by the initial optimization
time, since the optimization problem at successive time steps
gets progressively easier to solve and a lot of effort is spent
in computing the ﬁrst locally-optimal solution.
6489
Scenario Belief Control Num Avg. time Avg time
state input time initial optimization total exececution
dim dim steps (secs) (secs)
point 5 2 20 1.6 9.8
car (static) 35 2 30 66.9 105.9
car (moving) 35 6 30 39.1 206
arm (static) 20 3 12 3.9 9.5
arm (moving) 27 4 12 15.3 30.9
Fig. 9. Performance of our approach: The average time for initial
optimization indicates the time it takes to compute a locally-optimal solution
for the ﬁrst iteration (? = 0). The total execution time includes computation
time required for re-planning after every time step. Performance evaluated
using a C++ implementation running on a 3.2 GHz Intel PC.
VII. CONCLUSION AND FUTURE WORK
In this work, we have addressed the problem of incorporat-
ing sensing discontinuities due to factors such as limited ﬁeld
of view of sensors and occlusions, in an optimization-based
framework for belief space planning. Our key contributions
include (i) solving a sequence of optimization problems that
approximate sensing discontinuities using sigmoid functions
in a SQP-based optimization framework, (ii) using the notion
of signed distance between the estimated state of the system
and the valid sensing region to ascertain if a measurement
may be obtained, and (iii) using truncated Gaussians to
update the belief state during execution to incorporate infor-
mation contained in not obtaining a measurement. Our ex-
periments suggest that this approach can be used to compute
locally-optimal trajectories in belief space and effectively
cope with discontinuities in sensing domains.
Our work opens up several avenues for future research.
We plan to incorporate probabilistic collision avoidance
constraints in our work [15]. Our experiments indicate that
Gaussian belief space planning can provide compelling solu-
tions to planning problems arising in robotic navigation and
manipulation tasks. In situations where multi-modal beliefs
are expected to appear, we plan to extend our approach to
incorporate other general belief state representations [22].
We also want to apply this approach to real-world domains
such as autonomous grasping and manipulation tasks with
imprecise, articulated robots and medical needle steering.
ACKNOWLEDGMENTS
This research has been funded in part by AFOSR-YIP
Award #FA9550-12-1-0345, by NSF under award #1227536,
by Darpa Young Faculty Award #D13AP00046, and by a
Sloan Fellowship.
REFERENCES
[1] H. Bai, D. Hsu, W. S. Lee, and V . A. Ngo, “Monte Carlo value
iteration for continuous-state POMDPs,” Proc. Workshop Algorithmic
Foundations of Robotics (WAFR), pp. 175–191, 2011.
[2] R. Bajcsy, “Active perception,” Proceedings of the IEEE, vol. 76, no. 8,
pp. 966–1005, 1988.
[3] J. T. Betts, Practical methods for optimal control and estimation
using nonlinear programming. Society for Industrial & Applied
Mathematics, 2010, vol. 19.
[4] A. Bry and N. Roy, “Rapidly-exploring random belief trees for motion
planning under uncertainty,” in Proc. IEEE Int. Conf. Robotics and
Automation (ICRA), 2011, pp. 723–730.
[5] S. Burer and A. N. Letchford, “Non-convex mixed-integer nonlinear
programming: A survey,” Surveys in Operations Research and Man-
agement Science, vol. 17, no. 2, pp. 97–106, 2012.
[6] C. Chen and O. L. Mangasarian, “Smoothing methods for convex
inequalities and linear complementarity problems,” Mathematical Pro-
gramming, vol. 71, no. 1, pp. 51–69, 1995.
[7] S. Chen, Y . Li, and N. Kwok, “Active vision in robotic systems: A
survey of recent developments,” The International Journal of Robotics
Research (IJRR), vol. 30, no. 11, pp. 1343–1377, 2011.
[8] T. Erez and W. D. Smart, “A scalable method for solving high-
dimensional continuous POMDPs using local approximation,” in Un-
certainty in Artiﬁcial Intelligence, 2010, pp. 160–167.
[9] K. Hauser, “Randomized belief-space replanning in partially observ-
able continuous spaces,” Proc. Workshop Algorithmic Foundations of
Robotics (WAFR), pp. 193–209, 2011.
[10] G. Hollinger and G. Sukhatme, “Stochastic motion planning for
robotic information gathering,” in Robotics: Science and Systems
(RSS), 2013.
[11] N. L. Johnson, S. Kotz, and N. Balakrishnan, Continuous Multivariate
Distributions: Models and Applications. New York: John Wiley &
Sons, 2002.
[12] L. P. Kaelbling and T. Lozano-Perez, “Integrated task and motion
planning in belief space,” Int. Journal of Robotics Research, 2013.
[13] T. Kollar and N. Roy, “Trajectory optimization using reinforcement
learning for map exploration,” Int. Journal of Robotics Research,
vol. 27, no. 2, pp. 175–196, 2008.
[14] H. Kurniawati, D. Hsu, and W. S. Lee, “SARSOP: Efﬁcient point-
based POMDP planning by approximating optimally reachable belief
spaces,” in Robotics: Science and Systems, 2008.
[15] A. Lee, S. Patil, J. Schulman, Z. McCarthy, J. van den Berg, K. Gold-
berg, and P. Abbeel, “Gaussian belief space planning for imprecise
articulated robots,” in IROS (to appear), 2013.
[16] R. Martinez-Cantin, N. de Freitas, E. Brochu, J. Castellanos, and
A. Doucet, “A Bayesian exploration-exploitation approach for optimal
online sensing and planning with a visually guided mobile robot,”
Autonomous Robots, vol. 27, no. 2, pp. 93–103, 2009.
[17] S. Patil, J. van den Berg, and R. Alterovitz, “Estimating probability
of collision for safe planning under Gaussian motion and sensing
uncertainty,” in ICRA, 2012, pp. 3238–3244.
[18] R. Platt, R. Tedrake, L. Kaelbling, and T. Lozano-Perez, “Belief space
planning assuming maximum likelihood observations,” in Robotics:
Science and Systems (RSS), 2010.
[19] J. Porta, N. Vlassis, M. Spaan, and P. Poupart, “Point-based value
iteration for continuous POMDPs,” Journal of Machine Learning
Research, vol. 7, pp. 2329–2367, 2006.
[20] S. Prentice and N. Roy, “The belief roadmap: Efﬁcient planning in
belief space by factoring the covariance,” Int. Journal of Robotics
Research, vol. 28, no. 11–12, pp. 1448–1465, 2009.
[21] J. Rawlings, “Tutorial overview of model predictive control,” IEEE
Control Systems Magazine, vol. 20, no. 3, pp. 38–52, 2000.
[22] N. Roy, G. Gordon, and S. Thrun, “Finding approximate POMDP
solutions through belief compression,” Journal of Artiﬁcial Intelligence
(JAIR), vol. 23, pp. 1–40, 2005.
[23] J. Schulman, J. Ho, A. Lee, H. Bradlow, I. Awwal, and P. Abbeel,
“Finding locally optimal, collision-free trajectories with sequential
convex optimization,” in RSS, 2013.
[24] B. Sinopoli, L. Schenato, M. Franceschetti, K. Poolla, M. I. Jordan,
and S. S. Sastry, “Kalman ﬁltering with intermittent observations,”
Trans. on Automatic Control, vol. 49, no. 9, pp. 1453–1464, 2004.
[25] C. Stachniss, G. Grisetti, and W. Burgard, “Information gain-based
exploration using Rao-Blackwellized particle ﬁlters,” in Robotics:
Science and Systems (RSS), 2005.
[26] S. Thrun, W. Burgard, and D. Fox, Probabilistic Robotics. MIT Press,
2005.
[27] J. van den Berg, S. Patil, and R. Alterovitz, “Motion planning under
uncertainty using iterative local optimization in belief space,” Int.
Journal of Robotics Research, vol. 31, no. 11, pp. 1263–1278, 2012.
[28] M. Vitus and C. Tomlin, “Sensor placement for improved robotic
navigation,” in Proc. of Robotics: Science and Systems (RSS), 2010.
[29] L. T. Watson and R. T. Haftka, “Modern homotopy methods in opti-
mization,” Computer Methods in Applied Mechanics and Engineering,
vol. 74, no. 3, pp. 289–305, 1989.
6490
