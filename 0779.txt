Spin Observation and Trajectory Prediction of a Ping-Pong Ball
Yifeng Zhang
1
, Yongsheng Zhao
1
, Rong Xiong
1
, Yue Wang
1
, Jianguo Wang
2
and Jian Chu
1
Abstract— For ping-pong playing robots, observing a ball and
predicting a ball’s trajectory accurately in real-time is essential.
However, most existing vision systems can only provide ball’s
position observation, and do not take into consideration the
spin of the ball, which is very important in competitions. This
paper proposes a way to observe and estimate ball’s spin in
real-time, and achieve an accurate prediction. Based on the
fact that a spinning ball’s motion can be separated into global
movement and spinning respect to its center, we construct an
integrated vision system to observe the two motions separately.
With a pan-tilt vision system, the spinning motion is observed
through recognizing the position of the brand on the ball and
restoring the 3D pose of the ball. Then the spin state is estimated
with the method of plane ﬁtting on current and historical
observations. With both position and spin information, accurate
state estimation and trajectory prediction are realized via
Extended Kalman Filter(EKF). Experimental results show the
effectiveness and accuracy of the proposed method.
I. INTRODUCTION
Ping-pong playing robots have attracted the attention of
more and more researchers because it is an ideal platform
for real-time hand-eye coordination experiments. Observing
the ball and predicting ball’s trajectory accurately in real-
time mode is challenging but essential for successful playing.
The main difﬁculties come from two points. One is that
the ball travels very fast in a short distance. In professional
competitions, the maximal ball speed can reach up to more
than 20m/s, while the whole length of ping-pong table is
only 2.73m. The other is there needs to be enough time left
for the robot to react. The more time left, lower requirement
on robot’s mechanics, such as joint velocity and acceleration.
Various vision systems have been developed for ball
observation. L. Acosta et al. developed a monocular vision
system to locate the ball’s 3D position based on detection of
the ball and it’s shadow, but the ball’s ﬂying area and velocity
were highly restricted [1]. Y . Zhang et al. carried this method
forward to a standard playing environment [2]. Recently,
many stereo-vision [3][4][5][6] and multi-vision [7] systems
have been developed and applied to ping-pong playing robots
This work was supported by the National Nature Science Foundation of
China (Grant No.61075078), the Innovation Team of Advanced Technology
of Zhejiang Province (Grant No. 2009R50014), the Scholarship Award for
Excellent Doctoral Student granted by Ministry of Education and the Joint
Center for Robotics Research (JCRR) between Zhejiang University and the
University of Technology, Sydney.
1
Yifeng Zhang, Yongsheng Zhao, Rong Xiong, Yue Wang and Jian Chu
are with the State Key Laboratory of Industrial Control and Technology,
Zhejiang University, Hangzhou, P. R. China. Rong Xiong is the correspond-
ing author. rxiong@iipc.zju.edu.cn
2
Jianguo Wang is with the Center for Autonomous Systems, Faculty of
Engineering and IT, University of Technology, Sydney, Australia.
The authors are all with JCRR.
as they are more robust and can provide more accurate po-
sition information. However, current existing vision systems
only observe the position of the ball, which greatly restricts
the available information provided to trajectory analysis and
prediction. In this paper, this type of vision system is called
as position vision system.
Limited by the observation, literatures on trajectory anal-
ysis have mainly focused on position state estimation and
prediction. M. Matsushima et al. estimated ball’s state by
ﬁtting a polynomial and predicted following trajectory using
two learned maps [3]. Z. Zhang et al. deduced the dynamic
model of ping-pong ball based on forces analysis and used
it in prediction, but the ball’s state is estimated based on
ﬁtting a polynomial rather than using dynamic model [4].
K. Mulling et al. used EKF based on dynamic model to get
state estimation [8]. Y . Zhang et al. proposed the idea that the
dynamic model is described in discrete and continuous forms
for state estimation and trajectory prediction respectively
and share the same parameters, and they gave a solution
to learn and adapt parameters to improve the performance
[5]. This method worked well and successfully supported
the humanoid robots ’Wu’ and ’Kong’ continuously play
with human players or with each other
1
. The algorithms
mentioned above are good at predicting trajectory of a ball
without spin, but is less successful for a spinning ball.
Utilizing spin is one of the most important skills for human
ping-pong players. As stated in [9], adding spin to the ball
is very popular in modern ping-pong competitions, because
the spin can vastly deviate the trajectory and make the
trajectory hard to be estimated, even for professional players.
Researchers have put much effort into analysis of how
spinning will affect ﬂight trajectory. Some experiments were
carried out to measure the lift force (also known as Magnus
force) and the lift coefﬁcient for different shapes under
different moving and spinning velocities [10][11][12][13].
S. Furnuno et al. [14] and T. Tamaki et al. [15] tried
to measure a ball’s spin via a vision system conﬁgured
with a super-high frequency camera. The ball was manually
marked, the relationship between camera target direction and
moving ball direction was constrained to be perpendicular.
Moreover, image processing to recognize the marks on the
ball can’t catch the super-high frequency of camera (1200fps
and 600fps respectively) which limits the system in real-
time application. A. Nakashima et al. applied a similar idea
to measure the spin of a ping-pong ball that was manually
marked with dots and used the results to help modeling
1
http://news.cnet.com/8301-17938 105-20125182-1/chinas-ping-pong-
robots-got-game/
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 4108
rebound process [16]. Due to the similar approach, they have
the same shortcomings. X. Chen et al. proposed a novel idea
that spin can be estimated from the deviation of trajectory.
They deduced the dynamic model of a spinning ball, then
the ﬂight trajectory of a spinning ball can be predicted
with estimated spin state [6]. Y . Huang et al. detailed the
derivation of this idea and implemented several experiments
to verify the result [17]. However our experiments indicate
that the spin estimation based only on position information
is not robust and very sensitive to observation error, The
detailed explanation is given in Section II. In summary, real-
time observation and trajectory prediction for spinning ball
are still open problems.
Based on the fact that a spinning ball’s motion can be
separated into global movement and spinning respect to
its center, this paper proposes a new vision system that
combines a traditional position vision system with a pan-
tilt vision system to observe the two motions separately.
We call the new vision system as position and spin vision
system, in which the the position vision system observes
the ball’s position state using the method of [5], while the
pan-tilt vision system restores ball’s 3D pose by recognizing
the brand of the ball and estimates ball’s spin state with the
method of plane ﬁtting on current and historical observations.
With both position and spin information, we can estimate
ball’s state and predict the trajectory accurately via EKF.
Compared with [14][16], the proposed method dose not
require manual marks, or super-high frequency camera, and
there are no strict limitation on the camera’s installation. Our
method gives an innovative solution to observe spin directly
and in real-time, with which the prediction accuracy is well
improved.
The remainder of this paper is arranged as follows. In
Section II, the motivation of this work is discussed and the
framework is introduced. Then ball’s 3D pose restoring, spin
state estimation and trajectory prediction are described in
Section III, IV and V respectively. Experiments that verify
the effectiveness of the proposed method are conducted in
Section VI. Finally, conclusion is given.
II. MOTIVATION STATEMENT AND FRAMEWORK
A. MOTIVATION
There are three main forces that impact on a ﬂying ball:
gravityF
g
, air dragF
d
, and Magnus forceF
m
.F
d
is opposite
to ﬂying direction, andF
m
is perpendicular to spin axis and
ﬂying direction, as shown in Fig. 1. Their values can be
calculated as follows.
F
g
=
 
0 0  mg

T
(1)
F
d
= 
1
2
C
D

a
Akvkv (2)
F
m
=
1
2
C
M

a
Ar(!v) (3)
wherem is the mass of ball,g is the acceleration of gravity,

a
is the air density,C
D
is the drag coefﬁcient,C
M
is the lift
coefﬁcient,r is the radius of the ball,A is the cross-sectional
Fig. 1. Forces that impact on a ﬂying ball.
area of the ball, v = [v
x
;v
y
;v
z
]
T
is the global velocity, and
! = [!
x
;!
y
;!
z
]
T
is the spin velocity of the ball.
Then the kinematical model is given as
0
@
_ v
x
_ v
y
_ v
z
1
A
=
0
@
 k
D
kvkv
x
+k
M
(!
y
v
z
 !
z
v
y
)
 k
D
kvkv
y
+k
M
(!
z
v
x
 !
x
v
z
)
 g k
D
kvkv
z
+k
M
(!
x
v
y
 !
y
v
x
)
1
A
(4)
where k
D
=
1
2m
C
D

a
A, k
M
=
1
2m
C
M

a
rA. (4) shows
the fact that velocities along different axes are coupled, so
are the positions. When a ball is moving with spinning, the
trajectory analysis based on the assumption that position and
velocity can be separated into three directions and be solved
independently, will cause unexpected error.
For position vision systems, only ball positions on each
cycle can be obtained. If we want to resolve the spin velocity
! based on (4), the estimation error would be high due to
ﬁrst derivative and second derivative of the observation noise,
as well as the nonlinearity between v and !. However, this
error can be reduced if the spin is directly observed, which
inspires the strategy of our work.
B. FRAMEWORK
Fig. 2 shows the idea of combining position vision system
with pan-tilt vision system. The position vision system has
two or more cameras with short lens to get a wide view
covering the table, with which the image of ball is very
small and blurred, so only ball’s position information can
be observed. The pan-tilt vision system equips long lens to
tracks the ball, with a narrow view it can get large and clear
image of ball, thus it is practical to recognize the brand on
it and then estimate the spin state.
The framework of position and spin vision system is
shown in Fig. 3. The position vision system outputs ball’s
global position and the pan-tilt vision system estimates the
spin state of ball, then these two observations are combined
together to do state estimation and trajectory prediction
of ball’s ﬂight. Brand recognition and ball tracking are
implemented in multi-thread way. Once current position of
ball is updated by position vision system, the motors of
pan-tilt vision system are driven to track the ball according
to geometric relationship. The time delay of whole system
should be taken into account when tracking. In the meantime,
when a new frame is captured by the pan-tilt camera, the
brand on the ball is recognized based on frame difference
4109
Fig. 2. 3D virtual scene of position and spin vision system.
Fig. 3. Framework of position and spin vision system.
algorithm. Then ball’s 3D pose is restored and the spin state
is estimated with current and historical observations. One
thing needs to be pointed out is that two or more pan-tilt
vision systems can work together in our framework to get
more observations and do more precise estimation of ball’s
spin state. As each pan-tilt camera can only observe one side
of the ball, two such cameras are equipped on both sides of
the table in our experiment.
III. RESTORING BALL’S 3D POSE
Restoring the ball’s 3D pose at each frame is one of the
key techniques of our method, which can be realized through
three main steps: brand recognition, 3D pose restoration
in camera coordinates, and 3D pose calculation in ball
coordinates.
A. DEFINITION OF BALL COORDINATES
The spinning motion can be split from ball’s global
movement, and analyzed in a dynamic coordinates respect to
ball’s center. Fig. 4 shows the deﬁnition of ball coordinates,
in which the origin is the ball’s center and the axes are
parallel to axes of global coordinates. Then ping-pong ball’s
3D pose can be represented as the vector pointing from
ball’s center to brand’s center, in other words the position
of brand’s center in ball coordinates.
Fig. 4. Deﬁnition of ball coordinates and representation of ball’s 3D pose.
Fig. 5. Demonstration of brand recognition process. Images in ﬁrst row are
ball’s raw images in successive frames after size normalization. Images in
second row are the difference results between ball’s current and background
images. Images in third row show the brand recognition results.
B. BRAND RECOGNITION
The main challenge of brand recognition lies in the uneven
illumination in different areas of environment. In most cases,
both shadows and reﬂection exist in ball’s image. Based on
the illumination model of environment and the fact that ball’s
positions are very close between two adjacent frames, we
can assume that illuminations are the same in two adjacent
frames. Thus we proposed to use frame difference technique
between the ball’s background image and the ball’s image to
recognize the brand, where the ball’s background image is
updated frame by frame to adapt the uneven illumination.
Several ball’s background images in different areas are
learned off-line which can be used as the initial background
image according to ball’s global position.
Fig. 5 demonstrates the brand recognition process. Firstly,
all of the ball’s images in different frames are uniﬁed into
same size, 61 61 pixels in this paper, as shown in ﬁrst
row. Secondly, difference between current frame image and
the updated background image is obtained, as illustrated
in second row. After that, the brand is segmented using a
threshold and veriﬁed by a contour ﬁtting method, the result
is shown in third row. The difference and segmentation steps
can be described by
I
bd
(x;y) =
(
1 if I
bk
(x;y) I
bl
(x;y)>T
r
(x;y)
0 else
(5)
where I
bd
is the segmentation result, which is a binary
image.I
bk
andI
bl
are ball’s background and current images
respectively. T
r
is the threshold with a positive value.
4110
The ball’s background image is updated for each frame as
I
bk
(x;y) =
(
I
bk
(x;y) if I
bd
(x;y) = 1
(1 )I
bk
(x;y) +I
bl
(x;y) else
(6)
where is the update rate in [0, 1]. The value of is inverted
with the frequency of vision system. The lower the frequency
is, the larger the value. According to our experiments,  =
0:5 works well at the frequency of 120fps.
Fig. 5 also indicates that when brand locates closer to the
edge area of ball in the image, its location error becomes
larger due to occlusion and noise. So we assign the recogni-
tion result a conﬁdence. The closer the brand location is to
the ball’s center, the higher the conﬁdence it has, and vice
versa.
C. 3D POSE RESTORATION IN CAMERA COORDINATES
The camera calibration result gives the relationships be-
tween image coordinates and camera coordinates. After
getting the positions of ball’s center and brand’s center in
image coordinates, their positions in camera coordinates are
easy to be calculated.
0
@
X
c
Y
c
Z
c
1
A
=
0
@
f
x
0 c
x
0 f
y
c
y
0 0 1
1
A
 1
0
@
su
sv
s
1
A
(7)
wheref
x
,f
y
,c
x
,c
y
are the intrinsic parameters of camera,s is
the scale factor, (X
c
;Y
c
;Z
c
) are coordinates of a 3D point in
camera coordinates, (u;v) are coordinates of point projection
in pixels. For further convenience we denote (X
b
;Y
b
;Z
b
) and
(X
m
;Y
m
;Z
m
) as the positions of ball’s center and brand’s
center in camera coordinates, (u
b
;v
b
) and (u
m
;v
m
) as their
projections in image coordinates.
Camera calibration also gives the initial position of camera
P
c
in global coordinates, while the ball’s positionP
b
at each
cycle is provided by position vision system. The distance
between ball and camera can be approximately calculated
as the ball to the initial position of camera since the pan-
tilt movement will not change the camera’s position much.
Denote D =kP
b
 P
c
k, then
X
b
2
+Y
b
2
+Z
b
2
=D
2
(8)
From (7) and (8), we can get the ball’s position.
8
>
<
>
:
X
b
=
u
b
 cx
fx
Zc
b
Y
b
=
v
b
 cy
fy
Zc
b
Z
b
=
p
D
2
 X
b
2
 Y
b
2
(9)
The brand is on the sphere surface, so
(X
m
 X
b
)
2
+ (Y
m
 Y
b
)
2
+ (Z
m
 Z
b
)
2
=r
2
(10)
where r is the radius of ping-pong ball. Combining (7) and
(10), we can get the brand’s position.
as
2
+bs +c = 0 (11)
where
8
>
<
>
:
a = (
um cx
fx
)
2
+ (
vm cy
fy
)
2
+ 1
b = 2(
um cx
fx
Xc
b
+
vm cy
fy
Yc
b
+Zc
b
)
c = (Xc
b
)
2
+ (Yc
b
)
2
+ (Zc
b
)
2
 r
2
(11) has two solutions ofs, which indicates that two points
on the sphere can project to the pixel (u
m
;v
m
). The smaller
one corresponds to the real position of brand’s center.
After getting the positions of ball’s center and brand’s
center, the ball’s 3D pose in the camera coordinates P
c
can
be determined as the vector pointing from ball’s center to
brand’s center.
P
c
= [X
m
 X
b
Y
m
 Y
b
Z
m
 Z
b
]
T
(12)
D. 3D POSE RESTORATION IN BALL COORDINATES
The camera coordinates is changing with the pan-tilt
movement. To restore ball’s 3D pose in ball coordinates,
the camera’s pose in global coordinates has to be updated
at each cycle. According to Rodrigues’ rotation formula, the
rotation matrix caused by pan-tilt movement can be solved
as
R
r
() = cos()I + (1  cos())rr
T
+ sin()
0
@
0  r
z
r
y
r
z
0  r
x
 r
y
r
x
0
1
A
(13)
R
x
() =
0
@
1 0 0
0 cos()   sin()
0 sin() cos()
1
A
(14)
where and are the angles that camera pans and tilts from
initial position,r = [r
x
;r
y
;r
z
]
T
is the axis of pan movement
in initial camera coordinates. Then the extrinsic parameters
of camera at each cycle can be updated as follow.
[R T ] = (R
r
()R
x
())
 1
[R
0
T
0
] (15)
whereR
0
andT
0
are the camera extrinsic parameters at ini-
tial position. Since the axes of ball coordinates is parallel to
that of global coordinates, ball’s 3D pose in ball coordinates
P
b
can be easily calculated by
P
b
=R
 1
P
c
(16)
IV. SPIN STATE ESTIMATION
Spin state is estimated based on several frames of the ball’s
3D pose restored. All of the ball’s 3D poses are described
in the ball coordinates.
Fig. 6a illustrates the distribution of brand positions in
different frames of one ﬂying trajectory, in which two colors,
red and green, correspond to the observations of two pan-tilt
cameras. In some frames, both pan-tilt cameras observe the
brand, then a weighted average result is calculated based
on the conﬁdences of brand recognition and used as the
observation of that frame as shown in Fig. 6b.
It is seen the brand positions lie almost in one plane, which
means the axis of spin is not changing during ﬂying. Based
4111
Fig. 6. a. The observations of brand positions in frames of one ﬂying trajectory in ball coordinates, the ball has spun 6 cycles. The red points are the
observations by one pan-tilt camera and the green points are by the other. b. In some frames both pan-tilt cameras observed the brand, then weighted
average result will be used as new observation for that frame, as shown by blue circles. c. The axis of spin pass through ball’s center and is perpendicular
to the plane, shown as the black line. The magenta points are the projection of observation points to the cross section of ball perpendicular to axis, which
will be used to calculate the angular velocity.
Fig. 7. Calculate angular velocity at different frames.
on the forces analysis in Section II, main forces that impact
on a ﬂying ball all pass through the ball’s center, which
means they have no effect on the angular velocity of spin.
Hence we can infer: the axis and the angular velocity of
spin do not change during ﬂying.
Because the normal vector of the plane is parallel to the
axis of spin, we can transform the problem of spin axis
calculation to that of normal vector calculation. Fitting the
plane of all observation points with RANSAC method, the
normal vector is solved for. Thus the axis of spin can be
determined by ﬁxing the normal vector passing through ball’s
center, as shown in Fig. 6c.
Fig. 7 demonstrates how to calculate the angular velocity
of spin. The error variance of brand observation is quite
different in each frame according to various situations of
illumination and ball’s pose in camera coordinates, thus it’s
hard to be modeled. So we use the average ﬁlter rather
than other ﬁlter algorithms, the average angular velocity is
calculated as
 =
m 2 +
n 1
(n  1)T
(17)
wheren is current frame count,m means how many rotations
the ball has spun, and 
n
is the angle between current point
and the ﬁrst point. Observation error is only occurred in 
n
and independent to time. Thus as time goes by, the estimation
of  will be more and more accurate.
V. STATE ESTIMATION AND TRAJECTORY
PREDICTION
A. STATE ESTIMATION
To apply the kinematical model to trajectory analysis of a
ﬂying ball, the discrete form of dynamic model is needed due
to discrete observations. Denote the time interval between
frames as T , andk
d
=k
D
T ,k
m
=k
M
T , the discrete
dynamic model is given as follows.
0
B
B
B
B
B
B
@
x(k + 1)
y(k + 1)
z(k + 1)
v
x
(k + 1)
v
y
(k + 1)
v
z
(k + 1)
1
C
C
C
C
C
C
A
=F (k)
0
B
B
B
B
B
B
@
x(k)
y(k)
z(k)
v
x
(k)
v
y
(k)
v
z
(k)
1
C
C
C
C
C
C
A
+
0
B
B
B
B
B
B
@
0
0
0
0
0
 gT
1
C
C
C
C
C
C
A
(18)
where (x(k);y(k);z(k)) and (v
x
(k);v
y
(k);v
z
(k)) are ball’s
position and velocity in k
th
frame, and
F(k) =
0
B
B
B
B
B
@
1 0 0 T 0 0
0 1 0 0 T 0
0 0 1 0 0 T
0 0 0 1 k
d
kv(k)k  km!z km!y
0 0 0 km!z 1 k
d
kv(k)k  km!x
0 0 0  km!y km!x 1 k
d
kv(k)k
1
C
C
C
C
C
A
Then EKF can be applied to do state estimation, the
state variable is [x(k);y(k);z(k);v
x
(k);v
y
(k);v
z
(k)]
T
, the
predict model is given by (18). The measurement model is
given as
0
@
x(k)
y(k)
z(k)
1
A
=
 
I
33
0
33

0
B
B
B
B
B
B
@
x(k)
y(k)
z(k)
v
x
(k)
v
y
(k)
v
z
(k)
1
C
C
C
C
C
C
A
(19)
The spin velocity! is used as a constant value in EKF. As
discussed in Section IV ,! is estimated based on all historical
observations, and the estimation tends to be more precise
4112
with more observations. So in each frame, ! will be re-
estimated, and the EKF will also have to restart over again for
all observations of this ﬂying trajectory with the new!. For
a ping-pong game, this process will not cost much time but
can provide more precise estimation. For other continuous
running applications, we can just reﬁlter the latest several
observations.
B. TRAJECTORY PREDICTION
When playing a ping-pong game, the ﬂight trajectory can
be split into three parts: ﬂying before collision, collision with
table, and ﬂying after collision. The two ﬂying trajectories
satisfy the dynamic model given above.
Considering the physical properties of rebound and refer-
ring to experiments result, the rebound model for collision
between ball and table is described as
8
>
>
>
>
>
>
>
>
>
>
<
>
>
>
>
>
>
>
>
>
>
:
v
xout
=
h
v
xin
!
yin
i
b
1
v
yout
=
h
v
yin
!
xin
i
b
2
v
zout
= v
zin
b
3
!
xout
=
h
v
yin
!
xin
i
b
4
!
yout
=
h
v
xin
!
yin
i
b
5
!
zout
= !
zin
b
6
(20)
where b
1
;b
2
;b
4
;b
5
2R
2
and b
3
;b
6
2R, and the values are
estimated using Least Square Method(LSM).
Once the current state of ball is estimated, its following
trajectory can be easily calculated.
VI. EXPERIMENTS
Experiments are conducted to verify the proposed method
on spin observation and trajectory prediction of a spinning
ping-pong ball. One position vision system catches global
position of ball, the average localization error< 0:9cm. Two
pan-tilt vision systems are used to estimate spin state of ball.
All cameras are working in 120fps with the resolution of
640 480 pixels. The time cost of the proposed method for
each frame is less than 5ms on a PC equipped with Core 2
Duo 2.67GHz processor and 2GB RAM.
Parameters used in experiments are as follows. T =
1=120s, r = 0:02m, m = 0:00275kg, g = 9:82m=s
2
, 
a
=
1:29kg=m
3
,C
D
= 0:405,C
M
= 0:62,b
1
= [0:75; 0:0015]
T
,
b
2
= [0:75; 0:0015]
T
, b
3
=  0:97, b
4
= [ 26; 0:53]
T
,
b
5
= [25; 0:6]
T
, b
6
= 0:9.
Fig. 8 shows the spin estimation of each frame in one
ﬂight trajectory. The proposed method estimates spin state
based on the current and historical observations, and at least
three observations are needed. So the vision system has to
wait a few frames to get a estimation result, the waiting
time is only related to number of brand images captured
by pan-tilt cameras and independent to ball’s spin velocity.
According our experiments, In most cases our vision system
can give a precise spin estimation in less than 10 frames. For
the example in Fig. 8, the vision system gave accurate spin
estimation at 8th frame for ﬂying before collision with table.
Fig. 8. Estimation of spin state ! = (!x;!y;!z)
T
, in each frame the
estimation is based on observations before this frame.
Fig. 9. Prediction result on bouncing point. The green line indicates the
time when ball is ﬂying through 1/4 length of table
After collision between frame 45 and 46, the spin estimating
process restarted and gave accurate result 4 frames later. Fig.
8 also proved the inference that spin state does not change
during ﬂying is reasonable.
Fig. 9 shows the prediction result on the bouncing point
of the same data using the spin estimation result in Fig. 8.
The pan-tilt vision system had to wait 5 frames to get a
rough estimation of spin state, so the prediction results were
the same in ﬁrst 4 frames. At the 5th frame, although the
estimated spin state was not accurate, its spin direction was
approximately correct and can still increase the prediction
accuracy if this information is used. The spin estimation
became more precise since 8th frame and the prediction was
greatly improved.
In the application of ping-pong playing robots, the vision
system should give precise predictions in early stage to leave
enough time for robots to react. When ball is moving with a
velocity of [6  10]m=s, the robot should begin to move at
the time about ball passing through 1/4 length of the table,
shown as the green line in Fig. 9. Fig. 10 illuminates the
prediction result when ball was ﬂying through 1/4 length of
the table in different views.
In addition, the main component of ball’s velocity was
along positive y axis, and Fig. 8 shows the spin was mostly
in negative z direction. According to the dynamic model,
the Magnus force was mainly in positive x direction, so
the trajectory would be deviated to positive x direction,
which was consistent with the result that the prediction error
was mostly in x axis if not considering spin in Fig. 10.
Furthermore, the rebound model indicates that !
xout
would
decrease after rebounding which was also supported by the
result in Fig. 8.
4113
Fig. 10. Trajectory prediction when ball has ﬂied 1/4 length of the table.
The blue points give the truth trajectory. The red circle at the head of the
trajectory is the ﬁlter result based on observations before each frame, and
the last red circle indicate current frame. The red points and the green points
are the prediction result with and without considering spin.
TABLE I
ERROR ANALYSIS OF TRAJECTORY PREDICTION RESULT.
prediction error on
bouncing point(x-y)
prediction error on
hitting point(x-z)
/mm average
standard
deviation
average
standard
deviation
Method1
x 65.9 71.9 141.7 156.8
y / z 78.6 103.7 29.4 53.8
Method2
x 35.6 38.0 46.6 51.3
y / z 36.4 48.0 39.1 45.6
Method3
x 13.2 16.1 18.6 21.3
y / z 21.6 24.9 20.6 23.5
The proposed method was tested by 15 trajectory data
with various spin velocities from 60rad=s to 200rad=s,
and compared with the method not considering spin and
the method estimating spin from trajectory deviation. Tab.
I lists the error of trajectory prediction on bouncing points
and hitting points, the prediction was done at the last frame
before ball ﬂying through 1/4 length of the table. Method1
used only position information and didn’t consider spin.
Method2 used only position information, but it considered
spin which was estimated based on trajectory deviation.
Method3 was the proposed method that used both position
and spin information to do state estimation and trajectory
prediction. The result shows the effectiveness and advance-
ment of the proposed method.
VII. CONCLUSIONS
This paper proposed an innovative position and spin
vision system, which can observe both position and spin
information of a ping-pong ball directly and in real-time.
Applying these information in a dynamic model based on
forces analysis with EKF method, we can get more precise
state estimation and trajectory prediction results for a spin-
ning ball. Experimental results show the effectiveness and
accuracy of the proposed method.
Although the proposed method may not work well in the
particular case that the brand on the ball lies at the spin
axis. One solution is using the brand recognition result as
an ellipse rather than just a point, then axis direction of
the ellipse can be used to estimate spin state. This solution
is relied on more accurate and robust brand recognition,
which we will focus on in our next work. Also the method
of estimating spin state from trajectory deviation can be
used as a supplementary of the proposed method, such as
providing initial values in ﬁrst several frames and handling
above special situations.
Another piece of future work will concentrate on modeling
the rebounding process between ball and racquet, which can
help the robot to hit spinning balls back to a target area on
the opponent’s court.
REFERENCES
[1] L. Acosta, J. Rodrigo, J. A. Mendez, G. Marichal, and M. Sigut, “Ping-
pong player prototype,” Robotics & Automation Magazine, IEEE,
vol. 10, no. 4, pp. 44–52, 2003.
[2] Y .-h. Zhang, W. Wei, D. Yu, and C.-w. Zhong, “A tracking and
predicting scheme for ping pong robot,” Journal of Zhejiang University
SCIENCE C, vol. 12, no. 2, pp. 110–115, 2011.
[3] M. Matsushima, T. Hashimoto, M. Takeuchi, and F. Miyazaki, “A
learning approach to robotic table tennis,” Robotics, IEEE Transactions
on, vol. 21, no. 4, pp. 767–771, 2005.
[4] Z. Zhang, D. Xu, and M. Tan, “Visual measurement and prediction of
ball trajectory for table tennis robot,” Instrumentation and Measure-
ment, IEEE Transactions on, vol. 59, no. 12, pp. 3195–3205, 2010.
[5] Y . Zhang, R. Xiong, Y . Zhao, and J. Chu, “An adaptive trajectory
prediction method for ping-pong robots,” in Intelligent Robotics and
Applications. Springer, 2012, pp. 448–459.
[6] X. Chen, Y . Tian, Q. Huang, W. Zhang, and Z. Yu, “Dynamic model
based ball trajectory prediction for a robot ping-pong player,” in
Robotics and Biomimetics (ROBIO), 2010 IEEE International Con-
ference on. IEEE, 2010, pp. 603–608.
[7] C. H. Lampert and J. Peters, “Real-time detection of colored objects
in multiple camera streams with off-the-shelf hardware components,”
Journal of Real-Time Image Processing, vol. 7, no. 1, pp. 31–41, 2012.
[8] K. M¨ ulling, J. Kober, and J. Peters, “A biomimetic approach to robot
table tennis,” Adaptive Behavior, vol. 19, no. 5, pp. 359–376, 2011.
[9] Y . Drianovski and G. Otcheva, “Survey of games styles of some
of the best asian players at the 12th world university table tennis
championships (sof´ ıa, 1998),” Table Tennis Sciences, vol. 4, pp. 3–9,
2002.
[10] B. Robins, New principles of gunnery. Hutton, 1805.
[11] G. Magnus, “Ueber die abweichung der geschosse, und: Ueber eine
auffallende erscheinung bei rotirenden k¨ orpern,” Annalen der physik,
vol. 164, no. 1, pp. 1–29, 1853.
[12] H. Barkla and L. Auchterlonie, “The Magnus or Robins effect on
rotating spheres,” J. Fluid Mech, vol. 47, no. part 3, pp. 437–447,
1971.
[13] C. T. Crowe, D. F. Elger, J. A. Roberson, C. T. Crowe, and C. T.
Crowe, Engineering ﬂuid mechanics. Wiley Hoboken, 2005, vol. 7.
[14] S. Furuno, K. Kobayashi, T. Okubo, and Y . Kurihara, “A study on spin-
rate measurement using a uniquely marked moving ball,” in ICCAS-
SICE, 2009. IEEE, 2009, pp. 3439–3442.
[15] T. Tamaki, H. Wang, B. Raytchev, K. Kaneda, and Y . Ushiyama,
“Estimating the spin of a table tennis ball using inverse compositional
image alignment,” in ICASSP , 2012. IEEE, 2012, pp. 1457–1460.
[16] A. Nakashima, Y . Ogawa, Y . Kobayashi, and Y . Hayakawa, “Modeling
of rebound phenomenon of a rigid ball with friction and elastic
effects,” in American Control Conference (ACC), 2010. IEEE, 2010,
pp. 1410–1415.
[17] Y . Huang, D. Xu, M. Tan, and H. Su, “Trajectory prediction of
spinning ball for ping-pong player robot,” in Intelligent Robots and
Systems (IROS), 2011 IEEE/RSJ International Conference on. IEEE,
2011, pp. 3434–3439.
4114
