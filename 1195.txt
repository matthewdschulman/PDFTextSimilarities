Hierarchical Sparse Coded Surface Models
Michael Ruhnke Liefeng Bo Dieter Fox Wolfram Burgard
Abstract—In this paper, we describe a novel approach to
construct textured 3D environment models in a hierarchical
fashion based on local surface patches. Compared to previous
approaches, the hierarchy enables our method to represent
the environment with differently sized surface patches. The
reconstruction scheme starts at a coarse resolution with large
patches and in an iterative fashion usesthe reconstruction error
to guide the decision as to whether the resolution should be
reﬁned. This leads to variable resolution models that represent
areas with few variations at low resolution and areas with
large variations at high resolution. In addition, we compactly
describe local surface attributes via sparse coding based on an
overcomplete dictionary. In this way, we additionally exploit
similarities in structure and texture, which leads to compact
models. We learn the dictionary directly from the input data
and independently for every level in the hierarchy in an
unsupervised fashion. Practical experiments with large-scale
datasets demonstrate that our method compares favorably
with two state-of-the-art techniques while being comparable
in accuracy.
I. INTRODUCTION
There is an increasing interest in accurate and textured
3D models of real-world environments or objects as they are
relevant for various applications including surveillance, envi-
ronmental monitoring and virtual reality. Also in the context
of robotics many applications rely on accurate 3D models
like navigation, object recognition, and mobile manipulation.
Recently, dense 3D reconstruction with RGBD cameras has
become popular due to the availability and low costs of
such cameras. However, especially large-scale environments
or high resolution models ask for compact representations of
dense 3D models.
In this paper, we propose a hierarchical method to con-
struct compact and textured 3D models of an environment
from RGBD data. We describe local surface attributes with
sparse codes that refer to an overcomplete dictionary. Sparse
Coding [12] is a ﬂexible and adaptive toolkit to compactly
encode similarities in large data collections. A sparse code
describes data with up to n ? N dictionary entries and we
use it to encode local depth and texture data. In this way we
exploit the redundancy in typical human made environments
to build highly compact models. By doing this in a hier-
archical fashion with local surface descriptions of different
sizes and resolutions, we are able to capture similarities at
different scales. This leads to even more compact models
Michael Ruhnkeand Wolfram Burgard are with the Autonomous Systems
Lab, University of Freiburg. Liefeng Bo is with the Intel Science and
Technology Center for Pervasive Computing (ISTC-PC). Dieter Fox is with
theRoboticsandStateEstimationLab,UniversityofWashington.Thiswork
was partially funded by the EC under ERC-AG-PE7-267686-LifeNav and
FP7-610603-EUROPA2, by the German Research Foundation under grant
number EXC 1086 and by the ISTC-PC.
Fig. 1. This ﬁgure illustrates our hierarchical surface description scheme.
The large areas in the left picture correspond to the regions that are
represented at the highest level using the large patches. The green areas
are represented with smaller patches at level two and the blue area is
represented with small high resolution patches. The other picture shows
the corresponding model with a size of 343kB compared to 4.7MB of the
original point cloud.
with high resolution in areas with high variation and low
resolution in areas with minor variations. Fig. 1 shows an
example obtained with our approach. The red surfaces in the
left picture correspond to the largest surface patches and the
blue surfaces to the smallest patches. The right picture shows
the full model with RGB information.
We construct such hierarchical models in a greedy fashion
by starting at the highest level of our hierarchy with the
largest surface descriptions and use the standard deviation
in depth and RGB-space to decide as to whether a local
surface should be used at the current level. The idea is it to
describe everything that cannot be accurately represented at
thecurrentlevelatahigherresolution.Toguaranteecoverage
we describe all remaining data at the lowest level. Once we
knowthelevelofdetailforalldata,weapplyK-SVDtolearn
a dictionary for every level in the hierarchy and calculate a
sparse code for every local surface.
II. RELATED WORK
There exists a wide variety of different representations for
textured 3D data. Depending on the desired application the
individualapproacheseitherfocusonaccuracy,compactness,
or rendering performance. Recent developments in simulta-
neous localization and mapping (SLAM) and the availability
of RGBD-cameras made it possible to obtain large colored
metric models. Whereas a major advantage of colored point-
clouds lies in their accuracy, their drawback lies in their
storage requirement, since we need to store every single
data item in both 3D and RGB-space. Therefore, RGBD-
based SLAM systems often use only a subset of features
internally [7].
Most recent GPU driven RGBD-SLAM systems utilize
the Truncated Signed Distance Function (TSDF) [2] as
representation. The main advantages of this approach are
the smoothness and the resolution of the estimated surface.
However, this approach requires to maintain a cubic voxel
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 6238
grid in memory, which restricts the size of such a grid
to ﬁt into GPU memory. Recent extensions use either a
moving TSDF volume representation [17] and maintain data
outside of the GPU or use local TSDF volumes or patches
to represent only local aspects of the environment [6]. Since
TSDF volumes have a limited compactness and require ray
casting for visualization, the volumes are typically converted
into meshes for that purpose. Meshes, however, are a highly
accurate representation but lack compactness and further-
more cannot be easily updated.
Recently, Ma et al. [10] presented a planar simpliﬁcation
scheme for large meshes to drastically reduce the number
of vertices on planar surfaces. In contrast to our work
the quadtree-based triangulation scheme produces a mesh
without overlap, while our method produces overlapping
surfaces. On the other side it reduces only the structural
information and does not exploit repetitive structures or
textures. It furthermore is limited to planar surfaces.
Another compact volumetric representation for 3D data
are octrees. Octrees represent occupancy and implicitly free
space in a hierarchical grid structure. Fairﬁeld et al. [4]
used octrees in the context of SLAM for underwater ve-
hicles. Recently Wurm et al. [18] introduced an open source
implementation of octrees called Octomap which can store
additional RGB information. In the context of compression
Kammerl et al. [9] used octrees to compactly transmit point
cloud streams by sending only the differences in successive
frames. Especially for large voxel sizes, octrees are compact
but suffer from discretization errors due to the alignment to
the voxel structure. On the other hand, they are accurate for
small voxel size models but not compact anymore.
In our previous work on Sparse Coded Surface Models
(SCSM)[14] we introduced a surface-patch-based represen-
tation that uses Sparse Coding to compactly describe the
surface attributes in both, 3D and RGB space. Sparse Cod-
ing [12] is a machine learning technique used for signal
approximation[13],imagedenoising[8],[3]andforlearning
features [1], [19]. In this paper we present a hierarchical
extension that better adapts to the level of detail needed
to accurately describe local surfaces. This extension leads
to even more compact models. Additionally we present a
novel keypoint method driven by maximizing coverage and
alignment to substantially reduce the number of patches
neededtorepresenttheinputdata.Furthermore,weintroduce
a distance-based weighting scheme to compute weighted
means for the surface descriptions. This approach has been
applied successfully in the past especially to TSDF-based
SLAM methods [11], [17], [6]. As a result, the represented
surfaces suffer less from noisy far range measurements of
RGBD cameras.
III. HIERARCHICAL SPARSE CODED SURFACE MODELS
The main idea of our method is to represent colored 3D
data with a set of surface patches and to encode every of
theselocalsurfacesusingSparseCodingbasedonareference
dictionary. In this way, we can exploit the repetition of
structures and textures and build highly compact models.
a) b)
c) d)
Fig. 2. This ﬁgure shows a colored point cloud with a green cube that will
be represented by a patch (a), the depth description (b), the color description
(c) and the bitmask (d). The light green areas in (b) and (c) correspond to
undeﬁned areas, which are marked as zeroes in the patch bitmask (d).
Note that we need more than one surface patch to describe a
volume with this strategy. One major challenge in this con-
text is that the scale at which structure or texture reappears
can be arbitrary. Therefore it seems desirable to introduce
surface patches of different sizes to capture similarities at
different scales.
Similar to SCSM we encode local colored 3D data at a
well-deﬁned location as set of 2D images for three channels,
which are depth, RGB, and bitmask (see Fig. 2). The grey
value on the depth channel (b) corresponds to the weighted
meanofthedistancetothesurfaceindirectionofthenormal.
We compute a RGB value for the texture channel (c) as the
weighted mean of the RGB values that fall into a pixel. Note
thatwecancomputealocalrangeimageandacorresponding
texture at every location in an unorganized point cloud. In
contrast to SCSM, we use the error model described in [15]
to weight the error according to the error of the maximum
range of the sensor. The bitmask (d) encodes which pixel
have a valid value. In this way, we can encode surfaces that
are smaller than the given patch size and also deal with
occlusions (see Fig. 2). In our current implementation we
startwithamaximumpatchsizeandaminimumresolutionat
the highest level and halve the size in every patch dimension
and double the resolution for every following level.
The main intuition of the hierarchical modeling is that
we try to explain everything on the current level and use
coverage and error distributions to guide the decision as to
whether a surface is well represented or should be repre-
sented at a lower level and higher resolution. Starting with
a pre-registered set of colored point clouds as input data we
build a model using large patches with low resolution to
represent the full data set. If a patch does not cover more
than 90% we can easily describe it at the next lower level.
The standard deviation ?
c
of a pixel in a patch gives us
the information how good the patch resolution can represent
the data at the current level of the hierarchy. We introduce
a maximum standard variation ?
depth
max
and ?
rgb
max
for both
channels to control how accurate a model will represent
details. If the standard deviation of a pixel is above one of
6239
Fig. 3. This ﬁgure illustrates the greedy-based hierarchical modeling
scheme we apply. The left picture shows the input point cloud and the
right picture shows all points that could not be accurately represented at the
ﬁrst level of the hierarchy. These points are the input for the next level.
these thresholds we set the bitmask of this pixel to 0 and
postpone this part of the surface to be represented at the
next level. Fig. 3 illustrates the procedure. The left picture
shows the input point cloud and the right picture shows the
point cloud of all remaining points after modeling the ﬁrst
level. The latter corresponds to the input for the next level.
At the lowest level we accept all patches independent of
the computed standard deviation to ensure that the model is
complete and represents all data.
We deﬁne a Hierarchical Sparse Coded Surface Model
(HSCSM) as M(H,D
depth
,D
rgb
,I) with the hierarchy de-
scription H = {h
1
,...,h
|H|
} consisting of a tuple h
j
=
hps
j
,pr
j
i for the j-th level which deﬁnes the patch size
ps
j
and patch resolution pr
j
, reference dictionaries for both
channels, D
depth
and D
rgb
, and a scene description I =
{i
1
,...,i
|I|
}. The reference dictionary of every channel has
entries that correspond to a particular level of the hierarchy
D
depth
= {D
depth
1
,...,D
depth
|H|
} that we construct by con-
catenating the learned dictionaries for every level. All entries
d
depth
k
of a depth dictionary D
depth
j
={d
depth
1
,...,d
depth
n
}
with n = |D
depth
j
| have the same number of rows and
columns as the depth channels of the surface patches of
their corresponding level. Currently we us the same di-
mensions for all levels, but this is not mandatory. Every
i
j
=hT
j
,c
depth
j
,c
rgb
j
,b
j
,level
j
i stores a transformation T
j
,
consisting of the 3D pose and the orientation for the surface
patch, one sparse code for the depth c
depth
j
and one for the
RGBchannelc
rgb
j
,abitmaskb
j
thatis0forundeﬁnedpixels
and 1 for deﬁned pixels and the index of its level level
j
. In
the following we will discuss how we compute the positions
for our surface patches and will give an overview of the
dictionary learning scheme we apply.
A. Surface Patch Locations
To fully represent a set of input point clouds P we need
to ﬁnd locations for the surface patches such that all data
is covered by the patches. In general, ﬁnding the minimum
number of subsets that contain all elements of P is a
set covering problem known to be NP-complete [5]. For
SCSM we used a spatial subsampling strategy to uniformly
distribute the patch positions on the data as approximate
solution. Since we have different patch sizes for every level
of our hierarchy, we cannot follow the same strategy here.
Therefore, we propose to solve this by applying a greedy
algorithm that searches for the best patch locations at every
level starting with the largest patches.
Possible ways to deﬁne the quality of patch locations
are the area they cover, the error introduced by the patch
discretization, and the error of the reconstruction based on
our dictionary. Since we compute the dictionary in a later
step, we could only use the reconstruction error by either
introducingatwopassencoding,whichresultsinbetterpatch
locationsinthesecondpass,orusingageneralpre-computed
dictionary for every patch size and resolution. Therefore,
we rely only on coverage and discretization error. Since
we reject pixels in the 2D projection that introduce high
discretization errors, this also inﬂuences the area covered
by a patch. Therefore, we sub-sample P to a resolution
close to the resolution of a patch pixel P
?
and calculate the
approximate coverage value for P
?
by computing surface
patches and counting the number of valid pixels. We use
the coverage value to guide our greedy selection of possible
locations and start with the location that corresponds to the
best coverage value. Once selected, we update the coverage
of the neighborhood of a location according to the area the
corresponding patch covers. To compute a coordinate frame
of a patch we compute the normal of the range data in the
patch space and chose x- and y-axes from the two global
coordinate axes that have the larger angle to the computed
normal and make them orthogonal to the normal. In this
way,weconstrainthecubicalsurfacepatchesintheirrotation
around the normal according to a global coordinate frame.
Given constrained orientations for surface patches we can
extend the greedy search to ﬁrst select a maximum coverage
location and then search in the neighborhood along the
deﬁnedx,y-directionsforpossiblecandidatelocationswhich
are well-aligned to our cubical patch structure. As a result
of this alignment the average distance between neighboring
surface patch locations is increased compared to distance-
only based methods while still covering the same surface.
B. Dictionary Learning with wK-SVD
The extracted surface patchesS contain a lot of redundant
information on RGB and depth channels. Thus, we intend to
compute a sparse approximation to ﬁnd a compact represen-
tation of the data. Let S be the data matrix that contains
every s
i
as i-th column vector. The idea of K-SVD is to
learn an overcomplete dictionary D and a sparse description
X toapproximateS.Wecanformulatethisasaminimization
problem using the following equation:
minkS?(W ?(DX))k
2
F
s.t. ?ikx
i
k
0
≤ k. (1)
Here, kAk
F
denotes the Frobenius norm, ? denotes the
element-wise matrix multiplication, and k is the maximum
number of nonzero entries for each column x
i
that approxi-
mates a corresponding surface patch s
i
≈ Dx
i
.
To deal with undeﬁned values we use weighted K-SVD
(wK-SVD) which applies a binary weighting matrix W that
contains a 1 for data pixels that were actually observed
and 0 otherwise. This information is represented in the
bitmask channel of the patches. In this way we ignore the
reconstruction results for undeﬁned values and focus the
reconstruction accuracy on the observed values. Undeﬁned
6240
pixels store a value of zero in S and by multiplying W in an
element-wise fashion we ensure that the reconstructed values
of undeﬁned pixels are ignored during the optimization. A
more detailed description of wK-SVD and a comparison to
regular K-SVD can be found here [14] give.
To learn our reference dictionary we apply wK-SVD
independently on every level for the depth channel and the
RGB channel and concatenate the dictionaries per channel
and update the indices of the sparse codes accordingly. Since
the impact of errors on the resulting model scales with the
size of a patch, we require a low reconstruction error for the
higher levels. We start with a maximum number of allowed
dictionary entries or the maximum number of data entries for
the current level. Since wK-SVD reports back the number
of unused entries, we crop the dictionary afterwards and
proceed with the next level.
We can decode a modelM(H,D
depth
,D
rgb
,I) back into
apointcloudifneeded.Thiscanbedonebyiteratingthrough
all elements of I and decoding the j-th element with
ˆ s
j
depth
=D
depth
·c
depth
j
. (2)
With c
depth
j
= [?
1
j
,...,?
N
j
] this can be rewritten as
ˆ s
j
= ?
1
j
·d
depth
1
+···+?
N
j
·d
depth
N
. (3)
Note that the sparse code c
j
is a sparse vector with only k?
N nonzero entries. We apply the same scheme for decoding
the color channel and project the joint information into a
colored 3D point cloud according to the scale information
for all values deﬁned in b
j
. Finally, we apply T
j
to put the
patch point cloud at the right location in the resulting
ˆ
P.
IV. EXPERIMENTS
The interesting quantities for our models are accuracy,
compactness and the time needed to compute a model.
As measure of compactness, we take the ﬁle size of the
resulting models. As measure of accuracy, we compute the
Root Mean Squared Error (RMSE) between the input point
clouds P and the point cloud reconstruction of our model
ˆ
P. Obviously, this depends on the sensor noise and the
discretizationschemeweapplyinourmodels.Still,theorder
ofmagnitudeoftheerrorisagoodindicatorfortheaccuracy.
We compute the error for every point in
ˆ
P by searching for
the nearest neighbor in P and vice-versa. In this way, the
error measures inliers and outliers.
A. Inﬂuence of Maximum Standard Deviation
Crucial questions are how much we gain from introducing
multiplelevels withdifferent patch sizes and ifthemaximum
standard deviation is a good criterion to guide our decision
what to model on a certain level. Therefore, we conducted a
corresponding experiment on the small RGB-D frame shown
in Fig. 3. We chose to use 4 levels with patch sizes of
24/12/6/3 cm and corresponding resolutions of 24/12/6/3
mm. In the ﬁrst setting, we varied the maximum allowed
standard deviation of the depth channel ?
depth
max
for a ﬁxed
maximum standard deviation of the RGB channel ?
rgb
max
=
100. In the second setting, we used a ﬁx ?
depth
max
= 1.0
Fig. 4. This Figure shows the data sets used for comparison with Octomap
and Sparse Coded Surface Models. The top picture shows an overview of
a RGBD data set acquired in a typical corridor environment. The second
picture shows the publicly available fr1/room data set.
and varied ?
rgb
max
. We chose large values for ?
max
to reduce
the impact of the dependency between the two parameters.
Fig. 5 shows the resulting plots. The left plot shows the area
covered for every level of the hierarchy and the resulting
RMSE for the corresponding model. For small ?
depth
max
the
models are fully covered with small patches of the lowest
level. By increasing ?
depth
max
the contribution in coverage is
shifted to higher levels. This drastically reduces the number
of patches needed to describe the surface and results in more
compact models. The right plot shows a similar evaluation
for ?
rgb
max
. Again, the area covered with larger patches of
higher levels increases while relaxing the parameter. We
highlightedthemostinterestingparameterrangeswithalight
gray box. In this parameter range the ﬁle size is reduced
around 25% while only moderately increasing the error.
B. Comparison to Octomap and SCSM
In this section, we compare our proposed method to
Octomap [18] and the non-hierarchical SCSM. Therefore
we applied our method on three different data sets, the
example scene illustrated in Fig. 3, a SLAM solution
1
and
the publicly available fr1/room data set [16], both shown in
Fig. 4. Table I gives an overview of the relevant statistics
for Octomap, SCSM and the proposed method. Note that
we chose the minimum resolution according to the average
distance between sensor and surfaces in the data set and to
avoid over-ﬁtting to sensor noise. On the three data sets,
our method never extracted patches on level 4 or higher.
Therefore, we provide timings for the larger data sets only
with 3 levels.
For the corridor SLAM data set, we applied our method
to the accumulated point cloud and built a model with
35,824 surface patches on three hierarchy levels (251 / 801
/ 34,772). As can be seen, the resulting models have no
patches on the highest level. The full process of creating the
model took 19min including the dictionary learning with a
dictionary size of 1,000 for the depth channel and 3,500 for
1
Courtesy of Peter Henry
6241
0
10
20
30
40
50
0 0.02 0.04 0.06 0.08 0.1
0
1
2
3
4
m
2
milimeter
?
depth
max
[mm]
area level 4
area level 3
area level 2
area level 1
RMSE [mm]
0
10
20
30
40
50
0 2 4 6 8 10 12
0
0.1
0.2
0.3
0.4
0.5
m
2
/ RGB error
ﬁle size [MB]
?
rgb
max
[RGB]
area level 4
area level 3
area level 2
area level 1
ﬁle size [MB]
RMSE [RGB]
Fig. 5. Impact of the maximum standard deviation parameters ?
depth
max
and ?
rgb
max
on our hierarchical model. The left plot shows the area covered for
every level of the hierarchy and the resulting RMSE. For small values of ?
depth
max
our model is fully covered with small patches of the lowest level. By
increasing ?
depth
max
we shift the contribution in coverage to higher levels. This reduces the number of patches needed to describe the surface. The right
plot shows a similar evaluation for ?
rgb
max
. Again, the area covered with larger patches at higher levels increases while relaxing this parameter. The most
interesting parameter ranges are marked with light gray boxes. In this area the ﬁle size is reduced by 25% with only a moderate increase in error.
Data set method dict. (D/RGB) patch size res.(cm) input result RMSE (D/RGB) time
Scene Fig. 3 Octomap - / - - 0.3 4.7MB 918kB 0.0014m / 8.2 0.25s
Scene Fig. 3 SCSM 100 / 200 0.03m 0.3 4.7MB 423.9kB 0.0016m / 14.3 7s
Scene Fig. 3 HSCSM 100 / 200 0.03m 2.4 / 1.2 / 0.6 / 0.3 4.7MB 343.6kB 0.0017m / 15.2 8s
RGBD Corridor Octomap - / - - 2 3.35GB 44.5MB 0.016m / 25.1 56s
RGBD Corridor SCSM 100 / 500 0.2m 2 3.35GB 10.2MB 0.017m / 19.9 8min
RGBD Corridor HSCSM 1000 / 3000 0.8 / 0.4 / 0.2m 8 / 4 / 2 3.35GB 7.8MB 0.013m / 21.7 19min
fr1/room Octomap - / - - 1 2.7GB 45MB 0.006m / 39.6 2min
fr1/room SCSM 500 / 3500 0.05m 1 2.7GB 8.1MB 0.005m / 29.9 31min
fr1/room HSCSM 500 / 3500 0.2 / 0.1 / 0.05 m 4 / 2 / 1 2.7GB 7.2MB 0.005m / 30.0 36min
TABLE I
EXPERIMENTAL EVALUATION FOR EACH DATA SET AND METHOD. THE DICTIONARY SIZE AND RMSE ERRORS ARE SPLIT INTO DEPTH AND RGB. WE
MEASURED THE TIMINGS ON A STANDARD DESKTOP CPU WITH 3 GHZ.
the RGB channel. The model created with our hierarchical
method outperforms Octomap in terms of accuracy and also
visually as can be seen in Fig. 6 (b) and (d). Regarding
runtime, Octomap is fastest with less than a minute but
introduces a higher error in both depth and RGB space.
Compared to SCSM, the hierarchical model is 24% more
compact and more accurate in the depth channel. The error
in RGB space is slightly higher. This is due to the fact that
encoding errors in larger patches have a bigger impact on the
overall error calculation. Therefore we had to increase the
dictionary sizes compared to the non hierarchical method.
The fr1/room data set was captured in a cluttered ofﬁce
environment and is a challenging benchmark for our method.
Clutter introduces a high entropy and makes it harder to ﬁnd
similar structures. Fig. 7 shows an example view for the
raw point cloud, Octomap, SCSM and our method. Again,
our method outperforms Octomap in terms of accuracy and
compactness, while it requires more computation time. The
model also looks smoother while being 84% smaller in size.
IncomparisontoSCSMwegain9%intermsofcompactness
while introducing a slightly higher error in RGB. In general,
the gain in compactness is highly inﬂuenced by the amount
of variations in structure and texture. In the worst case the
full surface needs to be represented at the lowest level so
that the resulting model performs similar to SCSM.
V. CONCLUSIONS
In this paper, we presented a novel approach to con-
struct textured 3D models using a hierarchy of local sur-
face patches. Our method employs differently sized surface
patches thus leading to more compact models. Furthermore,
our method exploits similarities in structure and texture by
using Sparse Coding to describe surface attributes. It learns
the required dictionaries during the model creation process
in an unsupervised fashion. Practical experiments carried out
with data sets of different scale demonstrate that our method
compares favorably with two state-of-the-art techniques.
REFERENCES
[1] L. Bo, X. Ren, and D. Fox, “Unsupervised feature learning for rgb-d
basedobjectrecognition,”Proc.oftheInt.SymposiumonExperimental
Robotic(ISER), 2012.
[2] B. Curless and M. Levoy, “A volumetric method for building complex
models from range images,” in Proceedings of the 23rd annual
conference on Computer graphics and interactive techniques. ACM,
1996, pp. 303–312.
[3] M. Elad and M. Aharon, “Image denoising via sparse and redundant
representations over learned dictionaries,” IEEE Transactions on Im-
age Processing, vol. 15, no. 12, pp. 3736–3745, 2006.
[4] N.Fairﬁeld,G.A.Kantor,andD.Wettergreen,“Real-timeSLAMwith
octree evidence grids for exploration in underwater tunnels,” Journal
of Field Robotics, 2007.
[5] U. Feige, “A threshold of ln n for approximating set cover,” Journal
of the ACM (JACM), vol. 45, no. 4, pp. 634–652, 1998.
[6] P. Henry, D. Fox, A. Bhowmik, and R. Mongia, “Patch volumes:
Segmentation-based consistent mapping with RGB-D cameras,” in
International Conference on 3D Vision (3DV), 2013.
6242
a) b)
c) d)
Fig. 6. Resulting model for the RGB Corridor data set, a representative part of the model as a raw point cloud (a), an octomap (b), SCSM (c) and the
hierarchical variant we propose (d). The Octomap occupancy grid has a ﬁle size of 44.49MB with a voxel size of 2cm, an RMSE of 0.016m on the depth
channel and an RMSE of 25.1 on the RGB channel.The model without hierarchy has a ﬁle size of 10.2MB and stores a depth dictionary with 100 entries
and a RGB dictionary with 500 entries. The RMSE is 0.017m for the depth channel and 19.9 for the RGB channel. The hierarchical model has an RMSE
of 0.013m for the depth and of 21.7 for the RGB channel. In comparison, the hierarchical model has the lowest error in the depth data and an error in
the RGB data that is between the octomap and Sparse Coded Surface Model errors. Organizing the data with the hierarchical model reduces the required
storage from 10.2MB to 7.8MB.
a) b) c) d)
Fig. 7. Resulting model for the fr1/room data set, a representative part of the model as raw point cloud (a), an Octomap (b), SCSM (c) and HSCSM (d).
[7] P. Henry, M. Krainin, E. Herbst, X. Ren, and D. Fox, “RGB-D
mapping: Using depth cameras for dense 3d modeling of indoor
environments,” in Proc. of the Int. Symposium on Experimental
Robotic(ISER), vol. 20, 2010, pp. 22–25.
[8] A. Hyvarinen, P. Hoyer, and E. Oja, “Image denoising by sparse code
shrinkage,” Intelligent Signal Processing, pp. 554–568, 2001.
[9] J. Kammerl, N. Blodow, R. B. Rusu, S. Gedikli, M. Beetz, and
E. Steinbach, “Real-time compression of point cloud streams,” in
Proc. of the IEEE Int. Conf. on Robotics & Automation (ICRA),
Minnesota, USA, May 2012.
[10] L. Ma, T. Whelan, E. Bondarev, P. H. N. de With, and J. McDonald,
“Planar simpliﬁcation and texturing of dense point cloud maps,”
in Proc. of the European Conference on Mobile Robots (ECMR),
Barcelona, Spain, September 2013.
[11] R. Newcombe, A. Davison, S. Izadi, P. Kohli, O. Hilliges, J. Shotton,
D. Molyneaux, S. Hodges, D. Kim, and A. Fitzgibbon, “Kinectfusion:
Real-time dense surface mapping and tracking,” in IEEE International
Symposium Mixed and Augmented Reality (ISMAR), 2011.
[12] B. Olshausen, D. Field, et al., “Sparse coding with an overcomplete
basis set: A strategy employed by vi?” Vision research, vol. 37, no. 23,
pp. 3311–3326, 1997.
[13] R.Rubinstein,M.Zibulevsky,andM.Elad,“Doublesparsity:Learning
sparse dictionaries for sparse signal approximation,” IEEE Transac-
tions on Signal Processing, vol. 58, no. 3, pp. 1553–1564, 2010.
[14] M. Ruhnke, L. Bo, D. Fox, and W. Burgard, “Compact RGBD surface
models based on sparse coding,” in Proc. of the National Conference
on Artiﬁcial Intelligence (AAAI), 2013.
[15] M. Ruhnke, R. K¨ ummerle, G. Grisetti, and W. Burgard, “Highly
accurate 3d surface models by sparse surface adjustment,” in Proc. of
the IEEE Int. Conf. on Robotics & Automation (ICRA), 2012.
[16] J. Sturm, N. Engelhard, F. Endres, W. Burgard, and D. Cremers, “A
benchmark for the evaluation of rgb-d slam systems,” in Proc. of the
Int. Conf. on Intelligent Robots and Systems (IROS), 2012.
[17] T. Whelan, M. Kaess, J. Leonard, and J. McDonald, “Deformation-
based loop closure for large scale dense RGB-D SLAM,” in Proc. of
the Int. Conf. on Intelligent Robots and Systems (IROS), 2013, (to
appear).
[18] K. Wurm, A. Hornung, M. Bennewitz, C. Stachniss, and W. Burgard,
“Octomap: A probabilistic, ﬂexible, and compact 3d map represen-
tation for robotic systems,” in Proc. of the ICRA 2010 workshop on
best practice in 3D perception and modeling for mobile manipulation,
vol. 2, 2010.
[19] J. Yang, K. Yu, Y. Gong, and T. Huang, “Linear spatial pyramid
matching using sparse coding for image classiﬁcation,” in Proc. of
the IEEE Conf. on Computer Vision and Pattern Recognition (CVPR),
2009, pp. 1794–1801.
6243
