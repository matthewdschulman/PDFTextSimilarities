 
 
 
? 
Abstract— Haptic devices are dedicated to render virtual 
tactile stimulation. A limitation of these devices is the 
intrusiveness of their mechanical structures, i.e. the user need 
to hold or wear the device to interact with the environment. 
Here, we propose a concept of new tactile device named HAIR. 
The device is composed of a computer vision system, a 
mechatronic device and air jets that stimulate the skin. We 
designed a first prototype and conducted a preliminary 
experiment to validate our concept. The interface enables a 
tactile interaction without using physical contact with material 
devices, providing better freedom of movement and enhancing 
the interaction transparency.  
 
I. INTRODUCTION 
Haptic rendering technologies are becoming a strategic 
component of the new Human-Computer Interfaces (HCI). 
Haptic interfaces stimulate users through tactile and 
kinesthetic channels to improve the interaction and 
immersion in teleoperated tasks or virtual environments [1]. 
Haptic technologies demonstrated their value in different 
application fields. The use of haptic feedback for robotic 
teleoperated minimally invasive surgery can significantly 
enhance a surgeon’s accuracy, dexterity and visualization [2]. 
Haptic based Virtual Reality (VR) approaches have increased 
both speed and accuracy of human-computer interactions for 
the edition and the assembly of 3D Computer Aided Design 
(CAD) models [3]. In the field of rehabilitation, haptics plays 
an important role for the training of sensory motor skills and 
to alleviate the motor system impairments [4]. In education, 
games, and entertainment several studies have shown the role 
of haptics to improve the learning and the interactivity 
though the physical interaction with the content [5]. Despite 
the key role of haptic feedback in enhancing human computer 
interactions; the use of haptic devices in everyday and 
industrial applications is still limited. This is due to the 
intrusiveness and the limit of some performance factors of 
existing haptic devices. For example, haptic interfaces based 
on articulated robotic structures like exoskeletons [6], or 
cable systems [7] adopt devices that must be physically 
 
Mohamed Yassine Tsalamlal, Paul Issartel, and Mehdi Ammi are with 
LIMSI/CNRS and the University of Paris-South, Bâtiments 508, 502bis & 
512 Rue John von Neumann Université Paris-Sud 91403 Orsay, France ( e-
mail: first_name.last_name@ limsi.fr).  
Nizar Ouarti is with ISIR/CNRS, University of Pierre and Marie Curie,  
Pyramide - Tour 55  4 Place Jussieu 75005 Paris - France (e-mail: 
first_name.last_name@isir.upmc.fr). 
 
connected to the user through mechanical systems. These 
systems are often intrusive, limiting the comfort and the 
transparency of interaction. 
In this research, we introduce the concept and first design 
stages of a novel non-intrusive haptic interface based on 
direct air jet tactile stimulation. The interface named HAIR 
enables a tactile interaction without using physical contact 
with material devices, providing better freedom of movement 
and enhancing interaction transparency. This paper is 
structured as follow: In section II, we first highlight studies 
and new actuation technologies that address workspace and 
intrusiveness constraints. The section III presents the concept 
of the proposed tactile stimulation approach.  In section IV, 
V, VI, and VII we detail the different parts of the prototype 
device. Finally in section VIII we present a preliminary user 
experimental study to evaluate some performances of the 
proposed haptic device. 
II. RELATED WORK 
Several works have address the intrusiveness contains of 
existing haptic devices [8]. The most promising approach 
does not require contacts with material devices. This 
approach can be classified into two different strategies.  
The first strategy is based on acoustic radiations [9]. It 
consists in the control of the phase delays of acoustic waves 
to generate a focal point. This strategy provides a tactile 
feedback in 3D environments without physical contact with 
transductions. The main drawback of this strategy is the low 
intensity of generated force (Maximum force of 160mN). 
Moreover, the authors highlighted some potential medical 
risks for interactions with sensitive regions (e.g., head and 
face).  
The second strategy consists in the use of air based 
stimulations. The first work proposed to use multiple air jets 
arranged in a matrix. These jets hit an air receiver, kept by 
the user, in order to apply a force on the user's hand [10]. 
This strategy generates a kinesthetic feedback with 
important force intensity. However, it provides poor force 
and position resolutions. Moreover, the user needs to handle 
an end-effector in order to interact with the air jets. 
Thereafter, Inoue et al. [11] proposed to use a flexible sheet 
driven by an air jet. This approach provides a virtual haptic 
sensation of lumps under the user’s fingers. The main 
handicap of this method is that the flexible sheet is fixed and 
cannot move to enable a free exploration. For a free 
   HAIR: HAptic feedback with a mobile AIR jet  
Mohamed Yassine Tsalamlal, Paul Issartel, Nizar Ouarti, and Mehdi Ammi
 
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 2699
 
 
 
exploration and interaction, Romano and Kuchenbecker [12] 
proposed the AirWand device. The device is based on two 
air jets aligned along the longitudinal axis of the tool, 
comprising two air outlets. These two jets are used to create 
driving forces along the longitudinal axis in the positive and 
negative directions. The combination of three actuating axes 
enables the free interaction in a large working area but the 
resolution of the force is still limited. Finally, Bianchi et al. 
[13] proposed to use the air jet for the direct tactile 
stimulation. It consists to direct a thin stream of air on the 
finger pad. This work was limited to a distance of 2 cm. This 
system was designed for palpation using robot-assisted 
minimally invasive surgery (RMIS). This stimulation 
configuration (i.e., stimulation at 2 cm) greatly restricts the 
movement of the user and does not allow a free exploration 
of 3D environments. Recently, Disney research proposed the 
AIRAL device [14]. It consists to use toroid vortices that can 
travel large distances, to stimulate skin. Moreover, they 
proposed an efficient tilt pan system to control the 
orientation of the vortices generation. The main constraint of 
this approach concerns the discontinuity of stimulation. In 
fact, the device cannot provide continuous air tactile 
stimulation. 
     It is clear that air based stimulation strategy is a very 
promising approach to address intrusiveness contains of 
actual haptic devices. However, existing works exploit either 
intermediate object for interaction with air jets (i.e., air 
receiver), or exploit very short air jet stimulation distances, 
restricting the user’s workspace, and devices that use air 
vortexes cannot provide continuous tactile stimulation witch 
is necessary for the continuous perception of data.  
III. CONCEPT & PROTOTYPING DESIGN STAGES 
In order to provide a continuous position and force tactile 
stimulation in the free space without handling or wearing 
any material device, we propose a new actuation technology 
based on the relevant features of the air jet tactile 
stimulation. The proposed concept consists on providing air 
jet tactile stimulation according to the movement of the user 
and the features of the interaction data. This approach uses 
long distance and continuous stimulation, addressing the 
limitations of actual air based interfaces.  
The proposed device is based on combining an air jet, used 
on a suitable distance that provides the best compromises 
between flow features (i.e., level of turbulences, flow rate 
intensity), with a robotic structure for the positioning and the 
orientation of the stimulus according to the relative 
configuration of the displayed data (see figure 1). 
The designed prototype includes three main components: 1) 
the air jet system to control the flow features; 2) the robotic 
structure to control the position and the orientation of the air 
jet; and 3) the computer vision system to track the region on 
the body to stimulate (e.g., hand, forearm). 
 
The air jet tactile stimulation represents the central part of 
the proposed haptic device. The first step, it is to study and 
identify the different configurations of stimulation and the 
design of an air jet system.  
The second step is the design and the implementation of 
the robotic platform to enable the positioning and orientation 
of the air jet in the 3D space. This task includes the study 
and development of the mechanical structure, the 
characterization and the integration of the actuators 
components, and the development of the control laws 
according to the required behaviors and involved constrains.  
To simplify the implementation of the first prototype, the 
current version only supports 2D horizontal movements (X 
and Z axes) for the air jet. Moreover, the orientation of the 
air jet is fixed vertically (Y axes). We plan to include the 
additional Degree of Freedom (DoF) in next versions to 
support the 3D positioning and the orientation of the air jet.  
 
 
 
Figure 1.  Interface design concept 
 
To simplify the implementation of the first prototype, the 
current version only supports 2D horizontal movements (X 
and Z axes) for the air jet. Moreover, the orientation of the 
air jet is fixed vertically (Y axes). We plan to include the 
additional Degree of Freedom (DoF) in next versions to 
support the 3D positioning and the orientation of the air jet.  
For this first prototype we decided to focus on tracking 
and stimulating the users hand palm, we developed a 
computer vision system that uses both color and depth 
information of the scene to detect the position the hand in 
3D space. Although the robotic structure moves in 2D space, 
2700
 
 
 
it is possible to modulate the tactile stimulation according to 
the distance from the air jet system to provide tactile 
feedback in 3D space. The color and depth information are 
computed by a kinect device placed above the user. 
The last step was the implantation of a global software 
framework to provide a flexible access to the different levels 
of control and information of the haptic interface. We also 
designed some applications to study the usability of the 
proposed haptic device for the interaction with various types 
of environments (dataset exploration, perception of surface, 
etc.).  
The design of the different parts of the device is detailed 
in the next flowing sections.  
IV. AIR JET STIMULATION 
A. Dynamic modelling of air jet flow 
The design of the air jet tactile stimulation must respond to a 
number of constraints. In fact, it has to enable long distance 
tactile stimulation while providing the adequate applied 
force. A theoretical study was necessary to understand the 
air jet dynamics and characteristics. This should lead to an 
efficient design of air jet stimulation and address the 
mentioned constraints. The free air jet has been widely 
studied with different configurations.  This is mainly due to 
the high number of parameters that affect the aerodynamic 
of the air jet. In fact, the system is affected by many factors 
[15], including the shape of the nozzle, the initial rate of 
turbulence of the jet (i.e., Reynolds number)… 
Gauntner et al. [16] highlighted that the free round air jet is 
characterized by two different flow regions. The potential 
core region and the free jet region (see figure 2).  These 
regions are related to centerline velocity of the jet.  
 
 
Figure 2.  Free air jet flow regions  
 
Region 1: Corresponds to a short zone (potential core) 
where centerline velocity  
 
 at a distance x from the outlet 
is equal to outlet velocity  
 
. 
 
    
 
  
 
                                        (1) 
 
The region 1 presents the best air jet features, but it provides 
a very short stimulation distance which could constraint the 
user movements. Moreover, it covers a small area limiting 
the surface of stimulation. This may not be suitable for some 
applications requiring greater stimulation area (e.g., hand 
palm). 
 
Region 2: Corresponds to the full air jet development zone. 
The centerline velocity of the jet in region 2 can be 
calculated from an equation based on the principle of 
momentum conservation along the jet (2).  
 
 
 
 
 
  
 
   
 
                                      (2) 
 
Where  
 
 corresponds to the end of the potential core zone 
(region 1),   corresponds to the outlet diameter, and   is the 
decay constant coefficient. The   value is an important 
factor for describing jet performance.   
 
 and   value is 
usually calculated by measuring mean velocities in different 
centerline positions of the air jet.  
Obviously, to measure theses velocities it is necessary to 
perform tedious experimental studies. 
Velocity distribution in the cross-section of a jet in the 
region of fully developed jet follows a general trend of the 
Gaussian distribution  
         
 
 
 
 
      
 
 
   
 .                             (3) 
Where   is the trasverse distance from the centerline or axis 
and   the root-mean-square-deviation. 
   Region 2 presents intermediate features. In fact, it 
corresponds to a longer distance region 1, which provides 
greater workspace allowing free users’ movements. Besides, 
with an average flow rate, the velocity intensity is sufficient 
to provide high range of force stimulation intensity. 
Additionally, the contact zone is greater than region 1, 
because of the spreading effect, providing greater 
stimulation area. Yet, the end of region 2 corresponds to a 
highly turbulent flow, where the centerline velocity 
decreases rapidly.  
This state of the art of air jet flow permits to understand its 
dynamics and features. To provide a relevant haptic 
rendering, we propose to exploit region 2 for tactile 
stimulation. However, it is necessary to perform empirical 
studies to the physical features of the air jet. In fact, it is not 
possible evaluate the jet characteristics (like the regions 
length) from theoretical models due to the large number of 
influencing factors. These empirical studies should be 
addressed in our future works. 
The next step of our design is to develop the air jet system 
for the haptic device and identify its features. 
A. Air jet system & Physical features  
An air jet system is required for the generation of the air 
flow. In our implementation, this is based on three 
components. The air compressor, to generate the require 
working pressure; a mass flow controller which enables 
continuous control of the intensity and frequency of the air 
2701
 
 
 
jet; the nozzle, which allows control of some flow features 
such air jet diffusion envelope.  
The nozzle is supplied by air through a flexible tube with 
a 6 mm diameter. An air compressor provides sufficient air 
pressure (4 bars) and continuous air flow. The flow rate is 
accurately controlled (up to 50L/min ±0.02) using an 
industrial mass flow controller (MFC Burkert 8711). In this 
device the flow rate value measured by a sensor is compared 
by the integrated electronic controller with the digital set 
value. If a difference is detected, the control applied to the 
proportional valve is changed by using a PI control 
algorithm. The flow rate can be maintained at a fixed value 
or be assigned to a profile, regardless of variations in 
pressure or changes in the system. 
 To provide an accurate resolution of air jet tactile 
stimulation, we need to generate a concentrated air jet. The 
choice of the nozzle shape is a key parameter. In fact there is 
a direct relationship between this parameter and the 
diffusion angle of the jet [17]. Several types of nozzles were 
examined and tested. The adopted nozzle (SILVENT MJ4) 
is made of stainless steel with a central hole surrounded by 
slots to generate a concentrated air stream while limiting the 
sound level. Its small dimensions make this nozzle suitable 
for incorporation into the device. 
Ideally, the impinging force and the diameter of the jet 
envelope would be determined using models of fluid 
mechanics. Although, an accurate model is difficult to obtain 
since the system is affected by many factors [15], including 
the outlet geometry (e.g., shape, size), the type of air flow 
(e.g., laminar, turbulent), pressure losses due to friction 
along the length of the tubing, air temperature etc. In this 
study we propose to use empirical models determined using 
the datasheet of the nozzle.  
 
 
 
 
 
 
 
 
 
 
 
 
Figure 3.  Air jet envolope  
The technical specifications provide information about the 
jet flow including the blowing force (F) in Newton 
according to the flow rate (Q) in L/min, and the jet diameter 
(Ø) in millimeter as a function of distance (x) in millimeter 
(Figure 3). According to the datasheet, these two 
relationships, present a linear profile in a distance range 
[150;450] mm and flow rate range [23.3;135] L/min: 
 
                                                  (4) 
                                     
                                                   (5) 
 
B. Air jet perception features 
Beyond the physical features of the air jet, it is necessary to 
characterize the perception of users of the air jet tactile 
stimulation. We performed a quantitative study of human 
tactile perception, examining the relationship between the 
observed quantifiable physical stimuli and users responses 
[18]. The study of tactile perception involved two types of 
measurements: determining the absolute threshold and the 
differential threshold. Absolute threshold measurement is 
performed by detecting the presence of a stimulus. This 
value corresponds to the minimum intensity at which the 
stimulus is just detectable.  Moreover, it is important to 
determine the differential threshold. This threshold refers to 
the smallest change incremented or decremented in stimulus 
intensity that is detectable by the subjects. It is also known 
as the just noticeable difference (JND). The differential 
threshold is measured according to a reference stimulus; it 
must be presented in relation to this reference value. Both of 
the absolute and differential thresholds can be measured by 
similar experimental procedures. The details of experimental 
method used in the experiments can be found in [18]. 
Results (see figure 4) revealed that there is a linear 
relationship between the perceived absolute threshold and 
the distance from the hand palm to the nozzle.  
Figure 4.  Psychophysical featrues  
The second psychophysical experiment was made to 
determinate the just noticeable difference of the air flow rate 
according to three referential stimuli. Then we estimated the 
Weber fraction. These two results are important for the 
display control of the air jet tactile stimulation. Indeed, these 
features allowed to identify the optimal stimulation 
configuration (distance, applied tactile stimulus, etc.). 
V. TRACKING SYSTEM 
The tracking system allows the monitoring of the user's 
hand position. The system is based on a kinect sensor placed 
082 . 0 012 . 0 ? ? Q F
561 . 1 215 . 0 ? ? x ?
 
Air jet diameter (mm) 
Ø 65  Ø 35  Ø 100  
0
  
150  300  450  
Distance from the nozzle (mm) 
MJ 4 
0
10
20
30
150 250 350
Mean theshold 
(L/min) 
Distance from the nozzel (mm) 
,0
2,0
4,0
6,0
8,0
10 20 30
Mean JND (L/min) 
Reference flow rate ( (L/min) 
2702
 
 
 
above the workspace. The Kinect provides a depth map of 
the scene. With this information, it is possible to determine 
the position and orientation of the hand in three axes. The 
main reason for choosing the Kinect sensor for this project is 
it’s relatively low cost. Despite of some limitations, in 
particular the quality of depth image, the sensor is cheap and 
efficient for the design of a prototype. Today many 
computer vision projects are based on the Kinect sensor. 
However, Most of these works deal with 3D reconstruction 
[19], obstacle avoidance [20] and monitoring of entire 
silhouettes [21]. Some studies deal with the hand tracking 
only in the image. It is often the position of the fingers is 
sought [22]. However, none of these projects meet the needs 
and requirements of our system. Therefore, it was necessary 
to design a tracking algorithm suitable for the application. 
To simplify the tracking algorithm, a certain number of 
constraints have been adopted. The workspace is placed in 
the working range of the kinect. Only the arm and hand may 
enter a defined workspace. The palm of the hand is facing 
downwards. The fingers have to be tight (only the thumb can 
be removed); the inclination of the hand relative to the 
working plane must be less than 45°.  The tracking system 
uses the OpenCV library specializing in the analysis of real-
time images.  
VI. ROBOTIC STRUCTURE 
A. Mechanical Structure  
The robotic structure moves the end-effector (i.e., nozzle) 
according the user’s actions and the features of perceived 
data.  The design of the robotic structure must consider 
different constraints. The available working space must be 
suitable and sufficient. For some applications the end-
effector must follow the movement of the user’s hand. To 
limit the risks of contact between the mechanical structure 
and the user, we propose to separate the space reachable by 
the robotic structure and the working space of the user. The 
main movement of the end-effector corresponds to a 
horizontal translation (2 DoF) to follow the movement of the 
hand. For the first prototype, we adopted a serial mechanical 
structure with three rotoid joints. This configuration 
addresses the constraints mentioned above, and is relatively 
simple to implement (see figure 6). Considering that our first 
approach is consisting on designing a prototype to validate 
the proposed stimulation strategy. Simplicity feasibility and 
material cost constitute important criteria. To design the 
prototype we used a robotic kit [23]. This solution was 
chosen for the simplicity of the assembly of mechanical 
components and the control of actuators. 
B. Robot control method 
   The robot end-effector (i.e., nozzle) has to move according 
to the user’s actions. For example, the nozzle tracks and 
stimulates the users hand palm. We propose to implement a 
position control. The control loop of the end-effector is 
represented in the figure 5. The robot is positioned using 
individual movement of the joints which are described by 
the vector of joint variables   ). Since we know the length of 
the different axes of the manipulator and the operational 
variables that we want to target (X , we can calculate the 
values of the corresponding joint variables  ) [24] [25] [26].  
 
 
 
 
 
 
Figure 5.  Robot control loop 
We used the Jacobian Pseudoinverse matrix to ? ?
  calculate 
the   vector [27]. This algorithm provides a relationship 
between a small ∆X movement ∆  of the end effector and a 
small change in posture, as in  
 
∆  = ? ?
 ∆X.                                 (6) 
The different positions of the articulations are computed 
on a host PC and sent to the servomotors through a control 
board based on the Atmel386 microcontroller. 
VII. GLOBAL PLATFORM 
The global platform consists on assembling the three 
systems and the design of the software framework. First the 
nozzle of the air jet system is coupled to the robotic arm. 
The structure is fixed on a table that represents surface the 
work space. The Kinect sensor must be above the hand of 
the user, so it is attached to metallic support at 1m height 
(see figure 6). 
 
 
 
 
 
Invers 
kinematics 
Forward 
kinematics 
Axes 
controllers 
 
   
  
   
 
    
     
2703
 
 
 
 
Figure 6.    Haptic drvice prototype 
We have developed a software Framework in C++ to control 
the device. The software interface provides access to two 
levels of control: the first concerns the high input / output 
level functions. This mode allows the implementation of 
high-level haptic features, such as generating haptic surfaces 
with a simple description of plane coordinates. The second 
level provides functions of input / output low-level, such as 
controlling the position of the end effector or rate of the jet 
according the user movements. 
VIII. EVALUATION EXPERIMENT 
 We performed a preliminary user experiment to compare the 
some performances of the air jet tactile device with two 
other haptic devices. The first device is the CyberGlove, a 
wearable vibrotactile device [28]. The second device is the 
Phantom Omni, a desktop force feedback interface [29]. 
We designed a target detection task and measured mean 
duration and path length. Seven participants took part to the 
experiment. The task was to detect five invisible spheres of 5 
cm diameter on a virtual surface using. The spheres were 
placed in random position on a surface of (20   20) cm. 
Each participant used the three devices. The devices have 
the same physical metric scale. When the hand of the user 
touches a virtual sphere, he receives a haptic stimulation. 
The HAIR stimulates the users hand palm with an air jet. 
The CyberGlove stimulate the user with the vibrotactile 
actuator on his hand palm. Finally the participants held the 
tool of the Phantom and receive vibration when they touch a 
sphere. 
A training stage was performed by the subject with a visible 
sphere and the representation of the user’s hand in 3D (see 
figure 7). Then, the proper experiment can begin with the 
random invisible sphere but with a representation of the 
user’s hand still visible. The three conditions (Air jet, 
CyberGlove, Phantom) were presented randomly. 
 
 
 
Figure 7.  Graphic interface of the experiment. The green ball represents 
the target to reach and the 3D hand represents the hand of the user. These 
two objects are in the same 2D plane (in blue). The shadows of the objects 
are represented to help the user to move properly. In the training stage, the 
sphere is represented in green but in the experiment it is invisible.   
  For the three configurations, we measured the duration to 
reach each target, the path length covered by the hand of the 
participant to find a target. Mean results of the experiment 
are reported in figure 8. 
 
 
 
Figure 8.  Performences results 
 
    We performed a repeated measure ANOVA analyses to 
highlight if there is any significant differences. The analyses 
showed significant (p=0.012) differences in duration 
0
10
20
30
Mean duration (s)
HAIR
CyberGlove®
PHANTOM Omni®
0
1
2
3
Mean Path length (m)
2704
 
 
 
between the three devices. Post-Hoc pairwise analyses 
showed that participants take more time to find the target 
using the air jet device then using the CyberGlove (p=0.02). 
But, there is no significant difference between the HAIR 
device and the Phantom. The analyses also reveal that there 
were significant differences (p=0.02) between the three 
devices in the path length covered by the hand of the 
participants. Post-Hoc pairwise analyses showed that 
participants needed a longer path length to reach the targets 
using the HAIR device then the CyberGlove and the 
Phantom (respectively: p=0.004; p=0.013). The difference of 
performances of the HAIR interface can be related to the 
dynamics of the robotic arm of the device. In fact, as 
explained in section VI, the device is designed with a low 
quality robotic kit.  Also, the CyberGlove and the Phantom 
are attached to the hand of the user witch permits higher max 
acceleration and velocity amplitudes. These results seem to 
be promising. We can say that air jet device have 
comparable performances with the two different other haptic 
devices, even it still remains at a prototyping stage. 
IX.  CONCLUSION AND OUTLOOK 
    This paper proposes a new non-intrusive haptic 
interface based on air jet tactile stimulation. The proposed 
concept consists on stimulating the user with an air jet 
according to his actions and the rendering data. The device is 
based on combining three main parts: a computer vision 
system, an air jet system, and a robotic system. 
In this paper we presented a first prototype that allows a user 
to interact with virtual objects projected on a 3D scene. The 
proposed haptic interface provides an alternative to the use 
of intrusive mechanical systems. The device offers 
continuous haptic stimulation, and provides greater 
transparency of haptic rendering, while providing the user 
with a secure operating environment.  
The next step consists on the design of a more efficient 
robotic system. We plan to study another robot configuration 
like planer systems. This should enhance the tracking 
characteristics (i.e. acceleration, max speed, position 
accuracy).   We also we manage to add three other DoF. 
This to allow control of the orientation of the nozzle (2 DoF) 
and distance (1 DoF) of the user's hand (to maintain a 
constant distance between the nozzle and the stimulated 
region). 
  We will also use tactile sensors to collect physical data like 
the pressure impact distribution according to the dynamics 
of the air jet. Stimulation time delay…etc.  This will provide 
performance specifications for the air jet haptic display. 
We started to investigate some application for the 
designed interface. The first application consists on the 
exploration of a 3D volumetric data. This type of application 
should support the needs of scientists who are exploring a 
volumetric dataset. We propose to uses the air jet tactile 
stimulation to explore a dataset in the field of fluid 
mechanics (i.e. Finite Time Lyapunov Exponent data). We 
evaluated the device with fluid mechanics experts and report 
on their qualitative feedback. They reported that this 
exploration technic seems to be promising. In fact, it 
provides a natural interaction with datasets and permits to 
rapidly identify targeted data.  Another application is the use 
of the mobile air jet stimulation to communicate affective 
states [30]. The air jet stimulation permits to generate low 
amplitude forces, which might be more suitable than high 
amplitude forces for the stimulation of the mechanoreceptors 
involved in tactile affective perception.  
REFERENCES 
[1] V. Hayward, O.R. Astley, M. Cruz-Hernandez, D. Grant, and G. 
Robles-De-La-Torre, “Haptic interfaces and devices,” Sensor Review, 
2004.24:16–29. 
[2] A.M. Okamura., “Methods for haptic feedback in teleoperated robot-
assisted surgery,” In Rob, 2004, 31(6): 499–508. 
[3] M. Bordegoni, U. Cugini, P. Belluco, and M. Aliverti, “Evolution of a 
haptic-based interaction system for virtual manual assembly,” In 
Proceedings of the 3rd International Conference on Virtual and 
Mixed Reality, Berlin, Heidelberg, (2009), pp. 303–312. 
[4] J. Broeren, M.  Georgsson, M. Rydmark, and K. Sunnerhagen, 
“Virtual reality in stroke rehabilitation with the assistance of haptics 
and telemedicine,” Proc. 7th ICDVRAT with ArtAbilitation, 2008, 
Portugal. 
[5] O. Sourina, Q. Wang, and M. K., Nguyen “EEG-based Serious Games 
and Monitoring Tools for Pain Management,” In Proc. MMVR18, 
(2011), California, 8(12), pp. 606-610.  
[6] A. Nakai, T. Ohashi, and H. Hashimoto, “7 dof arm type haptic 
interface for teleoperation and virtual reality systems,” In Proceedings 
of IEEE/RSJ International Conference on Intelligent Robots and 
Systems,1998, pp. 1266–1271. 
[7] M. Ishii, Z. Tang, S. Hasegawa, and M. Sato. “Flat pointers for pick 
and place in virtual environments using spider,” In Proceedings of 
Virtual Environments 2009. 
[8] M.Y. Tsalamlal, N. Ouarti, M. Ammi, “Non-intrusive Haptic 
Interfaces: State-of-the Art Survey,” In Proceedings of Haptic and 
Audio Interaction Design, 2013. pp. 1-9. 
[9] T. Wamoto, M. Tatezono, H. Shinoda, “Non-Contact Method for 
Producing Tactile Sensation Using Airborne Ultrasound,” In Ferre, 
M. (ed.) EuroHaptics 2008. LNCS, vol. 5024, pp. 504–513.  
[10] Y. Suzuki, M.  Kobayashi, “Air jet driven force feedback in virtual 
reality,” IEEE Computer Graphics and Applications, 2005, 44–47. 
[11] K. Inoue,  F. Kato, S. Lee, “Haptic device using flexible sheet and air 
jet for presenting virtual lumps under skin,” In: Proc. IEEE/RSJ Intl. 
Conference on Intelligent Robots and Systems, (2009), pp. 1749–1754.  
[12] J.M. Romano, K.J.  Kuchenbecker, “The AirWand: Design and 
Characterization of a Large-Workspace Haptic Device,” In 
Proceedings, IEEE International Conference on Robotics and 
Automation, 2009, pp. 1461–1466.  
[13] J.C. Gwilliam, M. Bianchi, L.K. Su, A.M. Okamura, 
“Characterization and Psychophysical Studies of an Air-Jet Lump 
Display,” In IEEE Transactions on Haptics, 2011, pp. 156 – 166. 
[14] R. Sodhi, I. Poupyrev, M. Glisson, and A. Israr, AIREAL: Interactive 
Tactile Experiences in Free Air. In Proc. ACM SIGGRAPH (2013). 
Article No. 134. 
[15] R. Stephane. “Aerothermal experimental contribution for an 
acoustically forced impinging air jet,” PhD thesis, university of 
Poitiers, Jun 2011.  
2705
 
 
 
[16] J.W. Gauntner, J.N.B. Livingwood, P. Hrycak, Survey of literature on 
flow characteristics of a single turbulent jet impinging on a flat plate, 
NASA TN D-5652, 1970. 
[17] “Statistical Properties of Turbulent Free Jets Issuing from Nine 
Differently-Shaped Nozzles,” In Flow, Turbulence and Combustion  
Volume 84, Issue 4 , 2010, pp. 583-606 
[18] M.Y. Tsalamlal, N. Ouarti, and M. Ammi “Psychophysical study of 
air jet based tactile stimulation, “In IEEE World Haptics Conference, 
2013, pp. 639-644.  
[19] S. Izadi, D. Kim, O. Hilliges, D. Molyneaux, R.  Newcombe, P. Kohli, 
J. Shotton, S. Hodges, D. Freeman, A. Davison et A. Fitzgibbon, 
“KinectFusion : real-time 3D reconstruction and interaction using a 
moving depth camera”, Proceedings of the 24
th
 annual ACM 
symposium on User interface software and technology, 2011, pp59-
568. 
[20] V. Baltzinger, J. Derepper et Samuel Gosselin, “Integration of a 
Kinect on a Drone Platform,” Master dissertation Compiegne 
university of technology, 2011 
[21]  L. Xia, C. Chen, and J. K. Aggarwal, “Human Detection Using Depth 
Information by Kinect,” International Workshop on Human Activity 
Understanding from 3D Data in conjunction with CVPR (HAU3D), 
2011,pp.15 – 22. 
[22] V. Frati, and D. Prattichizzo, “Using Kinect for hand tracking and 
rendering in wearable haptics,” Proc.World Haptics Conference 
(WHC), 2011, pp.317 – 321. 
[23] Robotis bioloid Kit. http://www.robotis.com/xe/bioloid_en  
[24]  J. Korein and N. Balder, "Techniques for generating the goal-directed 
motion of articulated structures", IEEE Computer Graphics and 
Application, 1982, vol. 2, no. 9, pp. 71-81. 
[25] A. Goldenberg, B. Benhabib, and R. G. Fenton “A Complete 
Generalized Solution to the Inverse Kinematics of Robots”, IEEE 
Journal of Robotic and Automation, RA-1, n°. 1, March 1985. 
[26] L.-C.T Wang, C.C. Chen, “A Combined Optimization Method for 
Solving the Inverse Kinematics Problem of Mechanical 
Manipulators,”IEEE Transactions on Robotics & Applications, Vol. 7, 
No. 4, p.489-499, 1991. 
[27] R. Penrose, “A Generalized Inverse for Matrix,” Proc. Cambridge 
Phil, 1955, 406-413. 
[28] CyberGlove http://www.cyberglovesystems.com/ 
[29] Phantom Omni http://www.dentsable.com/haptic-phantom-omni.htm 
[30] Tsalamlal, M. Y. and Ouarti, N. and Martin, J.C. and Ammi, M. 
“Perception of Emotions from Air Jet Based Tactile Stimulation, 
International,” International Conference on Affective Computing and 
Intelligent Interaction (ACII 2013), pp. 215-220. 
2706
