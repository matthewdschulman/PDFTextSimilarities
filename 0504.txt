          
 
  
 
Abstract— Recent research suggests children with autism 
show certain positive social behaviors while interacting with 
robots without the presence of peer pressure. This paper 
explores possible use of interactive robots for interaction with 
children with autism. Logical artificial intelligence, reasoning 
about beliefs, desires and intentions (BDI model) serve as a basis 
to construct a set of scenarios. The present invention also 
describes a novel real-world motivated learning method. It uses a 
supervised reinforcement learning approach combined with goal 
creating. Autonomous agent learns problems in the real world 
through interaction with the patient. Methods and systems for 
management of brain and body functions and sensory 
perception, observing/analyzing, interactive behavior are 
presented. In one instance, the virtual agent is integrated with a 
computer-aided system for diagnosis, monitoring, and therapy. 
 
Index Terms— Robotics, BDI, Motivated Learning, Goal 
creation, Autism therapy, Children with autism, Social robot, 
Tele communication. 
 
I. BACKGROUND & CLINICAL SIGNIFICANCE   
All humans learn behaviors in an autonomous open ended 
manner through lifelong learning. Until now, no robot has this 
capacity. This is one of the greatest challenges in robotics 
today as well as the long term goal of the growing field of 
developmental robotics. This present invention explores a 
possible method towards such a goal.  
Research has shown that children with ASD may be 
preferentially drawn towards technologically-geared 
platforms. Rapid progress in technology, especially in the area 
of robotics, offers tremendous possibilities for innovation in 
treatment for individuals with Autism Spectrum Disorders 
(ASD). Considerable attention has been given to what type of 
robot might be effective, but not as much emphasis has been  
This research is supported partially under the NTU-NHG Innovation Seed 
Grant 2011, Singapore Millennium Foundation Research Grant and Singapore 
National Research Foundation under BeingThereCentre Program through 
IDMPO. 
Lili Liu is with Robotic Research Center, Nanyang Technological 
University, Singapore.  (E-mail: lililiu@ntu.edu.sg).  
Bingbing Li is with BeingThere Center, Institute for Media Innovation, 
Nanyang Technological University of Singapore. (E-mail: 
bli006@e.ntu.edu.sg).  
I-Ming Chen is with School of Mechanical and Aerospace Engineering, 
Nanyang Technological University, Singapore.  (E-mail: 
MICHEN@ntu.edu.sg). 
Tze Jui Goh, is with Child and Adolescent Psychiatry of Institute of 
Mental Health of Singapore.  (E-mail: Tze_Jui_Goh@imh.com.sg).  
Min Sung, is with Department of Child and Adolescent Psychiatry of 
Institute of Mental Health of Singapore.  (E-mail: min_sung@imh.com.sg).  
                                                                                                                              
_                                                                                                           
placed on the best ways to integrate the robot into therapy 
sessions. There are several open questions such as what the 
best roles for robots are in therapy, how to best integrate 
robots into interventions, and who among individuals with 
ASD are best suited for this approach. We focus on the broad 
approach of using robots, rather than any one particular target 
behavior. 
With the working hypothesis that children with ASD have 
an intrinsic interest in technology, robots can be used to elicit 
pro-social behaviors for therapeutic purpose. Robots can be 
programmed to respond to child’s behavior and provide 
interesting visual display to encourage a desirable and 
pro-social behavior from the child.  
Besides that, it is also proposed that an environment can be 
created where the child can practice specific skills with the 
robot. The aim is to use the robot to teach a skill that the child 
can learn and imitate and then transfer to interactions with 
human. The child can repeatedly practice a behavior or social 
interchange without the presence of peer pressure. Research in 
this area is still limited and can be improved with the 
integration of well-established treatment for ASD such as 
Applied Behavior Analysis (ABA)  
Conventional methods of therapy with demonstrated 
efficacy often relies on the therapeutic rapport between the 
therapist and child and often face problems in the 
generalizability of learnt behaviors outside the therapeutic 
setting. The robot adds to those sessions an element that is 
intrinsically interesting, engaging and rewarding for the 
children. In addition, in contrast to one to one session with a 
therapist, introducing a robot as a medium to learn social skills 
may alleviate anxiety experienced by some socially 
withdrawn individuals with ASD and also provide a less 
intrusive atmosphere of learning [7].  
Very little research has been done on what specific 
cognitive mechanisms might be targeted or affected by robot 
vs. human interactions. If individuals with ASD 
fundamentally think about, interact with, and respond to 
robots differently than humans, it will be necessary to 
determine how this may affect the generalization of skills. We 
believe that this work, in combination with work on clinical 
effectiveness and efficacy, will be mutually informative [3].  
II. OBJECTIVE 
The main aim of this study is to test the applicability of 
using half or full autonomous robot in improving the social 
skills learning of children with Autism Spectrum Disorders 
(ASD). We hope to establish improvements in social skills 
displayed by the child over the sessions they spend interacting 
Interactive robots as social partner for communication care 
Lili Liu, Bingbing Li, I-Ming Chen, Fellow, IEEE, Tze Jui Goh, Min Sung 
 
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 2231
          
 
with the robot. For the long term objectives, we aim to: 
1. Using a humanoid robot to augment intervention among 
children with ASD, does not preclude the role of the 
human therapist. Provide an additional platform in which 
children can learn social skills that are embedded in 
social interaction such as approach, initiation, request, 
maintenance of interest and termination of interaction. 
2. Technology and software should be adapted so that the 
semi or full autonomous robot can be controlled by the 
therapist no matter whether the therapist is inside or 
outside the room. Additionally, studies must not focus 
purely on behaviors, but also on cognitive processes as 
well. 
I. METHODOLOGY   
A. Human Robot Interaction (HRI) 
The aim of classical research in artificial intelligence is to 
achieve human-like intelligence and cognitive ability, 
especially in terms of problem solving, planning and so forth. 
However, some studies proposed that social intelligence is the 
key for making robot smarter. Hence, research in the field of 
social robotics or human-robot interaction becomes very 
crucial. This proves to be a great challenge as the robots need 
to deal with highly dynamic and stochastic elements inherent 
in social interaction on top of the normal problems in robotics. 
In conventional robotics research, the robots do not need to 
actively engage with the environment and induce reaction 
from it. However, social robots are required to initiate contact 
with human subject, interpret various social signals from the 
human and react accordingly. In human-robot interaction, any 
actions by robots may cause an unpredictable reaction from 
the human which needs to be handled. These two challenges 
make it difficult for researcher to design social robots with 
believable and contingent behaviors [5]. 
As such, the study of human-robot interaction has largely 
been done using a Wizard of Oz approach [6] instead of a fully 
autonomous robot.  A Wizard of Oz experiment is conducted 
with a human subject interacting with a robot that he or she 
believes to be autonomous but is actually being controlled by 
an unseen operator. The operator will interpret the situation 
and to the human subject [8].  
B. Human Machine Interface (HMI) - EBART Assessment 
System 
Emotions, behaviors and Audio Real Time (EBART) 
assessment system is a real time interface that allows the 
controller to interact with the child via the robot. EBART 
assessment system includes modules focusing on social 
interaction with the child. Areas of skills that may be elicited 
through the modules may include: conversational skills, social 
requesting, initiating social interaction and empathy.  
A graphical user interface that is simple and intuitive for 
users to control the robot in real time is developed to integrate 
the required functionalities of the modules. PyQT is used as a 
tool to create the interface. The EBART Wizard interface is 
shown in Fig. 1. It contains different types of human-like 
motions, emotions, joint attention, four games, audio live 
streaming and dances that can be chosen by the user. 
 
Fig. 1. EBART Wizard interface 
 
The sessions are conducted across two rooms, one with a 
camera and the other a control room. NAO is placed on a 
platform across the child seated on a chair in the room with the 
camera. The height of the chair and the platform are adjusted 
so that most children will be able to see NAO at eye level. 
Study team members in the control room observe the 
interaction session through the camera. Fig. 2 shows the 
control room used for the study. 
 
Fig. 2. Control room for autism study 
 
The computer in the control room is connected to NAO via 
wireless network. Live feeds of audio and video are captured 
by the camera and the microphone on NAO and transmitted to 
the computer for the controller to manipulate the robot using 
the EBART Wizard interface.  
II. APPROACH  
A. BDI Model 
BDI (belief, desire and intention) model acknowledges the 
primacy of these entities in the practical reasoning process. 
For our purposes, we merge desire (instant goal) and intention 
(final goal). To adapt BDI model to our environment, we split 
the cognitive state into belief and knowledge. The difference 
between belief and knowledge is that an agent is capable of 
changing and revising beliefs, but knowledge is only subject 
to acquisition and cannot contain a false fact. Some mental 
concepts cannot be formally derived using the basis above.  
In this study of human-robot interaction has largely been 
done using a Wizard of Oz approach [6] instead of a fully 
autonomous robot.  A Wizard of Oz experiment is conducted 
with a human subject interacting with a robot that he or she 
2232
          
 
believes to be autonomous but is actually being controlled by 
an unseen operator.  
B. Motivated Learning 
Motivated Learning (ML), the main idea is intrinsic 
motivations created by learning machines. It is needed base on 
motivation, goal creation and learning in an embodied agent 
[2], [4]. Autonomous robot learns problems in real world 
through interaction with the environment. As a branch of 
supervised learning, reinforcement learning can maximizes 
the reward in single value function. However, motivated 
learning as a combination of Reinforcement Learning (RL) + 
Goal Creation System (GCS) can dynamically learn better in 
complex unpredictable environment. 
In the environment, every resource discovers by the robot 
becomes a potential goal and is assigned a value function 
“level”; GCS establishes new goals and switches robot’s 
activity between them; RL algorithm learns value functions on 
different levels. 
C. Key Tasks  
We develop behavior-based interaction architecture (BIA) 
for NAO robot to facilitate the use of the robot in 
therapy/intervention among children with autism. This 
behavior- based architecture will integrate an array of NAO’s 
sensory inputs (camera, microphone, sonar, touch sensor) and 
output devices (speakers, motors) with a set of simple control 
rules that can execute autonomously and semi-autonomously 
with human intervention. The semi-autonomous control in 
BIA will be a critical feature for NAO robot uses in 
intervention sessions among children with ASD to enable the 
therapist to have full control of the process.  The goal is to 
carry on a conversation through pre-designed and instant 
dialogues. The interaction sessions elicit social skills of the 
child including greetings, elicitation of comfort/ empathy, 
initiate and maintain conversations etc. Examples of overture 
from the robot: “Hi, what is your name?”; “Would you like to 
draw a picture”. The robot may engage in a small dance to 
encourage positive responses from the child. 
 
 
(a)       (b)            (c)       (d) 
Fig. 3. Trolley session 
(a) NAO looks for the trolley   (b) NAO grasps the trolley 
(c) NAO falls down, the typical developing child’s empathy 
is observed (d) Child draws and shows to NAO 
 
Fig. 3 shows a sequence in a session, the girl in the photo is 
a typical developing child participating in a pre-study 
technical test. After the robot gets the trolley, the robot falls 
down when it is turning the trolley. The child is observed for 
demonstration of empathy during the process. 
D. Model Architecture and Learning 
In order to make reinforcement learning practical in 
real-world scenarios, supervised reinforcement learning offers 
the possibility of reducing the number of learning steps by 
avoiding the initial exploration of the state space. This is 
achieved by providing the robot (work as an agent) with a few 
correct training examples and using them for off-line training. 
We create the training examples by remote control the 
robot from several random positions to the goal position, 
while saving state, action and reward information. The off-line 
training consists of the presentation of the saved action and 
state vectors (or action sequences) to the robot. Thus, the robot 
can learn the given action sequences without additional 
real-world execution of actions. 
Since the training examples represent only a reduced 
subset of possible solutions, we use additional reinforcement 
learning to safely control the robot around the near-optimal 
solutions provided by the operator. Especially, we use SARSA 
learning, which is a classical on-policy algorithm for temporal 
difference (TD) learning. SARSA does not have major 
restrictions of convergence, and it can easily be combined 
with eligibility trace, opposed to Q-learning.  
The model has an input layer, which represents the robot’s 
current state, and an output layer, which represents the chosen 
action. Both layers are fully connected. The number of states, 
actions and the size of the actions are adjusted empirically as a 
trade-off between speed and accuracy for each of the tested 
docking behaviors. The algorithm implementation will be 
explained using a grid-world example, which offers an 
intuitive ground and facilitates graphical representation of the 
modifications. 
The navigation problem is modeled as a Markov decision 
process (MDP) (see Fig. 4). An MDP is defined by a set of 
states S, a set of actions A, a transition model P(s
?
|s, a)that 
specifies the probability of reaching the next state s’ by taking 
action a in state s, a reward model R(s’, s, a) that specifies the 
immediate reward receives when taking action a in state s, and 
an exploration policy π (s|a), which is a mapping from states 
to actions.  
 
Fig. 4. Markov decision process flow 
 
Considering the two dimensional grid-world example, the 
state space S is formed by all cells. The goal position is 
indicated by a red cell and the current robot’s position by a 
black cell. The robot’s objective is to reach the rewarded goal 
position as quickly as possible.  
The actions are moving UP, DOWN, LEFT and RIGHT, 
for clarity, only one connection weight is shown. A move does 
not depend on the history but only on the policy π(s|a), which 
2233
          
 
depends on the learnt network weights W. A binary reward r is 
used to indicate whether the robot has succeeded or not. The 
robot is given r = 0 as long as the desired position is not 
reached. Once the goal position is reached, the robot receives 
r = 1 and the ‘‘trial’’ is finished. 
The learning algorithm is based on SARSA. For each trial 
the robot is placed at an initial random position within the 
defined workspace. The robot reads the cell’s coordinates to 
obtain the internal state activation vector s, with all entries 
zero except for the entry that corresponds to the world 
position. 
First, to avoid random exploration, a set of training 
examples are recorded and used for off-line training. The 
learning algorithm is realized within each trial. However, the 
selected action is provided by the remote operation data. We 
refer to this procedure as “supervised reinforcement learning”.  
E. Extend BDI Module and goal creation Simulation for 
Robot Facilitated Autism Therapy 
In this experiment, we use goal creation software (GCS) 
proposed by Starzyk [9] to extend an agent that has to function 
as our NAO robot. The primary objective of the project is to 
simulate our Robot to create the goal in dynamic time (which 
interacts with its environment) using the GCS software. 
Attached Fig. 5 shows the desire tree designed for session 2. 
The Robot has to learn to do various activities related by 
exploration for a “sense of achievement”. Thus the primary 
pain of the robot is the “sense of achievement” (pain id (9)). 
The sense of achievement is high when the robot successfully 
measures and assesses the behavior and smoothly interacts 
with child. There are eight externally triggered pains, eight 
sensory inputs and seven motor actions.  
 
 
 
Fig. 5. Desire tree for sessions 2 
 
I. The Goal Map and Valid Actions  
Table I provides a map of the valid goals and the pains that 
are reduced by the valid goals. The robot and environment 
architectures defined in the Goal creation software are used.   
Table I 
Pains and the valid actions that reduce particular pains 
 
II. NAO’s Parameters  
Default values have been assigned to most parameters of 
NAO. The parameters that have not been assigned the default 
value or the parameters that have been used for secondary 
objectives are listed below:  
• Number of iterations : 20000  
• Pain threshold tp: 0.2  
• Maximum increment of the P-G link weight ?g : 0.3  
Though it would have been interesting to study the effect 
of the pain threshold for curiosity, number of cycles to 
remember, and various other parameters, we have refrained 
from doing so. This is done for two reasons. First, though the 
effect of each parameter can be predicted analytically based on 
the GCS document [1]. Second, the parameters that have been 
chosen above have meaningful and direct impact on the 
behavior of robot. This facilitates in deriving some 
meaningful, well defined variations and discussing the 
observed behavior critically.  
III. Environment’s Parameters 
All the environment parameters except the resource 
depletion rate have been assigned the default values. The rate 
parameters are assigned as below:  
• Depletion rate of the “sense of achievement”: tc=10  
• Depletion rate of “Sally Anne Task” = tc/2 = 5  
• Depletion rate of “Simon Says Game”= tc = 10  
• Depletion rate of “Holidays or hobbies”= tc = 10  
• Depletion rate of “drawing” = 2tc = 20  
• Depletion rate of “trolley”= tc/3 =3.33  
• Depletion rate of “Drawing result” = 5tc = 50  
• Depletion rate of “Patient focus and look at robot”=tc=10  
• Depletion rate of  “Different topic” = tc = 10  
After 20,000 iterations, the robot must have learnt to adapt 
to the environment, understand its pains, satisfy its primary 
concerns (primitive pains), and respond to the situations that 
may occur in the environment. To study these aspects, we 
present some quantitative figures generated using GCS. 
Here, we intend to study the nature and efficiency of the 
NAO in learning the goals. For this purpose, we study the goal 
scatter plot presented in Fig. 6. The green colored data points 
refer to the goals that actually reduced the pain of NAO. In 
fact the occurrence of these valid goals can be correlated to the 
corresponding pain reaching the threshold. Such one-to-one 
2234
          
 
(almost) correspondence can be confirmed by matching the 
plot of pain and the occurrence of goal. 
 
Fig. 6. The goal scatter plot 
 
It is also seen that initially useless actions occur more 
frequently. However, in later stages, the occurrence of useless 
actions is greatly reduced. The overall counts of various valid 
goals, invalid goals and wrong goals are presented in Fig. 7. 
NAO demonstrates good capability to learn the goals. The 
total count of invalid action is only a little bit larger than the 
valid goal with maximum count. In fact, the sum of counts of 
all valid goals is significantly higher than the count of invalid 
goals. 
 
 
 
Fig. 7. Action Count Frequency 
F. Discussion 
The examples above demonstrate the efficacy of the Goal 
Creation Software in developing complex learning patterns. 
This is evident from the fact that in order to achieve NAO’s 
primary goal, “sense of achievement”, it has been able to 
identify other meaningful goals and their impact on the 
environment. It has also been able to reduce the occurrence of 
various pains as its learning progresses. This indicates that it 
has adapted to the initially hostile environment and found a 
balance in it. The frequency of various goals and their choice 
in a particular iteration show that it has been able to identify 
most important goal, most often required goal, goal most 
critical to its primary pain, etc.  
In the current scenario, the GCS model is a basic model 
implementing a crude hierarchy of the goals. Though this 
basic model itself has various salient features, such a model 
would mean that NAO is not only motivated for planning its 
goals and action path, it is also motivated to self-introspect and 
self-improve. 
III. CONCLUSION 
The NAO robot aims to act as a social interaction agent. 
The purpose of using a humanoid robot to augment 
intervention among children with ASD does not preclude the 
role of the human therapist. Rather, it is an enhancement to 
autism intervention. It provides an additional platform in 
which children can learn social skills that are embedded in 
social interaction such as approach, initiation, request, and 
maintenance of interest and termination of interaction. 
Conventional methods of therapy with demonstrated efficacy 
often relies on the therapeutic rapport between the therapist 
and child and often face problems in the generalizability of 
learnt behaviors outside the therapeutic setting. The robot adds 
an element that is intrinsically interesting, engaging and 
rewarding for the children. In contrast to one to one session 
with a therapist, introducing a robot as a medium to learn 
social skills may alleviate anxiety experienced by some 
socially withdrawn individuals with ASD and also provide a 
less intrusive atmosphere of learning.  
In general, the use of robotics for intervention in children 
with ASD appears to be promising. It would also be 
interesting to extend the use of this technology to children 
with other disabilities which share similar overlapping profiles 
of difficulty in social interaction and communication. For 
example, children with social anxiety may also benefit from 
such an application. The programs and specific modules may 
differ from those used for children with ASD, but additional 
research in this area could help in laying the groundwork for 
such an effort. The robot would be an augmentation to the 
intervention sessions between the therapist and the child with 
ASD. However, the robot’s autonomous capabilities may 
allow for it to be initiated in community or home-based 
environments in the future. The NAO robot is only one type of 
embodiment of the robotic augmentation for autism 
intervention. The robotic software architecture and the 
modules that are developed in this project can be mounted on 
other robotic platforms of similar capability. Hence, with a 
single hardware, it would pave the way for a new avenue for 
autism research that would bridge the gap between the 
families and community and the clinicians in a novel and 
interactive manner. 
ACKNOWLEDGEMENTS 
This research is supported partially under the NTU-NHG 
Innovation Seed Grant 2011, Singapore Millennium 
Foundation Research Grant and Singapore National Research 
Foundation under BeingThereCentre Program through 
IDMPO. The authors would also like to express our thanks to 
Prof. Domenico Campolo, Prof. Tan Ah Hwee and Mr. Soh 
Wei Jie for their suggestions and comments. The technical 
assistance from Sun Chunyang, Swee Tim Ho, Kok Hou 
Leong and Emily Toh are much appreciated. We would like to 
extend our heartfelt thanks to the participants and their 
parents.  
2235
          
 
REFERENCES 
[1] Pawel Raif, Janusz A. Starzyk, Motivated Learning In Autonomous 
Systems, Proceedings of International Joint Conference on Neural 
Networks, 2011, pp. 603 – 610. 
[2] Diehl, J.J., et al., The clinical use of robots for individuals with Autism 
Spectrum Disorders: A critical review. Research in Autism Spectrum 
Disorders, 2011. 
[3] Min Sung,  Yoon Phaik Ooi, Tze Jui Goh, Pavarthy Pathy, Daniel S. S. 
Fung, Rebecca P. Ang, Alina Chua, Chee Meng Lam, Effects of 
Cognitive-Behavioral Therapy on Anxiety in Children with Autism 
Spectrum Disorders: A Randomized Controlled Trial, Child Psychiatry 
& Human Development, 42(6), Dec. 2011 pp. 634–649. 
[4] Gillesen, J.C.C., Barakova, E.I., Huskens, B.E.B.M., Feijs, L.M.G., 
From training to robot behavior: Towards custom scenarios for robotics 
in training programs for ASD, 2011 IEEE 12th International 
Conference on Rehabilitation Robotics: Reaching Users & the 
Community (ICORR 2011), 2011. 
[5] Espinoza, R.R., et al., Child-Robot Interaction in The Wild: Advice to 
the Aspiring Experimenter, ICMI'11 Proceedings of the 13th 
international conference on multimodal interfaces, ACM, New York 
2011, (2011), pp. 335-342. 
[6] Ricks, D.J., Colton, M.B., Trends and considerations in robot-assisted 
autism therapy, 2010 IEEE International Conference on Robotics and 
Automation (ICRA 2010), 20 10, pp. 4354-4359. 
[7] Giannopulu, I. and G. Pradel, Multimodal interactions in free game 
play of children with autism and a mobile toy robot, 
NeuroRehabilitation, 27(4), 2010. pp. 305-311. 
[8] Boccanfuso, L. and J. O’Kane, Adaptive robot design with hand and 
face tracking for use in autism therapy, Social Robotics, 2010, pp. 
265-274. 
[9] J. A. Starzyk, Motivation in Embodied Intelligence, Frontiers in 
Robotics, Automation and Control, Oct. 2008, pp. 83-110.  
 
2236
