Robotic Cell Manipulation Using Optical Tweezers with Limited FOV
X. Li, C. C. Cheah, X. Yan, and D. Sun
AbstractÑ Microscopic optics and cameras are commonly
used in micromanipulation or biomanipulation workstations
since they provide a large spectrum of visual details and
information. The visual feedback information also improves
robustness to uncertainty and accuracy of micromanipulation.
Among various micromanipulation systems, optical tweezers
are one of the most useful instruments that utilize a focused
beam of light to manipulate biological cell or nanoparticles
without physical contact. However, current optical manipulation
techniques fail if the laser beam is not within the Þeld of view
(FOV) of the microscope. To solve this problem, we present a
robotic control technique for optical manipulation with limited
FOV of microscope. The proposed control strategy consists of
a vision based control that manipulates the trapped cell to
move to a desired position inside the FOV and a Cartesian-
space feedback control that drives the laser beam back when
it is outside the FOV . Thus, the proposed method allows the
laser beam to leave the FOV during the course of manipulation
and the transition from one feedback to another is smooth.
The stability of the closed-loop system is analysed by using
Lyapunov-like methods, with consideration of the dynamic
interaction between the cell and the manipulator of the laser
source. Experimental results are presented to illustrate the
performance of the proposed method.
I. INTRODUCTION
With the rapid advances in sensor technologies and the
integration of robotic and biomedical technologies at micro
and nano scales, a variety of vision-based robotic micro-
manipulation systems have been developed in biological or
biomedical engineering [1]Ð[4].
Among various micromanipulators, optical tweezers [5]
have been extensively used in micromanipulation because of
its ability of manipulating biological cell or nano particles
without physical contact. Over the past years, several robotic
control techniques have been introduced for optical tweezers
to improve the efÞciency of optical manipulation [6]Ð[15].
A comparison between the performance of several classic
control methods for optical manipulation was given in [6].
In [7], a proportional-gain feedback controller was imple-
mented on optical tweezers. In [8], a weighted-recursive-
least-square algorithm was proposed for real-time calibration
and estimation of system parameters. A minimum variance
control method was proposed to minimize the Brownian
motion of an optically trapped probe in [9]. In [10], a
simple setpoint controller was proposed to manipulate the
X. Li, C. C. Cheah, and X. Yan are with the School of Electrical and
Electronic Engineering, Nanyang Technological University, Singapore. D.
Sun is with the Department of Mechanical and Biomedical Engineering, City
University of Hong Kong, Hong Kong. The work of the Þrst three authors
was supported by the Agency For Science, Technology And Research of
Singapore (A*STAR), (reference 1121202014), and the work of the last
author was supported in part by the Hong Kong University Grants Council
(UGC) Special Equipment Grant (SET CityU 01).
single cell to a desired position. In [11], a PID feedback
controller and a synchronization control strategy were de-
veloped for automatic transportation of biological cells. In
[12], an adaptive disturbance observer was developed for
dynamic force sensing in an optical trap. To manipulate
multiple cells to a desired region, a region reaching control
method was presented in [13]. In [14], a dynamic viscous
drag force method was utilized to characterize the force
exerted on a trapped cell, and then a modiÞed A-star path
planning algorithm was proposed for cell transportation.
A simultaneous trapping and manipulation technique was
proposed for optical tweezers in [15], which allows the laser
beam to automatically trap then manipulate the cell when it
is not within the optical trap.
In an optical tweezers system, the position of cell can only
be speciÞed in image space inside the FOV of microscope,
and the visual feedback of the position of cell is required
for the closed-loop control of the laser beam. Therefore,
the position of laser in the optical tweezers system is also
speciÞed in image space, and the laser beam should be
controlled to stay within the FOV . While a high-resolution
microscope is required to guarantee the accuracy of optical
manipulation, the FOV is quite limited and existing optical
manipulation methods [6]Ð[15] fail when the laser beam
starts outside the FOV or leaves the FOV during the course
of manipulation. While several research works have been
reported in the literature of vision-based robot control with
limited FOV [16]Ð[18], the problem of optical manipulation
with limited FOV has not been systematically solved.
In this paper, a new robotic manipulation technique is
proposed for optical manipulation with limited FOV . The
proposed controller consists of a vision-based control that
ensures the manipulation of the trapped cell to the desired
position inside the FOV and a Cartesian-space feedback con-
trol that drives the laser beam back to the FOV of microscope
when it is outside. The use of feedback information that
transits smoothly between Cartesian space and vision space,
allows the laser beam to leave the FOV during the course
of manipulation. The proposed controller is based on the
dynamic formulation where the position of laser source is
controlled by closed-loop robotic manipulation techniques.
The stability of the overall system is analyzed by using
Lyapunov-like method, with consideration of the dynamic
interactions between the manipulator of laser source and
the biological cell. Experimental results are presented to
illustrate the performance of the proposed cell manipulation
method with limited FOV .
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 4588
II. OPTICAL TWEEZERS SYSTEM
The basic principle of optical trap is based on the transfer
of momentum from photons to microscopic objects, when
a focused beam of light passes through the object that is
immersed in a medium. The refraction of the photons at the
boundary between the object and the medium, results in a
stable trap of the object [5].
Optical tweezers are the scientiÞc instruments based on the
optical trap, which can manipulate the microscopic objects
without physical contact. The main features consist of a large
numerical aperture oil-immersion objective, a standard phase
contrast microscope illumination, and a CCD camera. The
laser beam is directed into the epißuorescence port of the
microscope and then introduced to the microscopeÕs optical
path using a dichroic mirror located in the cube turret.
A. Dynamic Model of Biological Cell and Manipulator
The dynamic model of the cell in an optical tweezers
system is described by the following equation [19]:
M ¬ x + B ú x + k(x? p)=0, (1)
where x =[x
1
,x
2
]
T
?
2
is the position of cell, and
p =[p
1
,p
2
]
T
?
2
is the position of laser, M?
2?2
denotes the mass matrix which is diagonal and positive
deÞnite, B?
2?2
represents the friction matrix which is
also diagonal and positive deÞnite, and k denotes the trapping
stiffness which is constant when the cell is located in a small
neighborhood of the centroid of the focused laser beam [10],
[11], [13]. Both x and p are speciÞed in image space of
microscope. Since the FOV is limited, the positions of laser
and cell in image space are only available within the FOV .
In this paper, the position of the laser beam p is controlled
by closed-loop robotic manipulation techniques. When a
linear motorized stage is used as a manipulator, the dynamic
model is speciÞed as [15]:
M
q
¬ q + B
q
ú q = u, (2)
where q?
n
is the position of laser beam in Cartesian
space, M
q
is the mass matrix which is diagonal and positive
deÞnite, B
q
represents the friction matrix which is also
diagonal and positive deÞnite, and u denotes the control
input which is the force exerted on the manipulator. The dy-
namic model described by equation (2) can be parameterized
as: M
q
¬ q +B
q
ú q = Y
q
( ú q, ¬ q)?
q
, where Y
q
( ú q, ¬ q) is a known
regressor matrix, and ?
q
=[?
q1
,ááá ,?
qnq
]
T
represents a set
of dynamic parameters.
B. Camera Model
In optical tweezers system, the relationship between the
robot frame and the camera is to be derived. The pinhole
camera model [20], [21] is widely used to represent the
mapping from Cartesian space to image space. Based on
the pinhole camera model, the velocity of the image feature
is related to the velocity of the feature point in Cartesian
space by using the image Jacobian matrix. The image-space
velocity of laser beam is related to the velocity of laser beam
in Cartesian space as:
ú p = J
I
(q) ú q, (3)
where J
I
(q) is the image Jacobian matrix [22], [23], ú p is the
velocity of laser beam in image space, and ú q is the velocity
of laser beam in Cartesian space. While the position of laser
beam in Cartesian space q is measured by encoders, the
position of laser beam in image space p can only be obtained
with image processing techniques within the FOV .
III. OPTICAL MANIPULATION WITH LIMITED FOV
Since the FOV of microscope is limited, the optical
manipulation fails when the laser beam leaves the FOV .
To solve the problem of limited FOV , a new robot control
method is proposed for optical manipulation of biological
cell in this section, which allows the laser beam to transit
smoothly outside or inside the FOV of microscope.
The main idea is to divide the entire workspace into a
Cartesian-space region and an image-space region as shown
in Fig. 1. The image-space region is formulated to match the
FOV and the Cartesian-space region is set slightly overlapped
with the image-space region such that the laser beam does
not get stuck when it transits between the image-space region
and the Cartesian-space region.
Laser
Cell
FOV of microscope
Visual feedback
Cartesian space
feedback
-
Desired
position
Image-space region
Cartesian-space region
Previous
position
Fig. 1. The visual feedback is employed to guarantee the convergence of
position error inside the FOV , while the Cartesian-space feedback is used
to drive the laser beam back to the FOV when it leaves the FOV during the
course of manipulation.
When the laser beam leaves the FOV during the course of
manipulation due to overshoot or external perturbation, nei-
ther the cell nor the laser can be observed by the microscope.
To solve the problem, the laser beam is Þrstly driven back to
the FOV with Cartesian-space feedback. After the laser beam
moves back into the FOV , that is, inside the image-space
region, the visual feedback is then activated and employed
to transport the trapped cell to the desired position.
The development of control strategy follows a back-
stepping procedure. First, a desired position input for the
laser beam p
d
is speciÞed in image space to guarantee the
convergence of position error. Next, a control input for the
manipulator of laser beam is derived with regional feedback
from Cartesian space and image space respectively, to ensure
that the actual position of laser beam p tracks the desired
position input p
d
such that ?p=p?p
d
?0.
4589
A. Desired Position Input of Laser Source
The desired position input for the laser is proposed as:
p
d
=x?k
?1
K
p
?x?k
?1
K
d
ú x, (4)
where K
p
and K
d
are diagonal and positive deÞnite, and
?x=x?x
d
where x
d
is the desired position that can only
be speciÞed in image space.
Substituting the desired position input for the laser beam
(4) into the dynamic equation of the cell, it is obtained:
M ¬ x+B ú x+K
p
?x+K
d
ú x=k?p. (5)
A Lyapunov-like candidate V
x
is proposed as:
V
x
=
1
2
ú x
T
M ú x+
1
2
?x
T
K
p
?x. (6)
Differentiating V
x
with respect to time and substituting
equation (5) into it, we have:
ú
V
x
=? ú x
T
[(B+K
d
) ú x+K
p
?x? k?p]+ ú x
T
K
p
?x
=? ú x
T
(B+K
d
) ú x+k ú x
T
?p. (7)
It can be shown that the position error ?x converges to
zero when ?p=0. A control input for the manipulator of the
laser source will be developed later to ensure the convergence
of ?p?0.
Remark 1: The desired position x
d
is referred to the position
of feature that can only be speciÞed in image space. For
example, in cell fusion [24], the desired position x
d
is
speciÞed as the position of the cell that is to be fused, which
can only be speciÞed in image space. Since both the position
of cell x and the desired position x
d
are only available
in image space, the desired position input p
d
in equation
(4) can only be speciÞed inside the FOV as well. Position
measurement obtained through image processing is usually
slower than the use of encoders. Therefore, a smaller image-
space region can be speciÞed to cover the vicinity of the
desired position only, instead of the entire FOV . 
B. Image-Space Region and Cartesian-Space Region
Since the desired position input is not available outside
the FOV , the desired position input is redeÞned as:
p
d
=w(x?k
?1
K
p
?x?k
?1
K
d
ú x), (8)
where w is a weight factor [18]. The weight factor w=0 when
the laser beam is outside the FOV , and it smoothly increases
to 1 when the laser beam enters the FOV . Therefore, p
d
=0,
and ú p
d
=0 when the laser beam is outside the FOV and p
d
is described by equation (4) when it is inside the FOV .
The image-space region consists of a task-oriented region
f
t
(p) and a high-order region f
h
(p). First, a task-oriented
region is introduced to enclose p
d
as:
f
t
(p)=
(p1?p
d1
)
2
(p
b1
?p
d1
)
2
+
(p2?p
d2
)
2
(p
b2
?p
d2
)
2
?1²0, (9)
where p
b
=[p
b1
,p
b2
]
T
?
2
is the bound of the region. The
region described by equation (9) represents a superellipse in
image space, and the bounds are divided into four parts such
that the desired position p
d
is not necessary the centre of the
superellipse.
The potential energy for the region f
t
(p) is introduced as:
P
t
(p)=
kt
N
{1?[min(0,f
t
(p))]
N
}, (10)
where k
t
is a positive constant, and N³4 is the order of the
potential energy function which is also an even integer. Note
that the bottom point of the potential energy corresponds to
the desired position input p
d
, and thus the potential Þeld of
P
t
(p) drives the actual position of the laser beam p to track
the desired position p
d
such that ?p?0.
The top contour of P
t
(p) is not a rectangle and varies as
p
d
is varying, which cannot match the FOV . Therefore, a
high-order region is formulated to enclose f
t
(p)² 0 as:
f
h
(p)=
(p1?p
d1
)
n
h
(p
b1
?p
d1
)
n
h
+
(p2?p
d2
)
n
h
(p
b2
?p
d2
)
n
h
?1²0, (11)
where n
h
is the order of the region function which is also
an even integer. In general, n
h
³ 20 such that the high-
order region f
h
(p) is speciÞed as a rectangle with rounded
corners which can match the Þxed FOV . The potential energy
for f
h
(p) is proposed as:
P
h
(p)=
k
h
N
2
{min[0,[min(0,f
h
(p))]
N
?(?
n
h
h
? 1)
N
]}
N
,(12)
where k
h
is a positive constant, and 0<?
h
<1 is a positive
constant. The top contour of P
h
(p) corresponds to the region
f
h
(p) which is a rectangle with rounded corners.
The overall potential energy in image space is deÞned as
the summation of P
t
(p) and P
h
(p) as:
P
I
(p)= k
p
?
x
(P
t
(p)+ P
h
(p)), (13)
where k
p
and ?
x
are positive constants. The top contour
of P
I
(p) is a rectangle with Þxed contour that corresponds
to the high-order region f
h
(p), and its bottom part is the
desired position input p
d
. The combination of task-oriented
region and high-order region not only matches the Þxed
rectangular FOV of microscope but also guarantees that the
actual position of laser beam in image space p tracks the
desired position input p
d
after the laser beam enters the
image-space region.
Partial differentiating the potential energy function P
I
(p)
with respect to ?p = p?p
d
, the gradient of the potential
energy is obtained respectively as:
(
¶PI (p)
¶?p
)
T
=k
p
?
x
[(
¶Pt(p)
¶?p
)
T
+(
¶P
h
(p)
¶?p
)
T
]

=k
p
?
x
??
x
, (14)
where
(
¶P
h
(p)
¶?p
)
T
=k
h
{min{0, [min(0,f
h
(p))]
N
?
(?
n
h
h
? 1)
N
}}
N?1
[min(0,f
h
(p))]
N?1
(
¶f
h
(p)
¶?p
)
T
, (15)
and
(
¶Pt(p)
¶?p
)
T
=?k
t
[min(0,f
t
(p))]
N?1
(
¶ft(p)
¶?p
)
T
. (16)
The vector ??
x
is the image-space region error which is
used to ensure the convergence of p?p
d
inside the image-
space region. Note that ??
x
reduces to zero when the laser
beam is outside the image-space region where f
h
(p) > 0.
That is, the visual feedback is only activated after the laser
beam enters the image-space region.
4590
A Cartesian-space region is then introduced to drive the
laser beam towards the image-space region if the laser beam
leaves the FOV during the course of manipulation. Since the
objective is to bring the laser beam into the image-space
region, only the position of the laser beam is sufÞcient.
Therefore, the Cartesian-space region is speciÞed as:
f
c
(q)=
? ? f
c1
(q
1
)
f
c2
(q
2
)
f
c3
(q
2
)
? ? =
? ? ? ? (q1?q
f1
)
2
(q
b1
?q
f1
)
2
? 1
(q2?q
f2
)
2
(q
b2
?q
f2
)
2
? 1
(q3?q
f3
)
2
(q
b3
?q
f3
)
2
? 1
? ? ? ? ³0, (17)
where q
f
=[q
f1
,q
f2
,q
f3
]
T
is a static reference position, and
the vector q
b
=[q
b1
,q
b2
,q
b3
]
T
denotes bounds of Cartesian-
space region. When the function f
c
(q) is mapped from
Cartesian space to image space, it corresponds to a rectangle
which can match the high-order image-space region f
h
(p).
The Cartesian-space feedback is employed where f
c
(q)³0.
The corresponding potential energy is deÞned as:
P
C
(q)=k
p
?
q
3

i=1
kri
N
[max(0,f
ci
(q
i
))]
N
, (18)
where ?
q
and k
ri
are positive constants. As seen from
equation (18), P
C
(q) is smooth and lower-bounded by zero,
and it automatically reduces to zero where f
c
(q)²0.
Similarly, partial differentiating the potential energy func-
tion P
C
(q) with respect to q, the gradient is obtained as:
(
¶PC(q)
¶q
)
T
=k
p
?
q
3

i=1
k
ri
[max(0,f
ci
(q
i
))]
N? 1
(
¶fci(qi)
¶q
)
T

= k
p
?
q
??
q
, (19)
where ??
q
denotes the Cartesian-space region error which
drives the laser beam to transit from the Cartesian-space
region to the image-space region, and it naturally reduces
to zero after the laser beam leaves the Cartesian-space
region. Different region error variables work in different local
regions, and the combination of local feedback guarantees
the realization of optical manipulation with limited FOV .
IV. ROBOTIC MANIPULATION OF LASER SOURCE
Using the region errors in image space and Cartesian
space, a robotic control strategy is developed for optical ma-
nipulation in this section. First, a sliding vector is introduced
for the manipulator of laser source as:
s
q
= ú q? ú q
r
= ú q? J
+
I
(q) ú p
a
+?
x
J
T
I
(q)??
x
+?
q
??
q
, (20)
where J
+
I
(q) is the pseudo-inverse of J
I
(q), and ú p
a
is a
reference vector as: ú p
a
=[ú p
d1
p
b1
?p1
p
b1
?p
d1
, ú p
d2
p
b2
?p2
p
b2
?p
d2
]
T
.
Using the sliding vector s
q
, the dynamic model of the
manipulator in equation (2) is rewritten as:
M
q
ú s
q
+B
q
s
q
+Y
q
( ú q
r
, ¬ q
r
)?
q
=u. (21)
The control input of the manipulator is proposed as:
u =?K
s
s
q
+ Y
q
( ú q
r
, ¬ q
r
)
ö
?
q
?k
p
(?
x
J
T
I
(q)??
x
+?
q
??
q
), (22)
where K
s
is a diagonal and positive deÞnite matrix, and the
estimated parameters
ö
?
q
are updated as:
ú
ö
?
q
=?L
q
Y
T
q
( ú q
r
, ¬ q
r
)s
q
, (23)
where L
q
is a positive deÞnite matrix. The region errors
??
x
and ??
q
are activated in the image-space region and
the Cartesian-space region respectively. Since both ??
x
and
??
q
are continuous, the control input of the manipulator
u is also continuous without hard switching which is not
desirable for cell manipulation.
The closed-loop equation is obtained by substituting the
proposed controller in equation (22) into the dynamic model
in equation (21) as:
M
q
ú s
q
+(B
q
+K
s
)s
q
+Y
q
( ú q
r
, ¬ q
r
)??
q
+k
p
(?
x
J
T
(q)??
x
+?
q
??
q
)=0. (24)
A Lyapunov-like candidate is proposed as:
V =V
x
+
1
2
s
T
q
M(q)s
q
+P
I
(p)+P
C
(q)+
1
2
??
T
q
L
?1
q
??
q
.(25)
Differentiating equation (25) with respect to time and sub-
stituting equations (7), (23) and (24) into it, we have:
ú
V =? ú x
T
(B+K
d
) ú x+k ú x
T
?p
?s
T
q
(B
q
+K
s
)s
q
+k
p
?
q
ú p
T
a
J
+T
I
(q)??
q
?
k
p
(?
x
J
T
I
(q)??
x
+?
q
??
q
)
T
(?
x
J
T
I
(q)??
x
+?
q
??
q
).(26)
The Cartesian-space region error ??
q
is nonzero where
f
c
(q)>0, while the time derivative of the desired position
input ú p
d
is nonzero where f
c
(q)²0, as seen from equation
(8). That is, ??
q
and ú p
d
cannot be nonzero at the same time.
From the deÞnition of ú p
a
, ??
q
and ú p
a
cannot be nonzero
at the same time either. Therefore, ú p
T
a
J
+T
I
(q)??
q
=0, and
equation (26) becomes:
ú
V =? ú x
T
(B+K
d
) ú x+k ú x
T
?p?s
T
q
(B
q
+K
s
)s
q
?k
p
(?
x
J
T
I
(q)??
x
+?
q
??
q
)
T
(?
x
J
T
I
(q)??
x
+?
q
??
q
).(27)
Note that k ú x
T
?p ²
k
2
( ú x
T
ú x+?p
T
?p). If the control
parameters are set such that:
k
p
(?
x
J
T
I
(q)??
x
+?
q
??
q
)
T
(?
x
J
T
I
(q)??
x
+?
q
??
q
)
³
k
2
?p
T
?p, (28)
?
min
[B+K
d
]³
k
2
, (29)
where ?
min
[¥] is the minimum eigenvalue, then
ú
V ² 0.We
can now state the following theorem:
Theorem: The robotic control law (22) and the update
law (23) for the optical tweezers system guarantee the
convergence of manipulation task, that is, x ? x
d
, and
p ? p
d
as t?°, if the control parameters are chosen
such that the conditions (28) and (29) are satisÞed.
Proof: If the conditions (28) and (29) are satisÞed, we have
V>0 and
ú
V²0, and hence V is bounded. Therefore, ú x, s
q
,
??
q
, ?x, P
I
(p), and P
C
(q) are bounded. The boundedness
of ?x ensures the boundedness of x since ?x=x?x
d
. The
boundedness of P
I
(p) and P
C
(q) ensures the boundedness
of f
t
(p), f
h
(p) and f
c
(q). Since the region functions are
4591
bounded, the variables p and q are bounded. Therefore, the
region errors ??
q
and ??
x
are bounded. In addition, the
boundedness of ú x, x, and p ensures the boundedness of ¬ x
from equation (1). Differentiating equation (4) with respect
to time, it is obtained that ú p
d
is bounded. Therefore, ú q
r
is
also bounded since ??
q
, ??
x
, ú p
d
and p are bounded. From
equation (20), ú q is bounded because s
q
and ú q
r
are bounded.
The boundedness of ú q guarantees the boundedness of ú p since
J
I
(q) is a trigonometric function of q or constant. Therefore,
the term ?
x
J
T
I
(q)??
x
+ ?
q
??
q
is uniformly continuous. From
equation (27), it is easy to verify that ?
x
J
T
I
(q)??
x
+?
q
??
q
?
L
2
(0, +°). Then it follows [25]Ð[27] that:
?
x
J
T
I
(q)??
x
+?
q
??
q
?0. (30)
If the laser beam is located outside the image-space region
where f
h
(p) > 0,wehave ??
q
	=0 and ??
x
=0, which
contracts with equation (30) since J
I
(q) is non-singular.
If the laser beam is located in the overlapping area where
f
c
(q) >0 and f
h
(p)² 0,wehave ??
x
	=0 and ??
q
	=0.
Since the gradient of potential energy is not zero, the laser
beam cannot stay in the overlapping area.
Therefore, the laser beam can only settle down where
f
c
(q)²0 and thus f
t
(p)²0. That is, ??
q
=0. Since J
I
(q)
is non-singular, ??
x
=0 from equation (30). From equation
(14), ??
x
=0 can only be satisÞed where f
t
(p) ² 0, and
hence ??
x
=0 means that
¶ft(p)
¶?p
= 0. That is, p ? p
d
as
t?°. The convergence of p ? p
d
then guarantees that
x? x
d
and ú x?0 as t?°. 
Remark 2: Since the trapping stiffness k is very small and
the gradient of the potential energy ?
x
J
T
I
(q)??
x
+?
q
??
q
is
nonzero until the the actual position p reaches the desired
position p
d
, the control parameters k
p
, ?
x
, and ?
q
can be
chosen sufÞciently large such that condition (28) is satisÞed.

V. EXPERIMENT
The proposed control method was implemented in a robot-
tweezer manipulation system in the City University of Hong
Kong, as shown in Fig. 2. The system is constituted of
three modules for sensing, control and execution [11]. The
sensing module consists of a microscope and a CCD cam-
era, and the position of the cell can be obtained through
image processing. The control module consists of a phase
modulator and a stepping motor controller. The execution
module consists of the holographic optical trapping and the
motorized stage. The mechanical components are supported
by an anti-vibration table in a clean room. The optical
tweezers were controlled to manipulate the yeast cell, and
the relationship between the Cartesian space and the image
space is known as 0.11 ?m/pixel.
To illustrate the performance of the proposed control
method, the positions of the laser beam and the trapped cell
were intentionally moved outside the FOV as shown in Fig.
3. A yeast cell was manipulated by the laser from the position
(13.3,37.0) ?m inside the Cartesian-space region (outside
FOV) to a desired position at (400,300) pixel within the
image-space region (inside FOV) as shown in Fig. 3.
CCDCamera
SLM
OpticalTweezers
Motorized Stage
Fig. 2. A robot-tweezer manipulation system.
The task-oriented image-space region f
t
(p) was formu-
lated to enclose the desired position p
d
, and the parameters
of the region in equation (9) were set as: p
b1
= 300 pixel
if p
1
² p
d1
else p
b1
= 500 pixel; p
b2
= 200 pixel if
p
2
²p
d2
else p
b2
= 400 pixel. Next, the high-order image-
space region f
h
(p) was formulated to match the FOV , and
the parameters of the region in equation (11) were set as:
n
h
=20, and ?=0.7. To drive the laser back to the FOV , the
Cartesian-space region f
c
(q) in equation (17) was speciÞed
as: [q
f1
,q
f2
]
T
=[60,33]
T
?m, q
b1
=36.3 ?m if q
1
²q
f1
else
q
b1
=51.7 ?m; q
b2
=25.3 ?m if q
2
²q
f2
else q
b2
=40.7 ?m.
Note that the Cartesian-space region is speciÞed in 2-D
space, since the laser beam evolves in the 2-D plane of the
stage while the camera is perpendicular to the evolving plane
of the laser beam. The visual feedback is employed where
f
t
(p)²0 and f
h
(p)²0, and the Cartesian-space feedback is
employed where f
c
(q)>0.
The control parameters in equation (22) were set as: K
s
=
diag{0.2,0.2}, ?
x
=5, ?
q
=10, k
p
=1, k
h
=2, k
t
=1, k
r1
=
k
r2
=1, and L
q
=diag{0.0001,0.0001}. The path of the laser
and the cell in Cartesian space was shown in Fig. 4(a), and
the path in image space was shown in Fig. 4(b). It is seen
that the laser beam moves from the Cartesian-space region
back to the image-space region and converges to the desired
position within the image-space region. The position error is
shown in Fig. 4(c), which converges to zero in about3s.
VI. CONCLUSIONS
In this paper, a new robotic manipulation technique has
been developed for optical manipulation with the limited
FOV . The proposed control strategy consists of a visual
feedback control that ensures the convergence of position
error inside the FOV and a Cartesian-space feedback control
that drives the laser beam back to the FOV . The smooth
combination of the Cartesian-space feedback and the visual
feedback allows the laser beam to leave the FOV during the
course of manipulation, such that the problem of the limited
FOV is resolved. Experimental results have been presented
to illustrate the performance of the proposed control method.
REFERENCES
[1] M. Rakotondrabe, and I. A. Ivan, ÓDevelopment and force/position
control of a new hybrid thermo-piezoelectric microgripper dedicated
4592
Desired
position
Image-space region
Initial
position
(a) t=0 s
Desired
position
Image-space region
Cell
(b) t=1 s
Desired
position
Image-space region
Cell
(c) t=4 s
Fig. 3. Experiment 1: Both the laser and the cell move from outside to inside the FOV .
0 10 20 30 40 50 60
10
20
30
40
50
p
1
 (? m)
p
2
 (? m)
 
 
cell
bound
Cartesian?space region 
Initial position
(13.3, 37.0)
(a) path in Cartesian space
0 100 200 300 400 500 600
100
200
300
400
500
x
1
 (pixel)
x
2
 (pixel)
 
 
cell
desired
bound
desired position 
(400, 300)
Image?space
region
(b) path in image space
0 1 2 3 4
?400
?300
?200
?100
0
100
200
300
400
Time (s)
Error (pixel)
 
 
x
1
x
2
(c) position error
Fig. 4. Experiment 1: Both the laser and the cell move from (13.3,37.0) µm in Cartesian space (outside FOV) to the desired position at [p
d1
,p
d2
]
T
=
[400,300]
T
pixel in image space (inside FOV).
to micromanipulation tasks,Ó IEEE Trans. Autom. Sci. Eng., V ol. 8,
No. 4, pp. 824-834, 2011.
[2] Y . Sun, and B. J. Nelson, ÓBiological cell injection using an au-
tonomous microrobotic system,ÓInt.J.RoboticsRes., 21(10-11), 861-
868, 2002.
[3] H. Huang, D. Sun, J. K. Mills, and S. H. Cheng, ÓRobotic cell
injection system with position and force control: toward automatic
batch biomanipulation,Ó IEEETrans. Robotics, 25(3), 727-737, 2009.
[4] X. Zhang, C, Leung, Z. Lu, N. Esfandiari, R. F. Casper, and Y .
Sun, ÓControlled aspiration and positioning of biological cells in a
micropipette,Ó IEEE Trans. Biomed. Eng., 59(4), 1032-1040, 2012.
[5] A. Ashkin, J. M. Dziedzic, J. E. Bjorkholm, and S. Chu, ÓObservation
of a single beam gradient force optical trap for dielectric particles,Ó
Opt. Letters, V ol. 11, pp. 288-290, 1986.
[6] A. Ranaweera, and B. Bamieh, ÓModeling, identiÞcation and control
of a spherical particle trapped in an optical tweezer,Ó Int. J. Robust
Nonlin., V ol. 15, No. 16, pp. 747-768, 2005.
[7] A. E. Wallin, H. Ojala, E. Haggstrom, and R. Tuma, ÓStiffer
optical tweezers through real-time feedback control,Ó Applied Physics
Letters, V ol. 92, 2008.
[8] J. Wan, Y . Huang, S. Jhiang, and C. H. Menq, ÓReal-time in situ
calibration of an optically trapped probing system,Ó Appl. Opt., V ol.
48, No. 25, pp. 4832-4841, 2009.
[9] Y . Huang, Z. Zhang, and C. H. Menq, ÓMinimum-variance brownian
motion control of an optically trapped probe,Ó Appl. Opt., V ol. 48,
No. 3, pp. 5871-5880, 2009.
[10] C. Aguilar-Ibanez, M. S. Suarez-Castanon, and L. I. Rosas-Soriano,
ÓA simple control scheme for the manipulation of a particle by means
of optical tweezers,Ó Int. J. Robust Nonlin., 21(3), 328-337, 2010.
[11] S. Hu, and D. Sun, ÓAutomatic transportation of biological cells with
a robot-tweezer manipulation system,Ó Int. J. Robotics Res., V ol. 30,
No. 14, pp. 1681-1694, 2011.
[12] Y . Huang, P. Cheng, and C. H. Menq, ÓDynamic force sensing using
an optically trapped probing system,Ó IEEE/ASMETrans. Mech., V ol.
16, No. 6, pp. 1145-1154, 2011.
[13] H. Chen, and D. Sun, ÓMoving groups of microparticles into array
with a robot-tweezers manipulation system,Ó IEEE Trans. Robotics,
V ol. 28, No. 5, pp. 1069-1080, 2012.
[14] Y . Wu, D. Sun, W. Huang, and N. Xi, ÓDynamics analysis and motion
planning for automated cell transportation with optical tweezers,Ó
IEEE/ASME Trans. Mech., V ol. 18, No. 2, pp. 706-713, 2013.
[15] X. Li, C. C. Cheah, S. Hu, and D. Sun, ÓDynamic trapping and
manipulation of biological cells with optical tweezers,Ó Automatica,
V ol. 49, No. 6, 1614-1625, 2013.
[16] N. Garcia-Aracil, E. Malis, R. Aracil-Santonja, and C. Perez-Vidal,
ÓContinuous visual servoing despite the changes of visibility in image
features,Ó IEEETrans.Robotics, V ol. 21, No. 6, pp. 1214-1220, 2005.
[17] N. R. Gans, G. Hu, K. Nagarajan, and W. E. Dixon, ÓKeeping
multiple moving targets in the Þeld of view of a mobile camera,Ó
IEEE Trans. Robotics, V ol. 27, No. 4, pp. 822-828, 2011.
[18] X. Li, and C. C. Cheah, ÓGlobal task-space adaptive control of robot,Ó
Automatica, V ol. 49, No. 1, pp. 58-69, 2013.
[19] X. Li, and C. C. Cheah, ÓDynamic region control for robot-assisted
cell manipulation using optical tweezers,Ó IEEE Int. Conf. Robotics
Automat., pp. 1057-1062, 2012.
[20] S. Hutchinson, G. Hager, and P. Corke, ÓA tutorial on visual servo
control,Ó IEEE Trans. Robotics Automat., 12(5), 651-670, 1996.
[21] Y . H. Liu, H. Wang, C. Wang, and K. K. Lam, ÓUncalibrated visual
servoing of robots using a depth-independent interaction matrix,Ó
IEEE Trans. Robotics, V ol. 22, No. 4, pp. 804-817, 2006.
[22] B. Espiau, F. Chaumette, and P. Rives, ÓA new approach to visual
servoing in robotics,Ó IEEE Trans. Robotics Automat., V ol. 8, No. 3,
pp. 313-326, 1992.
[23] L. E. Weiss, A. C. Sanderson, and C. P. Neuman, ÓDynamic sensor-
based control of robots with visual feedback,Ó IEEE Trans. Robotics
Automat., V ol. RA-3, No. 5, pp. 404-417, 1987.
[24] R. Steubling, S. Cheng, and M. W. Berns, ÓLaser-induced cell fusion
in combination with optical tweezers: The laser-cell fusion trap,Ó
Cytometry, V ol. 12, No. 6, pp. 505-510, 1991.
[25] J. J. E. Slotine, and W. Li, Applied Nonlinear Control. Englewood
Cliffs, New Jersy: Prentice Hall, 1991.
[26] S. Arimoto, Control Theory of Nonlinear Mechanical Systems - A
Passivity-Based and Circuit-Theoretic Approach, Oxford, 1996.
[27] M. W. Spong, and M. Vidyasagar, RobotDynamics andControl.New
York: John Wiley & Sons, 1989.
4593
