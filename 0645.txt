Learning Object-level Impedance Control for Robust Grasping and
Dexterous Manipulation
Miao Li
1
, Hang Yin
1
, Kenji Tahara
2;1
and Aude Billard
1
Abstract—Object-level impedance control is of great impor-
tance for object-centric tasks, such as robust grasping and
dexterous manipulation. Despite the recent progress on this
topic, how to specify the desired object impedance for a given
task remains an open issue. In this paper, we decompose
the object’s impedance into two complementary components–
the impedance for stable grasping and impedance for object
manipulation. Then, we present a method to learn the desired
object’s manipulation impedance (stiffness) using data obtained
from human demonstration. The approach is validated in two
tasks, for robust grasping of a wine glass and for inserting a
bulb, using the 16 degrees of freedom Allegro Hand mounted
with the SynTouch tactile sensors.
I. INTRODUCTION
Robust grasping and dexterous manipulation are two of
the most important capabilities that a robot is expected
to have. The main characteristic of a robust grasp is its
ability to comply with external perturbations applied to the
grasped object while still maintaining the grasp. In dexterous
manipulation, the robotic hand, mainly the ﬁngertips, have
to physically interact with the object in order to move it to a
desired conﬁguration. In both scenarios, appropriate grasping
forces need to be applied on the grasped or manipulated
object, either to keep the grasp stable under perturbation or
to move the object to a desired conﬁguration.
To this end, various control algorithms have been proposed
and ported to control multi-ﬁngered robotic hand. These can
be roughly divided into two groups. The ﬁrst group encom-
pass hybrid position/force control approaches that modulates
the force explicitly to manage the interaction imposed by the
environment [1], [2], [3]. Another group uses impedance con-
trol to regulate the interaction force implicitly by specifying
the impedance of the grasped object [4], [5], [6]. [7]. In gen-
eral, the hybrid position/force control is more precise when
controlling simultaneously the force and position. The main
deﬁciency of hybrid control is the transition between position
and force control when the contact state varies between non-
contact and contact. A small delay in this transition may
lead to a very large overshot contact force. In addition, the
selection of accurate grasping forces for hybrid control that
fulﬁl the friction constraints and task requirements is still a
difﬁcult planning problem [3]. In impedance controller, the
object motion is realized by a desired object impedance that
1
M. Li, H. Yin and A. Billard are with LASA,
´
Ecole Poly-
technique F´ ed´ erale de Lausanne (EPFL), Switzerland fmiao.li,
hang.yin,aude.billardg@epfl.ch
2
K. Tahara is with Faculty of Engineering, Kyushu University,
744 Moto’oka, Nishi-ku, Fukuoka 819-0395, Japan. He is
currently a visiting scholar at LASA. tahara@ieee.org,
kenji.tahara@epfl.ch
Robust 
Grasping 
Dexterous 
Manipulation 
Object-level Impedance Learning 
Fig. 1: The object-level impedance for robust grasping and dexterous
manipulation are learned from human demonstration.
generates force to move the object to a desired conﬁguration.
It has the advantage that it will converge to the desired
position in free motion and a stable equilibrium position in
the case of interaction with the environment. This merit can
be greatly beneﬁcial for both robust grasping and dexterous
manipulation. Therefore, we restrict the rest of this review
to impedance controllers only. In [8], a ﬁngertip Cartesian
stiffness controller was introduced using ﬁngertip force sen-
sor. However, the stiffness controller can not actively control
the whole system dynamics. To overcome this defect, Liu
and Hirzinger [9] proposed a Cartesian impedance controller
for the DLR hand based on the joint torque measurements.
While these two controllers are in the ﬁngertip Cartesian
space, object-level impedance controllers are proposed by
directly specifying the desired impedance in the object frame,
which are usually more suitable for robust grasping and
dexterous manipulation of an object. In [4], an object level
impedance controller has been proposed for a multi-arm
manipulator to directly control the internal object forces and
compensate the system dynamics. The object is assumed to
be rigidly grasped that can transmit bilateral contact forces
between the ﬁngertips and the object. Wimbock et al. [5],
[7] recently presented their experimental evaluation of an
intrinsically passive controller for multi-ﬁngered hand, where
the damping parameters are designed and implemented as a
function of the object effective inertia and stiffness matrix.
A similar impedance controller was also proposed in [6] and
[10] by deﬁning a virtual frame which depends only on the
ﬁngertip positions. The damping parameters are designed in
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 6784
both the ﬁnger joint space and the object frame.
However, despite all the above-mentioned progress, one
critical issue still remains unaddressed: how to specify the
proper impedance for a given task? The speciﬁcation of
impedance is known as a difﬁcult problem as it depends
on the task at hand as well as the kinematic and dynamic
limitation of the robot [11], [12]. Moreover, the impedance
parameters may need to adapt to the task requirements or to
variation in the environment, such as the bulb replacement
task that the torsional resistance increases greatly during the
last phase of the task. To this end, sensor feedback should be
taken into account to monitor the status of task’s completion
and to vary the impedance accordingly.
In this paper, we attempt to address this problem by learn-
ing the impedance from human demonstration. In the fol-
lowing Section II, some related works regarding impedance
speciﬁcation are summarized. In Section III, an object-level
impedance controller is reformulated. In Section IV, methods
for learning impedance from human demonstration for robust
grasping and dexterous manipulation are presented. Experi-
ments on a multi-ﬁngered robotic hand are demonstrated and
discussed in Section V. Finally, we give a conclusion and an
outlook on future work in Section IV .
II. RELATED WORK
a) Analytical Impedance Speciﬁcation: In one of their
early works, Mason and Salisbury [8] used the congruence
transformation to obtain the desired object stiffness from
joint stiffness. Based on this work, Cutkosky and Kao [13]
expressed the compliance of a grasp as a function of grasp
geometry, contact conditions and mechanical properties of
the ﬁngers. In order to choose the grasp compliance for
a given task, Shimoga and Goldenberg [14] formulated a
concept termed Grasp Admittance Center, which is the origin
of a frame that impedance matrices will be diagonal. Also, a
qualitative method has been developed to choose the relative
magnitude of the impedance parameters for a set of tasks. In
[15], [16], Kim et al. analysed the compliance characteristic
for different tasks by considering the grasp geometry, which
is the relation between the operational space and the ﬁngertip
space of multi-ﬁngered hand. Their analytical results show
that the non-diagonal terms in impedance matrices can not be
speciﬁed arbitrarily and they also used a qualitative method
(small and large value of stiffness) to specify the impedance
parameter.
b) Impedance Learning: Learning of tasks is another
approach by which desired impedance parameters can be
speciﬁed. In [17], the impedance learning problem is for-
mulated as a model-based reinforcement learning problem,
where the impedance parameters can gradually change to
improve the task performance. In [18], the authors ac-
complished a variable impedance controller with a model-
free, sample-based reinforcement learning method. However,
the reinforcement function needs to be carefully deﬁned
to capture the essence of the task, which will be difﬁcult
for complex tasks, such as dexterous manipulation. Sikka
and McCarragher [19] presented a method that can learn
ext
f
H
VF
,1 f
f
,2 f
f
,3 f
f
Fig. 2: An object grasped by 3 ﬁngers. The object impedance and grasp
impedance are shown as springs. The f
f;i
;i = 1; 2; 3 are the contact forces
on each ﬁngertips. fext is the external perturbation force. The frame H and
VF are the inertial frame and the virtual frame, respectively.
the robot end-point stiffness of contact tasks from human
demonstration. An online, incremental algorithm has been
proposed in [20] to learn varying end-point stiffness from
human demonstration. For a multi-ﬁngered robotic hand, a
implicit compliant controller [21] is learned to adapt the
grasp under perturbation, which actually mapping the ﬁnger-
tips tactile response to ﬁnger joints. However, this method
is hand dependent and difﬁcult to generalize to manipulation
tasks.
As discussed in [22], the tasks for multi-ﬁngered hand
are usually object-centric. In these cases, learning an object-
level impedance is more suitable and can be easily applied
to other hands. In this paper, we extend the object-level
impedance controller in [10] with tactile feedback and object-
level impedance learned from human demonstration.
III. OBJECT-LEVEL IMPEDANCE CONTROL
In this section, we will reformulate the object-level
impedance controller proposed in [10], which is mainly
composed of two parts, a stable grasp controller and an object
manipulation controller.
A. Object Manipulation Impedance
Following the formulation of impedance control in [11],
the dynamics of the object, as shown in Fig. 2, is governed
by the equation:
f
f;o
+ f
ext
=M
0
 x (1)
where f
f;o
is the summation of manipulating forces f
f;oi
exerted on the object from each ﬁngertip, f
ext
is the ex-
ternal perturbation force. All the forces are expressed in the
inertial frame. M
0
is the actual inertia matrix and x is the
position and orientation of the object. Usually, the position
and orientation are controlled independently [10]. Here for
simplicity, we put position and orientation in one vector x
to introduce the controller.
The objective of impedance control is to modulate the
interaction between the object and the environment by con-
trolling the contact forces. The desired interaction of the
system is given by:
f
ext
=M x +D(_ x  _ x
r
) +K(x  x
r
) (2)
6785
where x
r
; _ x
r
is the reference trajectory andM;D;K are the
desired apparent inertia, damping and stiffness, respectively.
From equations (1) and (2), we can derive the object-level
impedance control law given as:
f
f;o
=ED(_ x
r
  _ x) +EK(x
r
  x) + (E I)f
ext
(3)
whereE =M
0
M
 1
andI is the identity matrix. In practice,
it is often sufﬁcient to keep the inertia unchanged, i.e.,
M
0
= M and only shape the stiffness and damping. Then
the equation (3) can be simpliﬁed as:
f
f;o
=D(_ x
r
  _ x) +K(x
r
  x) (4)
B. Stable Grasping Impedance
Up to now, only the object manipulation impedance has
been considered. In order to make the grasp stable during ma-
nipulation, we need to design a stable grasping impedance,
which can be used to change the grasping forces. In our
paper, the contact model between the object and the ﬁngertips
is assumed to be point contact with friction, which can
only transmit contact forces. Therefore, we only use one
translational spring connecting each ﬁngertip and the origin
of the object (virtual) frame to represent the stable grasping
impedance (stiffness), as shown in Fig. 2. The grasping
forces can be expressed as:
f
f;gi
=K
gi
(kp
i
k L
i
)
p
i
kp
i
k
(5)
where f
f;gi
and K
gi
are the grasping force and stable
grasping stiffness ati-th ﬁngertip. p
i
= p
o
 p
i
with p
i
as
the position of contact point on i-th ﬁngertip and p
o
as the
position of the object frame origin.L
i
is the desired distance
from the i-th ﬁngertip to the object frame origin.
C. Implementation Issues
A rigorous implementation of the controller will require
a lot of computational load [23]. To reduce it, the ﬁnger
dynamics is not compensated and thus joint torques at each
ﬁnger can be obtained from a simple Jacobian transpose.

f;i
=J
T
f;i
f
f;i
(6)
where 
f;i
are the joint torques at i-th ﬁnger and J
f;i
is
the Jacobian of the i-th ﬁnger. The contact force can be
computed as: f
f;i
= f
o;i
+ f
g;i
. The more rigorous way to
compute the contact force using grasp mapping can be also
use here [7], which is also more computational expensive.
In order to implement this controller, we need to address
the following issues: (a) measure the object position and
orientation x; (b) design the reference trajectory x
r
; _ x
r
; (c)
choose the impedance parametersK andD. While (a) will be
discussed in the remaining part of this section by introducing
a Virtual Frame, the method to deal with (b) and (c) by
learning from human demonstration will be presented in the
next section.
D. Virtual Object Frame
Due to the occlusion of the hand, it is still very difﬁcult
to rely on vision to obtain the actual object position and
orientation in the controller. To deal with this, the concept
of Virtual Frame (VF) is adopted here, which is a function of
all the contact points between object and ﬁngertips. Virtual
frame (VF) can be used to estimate the real object position
and orientation if we assume that relative contact points
between object and ﬁngertips do not change
1
. Different from
the deﬁnition in [10], the VF in this work is the function of
real contact point on each ﬁngertip, which can be obtained
from tactile feedback. In our work, we only use three ﬁngers,
the origin of VF is:
p
o
=
1
3
3
X
i=1
p
i
(7)
The orientation of the frame is deﬁned in the following way:
R
o
= [r
x
; r
y
; r
z
]2SO(3) (8)
r
x
=
p
3
  p
1
kp
3
  p
1
k
r
z
=
(p
2
  p
1
) r
x
k(p
2
  p
1
) r
x
k
r
y
= r
z
 r
x
With the deﬁned VF, one can compute the translation and ro-
tation difference between the VF and the desired or reference
frame. Thus, from equation (4), (5) and (6), the desired joint
torque for each ﬁnger can be calculated. For more details
about the implementation, one can refer to [10].
IV. IMPEDANCE LEARNING FROM HUMAN
DEMONSTRATION
In this section, methods about how to specify impedance
for robust grasping and dexterous manipulation will be
presented.
A. Relative Impedance for Robust Grasping
A robust grasp should be able to comply with external
perturbation from any directions. But in different directions,
the extent of compliance will depend on the grasp conﬁgura-
tion as well as the task requirement. For instance, grasping
a screwdriver as a tool and grasping a pen to write will
require totally different levels of rotational compliance along
the axial direction.
Our method of impedance selection for robust grasping
is quite intuitive: the object stiffness in one direction is
inversely proportional to the variance of displacement un-
der perturbation in the corresponding direction. From this
assumption, we can learn the relative stiffness for robust
grasping in different directions from human demonstration.
This idea has also been utilized to learn the end-point stiff-
ness for a single manipulator [20]. During the demonstration,
an object is grasped by a human demonstrator with eyes
closed, to mimic the fact that our controller will use solely
1
This assumption will neglect the rolling and slipping effects.
6786
proprioceptive and tactile information, with no vision. The
grasped object is perturbed by another person randomly and
the displacement of the object is recordedfx
i
;i = 1:::Ng.
Then the object stiffness can be speciﬁed as follows:
K =f
1
N
N
X
i=1
(x
i
  x
r
)(x
i
  x
r
)
T
g
 1
(9)
where  2 R
+
is a ratio parameter that needs to be set
manually and x
r
2 R
6
is the object initial (and desired)
position and orientation.
Besides stiffness speciﬁcation, object workspace mod-
elling is also very important for robust grasping as it de-
termines the extent of motion of a grasped object during
perturbation. However, the workspace of a grasped object
will depend on the hand kinematics and the grasp conﬁgu-
ration. To this end, we teach the robot the extend to which
it can stretch its ﬁngers through kinaesthetic demonstration,
by back-driving the ﬁngers, see Fig. 3. All positions and
orientations adopted by the hand during the demonstration
are used to build a probabilistic model of the workspace of
the hand. The use of a probabilistic model is advantageous
as it accounts for the imprecision of the recording and allows
to generalize outside the demonstrations. The latter is partic-
ularly important since demonstrations may not be exhaustive
and may not explore all possible postures. Here, we use
Gaussian Mixture Model (GMM). A GMM is a probabilistic
model of density function composed ofK Gaussian compo-
nents. The likelihood of each position/orientation under this
model is given by:
p(x) =
K
X
k=1

k
N (xj
k
; 
k
) (10)
where 
k
is the prior of the kth Gaussian component and
N (
k
; 
k
) is the Gaussian distribution with mean 
k
and
covariance 
k
. A new VF, computed from (7) and (8), is said
to lie in the object’s workspace if its likelihood belongs to the
model is greater than a ﬁxed threshold, i.e.p(x

)>L
thresh
.
This threshold, in our experiment, is quite conservative and
is set as no more than 2 standard deviation, which means
that about 95:45% training position/orientation of VF will
be covered by the learned GMM. For more details about
the parameters selection for training GMM, one can refer to
[24].
With the object workspace model, one can design a desired
reaction behavior to improve grasping stability, e.g., increase
object stiffness gradually when the object is approaching
boundary of learned working space. This could be achieved
in our model by increasing the ratio parameter in equation
(9). This would however increase stiffness by the same
amount in all directions. It may often be useful to be able
to shape this increase along particular directions, such as
the direction the moves the object farthest away from the
workspace’s boundary.
B. Variable Impedance for Dexterous Manipulation
In the case of robust grasping, the reference frame can
be easily set as the initial position and orientation, which
(a) (b)
Fig. 3: (a) Human teaching of object workspace. The object impedance are
set to zero in all directions during the demonstration, which means human
can move the object freely in its workspace. (b) The position and orientation
of VF are recorded and trained using GMM. Here is shown the trained result
in the subspace of VF position. The red surface is the iso-surface with the
same threshold likelihood L
thresh
does not vary with time. For dexterous manipulation, a time-
varying reference trajectory x
r
; _ x
r
will be required. In this
section, we will present a method that learns the reference
trajectory and the desired object impedance simultaneously.
The objective of human demonstration is to model the
interaction between the object being manipulated and the
environment. Thus, during the demonstration, at each sample
instant i;i = 1:::N
s
, the motion of the objectfx(i); _ x(i)g
and the sum of manipulating forces f
f;o
(i) applied on the
object are recorded
2
. Consider t = 1:::N
t
consecutive sam-
ples of data obtained over a short time window. Assuming
the impedance parameters and reference trajectory remain
constant over this time window, the relationship between the
object motion and the force exerted on object is given by:
f
f;o
(i) =D(_ x
r
  _ x(i)) +K(x
r
  x(i));i = 1:::N
t
; (11)
During each time window, since we assume that the object’s
impedance parameters and the reference trajectory are not
changing with time, they can be obtained by minimizing the
following objective function:
min:
D;K;_ xr;xr
Nt
X
i=1
kf
f;o
(i) fD(_ x
r
  _ x(i)) +K(x
r
  x(i))gk
2
(12)
In practice, the term from damping is usually ignored by
assuming that the desired velocity trajectory is the same as
the measured one and thus equation (12) can be simpliﬁed
as:
min:
K;xr
Nt
X
i=1
kf
f;o
(i) fK(x
r
  x(i))gk
2
(13)
Note that the assumption that the object’s impedance pa-
rameters and reference trajectory are stationary for short
periods of time is only valid for tasks with small motion
and low velocities, where the dynamics is mainly dominated
by the compliance and contact condition. For fast tasks, it
will require some high speed (force and motion) sensors
to collected enough data points to obtain a reasonable
2
In practice, only the contact forces on each ﬁngertip can be measured,
which include the grasping forces and the manipulating forces. the sum of
grasping forces is very small in our setting from (5), which can be ignored.
6787
impedance estimation. Also, from (13), we can obtain the de-
sired impedance parameters for each time window and their
corresponding reference trajectory. In this framework, the
desired impedance parameters and the reference trajectory
will depend on time. To account for this, we deﬁne a variable
2 [0; 1] to represent the completion of the task, which is
a function of the desired trajectory, i.e.,  = (x
r
). In our
experiments,  is given by the distance from the current
conﬁguration to the goal conﬁguration. Thus, the impedance
parameters and desired trajectory are expressed as a function
of .
Since the system should be stable, additional constraints
should be taken into account. First, the stiffness matrix
should be positive semi-deﬁnite and its elements must be
less than some maximum value since we assume that human
will not demonstrate extremely large object stiffness. Also,
for the reference trajectory, it should not be too far away
from the actual measured object trajectory. Thus we have:
K
i;j
k
lim
; i = 1:::6;j = 1:::6;
kx
r
  x(i))k x
lim
; i = 1:::N
t
; (14)
k_ x
r
  _ x(i)k  _ x
lim
; i = 1:::N
t
;
where x
lim
2 R
+
;  _ x
lim
2 R
+
is upper bound of the
difference between the actual and real (position and velocity)
trajectories. With the objective function (13) and the con-
straints (14), the MATLAB built-in constrained optimization
function fmincon is used to ﬁnd the optimized impedance
parameters and reference trajectory.
V. EXPERIMENTS AND DISCUSSION
In the experiments, we use a 4-ﬁngered Allegro hand
3
to
test the object impedance speciﬁcation for robust grasping
and dexterous manipulation. The initial grasp and the grasp-
ing stiffness are predeﬁned.
A. Setup
SynTouch 
(a) Allegro hand (b) Human demonstration
Fig. 4: (a) The Allegro hand mounted with the SynTouch tactile sensors
on the ﬁngertips; (b) Human demonstration of bulb replacement.
Each of the four ﬁngers of the Allegro hand has 4
independent torque-controlled joints, see Fig. 4a. In our
experiments, we only use 3 ﬁngers even though our controller
can be generalized to 4 ﬁngers. Each ﬁngertip of these 3
ﬁngers has been mounted with a biometric tactile sensor from
SynTouch
4
, which has been calibrated to provide contact
information such as contact position and contact force.
3
http://www.simlab.co.kr/Allegro-Hand.htm
4
http://www.syntouchllc.com/
(a) (b) (c) (d)
Fig. 5: Human demonstration of robust grasping on 3 different objects:
glass, cup, screwdriver (side and top grasp). The motion of the object when
perturbed is tracked by OptiTrack.
B. Robust Grasping
In the robust grasping experiment, a human expert demon-
strates 4 grasps as shown in Fig. 5. The arm and wrist
are ﬁxated on the table so that the object motion will only
come from the ﬁnger motion. During the experiments, for
each object the perturbations are applied by another person
randomly. The position and orientation for the objects are
tracked using a motion capture system from OptiTrack
5
at
a sampling rate of 240Hz. More than 10000 datapoints are
collected for each object.
The recorded object orientation is transformed into RPY
Euler angles. The relative impedance parameters for the 4
grasps in different directions are computed using (9). In
general, the choice of frame of reference depends on the task.
Here we compute a diagonal stiffness matrix in the reference
frame of the object since this is also the frame of reference
in our impedance controller. It is also possible to extract the
principle directions and corresponding stiffness along these
directions from (9) [20], but then we need to transform the
stiffness along these principle directions into the object’s
frame of reference in real time during implementation.
The relative stiffness for these grasps are shown in Fig. 6–
Fig. 9. The results indicate that in different directions, the
relative stiffness for robust grasping is indeed different due
to various task-speciﬁc requirements and grasps. This result
may also imply that the anisotropic stiffness characteristic
is optimal for robust grasping, in the sense of keeping the
object stable with minimum efforts (grasping force). More
experiments will be conducted in our future work to verify
this implication.
Also, comparing the relative stiffness for two different
grasps on the screwdriver (Fig. 5, (c) and (d)), see Fig. 8 and
Fig. 9, we found that the rotational stiffness around Y -axis
is totally different. In the top grasp, the rotational stiffness
aroundY -axis is much smaller than that of side grasp, which
means that the top grasp requires smaller forces to rotate
the screwdriver around Y -axis. This result also coincides
with our intuition. Here, we only show the implementation
results for the grasp on the glass. The parameters are set as
follows: K
gi
= 20N=m, L
i
= 0:5kp
i
km, k
tx
= 20N=m,
k
ty
= 240N=m,k
tz
= 30N=m,k
rx
= 1:210
 3
Nm= deg,
k
ry
= 6 10
 3
Nm= deg, k
tz
= 1:2 10
 3
Nm= deg. The
snapshot of the implementation on the Allegro hand is shown
in Fig. 10.
5
http://www.naturalpoint.com/optitrack/
6788
(a) (b) (c) (d) (e)
Fig. 10: Testing of robust grasping: Snapshots of the response of our controller when a human perturbs the original position of the glass. The ﬁngers
adapt smoothly to follow the direction of motion induced by the human. The impedance was learned from former human demonstration, using results in
Fig. 6. The video is available at: http://lasa.epfl.ch/
˜
miao/robust_grasping.wmv
(a) glass (b) glass
Fig. 6: (a): The relative translational stiffness for glass,ktx <ktz <kty ;
(b): The relative rotational stiffness for glass, krxkrz <kty .
(a) cup (b) cup
Fig. 7: (a): The relative translational stiffness for cup,ktxktz <kty ;
(b): The relative rotational stiffness for cup, krx <krz <kty .
(a) screwdriver(side) (b) screwdriver(side)
Fig. 8: (a): The relative translational stiffness for screwdriver (side grasp),
ktxktz <kty ; (b): The relative rotational stiffness for screwdriver (side
grasp), krxkrz <kty .
C. Dexterous Manipulation
For dexterous manipulation, we use the bulb replacement
as an example, Fig. 4b. The bulb is initially on the socket
already. During the human demonstration, only two ﬁngers
are used as the impedance is learned in object’s frame of
reference and using two ﬁngers is easier to demonstrate. The
manipulating forces are measured using SynTouch mounted
on the ﬁngertips. The object real trajectory is tracked using
(a) screwdriver(top) (b) screwdriver(top)
Fig. 9: (a): The relative translational stiffness for screwdriver (top grasp),
ktxktz <kty ; (b): The relative rotational stiffness for screwdriver (top
grasp), kty <krxkrz .
OptiTrack
6
. Using equations (13) and (14), with x
lim
=
60 deg;k
lim
= 100N:mm=deg
7
, the reference trajectory and
desired stiffness for bulb replacement are obtained and shown
in Fig. 11 and Fig. 12a, respectively.
If we compare the desired rotation angle with the actual
rotation angle, we see that the difference varies during the
whole task. This means that human demonstrator indeed
regulates the difference between the actual and reference
trajectories as well as the stiffness parameter. When looking
at the desired object stiffness, Fig. 12a, we see that the
desired stiffness increases signiﬁcantly during the last phase
of the task. This is due to the fact that the resistance torque
between the bulb and the socket increases signiﬁcantly at
the last phase. We repeated this demonstration 10 times, the
obtained desired stiffness for each trial is shown in Fig. 12b.
If we could measure the rotational angle of the bulb
using vision, then the status of task completion  and the
correspondingk and x
r
can be obtained directly, which will
be very straightforward to implement the learned controller.
Unfortunately, it is difﬁcult to rely on vision for dexterous
manipulation task as the hand often obstructs the object
from the camera’s view. For this reason, we rely on tactile
information to guide the task process. Figure 12 indicates
that the regulation of stiffness during this task follows two
distinct phases. During the ﬁrst phase, which occurs before
break point  = 0:8 (i.e. more than 2/3rd of the total
duration of the task), the stiffness is quasi constant. Whereas
in the second phase, it increases steadily. We model this
6
During the human demonstration, in order to track the object robustly,
the experimenter must take care of not placing his ﬁngertips on the vision
markers.
7
x
lim
is chosen by considering the rotation limitation of human hand
and the Allegro hand.
6789
by setting a constant value for the stiffness for the ﬁrst
phase and by increasing linearly the stiffness up to its upper
bound for the remainder of the task, i.e., 4N:mm=deg, see
Fig. 12b. We noticed during the implementation that this
breakpoint corresponds to the instant when one ﬁngertip
(usually the thumb of Allegro hand) starts slipping on the
bulb. In order to detect the slippage, we use the contact forces
f
c
= [f
cx
;f
cy
;f
cz
] from SynTouch on each ﬁngertip, with
f
cx
;f
cy
andf
cz
being the tangential forces in two directions
and the normal force, respectively. A slippage occurs at
one ﬁngertip if the contact forces that ﬁngertip satisfying
q
f
2
cx
+f
2
cy
> f
cz
,  is the coefﬁcient of friction that is
set manually. In our task, we choose  = 0:9. The resulting
control strategy is given in Algorithm 1. The snapshot of the
implementation on Allegro hand is shown in Fig. 13.
Note that the current implementation of the bulb turning
task is incomplete since the task status can not be robustly
monitored only from tactile sensing. To ensure that the bulb
is actually moving and that the ﬁngers are not simply slipping
on the object, vision should be used in conjunction with
tactile information.
0 0.2 0.4 0.6 0.8 1
0
200
400
600
800
1000
1200
1400
?
rotation angles(deg)
desired and actual rotation angle
desired rotation angle
actual rotation angle
0.88 0.9 0.92 0.94 0.96 0.98 1
1040
1060
1080
1100
1120
1140
1160
1180
1200
?
desired rotation angle
actual rotation angle
Fig. 11: The learned reference trajectory for trial 5. is the variable that
represents the status of completion of the task, which is chosen as the ratio
between current rotational angle and maximal rotational angle.
0 0.2 0.4 0.6 0.8 1
0
0.5
1
1.5
2
2.5
3
3.5
4
?
rotation stiffness(N.mm/deg)
rotation stiffness
 
 
rotation stiffness
(a)
0 0.2 0.4 0.6 0.8 1
0
0.5
1
1.5
2
2.5
3
3.5
4
?
rotation stiffness(N.mm/deg)
rotation stiffness
 
 
trial 1
trial 2
trial 3
trial 4
trial 5
trial 6
trial 7
trial 8
trial 9
trial 10
(b)
Fig. 12: (a) The learned desired object stiffness for trial 5. The stiffness
will signiﬁcantly increase at the last phase of bulb replacement. (b) The
learned desired object stiffness for 10 different trials.
D. Discussion
During the robust grasping, we didn’t consider the problem
of grasp stability. As studied in [25], the object dynamic
stability will be closely related to the choice of grasp
stiffness. In future work, we will investigate ways in which
Algorithm 1: Controller for bulb replacement task
1 Move ﬁngers to initial positions: InitialGrasp();
2 repeat
Impedance Control Mode:
SetGrasp();
Compute the VF (eq.(7));
Set parameters:
L
i
= 0:5kp
i
km, k
tx
=k
ty
=k
tz
= 0N=m
k
rx
=k
rz
= 0Nm= deg, k
ry
= 1 10
 3
Nm= deg,
K
gi
= 12N=m
x
r
= 60 deg
interpolate x
r
to smooth the controller:
for i=1 to 1000 do
Compute the current reference point:
x
cr
=Slerp(x
r
,i);
Send joint torques: ObjImp();
Open Finger and move back to initial grasp:
InitialGrasp();
until DetectSlip()
3 if DetectSlip() then
4 Rotate the bulb for another 4 times:
for i=1 to 4 do
Impedance Control Mode:
SetGrasp();
Compute the VF (eq.(7));
Set parameters:
L
i
= 0:5kp
i
km, k
tx
=k
ty
=k
tz
= 0N=m
k
rx
=k
rz
= 0Nm= deg,
k
ry
= 1 +i 0:75 10
 3
Nm= deg,
K
gi
= 12 +i 2:5N=m
x
r
= 60 deg
interpolate x
r
to smooth the controller:
for i=1 to 1000 do
Compute the current reference point:
x
cr
=Slerp(x
r
,i);
Send joint torques: ObjImp();
Open Finger and move back to initial grasp:
InitialGrasp();
5 return 0;
to shape the stiffness while taking the grasp stability into
account.
Second, currently the initial grasp and grasp stiffness
are predeﬁned in our experiments, which is based on the
assumption that the given grasp can realize the desired object
impedance. However, given the object impedance speciﬁ-
cation and a multi-ﬁngered robotic hand, how to choose
a grasp that can realize this desired impedance will be a
challenging extension direction. One of the possible ways
will be employing the optimization framework for grasp
synthesis in our previous work [26].
Furthermore, in our extended work, more tasks will be
incorporated to demonstrate the generality of anisotropic
stiffness in robust grasping and varying stiffness in dexterous
manipulation.
6790
(a) (b) (c) (d) (e) (f)
Fig. 13: The snapshots for dexterous manipulation. The video for this demo is available at:http://lasa.epfl.ch/
˜
miao/bulb_replace.wmv
VI. CONCLUSIONS
In this paper, an object-level impedance learning approach
was proposed for both robust grasping and dexterous manip-
ulation. For robust grasping, the relative stiffness is speciﬁed
by measuring the displacement of object under perturbation.
For dexterous manipulation, the desired reference trajectory
and the desired object impedance is learned through an
optimization-based approach. Both of these approaches are
validated on a multi-ﬁngered robotic hand. The results show
that learning from human demonstration is an effective way
to specify the desired impedance for object-centric tasks.
We are currently working on integrating tactile feedback
into the object impedance controller for grasping stiffness
speciﬁcation.
ACKNOWLEDGMENT
Miao Li was supported by the European Union Seventh
Framework Programme FP7/2007-2013 under grant agree-
ment n
o
288533 ROBOHOW.COG. Hang Yin was supported
partly by a FCT doctoral grant (SFRH/BD/51933/2012)
under the IST-EPFL Joint Doctoral Initiative and by the
Swiss National Center of Robotics Research. Kenji Tahara
was supported by JSPS Grant-in-Aid for Young Scientists
(A) (25700028).
REFERENCES
[1] Z. Li, P. Hsu, and S. Sastry, “Grasping and coordinated manipulation
by a multiﬁngered robot hand.,” The International Journal of Robotics
Research, vol. 8, no. 4, pp. 33–50, 1989.
[2] T. Yoshikawa and X.-Z. Zheng, “Coordinated dynamic hybrid po-
sition/force control for multiple robot manipulators handling one
constrained object,” The International Journal of Robotics Research,
vol. 12, no. 3, pp. 219–230, 1993.
[3] Z. Li, Z. Qin, S. Jiang, and L. Han, “Coordinated motion generation
and real-time grasping force control for multiﬁngered manipulation,”
in Proceedings of International Conference on Robotics and Automa-
tion (ICRA), 1998.
[4] S. A. Schneider and R. H. Cannon, “Object impedance control for
cooperative manipulation: theory and experimental results,” IEEE
Transactions on Robotics and Automation, vol. 8, no. 3, pp. 383–394,
1992.
[5] T. Wimbock, C. Ott, and G. Hirzinger, “Analysis and experimental
evaluation of the intrinsically passive controller (IPC) for multiﬁngered
hands,” in Proceedings of International Conference on Robotics and
Automation (ICRA), 2008.
[6] K. Tahara, S. Arimoto, and M. Yoshida, “Dynamic object manipulation
using a virtual frame by a triple soft-ﬁngered robotic hand,” in
Proceedings of International Conference on Robotics and Automation
(ICRA), 2010.
[7] T. Wimbck, C. Ott, A. Albu-Schffer, and G. Hirzinger, “Comparison
of object-level grasp controllers for dynamic dexterous manipulation,”
The International Journal of Robotics Research, vol. 31, no. 1, pp. 3–
23, 2012.
[8] M. T. Mason and J. K. Salisbury, Robot Hands and the Mechanics of
Manipulation. The MIT series in Artiﬁcial Intelligence, Cambridge,
Massachusetts: The MIT Press, 1985.
[9] H. Liu and G. Hirzinger, “Cartesian impedance control for the DLR
hand,” in Proceedings of International Conference on Intelligent
Robots and Systems (IROS), 1999.
[10] K. Tahara, K. Maruta, A. Kawamura, and M. Yamamoto, “Externally
sensorless dynamic regrasping and manipulation by a triple-ﬁngered
robotic hand with torsional ﬁngertip joints,” in Proceedings of Inter-
national Conference on Robotics and Automation (ICRA), 2012.
[11] N. Hogan, “Impedance control - an approach to manipulation. i -
theory. II - implementation. III - applications,” ASME Transactions
Journal of Dynamic Systems and Measurement Control B, vol. 107,
pp. 1–24, Mar. 1985.
[12] B. Siciliano, L. Sciavicco, L. Villani, and G. Oriolo, Robotics:
Modelling, Planning and Control. Springer Publishing Company,
Incorporated, 1st ed., 2008.
[13] M. Cutkosky and I. Kao, “Computing and controlling compliance of a
robotic hand,” IEEE Transactions on Robotics and Automation, vol. 5,
no. 2, pp. 151–165, 1989.
[14] K. Shimoga and A. Goldenberg, “Grasp admittance center: Choosing
admittance center parameters,” in American Control Conference, 1991,
pp. 2527–2532, 1991.
[15] B.-H. Kim, B.-J. Yi, S.-R. Oh, and I. H. Suh, “Task-based compliance
planning for multiﬁngered hands,” in Proceedings of International
Conference on Robotics and Automation (ICRA), 2001.
[16] B.-H. Kim, B.-J. Yi, S.-R. Oh, and I. H. Suh, “Fundamentals and
analysis of compliance characteristics for multiﬁngered hands,” in
Proceedings of International Conference on Robotics and Automation
(ICRA), 2001.
[17] B.-H. Yang and H. Asada, “Progressive learning and its application to
robot impedance learning,” IEEE Transactions on Neural Networks,
vol. 7, no. 4, pp. 941–952, 1996.
[18] J. Buchli, F. Stulp, E. Theodorou, and S. Schaal, “Learning variable
impedance control,” The International Journal of Robotics Research,
vol. 30, no. 7, pp. 820–833, 2011.
[19] P. Sikka and B. J. McCarragher, “Stiffness-based understanding and
modeling of contact tasks by human demonstration,” in Proceedings
of International Conference on Intelligent Robots and Systems (IROS),
1997.
[20] K. Kronander and A. Billard, “Online learning of varying stiffness
through physical human-robot interaction,” in Proceedings of Interna-
tional Conference on Robotics and Automation (ICRA), 2012.
[21] E. L. Sauser, B. Argall, G. Metta, and A. Billard, “Iterative learning
of grasp adaptation through human corrections.,” Robotics and Au-
tonomous Systems, vol. 60, no. 1, pp. 55–71, 2011.
[22] A. Okamura, N. Smaby, and M. Cutkosky, “An overview of dexterous
manipulation,” in Proceedings of International Conference on Robotics
and Automation (ICRA), 2000.
[23] T. Yoshikawa, “Multiﬁngered robot hands: Control for grasping and
manipulation,” Annual Reviews in Control, vol. 34, no. 2, pp. 199 –
208, 2010.
[24] B. Huang, S. El-Khoury, M. Li, J. J. Bryson, and A. Billard, “Learning
a real time grasping strategy,” in Proceedings of International Confer-
ence on Robotics and Automation (ICRA), 2012.
[25] C.-H. Xiong, Y .-F. Li, H. Ding, and Y .-L. Xiong, “On the dynamic
stability of grasping,” The International Journal of Robotics Research,
vol. 18, no. 9, pp. 951–958, 1999.
[26] S. El Khoury, M. Li, and A. Billard, “Bridging the gap: One shot
grasp synthesis approach,” in Proceedings of International Conference
on Intelligent Robots and Systems (IROS), 2012.
6791
