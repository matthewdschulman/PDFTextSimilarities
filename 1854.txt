  
  
Abstract— Many researchers have employed some form of 
teleoperated leader to influence a robotic swarm; however, the 
way in which this influence is conveyed has not been well 
studied.  Some researchers employ designated leaders that are 
known to be leaders by other members of the swarm and hence 
followed.  Others do not impose a leader/follower distinction on 
the swarm’s algorithms and instead choose to influence the 
swarm indirectly through controlling one or more of its 
members.  Because the robustness of swarm behavior arises 
from its many distributed interactions, influence through 
designated leaders might render it susceptible to noise or 
disrupt its coherence by overriding these mechanisms.  
Conversely, limiting human influence to indirect control 
through the local effects of a leader might prove too sluggish to 
allow effective human control.  This paper compares leader-
based methods of each type, designated as Tacit leadership via  
consensus (no explicit leader/follower distinction) and Explicit 
leadership via flooding (influence propagating from leader 
takes precedence). These methods were compared in simulation 
and in human experiments finding that explicit leadership led 
to faster convergence in simulation and better performance in 
the experiments.  Effects of noise were slightly more 
pronounced for Explicit leaders and cohesion slightly poorer. 
 
I. INTRODUCTION 
In the near future, swarms of robots may replace humans 
and single robots for a number of common  tasks. Because 
swarms are made up of numerous robots that operate under 
scalable, distributed algorithms,  they can cover more area 
more robustly  than a single robot or teams of independent 
robots. This makes them suitable for jobs such as exploration 
and foraging [1],  [2],  [3],  construction  [4],  [5],  and fire 
fighting or HAZMAT situations [6], [7]. Indeed, in  recent 
years, we have seen swarms move from a theoretical 
possibility to systems implemented on real robots in 
laboratory settings,  such as those in [8], [9], [10]. 
Robots coordinated as swarms rely on simple control 
laws replicated across platforms which interact with each 
other to give rise to emergent organized behavior. Flocking 
behavior, for example, can be generated from three simple 
rules: 1) move away from any sensed robot closer than d
1
, 2) 
move toward any sensed robot further  away than d
2
, 3) 
adjust heading to average heading of sensed robots. The 
balancing of attractive and repulsive  forces and consensus on 
heading leads to a swarm that sticks together and moves in 
common, perhaps changing, directions.   
 
S. Amirpour Amraii, P. Walker, and M. Lewis are with the School of 
Information Sciences and Intelligent Systems Program, University of 
Pittsburgh, Pittsburgh, PA 15260, USA (phone: 412-980-1457; email: 
saman.amirpour@gmail.com).  
N. Chakraborty and K. Sycara are with the Robotics Institute, Carnegie 
Mellon University, 5000 Forbes Ave., Pittsburgh, PA, USA. 
 
While there are some cases where swarms might act with 
full autonomy, many tasks require some sort of coordination 
between a human operator and the swarm. For instance, if the 
operator is using a swarm of unmanned vehicles (UVs) to 
survey a large outdoor area, the operator may want to alter 
several details of the UVs’ operations, such as which areas 
should be explored first, what routes they should take,  and 
how closely they should move with respect to each other. 
Because swarm algorithms are designed to work with large 
numbers of robots, individual teleoperation of each swarm 
member is not feasible.  
Strategies for injecting human influence into a robotic 
swarm can be divided into global approaches which influence 
the swarm as a whole and bottom-up leader/follower 
approaches that influence the swarm through its members.  
Global approaches have been varied including broadcasts of 
parameters such as goal locations [11], “virtual leaders” that 
provide a reference signal for incorporation into local 
consensus [12], algorithm switching [11] [13] and beacons 
[11] or potential fields [14] to attract and channel the swarm.   
This paper compares the effects of Explicit and Tacit 
leadership on  robot swarms coordinating via local laws.  Our 
contributions are as follows. In contrast to most  
leader/follower studies that have been limited to small (2-3) 
UV groups [15] [16] in which leaders and followers are in 
direct contact and where no propagation of leader influence is 
needed, our focus is on groups of moderate size of between 
20-50 robots for which the leader may not be within 
sensor/communication range of all followers.  Additionally, 
we performed controlled human experiments and compared 
performance on a variety of measures. This is a contribution 
over current research which has been conducted in 
simulation[1],[2],[3],[4],[5],[11],[12],[13], [14] and relied on 
global methods for exerting influence rather than 
control/teleoperation of a leader. Moreover, we examine a 
variant of Explicit leadership in which the leader’s influence 
is propagated through the swarm via intermediaries rather 
than direct contact, much as orders might be propagated 
through a military chain of command.  
 
II. RELATED WORK 
Leader/follower strategies  differ primarily between 
Explicit approaches in which the influence of leaders over 
followers is distinguished from their influence over one 
another and Tacit ones in which it is not.  [15] provides an 
example of an Explicit leader.  In their system the operator 
teleoperates a leading quadrotor while other quadrotors 
obeying their control laws follow behind.   The leading 
quadrotor is equipped with an array of IR beacons that is 
used by the followers as a reference to maintain their relative 
Explicit vs. Tacit Leadership in Influencing the Behavior of Swarms 
Saman Amirpour Amraii, Phillip Walker, Michael Lewis, Member, IEEE, Nilanjan Chakraborty,  
Member, IEEE and Katia Sycara, Fellow, IEEE 
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 2209
  
positions.  Because the signal from the leader (IR beacon) is 
distinct and takes precedence over  sensing mediating 
responses to other quadrotors (obstacle avoidance), the 
system employs Explicit leadership.  Kira and Potter [13]  
provide an example of Tacit leadership in one of their 
human-in-the-loop experiments.  In their simulation UVs are 
controlled through physicomemetic control laws.  To 
influence the swarm the operator creates and directs virtual 
agents that do not exist in the environment to interact with the 
real agents via the same force law mechanisms to influence 
swarm behavior.  This is an example of Tacit leadership 
because the influence of the human directed leader is not 
distinguished from influences of other members of the 
swarm.  Free selection of leader and Explicit leadership can 
also be combined as in [16] in which the operator selects a 
leader for a team of UAVs.  A decision support algorithm 
proposes the leader  based  on optimal control calculations. 
The operator can designate a current follower as the next 
leader and the team will reconfigure itself and begin 
following the new leader.  Finally agents can be assigned 
additional capabilities as in [17] who distinguishes 
stakeholders that respond to both human input and other 
agents from leaders (respond only to human input) and 
followers (respond only to other agents).  In this case only the 
leader/follower relation remains fully Tacit while the 
stakeholder might be either a weakened form of Tacit leader 
(does not fully respond to operator input) or a variant of [12] 
global “virtual leader” strategy in a population containing 
only stakeholders.   
III. APPROACH 
We expect a rapid attenuation of a Tacit leader’s 
influence as it propagates while  that of an Explicit leader 
should result in more rapid convergence.  Two possible 
disadvantages of Explicit leadership, noise sensitivity and 
incoherence,  have been raised.  Goodrich [17]  argues that a 
human operator may have poorer knowledge of the state of 
the swarm and environment than the agents themselves under 
conditions of sensor/communication noise, and therefore 
might make poorer judgments.  The second objection is that 
by overriding local consensus, Explicit commands may 
disrupt the swarm’s coherence leading to loss of connections 
and expanding diameter.  Goodrich argues instead that the 
operator should “work within the system”  by injecting 
control through a small number of agents and allowing the 
system to adjust to these inputs over time.   
In our experiments we will examine all three of these 
hypotheses: 
H1: Explicit leadership will result in faster convergence 
to operator intent making swarms more responsive and easier 
to control 
H2: Sensor noise will affect Explicit leadership to a 
greater extent than Tacit leadership (e.g.; there will be a noise 
x leadership type interaction) 
H3: Swarms will exhibit less cohesion (more connected 
components and larger diameter) under Explicit leadership 
IV.  EXPERIMENT 1 
Many swarm control problems ranging from formation 
following, to rendezvous to flocking can be reduced to 
consensus problems.  The ability of an operator input to 
influence the development of consensus within a swarm  
therefore  provides  a basic measure of capabilities for 
bringing the system into agreement with operator intent.  For 
example if an operator sends an orientation command to a 
swarm, she would expect to see the robots’ orientations to 
begin changing and eventually settle at her intended value.  
Our first experiment compares the effects of propagating 
operator intent through either Explicit (tagged) or Tacit 
(indistinguishable) messages using static (robots are not 
moving) simulated networks.   
 We analyze the “consensus quality” based on:  
Convergence time: How long does it take for the swarm 
to converge on the intended value/command of the operator? 
 Noise tolerance: How robust is the convergence algorithm in 
the presence of noisy communication?  
and investigate the effects of: 
Graph size and connectivity: What are the effects of graph 
size and graph connectivity  on the convergence time?  
The leader in the Tacit condition is a robot (node) that is 
not distinguished from its neighbors in any way but that 
retains its designated value (that intended by the operator) 
while other robots continue to adjust values to reflect those of 
their neighbors as dictated by the consensus algorithm.  
In the Explicit condition, robots can distinguish between 
normal messages and tagged ones.  Messages from the leader 
are tagged and update the internal information state of the 
recipient which remains constant thereafter. This tagged 
message is then propagated as the robot’s current value at the 
next step of the consensus algorithm 
We define a swarm  as a set of robots occupying spatial 
positions in a plane during time:  
S(t) = {s
i
 (t)|s
i
 (t) ? R
2
 }. 
Robots also have an internal state which represents their 
knowledge at any moment in time. For example each robot’s 
internal state may reflect its set of internal rules (e.g. for 
switching between flocking and rendezvous behaviors). In 
our example this internal state is the robot’s orientation at 
each time step: 
X (t) = {x
i
 (t)|x
i
 (t) ? (?π, π)}.  
Our goal is to start from an arbitrary initial state X(0), choose 
a random orientation value  as our intention, x
?
, send it to the 
swarm and wait until the swarm converges on our intention. 
Convergence is achieved if there exists a time ? , after which 
the internal values of all robots remain within an error 
tolerance range ?
?
 of x
?
: 
?t ≥ ?, ?i    |x
i
 (t) ? x
?
| ≤ ?
?
 
Robots communicate with each other through a limited 
disk connectivity graph. In other words, robots that are in 
range ? can see each other and robots farther away would not 
be able to communicate directly. This results in a 
connectivity graph G = (N, E) which has N nodes (the 
number of robots in our swarm) and there is an edge e
ij
   ? E 
iff ?s
i
 ? s
j
?  ≤ ?. 
2210
  
The operator  chooses a random robot ? as her initial 
point of influence and updates the internal value of that robot 
with her desired random value: x
?
 (0) = x
?
 
We will refer to the Explicit Leader case as the flooding 
condition because propagation occurs in the manner of a 
flooding algorithm.  In flooding, a swarm  has an additional 
internal  state set P (t) which indicates which robots have 
received tagged messages.  Thus after the user sends x
?
 to ?, 
we would have p
?
 (0) = 1 while ?i ≠ ?   p
i
 (0) = 0. The 
internal states X and P are updated by this rule: ?i, j if e
ij
 ? E 
and p
j
 (t) = 1 and p
i
 (t) = 0 then p
i
 (t + 1) = 1 and x
i
 (t + 1) = 
x
j
 (t). In case a robot has more than one neighbors relaying 
tagged messages, it adopts the information from the first one. 
In the Tacit control method, also known as consensus, the 
internal state of each robot is updated by averaging over 
internal values of all of its neighbors (including itself). The 
only robot that doesn’t change its internal value is ? (i.e. the 
robot which receives x? from operator). The consensus 
algorithm  is based on the method presented in [18]. Here, we 
have a weight matrix W which defines the averaging 
coefficients.  Thus at each time t we have: 
X (t) = W 
t
 X (0) 
Instead of the optimal solution, we use a simpler approach 
which assigns  a fixed weight to all edges.  Xiao [18] 
demonstrates that if the swarm remains connected, any edge 
weight smaller than 1 will  guarantee convergence. He also 
proves that the optimal constant edge weight is 
?* = 
2
?1(L) + ?n?1(L)
  where ?(.) denotes the ith largest 
eigenvalue of a symmetric  matrix  and L is the Laplacian 
matrix of the connectivity graph G. In our experiments, we 
use this expression for the edge weight. 
For the simulation experiments in both Explicit and Tacit 
conditions we assume that the swarm is operating in an 
obstacle free environment and always maintains its 
connectivity (even when robots move). We perform   our 
analysis by assuming noiseless communication in a fixed 
connectivity graph. After comparing Explicit and Tacit 
methods and finding some lower bounds on the worst case 
convergence time, we expand our analysis by assuming noisy 
communication.. As [19], [20] have demonstrated, even in 
the presence of noise, the consensus method will converge as 
long as a swarm’s connectivity graph remains connected. 
Therefore our analysis focuses on its convergence time and 
its relation to the Explicit method’s convergence time. 
In the Flooding condition (Explicit leadership) the 
operator expresses intention to the leader and it propagates 
from there as a breadth first search (BFS) graph traversing 
algorithm.  For a static graph the algorithm takes at most D 
steps, where D is the the size of graph diameter, until the 
information reaches all the other We assume that noise is 
uniformly distributed E ? (??, ?) so that for static graphs the 
noise is at most ±D?.   For an error tolerance of ??, therefore, 
?  ≤ ?
?
/D.  
In the Consensus condition information also propagates 
as a BFS and again requires D steps until the information 
from ? can affect the farthest robot, however, because the 
message’s value has been affected by initial conditions of the 
intervening robots additional steps will be needed to reach 
convergence. Because error will be averaged rather than 
amplified an error tolerance of ?
?
 can be obtained provided ? 
≤ ?
?
 
In order to test Explicit and Tacit control approaches, we 
created random swarm configurations then analyzed their 
convergence time. The swarms were created by arbitrarily 
choosing from 1 to 50 robots and placing them randomly on a 
200 m ? 200 m environment. Then starting with a 
connectivity range of ? = [1, m], a connectivity graph was 
created by incrementing ?  until all robots formed a single 
connected graph. Random internal state values were selected 
from (?π, π) in order to simulate an orientation value. A 
random robot was selected as the leader to communicate the 
random intention x
?
. Both Explicit and Tacit methods are 
performed by the swarm and their convergence time 
measured. An error acceptance value of ?
?
 = 0.1 was used 
and results averaged over 10,000 experiments.  
 
Figure 1. (a) Convergence times for Explicit leaders (flooding) 
 
(b) Convergence times for Tacit leaders (consensus) 
 
 
Figure 1. Convergence times- note 200:1 differences in 
scales and irregularity of times for Tacit leaders 
2211
  
 
Figure 2.   The swarm of robots (left) is steered to the goal region (center) by the user teleoperating the leader robot (shown in red) using the virtual 
joystick (right). Robots that have detected the goal heading and speed from the leader (or an intervening neighbor) and are moving in that direction are 
shown in green.  
The convergence time for the Explicit and Tacit methods is 
presented in figures 1(a) and 1(b) respectively.  The 
convergence times are compared based on the number of 
nodes in the graph and the Fiedler value. The Fiedler value 
is the second smallest eigenvalue of the Laplacian of the 
connectivity graph (i.e. ?
1
(L(G))) [21].  A larger Fiedler 
value means that the graph is more connected and one has to 
remove more edges in order to cut the graph into 
independent components. While the Explicit method takes at 
most about 15-18 steps, the Tacit method takes much more 
time, sometimes   even more that 2000 steps. The Explicit 
method is also much more robust. As the Fiedler value 
increases (the graph is more connected), the Explicit method 
converges faster regardless of the number of nodes. Also 
when the Fiedler value is small, the convergence time of the 
Explicit method has a linear relationship with the number of 
nodes in the graph. On the other hand, the Tacit method 
behaves differently. When the Fiedler value is small, the 
convergence time increases exponentially with the number 
of nodes. Moreover, even when the Fiedler value is high and 
the graph is well connected, sometimes the convergence 
time spikes. It seems that the Tacit method convergence time 
does not behave linearly in relation to the connectivity level 
of the graph.        
The experiments had similar results for cases with 
moderate amounts of noise however when ? exceeded 10% 
of the error tolerance level ?? the swarm frequently failed to 
converge in the Explicit leader condition.  These results 
support hypotheses H1, namely faster convergence for 
Explicit leaders, and H2, namely better error tolerance for 
Tacit leaders.  Hypothesis H3, greater coherence for Tacit 
leaders, was not tested in these experiments. 
V.  EXPERIMENT 2 
In a follow up experiment we implemented flooding 
(Explicit leadership) and consensus (Tacit leadership) 
methods for propagating operator influence on a human-in-
the-loop testbed.  Our study investigated the ability of human 
operators to control a flocking swarm of robots in an open 
environment by teleoperating   a single leader via a 
continuous   velocity (i.e. heading and speed) command.  The 
main task for the users was to survey a given area by guiding 
the swarm to goal regions, which appeared dynamically in  
the environment. A goal region appeared at a random 
position only after another goal region has been visited by the 
swarm. Thus, the number of goal regions visited by the 
operator provided a natural measure of his or her 
performance.  In addition, we investigated the effect of 
sensing error on the ability of the operator to control the 
swarm.  
An open 100x100 meter environment in Stage v.3.2.2 
[17] was used to simulate 20 P2AT robots. Each robot was 
equipped with a sensor providing speed and heading of 
neighboring robots within 4 meters as well as the presence of 
a tag in the flooding condition.  In conditions with sensing 
error, simulated noise sampled from Gaussian distributions N 
(0, 0.2) meters for location and N (0,  π ) for orientation were 
added.  The swarm of robots was initialized randomly in a 
10x10 meter box, centered around the origin of the 
environment, with the leader at the origin with a random 
orientation. 
The human operator’s task was to steer the swarm to goal 
regions shown as blue circles in the environment (Figure 2). 
Once over half the swarm reached the goal region, a new goal 
appeared at a random position.  The operator used a virtual 
joystick to control the heading and speed of the leader.  Other 
robots moved according to local control laws. 
Alignment:  The alignment vector is determined by the 
propagation method (flooding or consensus). For the flooding 
propagation condition, each robot determines if any of it’s 
neighbors have tagged values. When a robot senses tagged 
values it sets its velocity and alignment vectors, (x
a
 , y
a
 ), to 
match the velocity and heading of that neighbor. Once that 
velocity and heading is matched (to within 15 degrees), the 
robot’s values are returned as tagged. In the event that neither 
the leader nor any privileged neighbors are detected, no 
alignment vector is used and the robot continues on its 
previous path.  For the consensus propagation method, each 
robot averages the speed and heading of each neighbor it can 
sense, and then sets its speed and alignment vector (x
a
 , y
a
 ) to 
that average speed. 
Cohesion and Repulsion:  In addition to sensing 
neighbors’ velocities, the robots also sense neighbors’ 
positions to maintain swarm cohesion and avoid inter-robot 
collisions by using cohesion and repulsion laws that allow the 
swarm to flock together. 
2212
  
Eighteen human operators participated in the study. Each 
participant received 3 minutes of training on each of the four 
conditions (flooding with and without error, and consensus 
with and without error). Following training, participants 
completed the four 10 minute experimental trials in a random 
order completing a NASA-TLX workload questionnaire [22] 
to assess  the workload of each trial. 
A.  Results 
The main measure of success for participants was the 
number of goal regions reached.  There was a significant 
difference between each of the four conditions (F = 72.45, p 
< .001, see Figure  2). Participants were most successful in  
 
         without error   with error    without error     with error 
Figure 3. Number of Goals Reached 
the flooding without error condition, where they reached an 
average of 13.78 goal regions. This was significantly more 
than the flooding with error condition (M  = 9.33, t = 3.49, p 
= .001). Furthermore, participants were significantly more 
successful  in  reaching the goal regions in the flooding (M  = 
11.56) than the consensus (M = 1.97) conditions overall (t = 
12.26, p < .001). Within the consensus conditions,  goals 
reached  in the consensus without error condition (M = 2.61) 
were significantly  higher than in consensus with error (M  = 
1.33, t = 2.46, p =.021).  These findings are also confirmed 
by the results of the NASA-TLX workload questionnaire (F  
= 26.18, p < .001) which found  workload higher in the 
consensus  (M   = 69.78) than the flooding conditions (M  = 
39.24, t = 7.84, p < .001), and higher in the error (M   = 
60.05) than the non-error conditions (M = 48.97, t = 2.14, p = 
.039).   
To examine cohesion we looked at connectivity and 
swarm diameter across the conditions.  Connectivity was 
measured by Fiedler value and swarm diameter as the 
furthest distance between any two robots in the largest 
connected component of the swarm.  Conditions without 
error showed significantly more connectivity (M  = 0.27) 
than conditions with error (M   = 0.17, t = 2.55, p  = .013). 
The only two conditions that showed significant differences 
in connectivity were the consensus without error condition 
(M = 0.30) and the flooding with error condition (M  =0.15 , t 
= 2.34, p = .027) although  connectivity  between consensus 
(M  = 0.24) and flooding (M  = 0.20) were not significant (t = 
0.92, p = .359). There were significant differences between 
the conditions for swarm diameter, however (F  = 20.48, p < 
.001, see Figure 3). The diameter of the swarm was  larger in 
the flooding conditions (M  = 10.79m) than in the consensus 
conditions (M = 9.60m, t = 4.26, p < .001). Similarly, the 
error conditions had a higher diameter (M = 10.84m) than the 
non-error conditions (M = 9.54m, t = 4.81, p < .001). 
 
 
 
 
               without error   with error    without error     with error 
Figure 4. Diameter of Swarm 
VI. DISCUSSION 
Overall, the results show that an Explicit leader with a 
flooding method of propagating information is more effective 
than a Tacit leader relying on existing control laws in 
influencing a swarm to match an operator’s intent.  The first 
experiment comparing flooding and consensus found a ratio 
of approximately 200:1 in convergence times favoring 
flooding.  This advantage was less pronounced in the human 
subject experiment which found only a 7:1 advantage for 
flooding in moving the swarm between goal regions.  The 
sluggishness of the swarm’s response to control through a 
Tacit leader is borne out both by the better performance in 
the Explicit leader conditions in moving swarms between 
target regions within a time limit,   and workload ratings 
which were twice as high for Tacit leaders.  Such high 
reported workload ratings are common for extremely low 
gain systems.  These findings provide strong support for our 
first hypothesis, H1: Explicit leadership will result in faster 
convergence to operator intent making swarm more 
responsive and easier to control. 
Evidence for our second hypothesis, H2: Sensor noise 
will affect Explicit leadership to a greater extent than Tacit 
leadership, is weak and equivocal.  Our simulation data show 
that sensor noise has little differential effect on performance 
up until very high levels where the flooding algorithm may 
fail to converge. The human subject data provided similar 
results.  Despite operators reaching fewer goals in the 
FLOODING 
CONSENSUS 
FLOODING 
CONSENSUS 
0 
5 
10 
15 
10 
12 
11 
9 
8 
7 
6 
2213
  
flooding with error condition, a corresponding drop in 
performance was found using the consensus method.  The 
absence of an interaction between leadership type and the 
presence of noise indicates no differential advantage in error 
tolerance for Tacit leadership.  In fact, flooding retained its 
7:1 advantage over consensus in the noise conditions. 
The third hypothesis, H3: Swarms will exhibit less 
cohesion under Explicit leadership, was better supported by 
our study.  Because connectivity was maintained in both the 
static and subsequently run dynamic graph conditions in the 
simulation this hypothesis could only be tested in the second 
experiment.  In the consensus conditions, the swarms were 
both more compact (smaller diameter) and had a more 
connected sensing graph (higher Fiedler value). This could 
provide significant benefit if bandwidth between swarm 
members is at a premium, as a more highly connected 
network would allow for more messages to be passed through 
the swarm. Denser swarms could also be beneficial in cases 
of operation in obstacle-filled   spaces, such as surveying the 
ocean floor or with small unmanned ground vehicles 
exploring urban and indoor environments.   
While sensor noise had only minor effects in our 
experiments there may be other conditions under which 
Goodrich’s [17] contention that “a human operator may have 
poorer knowledge of the state of the swarm and environment 
than the agents themselves” could lead to different results.  In 
a cluttered environment, for example, averaging with 
neighbors might aid in moving around obstacles while 
persisting at an operator dictated heading might not.  We 
would like to conduct further simulations imposing local 
constraints as well human control in cluttered environments 
to investigate these possibilities. 
VII. CONCLUSIONS 
One conclusion that may be drawn from this study is that 
it is important to consider mechanisms for exerting human 
influence when designing algorithms for coordinating 
swarms.  While consensus algorithms have valuable 
guarantees when operating independently they may be less 
subject to human influence than less robust forms of 
coordination.  Our finding of the relative robustness to noise 
of non-consensus influence propagation is encouraging.  
However, the loss of coherence resulting from imposing an 
external value on the consensus process may be a necessary 
price for improving the responsiveness of swarms whether 
through propagation or a global method such as broadcast. 
ACKNOWLEDGMENT 
This research   has  been sponsored  in  part by  ONR 
Grant N0001409-10680. 
REFERENCES 
[1] S. Bashyal and G. Venayagamoorthy,  “Human swarm interaction for 
radiation  source search and localization,”  in Swarm Intelligence 
Symposium, 2008. SIS 2008. IEEE.  IEEE, 2008, pp. 1–8. 
[2] P. Walker, S. Nunnally, M. Lewis, A. Kolling, N. Chakraborty, and K. 
Sycara, “Neglect benevolence in human control of swarms in the 
presence of latency,” in Systems, Man, and Cybernetics (SMC), 
2012IEEE International  Conference on.   IEEE, 2012, pp. 3009–3014. 
[3] S. Nunnally, P.  Walker, A.  Kolling,  N.  Chakraborty,  M.  Lewis, K. 
Sycara, and M. Goodrich, “Human influence of robotic swarms with 
bandwidth and localization issues,”  Systems,  Man, and Cybernetics 
(SMC), 2012 IEEE International  Conference on, pp. 333–338, 2012. 
[4] C. Parker, H. Zhang, and C. Kube, “Blind bulldozing: multiple robot 
nest construction,”  in Intelligent Robots  and Systems, 2003.(IROS 
2003). Proceedings.  2003 IEEE/RSJ  International Conference  on, 
vol. 2.   IEEE, 2003, pp. 2010–2015. 
[5] Y. Meng and J. Gan, “A distributed swarm intelligence based 
algorithm for a cooperative multi-robot  construction task,” in Swarm 
Intelligence Symposium, 2008. SIS 2008. IEEE.  IEEE, 2008, pp. 1–6. 
[6] A. Naghsh, J. Gancet, A. Tanoto, and C. Roast, “Analysis and design 
of human-robot swarm interaction in firefighting,” in Robot and 
Human Interactive Communication,  2008. RO-MAN 2008. The 17th 
IEEE International  Symposium on.   IEEE, 2008, pp. 255–260. 
[7] D.  Bruemmer,  “A robotic swarm for  spill  finding and perimeter 
formation,” DTIC Document, Tech. Rep., 2002. 
[8] M. Dorigo, E. Tuci, R. Groß, V. Trianni, T. Labella, S. Nouyan, C. 
Ampatzis,  J. Deneubourg,  G. Baldassarre,  S. Nolfi et al., “The 
swarm-bots project,” Swarm Robotics, pp. 31–44, 2005. 
[9] J.  McLurkin,  J.  Smith, J.  Frankel, D.  Sotkowitz, D.  Blau, and B. 
Schmidt, “Speaking  swarmish: Human-robot interface design for 
large swarms of autonomous mobile robots,”  in Proc. of the AAAI 
Spring Symposium, 2006, pp. 72–75. 
[10] A. Turgut, H. C¸ elikkanat, F. Go¨ kc¸e, and E. S¸ ahin, “Self-
organized flocking in mobile robot swarms,” Swarm Intelligence,  vol. 
2, no. 2, pp. 97–120, 2008. 
[11] A. Kolling, K. Sycara, S. Nunnally, & M. Lewis, “Human-swarm 
interaction: An experimental study of two types of interaction with 
foraging swarms,” Journal of Human-Robot Interaction, Vol. 2, No. 2, 
2013, pp. 104–129. DOI 10.5898/JHRI.2.2.Kolling 
[12] H. Shi, L. Wang, and T. Chu. "Virtual leader approach to coordinated 
control of multiple mobile agents with asymmetric 
interactions."Physica D: Nonlinear Phenomena 213.1, 2006, pp. 51-
65. 
[13] Z. Kira and M. Potter. "Exerting human control over decentralized 
robot swarms." Autonomous Robots and Agents, 2009. ICARA 2009. 
4th International Conference on. IEEE, 2009, pp. 566-571. 
[14] L. Barnes, M. Fields, and K. Valavanis, "Swarm formation control 
utilizing elliptical surfaces and limiting functions." Systems, Man, and 
Cybernetics, Part B: Cybernetics, IEEE Transactions on 39.6, 2009, 
pp. 1434-1445. 
[15] W. Etter Jr., P. Martiny and R. Mangharamz, “Cooperative flight 
guidance of autonomous unmanned aerial vehicles,” University of 
Pennsylvania, School of Engineering and Applied Science Real-Time 
and Embedded Systems Lab technical report, 2011, pp 1-9. 
[16] X. Ding, M. Powers, M., Egerstedt, S. Young, and T. Balch, (2009). 
“Executive decision support: Single-agent control of multiple UAVs,”  
Robotics & Automation Magazine, IEEE, 16(2), 2009, pp. 73-81. 
[17] M. Goodrich, S. Kerman, and S. Jung. "On Leadership and Influence 
in Human-Swarm Interaction." 2012 AAAI Fall Symposium Series,  
2012, pp 1-6. 
[18] L. Xiao and S. Boyd. "Fast linear iterations for distributed 
averaging."Systems & Control Letters 53(1), 2004, pp. 65-78. 
[19] L. Wang and Z. Liu, “Robust consensus of multi- agent systems with 
noise,”  Science in China Series F: Information Sciences 52(5), 2009, 
pp. 824–834. 
[20] W. Ren, R. Beard and E. Atkins,  “A survey of consensus problems  in 
multi-agent coordination,”  Proceedings of the 2005 American Control 
Conference, vol. 3., 2005, pp. 1859 –1864  
[21] J. Gross and J. Yellen, “Graph Theory and Its Applications,” CRC 
Press, 2006. 
[22] S. G. Hart and L. E. Staveland, “Development  of nasa-tlx (task load 
index): Results of empirical  and theoretical research,” Human mental 
workload, vol. 1, no. 3, 1998, pp. 139–183. 
 
2214
