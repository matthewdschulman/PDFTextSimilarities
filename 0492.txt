A Haptic Human-Robot Interface Accounting for Human Parameter Stochasticity
William Gallagher Jun Ueda
Abstract— Force feedback haptic devices require physical
contact between the operator and the machine, creating a
coupled system where the stiffness changes based on that of
the operator’s arm. The natural human tendency to increase
arm stiffness to stabilize motion increases the overall stiffness
and reduces stability. Controllers commonly address this with
increased damping, which slows the device and decreases
operator efﬁciency. Previous research designed a system to es-
timate operator arm stiffness by measuring muscle activity and
compensate accordingly, modifying the robot’s motion based on
operator interactions. This achieved the goal of reducing oscilla-
tions and increasing performance, but encountered drawbacks
related to the unpredictable way in which humans modulate
the dynamic parameters of their arm. Controllers designed
to be robust to stochastic variation of system parameters are
explored, and their effectiveness is validated experimentally.
This could further increase the operator performance and
reduce fatigue, which could translate into better efﬁciency and
higher productivity.
I. INTRODUCTION
As robotic technology advances, the area of human-robot
interaction (HRI) is expanding rapidly. Robots can no longer
be designed in isolation from the people that will use them,
as typical industrial systems have been. HRI systems must
consider that the human is an integral part of the system.
This applies especially to physical human-robot interaction
(pHRI) systems, where the operator is in physical contact
with the robot. Contact between the robot and the human
gives a coupled system, requiring a design incorporating an
understanding of how the human will move.
Industrial settings are increasingly utilizing robotics and
automation to streamline difﬁcult jobs, but some situations
make automation difﬁcult due to the usually strict tolerances
required for repetitive tasks. For exampe, on vehicle assem-
bly lines, the placement of a vehicle component, such as
a door, must be done within tolerances, but the location
of the vehicle itself may vary slightly. It is often more
efﬁcient to have a human accomplish the task, especially
for ones that requires a cautious force sensitivity that is best
accomplished through human touch. Components can often
be heavier than a worker can lift, but assistive robotic devices
can be useful in aiding the completion of such tasks through
force ampliﬁcation. Teleoperated systems could be used, but
this removes the operator from directly participating in the
task through remote sensing, introducing possible errors and
requiring slower motion. A system that the operator could
directly interact with is preferred.
Haptics is a popular control method, since people ﬁnd
touch very intuitive for controlling a robotic device. Force
Bio-Robotics and Human Modling Lab, Woodruff School of Mechanical
Engineering, Georgia Institute of Technology, Atlanta, GA, USA
Fig. 1. Conceptual drawing of a haptically controlled robotic device with
a controller that adjusts based on estimated operator model
feedback and haptic controllers are common from gaming to
industrial machines. Physical contact between the operator
and robot introduces force feedback, creating a coupled
operator-robot system. This can result in reduced stability
without an appropriate controller, making the robot harder to
operate. Instability increases task completion time, decreases
performance, and creates an opportunity for injury. Humans
naturally increase muscle stiffness to control to instability
or oscillation. Unfortunately, this creates a stiffer coupled
system with more instability. Generic robot controllers can-
not directly measure or adjust to operator stiffness. A system
with access to information about the operator’s motion could
adjust accordingly, and thereby increase stability, bolster
safety, and make operation easier. This would enable in-
creased operator performance, which in industrial settings
can result in increased efﬁciency.
This research developed a method to allow a haptic robot
controller to adjust to changes in how the operator interacts
with the robot by expanding the information available to
the controller. Fig 1 shows a conceptual illustration of the
system. It will measure metrics indicative of how the operator
intends to move the device and incorporate them into a model
to estimate the operator’s current motion. The controller then
adjusts its gains to assist. This allows the robot to actively
adjust to changes in the operator’s motion, ensuring stability
and ease of use. While it may be possible to instead design a
robust system to accommodate a wider range of parameters,
this tends to result in lower performance, which is counter
to the requirements of industrial settings.
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 4256
II. BACKGROUND
A. Haptic Assist Systems
Early work on force amplifying assistive devices by Kaze-
rooni led to the design of a force amplifying exoskeleton
system [1, 2]. Li has also investigated force ampliﬁcation
control for industrial type robots, which allow an operator
to manipulate heavy loads [3]. Such systems commonly
use impedance control, which masks the physical system
dynamics by generating an assistive force so the operator
feels some desired system dynamics [4].
Impedance based control methods can be effective in
increasing stability [5]. Limitations on how people adapt to
rapid changes in dynamics create a design trade off between
high performance and stability [6]. People modulate their
arm motion to help control unstable dynamics [7], leading
to work on how to measure the dynamic characteristics of
the arm efﬁctively [8]. Compensating systems have been
demonstrated to be capable of increased stability without
sacriﬁcing performance [9].
B. Human Arm Stiffness
Muscles can be modeled primarily as springs, though
nonlinear effects exist [10–12]. There is a reﬂexive compo-
nent of the nervous system’s attempts to maintain muscle
length which introduces a delay [13]. Generally, a larger
muscle force will exhibit a higher stiffness. Increases in
joint stiffness have been linked to simultaneous activation of
antagonistic muscles, or cocontraction [14], which causes an
increase in end-point stiffness [5], making cocontraction of
primary interest. People generally can not control end-point
stiffness independently of force and position [15], which
implies that an estimate of end-point stiffness is indicative
of upcoming motion. For consistent pose and low velocities,
a simpliﬁed linear stiffness model can be assumed [16],
modeling the arm as a mass-spring-damper system attached
to the robot handle [17]. People correct for variations from
a desired motion by increasing arm stiffness, leading to
increased cocontraction [18, 19].
III. STIFFNESS COMPENSATING SYSTEM
Prior work designed and tested a system that modeled
arm stiffness, k
o
, and adjusted an impedance controller
accordingly, as represented by Fig 2. Stiffness was estimated
from muscle activity measured by electromyogram (EMG).
Feasibility testing with volunteers measured its effect on
stability and performance. Ultimately, this should lead to
an industrially viable way of making robot operation easier,
and could be used in various human-machine interfaces with
applications such as industrial assembly lines, rehabilitaiton
Fig. 2. Basic tasks of compensating system
robotics, or space robots. Further details not presented here
are in [20–23].
A. Estimating Arm Stiffness
The Biceps Brachii (BB) and Triceps Brachii (TB) at the
elbow (E) and the Extensor Carpi Ulnaris (ECU) and Flexor
Carpi Ulnaris (FCU) at the wrist (W) were chosen as the best
muscles for measuring cocontraction, CC
i
, i =E;W , with
EMG. A threshold based classiﬁer was developed, which
determined based on the two cocontraction levels if the
stiffness level, Z, was high or low using the thresholds `
W
& `
E
as per (1).
Z =
(
high if CC
W
(t)`
W
or CC
E
(t)`
E
low if CC
W
(t)<`
W
and CC
E
(t)<`
E
(1)
Testing showed that more than two levels provided no
statistically signiﬁcant advantage, as shown by Fig 3. Further,
the data showed that the stiffness level generated by operators
was inconsistent and not necessarily just high enough for the
applied force. The stiffness,k
o
, data collected was poorly ﬁt
by several common distributions, but proved to be well ﬁt
by two separate Gaussians, shown in Fig 4, supporting the
two level classiﬁcation scheme.
B. Adjusting Controller
An impedance controller calculated the control force so
that the operator felt the dynamics of some desired model
system with mass, m
d
, damping, b
d
, and stiffness, k
d
. This
consised of an outer force component that passed this motion
to an inner position component utilizing a PD controller with
gainsK
p
andK
d
. Fig 5 gives the complete system, wherem,
b, andk are mass, damping, and stiffness, with the subscripts
Fig. 3. Average of classiﬁed stiffness levels for experimental data, error
bars show standard deviation of classiﬁed points.
Fig. 4. Stiffness, ko , data ﬁt with two normal distributions, R
2
= 0:917
4257
Fig. 5. s domain block diagram of impedance controller utilizing PD inner position control and operator system, as designed in [20–22]. Laplace domain
variables - Fo : Operator applied force, Fm : Measured force, X
d
: Desired position, E: Position error, T : Motor torque, X: Position
d, h, and o, denoting desired impedance characteristics of
the controller, dynamics of the haptic device, and dynamics
of the operator, respectively. Human contact decreased its
stability, especially when the operator stiffness,k
o
, increased,
therefore the desired values were adjusted based on the clas-
siﬁed stiffness. Experiments validated that stability increased
as compared to a ﬁxed system with the same performance
capability. Additionally, it provided better performance that
the typical more stable system.
However, there was a large amount of chatter in the
system, where the compensation would turn on and off
rapidly, which reduced performance and is undesireable. This
stemmed from the non-deterministic nature of the operator
stiffness, so tolerance of stochastically varying parameters
would be better. This research proposes replacing the PD
controller with an optimal controller designed to account for
the stochastic changes in human arm dynamics.
IV. CONTROL OF STOCHASTIC SYSTEMS
Humans do not deterministically generate force or stiffness
for the task they are performing. Since the complete system
is coupled between the human and device, the overall system
dynamics are changing in an unknown and stochastic manner.
Therefore, it is desirable for the controller to be tolerant of
these variances in the system parameters.
Consider the state space representation of the system given
by (2), where the system input, u is the applied force.
_ x =Ax+Bu y =Cx+Du (2)
where A =

0 1
 
ko+k
h
m
h
 
bo+b
h
m
h

, B =

0
1
m
h

, C =

1 0

, and D = 0. The A matrix varies stochastically
as the dynamic parameters of the arm, k
o
and b
o
, change.
A controller designed for uncertain system parameters can
minimize the effect of these variations and can be substituted
for inner PD position controller in the impedance control
scheme of Fig 5. An expected distribution of operator arm
stiffness can be found experimentally, allowing the design of
a controller that is optimal for the expected range of values.
A. Linear Quadratic Gaussian Control
The Linear Quadratic Regulator (LQR) is a common opti-
mal controller designed to stabilize a system with minimum
control effort [24], relying on the assumption that the system
is time-invariant. It can be adapted to control stochastic
systems by modeling variation as additive or multiplicative
noise [25]. Combined with Kalman’s ﬁlter to reduce uncer-
tainty and noise [26], the Linear Quadratic Gaussian (LQG)
control method is obtained [27], which has become one of
the fundamental techniques for control under uncertainty.
Consider a discrete linear system given by (3), where the
system matricesA,B, andC are assumed time-invariant.
x
t+1
=Ax
t
+Bu
t
y
t
=Cx
t
(3)
The LQR optimal control input, u
0
;u
1
;:::;u
t
, is found by
(4), where L is derived via the minimization of the cost
function, J, in (5) for all t. Q
1
and Q
2
are weighting
matrices to emphasize minimization of error and control
effort, respectively, and are positive semi-deﬁnite.
u
t
= Lx
t
(4)
J =
1
X
t=0
 
x
>
t
Q
1
x
t
+u
>
t
Q
2
u
t

(5)
The solution by dynamic programming porvides the Ricatti
equation in (6), giving the optimal control law in (7).
 =Q
1
+A
>
A A
>
B
 
Q
2
+B
>
B

 1
B
>
A
(6)
L =
 
Q
2
+B
>
B

 1
B
>
A (7)
This solution is optimal and minimizes control effort.
However, it relies on the accuracy of the system model and
the assumption of time invariance. Consider, instead, the
system with sensor output given by (8), where v
t
is process
noise and w
t
is sensor noise.
x
t+1
=Ax
t
+Bu
t
+v
t
y
t
=Cx
t
+w
t
(8)
The process and sensor noise are unknowable a priori and
not directly measurable. Utilizing the Kalman ﬁlter in (9) to
perform state estimation provides more accurate values for
the control law, given in (10).
^ x
t+1
=A^ x
t
+Bu
t
+K(y
t+1
 C(A^ x
t
+Bu
t
)) (9)
u
t
= L^ x
t
(10)
TheK found from the Ricatti equation in (11) and control
law solution in (12) is combined with theL found previously.
The diagonals ofW andV give the expected range of the
elements of w
t
and v
t
, respectively.
  =V +A A
>
 A C
>
 
W +CPC
>

 1
C A
>
(11)
K = C
>
(W +C C)
 1
(12)
A diagram of the LQG controller is shown in Fig 6.
4258
Fig. 6. State feedback block diagram of LQG controller
B. LQR for Stochastically Varying Parameters
The LQG controller is not designed speciﬁcally for sys-
tems with parameters that vary stochastically, but for time
invariant systems disturbed by noise. Minimax LQG con-
trollers handle complex uncertainty [28], but rely on an
assumption of bounded noise rather than a direct change
in system parameters. Controllers that attempt to minize
Kullback-Leibler distance [29] or theH
1
norm of the system
rather than a control cost function [30] exist, but often fo-
cused on ﬁxed dynamics with unknown time delay. The most
promising of these approaches for this research incorporated
an assumed distribution for the system parameters directly
into the derivation of the optimal control law, ensuring that
the controller was optimal for their expected value, but still
perform well as they varied [31, 32].
Consider (3) whereA andB have expected values E[A]
and E[B] vary stochastically according to some distribution
that does not change with time. The cost function should
therefore minimize not only the control effort, but also the
variance of the system’s error, as in (IV-B).
J = E
"
1
X
t=0
 
x
>
t
Q
1
x
t
+u
>
t
Q
2
u
t
+tr[Q
3
cov[x
t+1
;x
t
]]

#
(13)
By the methodology of Fujimoto [31, 32], the optimal control
gain is found by (16), with the parameter given by (IV-B)
and the covariances
XY
given by (15).
 =Q
1
+
AA
+E

A
>
A

 
 
E

A
>
B

+
AB

 
E

B
>
B

+
BB
+Q
2

 1
 
E

B
>
A

+
BA

(14)

XY
= E

X
>
Q
3
Y

 E[X]
>
Q
3
E[Y] (15)
L =
 
E

B
>
B

+
BB
+Q
2

 1
 
E

B
>
A

+
BA

(16)
This Stochastic Linear Quadratic Regulator (SLQR), shown
by Fig 7, is an optimal controller designed from the expected
value and covariance ofA andB to minimize the control
effort and variance of the system. The emphasis on each of
these can be varied by choosing appropriate values for the
Q’s. The state feedback diagram is drastically simpler, as the
state estimator is removed, since the calculation ofL already
incorporates an estimate of the stochasticity of the system.
Fig. 7. State feedback block diagram of SLQR controller
V. EXPERIMENTAL VALIDATION
A. Concept
The stochastic controllers were incorporated into the sys-
tem, replacing the PD position component of the impedance
controller and tested against each other and the baseline
system to evaluated the effects on system performance. The
compensating system was also compared with ﬁxed gain
systems with high damping for stability or low damping for
speed. It was expected that the compensation would give
better performance than current ﬁxed high damping systems
with regards to speed while providing better accuracy than
ﬁxed low damping systems.
Two tasks were designed to allow targeted testing of speed
and accuracy. In each task, the participant was given a series
of targets to reach on a computer screen in front of the
device. For the speed-based task, participants were told to
move the indicator to the target as quickly as possible,
with overshoot acceptable. For the accuracy-based task, they
were told to move the indicator to the target as accurately
as possible and to avoid overshoot. For both tasks, the
operator was given a score for each target that was displayed
once they had reached the target. The simulation, shown
in Fig 8, characterized accuracy and speed improvements
independently in a rigorous fashion.
Fig. 8. Experimental simulation - Yellow box moved with device handle;
Gray box was target with an emphasis on either speed or accuracy
Fig. 9. A participant performing the experiment
4259
(a) Accuracy task by classiﬁer (b) Accuracy task by controller (c) Speed task by classiﬁer (d) Speed task by controller
Fig. 10. Performance comparison experiment marginal means, lower scores indicate better performance
TABLE I
PERFORMANCE COMPARISON PARTICIPANT DATA
Total Male Female Ages
24 16 8 19 - 42
B. Method
The experiment utilized a one degree of freedom haptic
paddle system, which was used previous for system design
and testing, and is described further in [20–22]. The 1-DOF
device can be seen in Fig 9, which shows a participant with
the simulation displayed on the screen in front of them.
Participants stood next to the device with their right elbow
bent approximately 90

, grasping the handle with the right
hand, with EMG sensors attached to the four muscles of their
right arm They were given the instructions for each task and
allowed to run practice trials.
Each participant performed a full factorial of cases, with
3 classiﬁers and 3 controllers for both tasks, giving 18 trials,
each of which consisted of 24 scored targets. The trials
were ordered based on a Latin Squares design to esnure
that each participant saw the tasks in a unique order and
to minimize the effects of learning and fatigue. This was
conducted following an approved IRB protocol.
C. Analysis
The experiment included data from 24 volunteers, given
in Tbl I. Over 10,000 data points were collected, with a
statistical power of 1  > 0:999, ensuring strong statistical
signiﬁcance. The analysis utilized a generalized linear model
to perform a repeated-measures multivariate ANOV A.
The speed task score, j
s
, given by (17), normalized time
to the target,t
b
, by the distance to the target,d
b
. Equal scores
were differentiated with an accuracy factor based on over-
shoot time, t
o
. A lower score indicated better performance.
j
s
=
t
b
d
b
+c
s
t
s
(17)
The accuracy task score, j
a
, given by (18), was closest
distance to the target reached, d
min
, normalized by the
target width, h, and squared to more strongly penalize
poor accuracy. Overshoot was penalized by replacing d
min
with the maximum overshoot, d
s
, and adding an additional
penalizing factor was added. Equal scores were differentiated
with a time factor accounting for the velocity to reach the
target, _ x
z
. A lower score indicated better performance.
j
a
=
(
 
dmin
h

2
 
_ x
b
_ xmax
if no overshoot
 
ds
h

2
+
ds
h
+
_ x
b
_ xmax
if overshoot
(18)
D. Results
Fig 10 shows the means of the data for both tasks, sepa-
rated by classiﬁer in Figs 10(c) and 10(a) and by controller in
Figs 10(d) and 10(b), with all differences proving statistically
signiﬁcant. All statistics presented are corrected F value
using Pillai’s trace, and, unless otherwise stated, p< 0:001
may be assumed.
Results demonstrated that the classiﬁer had a statistically
signiﬁcant effect on both tests, with PV = 0:112 and
F = 162:0. The controller’s effect was also statistically
signiﬁcant, with PV = 0:125 and F = 273:9. Interactions
between the two independent variables proved to have a
statistically signiﬁcant effect, with PV = 0:48 and F =
33:52.
Pairwise comparisons between each of the classiﬁers
showed statistically signiﬁcance differences with p< 0:001.
Between the controllers, all pairs were signiﬁcantly different
with p < 0:001, except for between the LQG and SLQR,
which showed signiﬁcance with p = 0:017.
E. Discussion
The results strongly suggest improvement over the non-
compensating system. The trade-off between the speed
achieved with low damping and accuracy achieved with
high damping is clearly demonstrated, with the compensating
system achieving a balance between the two.
The low damping case provided the worst accuracy scores
and the high damping case provided the best. Fig 10(a)
the improved accuracy of compensating system over the
low damping case, especially with a stochastic controller.
Statistically, there is little difference between the LQG and
SLQR controllers, but the SLQR performed better with
the compensating system. In all cases except for the high
damping case, the two stochastic controllers outperformed
the PD. The effect of the controller became negligible for
the high damping case.
4260
The low damping case gave the best speed scores and
the high damping gave the worst, which was opposite of
the accuracy results as expected. Fig 10(c) shows that the
compensating system provided a compromise. The SLQR
and baseline gave similar results, but were both better
performing than the LQG.
The results conﬁrm the initial hypothesis that the compen-
sating system would outperform the current state-of-the-art.
The stochastically tolerant controllers yielded better accuracy
than the baseline PD, with the SLQR controller excelling
in the speed task. This supports implementation of such an
SLQR controller in a stiffness compensating system.
VI. CONCLUSION
A methodology for controlling a coupled human-robot
system that could account for the stochastic variation of
human dymanic characteristics was presented and integrated
into an existing stiffness compensating controller. In testing,
compensating controller was conﬁrmed to be effective at
providing both stability and performance. The stochastic
system gave improved accuracy, with the SLQR achieving
this without sacriﬁcing speed, demonstrating improvements
over the previously presented system.
The system could be further enhanced with a more ad-
vanced operator model. The threshold system has several dis-
advantages, while a probabilistic model could likely acieve
better results. The authors are currently developing a Hidden
Markov Model based method that will provide better op-
erator action estimates. Numerous controller enhancements,
including closing the force loop on the impedance controller,
are also being considered. These will ultimately enable
testing on a device with more degrees of freedom.
VII. ACKNOWLEDGEMENTS
The authors acknowledge General Motors, the National Science Foun-
dation (IIS EAGER 1142438, CNS 1059362), and the Center for Robotics
and Intelligent Machines at Georgia Tech for sponsorship. Also, thanks
to Timothy McPherson of the Bio-Robotics & Human Modeling Lab, JD
Huggins of the Intelligent Machine Dynamics Lab, Dr. Minoru Shinohara of
the Applied Physiology Department, and Dr. Karen Feigh of the Cognitive
Engineering Center at Georgia Tech for assistance and advice.
REFERENCES
[1] H. Kazerooni and M.-G. Her, “The dynamics and control of a haptic
interface device,” Trans on Rob and Automation, vol. 10, no. 4,
pp. 453–464, 1994.
[2] H. Kazerooni, A. Chu, and R. Steger, “That Which Does Not Stabilize,
Will Only Make Us Stronger,”IntlJofRobRes, vol. 26, no. 1, pp. 75–
89, 2007.
[3] P. Y . Li, “Design and Cont of a Hydraulic human power ampliﬁer,” in
Intl Mech Eng Cong and Expo, (Anaheim, CA, USA), pp. 385–393,
2004.
[4] B. Siciliano and L. Villani, Robot force control. Kluwer international
series in engineering and computer science, Kluwer Academic, 1999.
[5] N. Hogan, “Controlling impedance at the man/machine interface,” in
Intl Conf on Rob and Automation, (Scottsdale, AZ, USA), pp. 1626–
1631, Comput. Soc. Press, 1989.
[6] M. Zinn, B. Roth, O. Khatib, and J. K. Salisbury, “A New Actuation
Approach for Human Friendly Robot Design,” The Intl J of Rob Res,
vol. 23, no. 4, pp. 379–398, 2004.
[7] D. W. Franklin, R. Osu, E. Burdet, M. Kawato, and T. E. Milner,
“Adaptation to stable and unstable dynamics achieved by combined
impedance control and inverse dynamics model.,” J of Neruophys,
vol. 90, no. 5, pp. 3270–82, 2003.
[8] M. D. Hill and G. Niemeyer, “Real-time estimation of human
impedance for haptic interfaces,” in Joint Eurohaptics Conf and Symp
on Haptic Interfaces for Virtual Env and Teleoperator Systems, (Salt
Lake City, UT, USA), pp. 440–445, IEEE, 2009.
[9] F. Mobasser and K. Hashtrudi-Zaad, “Adaptive Teleoperation Cont
using Online Estimate of Operator’s Arm Damping,” in Conf on Dec
and Cont, (San Diego, CA, USA), pp. 2032–2038, Ieee, 2006.
[10] A. V . Hill, “The heat of shortening and the dynamic constants of
muscle,” Proceedings of the Royal Society of London. Series B, Biolog
Sciences, vol. 126, no. 843, pp. 136–195, 1938.
[11] N. A. Bernstein, The co-ordination and regulation of movements.
Pergamon Press, 1967.
[12] J. A. Monroy, A. K. Lappin, and K. C. Nishikawa, “Elastic Properties
of Active Muscle - On the Rebound?,” Exercise and Sport Sciences
Revs, vol. 35, no. 4, pp. 174–179, 2007.
[13] T. Sinkjæ r and R. Hayashi, “Regulation of wrist stiffness by the
stretch reﬂex.,” J of Biomechanics, vol. 22, no. 11-12, pp. 1133–40,
1989.
[14] N. Hogan, “Adaptive control of mechanical impedance by coactivation
of antagonist muscles,” Trans on Auto Cont, vol. 29, no. 8, pp. 681–
690, 1984.
[15] E. J. Perreault, R. F. Kirsch, and P. E. Crago, “V oluntary Cont of Static
Endpoint Stiffness During Force Regulation Tasks,” J of Neruophys,
vol. 87, no. 6, pp. 2808–2816, 2002.
[16] F. E. Zajac, “Muscle and tendon: Proporties, models, scaling, and
application to biomechanics and motor control,” Crit Revs in Biomed
Eng, vol. 17, no. 4, pp. 359–411, 1989.
[17] K. P. Tee, E. Burdet, C. M. Chew, and T. E. Milner, “A model of
force and impedance in human arm movements,” Biolog Cybernetics,
vol. 90, no. 5, pp. 368–375, 2004.
[18] E. Burdet, R. Osu, D. W. Franklin, T. E. Milner, and M. Kawato,
“The central nervous system stabilizes unstable dynamics by learning
optimal impedance.,” Nature, vol. 414, no. 6862, pp. 446–9, 2001.
[19] D. W. Franklin and T. E. Milner, “Adaptive control of stiffness to
stabilize hand position with large loads.,” Exp Brain Res, vol. 152,
no. 2, pp. 211–220, 2003.
[20] W. Gallagher, T. McPherson, J. D. Huggins, M. Shinohara, D. Gao,
R. Menassa, and J. Ueda, “An Improved Human-Robot Interface by
Measurement of Muscle Stiffness,” in Intl Conf on Biomed Rob and
Biomecha, (Rome, Italy), 2012.
[21] W. Gallagher, D. Gao, and J. Ueda, “Measurement of muscle stiffness
to improve stability of haptic human-robot interfaces,” in Dynamic
Systems and Cont Conf, (Ft. Lauderdale, FL, USA), 2012.
[22] W. Gallagher, D. Gao, and J. Ueda, “Improved Stability of Haptic
Human-Robot Interfaces using Measurement of Human Arm Stiff-
ness,” Adv Rob, 2014.
[23] W. Gallagher, M. Ding, and J. Ueda, “Relaxed individual control of
skeletal muscle forces via physical human-robot interaction,” Multi-
body Sys Dyn, vol. 30, no. 1, pp. 77–99, 2013.
[24] K. Zhou, J. C. Doyle, and K. Glover, Robust and Opt Cont. Prentice
Hall, 1996.
[25] W. L. De Koning, “Inﬁnite horizon optimal control of linear discrete
time systems with stochastic parameters,” Automatica, vol. 18, no. 4,
pp. 443–453, 1982.
[26] R. E. Kalman, “A new approach to linear ﬁltering and prediction
problems,” J of Basic Eng, vol. 82, no. 1, pp. 35–45, 1960.
[27] M. Athans, “The role and use of the stochastic linear-quadratic-
Gaussian problem in control system design,” Trans on Auto Cont,
vol. 16, no. 6, pp. 529–552, 1971.
[28] E. Yaz, “Minimax control of discrete nonlinear stochastic systems with
noise uncertainty,” inConfonDecandCont, (Brighton, England, UK),
pp. 1815–1816, 1991.
[29] M. K´ arn´ y and T. V . Guy, “Fully probabilistic control design,” Systems
& Cont Letters, vol. 55, no. 4, pp. 259–265, 2006.
[30] Z. Wang, D. W. C. Ho, Y . Liu, and X. Liu, “Robust control for a
class of nonlinear discrete time-delay stochastic systems with missing
measurements,” Automatica, vol. 45, no. 3, pp. 684–691, 2009.
[31] K. Fujimoto, S. Ogawa, Y . Ota, and M. Nakayama, “Opt control of
linear systems with stochastic parameters for variance suppression:
The ﬁnite time horizon case,” in IFAC World Cong, (Milan, Italy),
pp. 12605–12610, 2011.
[32] K. Fujimoto, Y . Ota, and M. Nakayama, “Opt control of linear systems
with stochastic parameters for variance suppression,” in Conf on Dec
and Cont and European Cont Conf, (Orlando, FL, USA), pp. 1424–
1429, Ieee, 2011.
4261
