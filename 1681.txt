Miniature Six-channel Range and Bearing System: Algorithm,
Analysis and Experimental Validation
Nicholas Farrow, John Klingner, Dustin Reishus and Nikolaus Correll
Abstract—We present an algorithm, analysis, and im-
plementation of a six-channel range and bearing system
for swarm robot systems with sizes in the order of
centimeters. The proposed approach relies on a custom
sensor and receiver model, and collection of intensity
signalsfromallpossiblesensor/emitterpairs.Thisallowsus
toimproverangecalculationbyaccountingfororientation-
dependent variations in the transmitted intensity, as well
as to determine the orientation of the emitting robot. We
show how the algorithm and analysis generalize to other
range and bearing systems, and evaluate its performance
experimentally using two ping-pong ball-sized “Droplets”
mounted on a precise gantry system.
I. INTRODUCTION
Range and bearing (R&B) detection is a critical
operation in multi-robot systems and swarm robotics
aggregation [1], dispersion [2], pattern recognition [3],
ﬂocking [4], and navigation [5], [6]. There exist multiple
systems based on infrared (IR) [7], ultra-sound/radio [8]
and ultra-wide-band radio [9] for medium-scale multi-
robot systems, but precise R&B on centimeter-scale
robots such as Alice [10], Jasmine [11] or Kilobot [12]
remains a challenge due to the size of emitter, receiver
and signal processing hardware. Robots at this size
scale therefore either focus on range-only sensors [12],
or implement only crude bearing measurements [10],
[11]. Although range and bearing information can be
derived from each other [13], [14], these methods are
not practical for dynamic applications.
Range and bearing requires measuring both the in-
tensity and the identity of other robots’ emitters. This
can be achieved by modulating the intensity signal
with data packages, which usually requires dedicated
signal processing hardware to measure the intensity of
the carrier wave before decoding information [7], [15],
[16], or during channel allocation, i.e., coordination
among robots to prevent simultaneous transmissions, as
in this paper. We propose a novel approach to range
and bearing, as well as a theoretical framework that
is general to the class of circular robots with signal
emitters/sensors arranged around the robots’ perimeter.
This class includes popular robots like Khepera III and
E-puck. In our platform, known as Droplets, each robot
Department of Computer Science, University
of Colorado at Boulder, Boulder, CO 80309,
firstname.lastname@colorado.edu
Fig. 1: The Droplet swarm robotics platform. Three Droplets
are shown, one with the cover removed. The background is a
ﬂoor of alternating power and ground strips from which the
Droplets draw power (for scale the strip width is 22.8 mm).
is circular with a 4.4 cm diameter and has six IR emitters
and receivers evenly distributed on the perimeter. This is
fewer than used on larger platforms, which use up to 12
channels [2], [7], [16]–[18]. As a result, we have less
information available and techniques like interpolating
between sensors [16] are less reliable. Previous work
also treats the emitting robot as a point source of
light located at the center of the robot, which ignores
variations in received intensity caused by the orientation
of the transmitting robot. The error introduced by this as-
sumption is reduced as the number of emitters increases,
and as the distance from the transmitting robot increases.
For near-distance applications involving smaller robots,
a different approach is needed.
Our range and bearing algorithm operates by taking
measurements for each distinct sensor-emitter pair. For a
platform with six emitters and sensors, this results in 36
pairwise intensities. This allows us to not only extract
information about the transmitting robot’s orientation
relative to the receiving robot, but also allows to fur-
ther improve accuracy by taking orientation-dependent
variations in the transmitted intensity into account.
Our algorithm generalizes to other platforms by ab-
stracting the equations that vary from platform to plat-
form from the algorithm itself. Existing work in this area
tends to be hardware speciﬁc. While the large number of
discrete measurements required by our method increases
the time spent collecting data, it is also direction neutral:
with a single transmission, all robots in range can get
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 6180
range and bearing data to the transmitting robot.
II. MATHEMATICAL MODEL FOR RANGE AND
BEARING ESTIMATION
This model assumes a collection of identical, cylin-
drically symmetric robots with radius . Each robot is
equipped withn infrared emitters andn infrared sensors
evenly distributed around the perimeter of the robot.
Each robot has a well-deﬁned forward direction. Without
loss of generality, we will assume that each robot has
its own local coordinate system with origin at its center,
and x-axis aligned with the forward direction, so that
forward is identiﬁed as 0 radians for bearing. Given an
arbitrary pair of robots from this collection, we denote
the robot using its sensors and running this algorithm as
RX, and the robot using its emitters as TX.
We propose an algorithm that simultaneously com-
putes: the distance from RX to TX (denoted R); the
direction TX lies in, or bearing, with respect to RX
(denoted ); and the relative orientation, or heading, of
TX to RX (denoted). Throughout this paper, range will
mean the center to center distance between robots, and
all angles are expressed in radians. Given some vector
X (denoted with a bold symbol), the scalarX is deﬁned
askXk.
In order for a range and bearing measurement to be
successful, the two robots (RX and TX) must coordinate
a measurement event using a communication channel.
This coordination is initiated by the robot RX, who
requests R&B information from a speciﬁc robot TX.
During this time, other robots within communication
range remain silent and TX turns on its emitters in
a predeﬁned sequence. RX then takes the appropriate
measurements based on the predetermined duration and
sequence of TX’s emissions. Given that the two robots
are asynchronous this coordination is necessary. Since
the clock speed variations between robots is small com-
pared to the timing of the range and bearing process,
coordination is only needed at the beginning of a mea-
surement cycle.
The sensors’ sensitivity depends on the incoming
light’s angle of incidence, . The sensor model S()
describes this dependence. Similarly, the intensity of
emitted light is dependent on the emitted light’s de-
viation from ‘straight on’, , and this dependence is
described by the emitter modelE(). So = 0 indicates
that the emitter is directly in front of the sensor, and
 = 0 indicates that the emitter is pointing directly at
the sensor.
S() and E() will necessarily be hardware de-
pendent and are typically taken from the component
datasheet. The point-source approximation that is com-
monly used, for example, is equivalent to the constant
emitter model E() = 1. We fully characterize the

5;6

5;6
RX
^
1
^
2
^
3
^
4
^
5
^
6 

TX
^
1
^
2
^
3
^
4
^
5
^
6

R
r
5;6
Fig. 2: Figure of two robots illustrating our terms. See Table I
for symbol meanings. Note the vectorri;j , connecting sensor i
with emitter j, andR, connecting the center of the two robots.
Symbol Meaning
RX Sensing robot
TX Transmitting robot
 Robot radius
n Number of sensors/emitters on each robot
 Angle from RX to TX, in RX’s coordinate frame
 Relative orientation of RX and TX
b
i Vector to sensor/emitter i
S Sensor model
E Emitter model
A Amplitude model
R Vector from RX to TX
r
i;j
Vector from sensor i on RX to emitter j on TX

i;j
Angle from sensor i’s direction on RX to emitter j
on TX

i;j
Angle from emitter j’s direction on TX to sensor i
on RX

i;j
Light intensity received by sensor i on RX that was
emitted by emitter j on TX
 nn matrix of 
i;j
S Vector of total light received by each sensor on RX
T Vector of total light transmitted by each emitter on
TX that was received by some sensor on RX
TABLE I
sensor and emitter models for the Droplet platform in
Section IV.
Next, we consider the light attenuation with distance.
We call this the amplitude model A(r) with r the
distance between the sensor and the light source. We
assume that amplitude fall-off is independent of the
angle that the light exited the emitter, e.g., that the
light is not focused or collimated by the emitter. This
assumption permits us to treat the amplitude model as
a function of r alone. We also assume that A(r) is
monotonic and invertible over the interval (0;1). We
fully characterize the amplitude model for our platform
in Section IV.
6181
We index the sensors by i and emitters by j: i;j2
f1; 2;:::;ng . The vectorr
i;j
connects sensori to emitter
j, and 
i;j
is the angle that light enters sensor i from
emitter j. Let
b
i be a unit length vector from the center
of the RX robot to its i
th
sensor. Similarly, let
b
j be a
unit length vector from the center of the TX robot to its
j
th
emitter. Geometrically, the vector equation
r
i;j
= R 
^
i +
^
j (1)
relates the vector r
i;j
between the sensors to the global
vector linking the center of the two robots along the axis
of transmission R. The cosine dot-product identity gives
us the following relationship betweenr
i;j
, 
i;j
, 
i;j
.

i;j
= cos
 1

b
i
r
i;j
kr
i;j
k

(2)

i;j
= cos
 1

b
j
 r
i;j
kr
i;j
k

(3)
The intensity that sensori on RX perceives from emitter
j on TX is denoted
i;j
. Note that
i;j
depends entirely
on the spatial conﬁguration of the robots.

i;j
=S(
i;j
)E(
i;j
)A(r
i;j
) (4)
The 
i;j
values are stored in an n n matrix ,
which we call a ‘brightness matrix’. From here, RX now
has enough information to compute R, , and , as
we demonstrate. S is a vector of length n whose i
th
component is the total light received by sensor i from
all emitters on TX, andT is a vector of lengthn whose
j
th
component is the total amount of light received from
emitter j by all sensors on RX.
S =hS
1
;S
2
;:::;S
n
i s.t. S
i
=
n
X
j=1

i;j
(5)
T =hT
1
;T
2
;:::;T
n
i s.t. T
j
=
n
X
i=1

i;j
(6)
Note that S is the result of summing the rows of the
brightness matrix , and T is the result of summing
the columns of  (or, equivalently, summing the rows
of 
T
).
Let  = h
b
1;
b
2;:::;b ni be the vector of all
b
i. By
taking the sum over the
b
i vectors weighted by the sensor
readings S
i
, we obtain a vector  whose direction
points approximately in the direction towards TX, .
Mathematically,
 =S =
n
X
i=1
S
i
b
i (7)
 = arg() (8)
By measuring 
i;j
pairwise we can immediately
extend this formalism to the TX robot to ﬁnd the
orientation  of TX in the coordinate frame of RX. By
taking the sum over the
b
j vectors weighted by theT
j
sensor readings, we obtain a vector  pointing in the
approximate direction of RX from the coordinate frame
of TX. By using a coordinate transform back to the
coordinate frame of RX, we obtain . Using  as an
estimate of  yields an estimate  of the relative angle
of RX and TX, using only local information available to
the robot RX through its sensors. Mathematically,
 =T =
n
X
j=1
T
j
b
j (9)
 = arg() + + (10)
We now have an axis connecting the robots (axis
of transmission) and have constrained the system from
three variables (, , and R) to one: R, the distance
between RX and TX. To obtain an estimate of R, it
would sufﬁce to invert Equation 4, solving for r
i;j
for
some sensori and emitterj and use the estimates and
 to computeR. However, inverting Equation 4 requires
knowledge ofR since both 
i;j
and 
i;j
depend onR
for each i and j. This relationship is:

i;j
= tan
 1

(
b
j 
b
i) +R

  arg(
b
i) (11)

i;j
= tan
 1

(
b
i 
b
j) R

  arg(
b
j)  arg(R)
(12)
To avoid this circular logic, we make the initial assump-
tion that R!1 in order to approximate 
i;j
and 
i;j
.
Under this initial approximation,r
i;j
is parallel withR
for all i and j, and hence 
i;j
depends only on  and

i;j
depends only on  and . Speciﬁcally, for every
sensor-emitter pair i;j we initially estimate the values

i;j
and 
i;j
with

i;j
=  arg(
b
i) (13)

i;j
=  arg(
b
j)   (14)
Since only one estimate r
i;j
is needed to improve the
estimate R
0
, it sufﬁces to choose one i;j pair. While
several different pairs may work, we ﬁnd the most
reliable results are obtained from choosing the i and
j from the maximal 
i;j
. An initial estimate r
0
i;j
+ 2
then provides an upper bound for R.
r
i;j
=A
 1


i;j
S(
i;j
)E(
i;j
)

(15)
RR =r
0
i;j
+ 2 (16)
Now, having an initial estimate R, we can drop the
assumption that R!1 and use the R
0
value instead.
This allows for more accurate estimates of 
i;j
, 
i;j
using Equations 11 and 12. Using these, we can calculate
r
i;j
for each (i, j) pair:
r
i;j
=A
 1


i;j
S(
i;j
)E(
i;j
)

(17)
6182
Finally, recalling Equation 1 we can use the improved
estimates of
i;j
,
i;j
, andr
i;j
to calculate an improved
estimate of the range R for each (i, j) pair:
R =r
i;j
+
b
i 
b
j (18)
A number of techniques could be employed to pick a
single R from the set produced, but we expect them to
vary based on the idiosyncracies of individual hardware
and leave that implementation to a case-by-case basis.
In our experience with the Droplet platform, choosing
R from the maximal 
i;j
works well in practice.
III. THE DROPLET SWARM ROBOTIC PLATFORM
The Droplets are an open-source swarm robotic plat-
form, with source code and manufacturing information
available online
1
. There are n = 6 infrared emitters
and receivers located symmetrically around the circum-
ference oriented horizontally. The Droplets use an At-
mel Xmega128A3U microcontroller to interface emitters
(Kingbright APA3010F3C-GX) and sensors (Kingbright
APECV A3010P3BT IR phototransistor) and perform
R&B signal processing. Current through the infrared
LED is controlled using a digital potentiometer (Mi-
crochip Technology MCP4331-503E/ML). The output
from the infrared sensors is read using the microcon-
troller’s built-in 8-bit analog-to-digital converter. Digital
communication between Droplets is accomplished using
the same infrared emitters and the microcontroller’s
built-in serial communications peripherals (UARTs).
Output from the UART is modulated on a 38 kHz
carrier wave, which is demodulated with a dedicated
remote receiver (Vishay TSOP39438). Note that range
and bearing communication occurs using unmodulated
DC signals.
IV. MODEL CHARACTERIZATION
In the state-of-the-practice experiments such as those
presented in [16], [17], it is common to use cosine or its
square to represent the sensor model, and it is common
to assume inverse relationship with r, or exponential
decay e
 r
to represent the amplitude model. While
these approximations work fairly well, they ignore the
complexities of real, physical sensors.
We experimentally obtained to high accuracy the sen-
sor model, emitter model, and amplitude model for the
Droplet platform by using an automated system capable
of repeatably positioning and by 0:9

increments and
of adjustingR to an accuracy of 0.5 mm. The apparatus,
shown in Figure 3, consists of two Droplets attached
to stepper motors (400
steps
rev
). One of the stepper motors
is connected to a Firgelli linear actuator with built-in
encoder. The apparatus was controlled using custom
1
https://code.google.com/p/cu-droplet/
Fig. 3: The apparatus used to characterize the sensor, emitter,
amplitude, and noise models of the mathematical system for
use in simulations.
software on an Arduino module with motor shield and
stepper motor drivers. We experimentally characterized
the accuracy of this actuator and its controller in [19].
To ﬁnd the sensor model S(), we held  ﬁxed so that
an emitter on TX was pointed directly at RX, held R
ﬁxed at 13 cm, 18 cm, 23 cm, or 28 cm, and varied
 from 180

to 180

in 0:9

increments. To ﬁnd the
emitter model E() a similar process was used, with
the roles of the RX and TX Droplets interchanged, and
the roles of and interchanged. The resulting models,
obtained by ﬁtting the experimental data (see Figure 4),
are given below:
S() =
(
 
4
+ 1 ifjj< 0:6186
1
8
4
else
(19)
E() =
(
 
4
+

2
2
+ 0:9375 ifjj< 0:7205
1
4
4
else
(20)
To ﬁnd the amplitude modelA(r), we held and ﬁxed
such that an emitter on TX was aligned with a sensor on
RX and variedR from 8 cm to 30 cm in increments of 2
mm. This was repeated 36 times at each distance: once
for each emitter on TX and sensor on RX. We found
that the sensors became saturated forR< 12cm, and so
cut off smaller data points before ﬁtting. Our resulting
Amplitude Model is
A(r) =
14000
(r  3)
2
  1 (21)
with corresponding inverse
A
 1
() =
118
p
 + 1
+ 3 (22)
For closer ranges, a different amplitude model was
similarly computed, with the IR emitters on TX set
to a lower power. Figure 4 shows the experimentally
determined (a) sensor model, (b) emitter model, and
(c) amplitude model, together with the data used to
construct the models. We also used the data described
above to determine the noise model for our hardware.
We ﬁnd that after calibration, the hardware error of our
model is approximately Gaussian with  = 0.
6183
Fig. 4: Experimental derivations of the sensor model, emitter model and amplitude model. In all ﬁgures the solid line indicates
our model (eqs. 19-21). Error bars indicate one standard deviation, centered on the mean. In (a) and (b) the dashed line is
p
cos
which has been used as a stand-in in other works. In (c) we also show a thin solid line as the near-range low power amplitude
model we use to cover the range where sensors saturate. Also, a dashed line is used to demonstrate a
1
R
2
model as has been
used as stand-ins in other works.
V. EXPERIMENTAL ANALYSIS
To demonstrate our algorithm on real hardware, we
used the same apparatus as for parameter characteri-
zation, pictured in Figure 3. With this apparatus, two
Droplets were swept through a variety of orientations
and distances, with the pair making a range and bearing
measurement at each position. The results of these
measurements are shown in Figures 5–7. We are able
to compare these results to the ground truth given by
the testing apparatus, which has negligible uncertainty
compared to our measurements. In these experiments,
each set of R&B measurements took approximately
500 ms; we have veriﬁed, however, that reliable R&B
measurements can be accomplished in less than 100 ms
on the Droplet platform, giving an update rate of 10 Hz.
The number of measurements represented by each
position is approximate because the Droplet does not
always successfully collect intensity data. This is due
to occasional dropped packets in the communication
subsystem—the RX robot needs to ask the TX robot
to transmit, and if that request is unheard, range and
bearing calculation is not performed. The RX robot is
Fig. 5: Absolute error in range estimation with respect to the
actual range. Error bars represent the standard deviation. At
least 250 measurements were taken for each position.
able to identify when this occurs by noticing that the
largest intensity received is comparable to background
noise. In the implementation used for these experiments,
the Droplet will make another communication attempt
if it detects that the previous attempt failed, repeating
this for up to ﬁve attempts. After ﬁve failed attempts,
it reports that a problem occurred and the test moves
on to the next position. As this represents an error in
the communication rather than the range and bearing,
these events are not included in the data. In the rare
event that communication fails but the RX Droplet does
not notice due to particularly high background noise, a
spurious data point is generated for that position. These
data points are included in the data.
We observe a near constant range error at distances
close to the robot, and the range error is always bound
within 1 robot diameter. The error does not seem to
change signiﬁcantly with distance up to the 4.5 robot
diameters that we checked. We were able to use our
algorithm down to inter-robot distances of one robot
radius, which is much smaller than other related works.
Although the relative error is high for distances shorter
than this, we hypothesize that this could be compensated
by running the emitter/receivers in reﬂective distance
sensor mode, which allows for millimeter accuracy in
comparable robots [10], [11].
Fig. 6: Absolute error in bearing estimation with respect to
the actual bearing. Error bars indicate one standard deviation.
Around 150 measurements are represented at each position.
6184
Fig. 7: Absolute error in heading estimation with respect to
the actual heading. Error bars indicate one standard deviation.
Around 125 measurements are represented at each position.
The error shown in Figure 6 for the bearing estimation
seems to be uniformly below 0

, however we attribute
this to the asymmetric real sensor values shown in
Figure 4(a). It is possible that the sensors may have
some asymmetry in their sensitivity and our model does
not account for this. The error shown in Figure 7 for
the heading estimation is somewhat larger, however this
calculation (Equation 9) also includes , therefore any
error in  is contributed to the error in . This error
exhibits periodicity consistent with the 6 sensor/emitter
pairs on the Droplets, as the two robots rotate in and out
of alignment with one another.
VI. CONCLUSIONS & FUTURE WORK
We present a range and bearing system for low-
cost, miniature robotic platforms. We develop a math-
ematical model that allows us to take variations in
the emitter angle into account. We then demonstrate a
practical algorithmic implementation of this framework
on the Droplet swarm robotics platform. Though com-
putationally more complex than existing state-of-the-
art algorithms, carefully modeling emitter and receiver
characteristics should increase the robustness and accu-
racy for platforms with a small number of sensors and
especially for small distances. Further, our approach is
able to calculate the orientation of the transmitting robot
directly.
Though our theoretical framework is able to capture
the particular characteristics of sensor/emitter pairs, we
do use the simplifying assumption that the sensor and
emitter models are consistent across different sensors
and emitters, which tends not to be the case. We plan
in future work to capture the sensor variation, perhaps
with an auto-calibration step on robot initialization.
ACKNOWLEDGMENTS
This work has been supported by NSF awards
#1153158, #1150223 and a CI fellowship to D. Reishus.
REFERENCES
[1] N. Correll and A. Martinoli, “Modeling and designing self-
organized aggregation in a swarm of miniature robots,” The
International Journal of Robotics Research, vol. 30, no. 5,
pp. 615–626, 2011.
[2] J. McLurkin and J. Smith, “Distributed algorithms for dispersion
in indoor environments using a swarm of autonomous mobile
robots,” Distributed Autonomous Robotic Systems 6, pp. 399–
408, 2007.
[3] L. Liu, B. Fine, D. Shell, and A. Klappenecker, “Approximate
characterization of multi-robot swarm “shapes” in sublinear-
time,” in Robotics and Automation (ICRA), IEEE Int. Conf. on,
pp. 2886–2891, IEEE, 2011.
[4] I. Navarro and F. Mat´ ıa, “Distributed orientation agreement in a
group of robots,” Autonomous Robots, pp. 1–21, 2012.
[5] F. Ducatelle, G. A. Di Caro, C. Pinciroli, F. Mondada, and L. M.
Gambardella, “Communication assisted navigation in robotic
swarms: self-organization and cooperation,” in Intelligent Robots
and Systems (IROS), IEEE/RSJ Int. Conf. on, pp. 4981–4988,
IEEE, 2011.
[6]
´
A. Guti´ errez, A. Campo, F. Monasterio-Huelin, L. Magdalena,
and M. Dorigo, “Collective decision-making based on social
odometry,” Neural Computing and Applications, vol. 19, no. 6,
pp. 807–823, 2010.
[7] J. Pugh and A. Martinoli, “Relative localization and communi-
cation module for small-scale multi-robot systems,” in Robotics
and Automation, 2006. ICRA 2006. Proceedings 2006 IEEE
International Conference on, pp. 188–193, IEEE, 2006.
[8] N. B. Priyantha, A. Chakraborty, and H. Balakrishnan, “The
cricket location-support system,” in Proceedings of the 6th
annual international conference on Mobile computing and net-
working, pp. 32–43, ACM, 2000.
[9] A. Prorok, P. Tom´ e, and A. Martinoli, “Accommodation of nlos
for ultra-wideband tdoa localization in single-and multi-robot
systems,” in Indoor Positioning and Indoor Navigation (IPIN),
2011 International Conference on, pp. 1–9, IEEE, 2011.
[10] G. Caprari and R. Siegwart, “Mobile micro-robots ready to use:
Alice,” in Intelligent Robots and Systems, 2005.(IROS 2005).
2005 IEEE/RSJ International Conference on, pp. 3295–3300,
IEEE, 2005.
[11] S. Kornienko, O. Kornienko, and P. Levi, “Minimalistic approach
towards communication and perception in microrobotic swarms,”
in Intelligent Robots and Systems (IROS), IEEE/RSJ Int. Conf.
on, pp. 2228–2234, IEEE, 2005.
[12] M. Rubenstein, C. Ahler, and R. Nagpal, “Kilobot: A low cost
scalable robot system for collective behaviors,” in Robotics and
Automation (ICRA), IEEE Int. Conf. on, pp. 3293–3298, IEEE,
2012.
[13] R. Nagpal, H. Shrobe, and J. Bachrach, “Organizing a global
coordinate system from local information on an ad hoc sen-
sor network,” in Information Processing in Sensor Networks,
pp. 333–348, Springer, 2003.
[14] A. Cornejo, A. J. Lynch, E. Fudge, S. Bilstein, M. Khabbazian,
and J. McLurkin, “Scale-free coordinates for multi-robot sys-
tems with bearing-only sensors,” in Algorithmic Foundations of
Robotics X, pp. 397–414, Springer, 2013.
[15] I. Kelly and A. Martinoli, “A scalable, on-board localisation
and communication system for indoor multi-robot experiments,”
Sensor Review, vol. 24, no. 2, pp. 167–180, 2004.
[16] J. Pugh, X. Raemy, C. Favre, R. Falconi, and A. Martinoli, “A
fast onboard relative positioning module for multirobot systems,”
Mechatronics, IEEE/ASME Transactions on, vol. 14, no. 2,
pp. 151–162, 2009.
[17] A. Guti´ errez, A. Campo, M. Dorigo, J. Donate, F. Monasterio-
Huelin, and L. Magdalena, “Open e-puck range & bearing
miniaturized board for local communication in swarm robotics,”
in Robotics and Automation, 2009. ICRA’09. IEEE International
Conference on, pp. 3111–3116, IEEE, 2009.
[18] S. Gowal, A. Prorok, and A. Martinoli, “Two-phase online
calibration for infrared-based inter-robot positioning modules,”
in Intelligent Robots and Systems (IROS), 2011 IEEE/RSJ Inter-
national Conference on, pp. 3313–3319, IEEE, 2011.
[19] E. Komendera, D. Reishus, J. T. Dorsey, W. R. Doggett, and
N. Correll, “Precise truss assembly using commodity parts and
low precision welding,” in IEEE Int. Conf. on Technologies for
Practical Robot Applications, April 2013.
6185
