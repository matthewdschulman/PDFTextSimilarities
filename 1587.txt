Persistent Monitoring of Events with Stochastic Arrivals
at Multiple Stations
Jingjin Yu
1,2
Sertac Karaman
3
Daniela Rus
1
Abstract—This paper is concerned with a novel mobile sensor
scheduling problem, involving a single robot tasked with moni-
toring several events of interest that occur at different locations.
Of particular interest is the monitoring of events that can
not be easily forecast. Prominent examples range from natural
phenomena (e.g., monitoring abnormal seismic activity around a
volcano using a ground robot) to urban activities (e.g., monitoring
early formations of trafﬁc congestion in the Boston area using
an aerial robot). Motivated by these examples, this paper focuses
on problems where the precise occurrence time of the events
is not known a priori, but some statistics for their inter-arrival
times are available from past observations. The robot’s task is to
monitor the events to optimize the following two objectives: (i)
maximize the number of events observed and (ii) minimize the
delay between two consecutive observations of events occurring
at the same location. Provided with only one robot, it is crucial
to optimize these objectives in a balanced way, so that they are
optimized at each station simultaneously. Our main theoretical
result is that this complex mobile sensor scheduling problem
can be reduced to a quasi-convex program, which can be solved
in polynomial time. In other words, a globally optimal solution
can be computed in time that is polynomial in the number
of locations. We also provide computational experiments that
validate our theoretical results.
I. INTRODUCTION
Consider a single robotic vehicle that is tasked with mon-
itoring events that occur at several locations. Unfortunately,
the precise occurrence time of an event is unknown to the
robot a priori. Hence, the robot must travel to the particular
location and wait for the event to occur, in order to monitor
the event and capture the data associated with it. Ideally, one
would like to monitor all events at all locations. However,
provided with a single robot, one must optimize the schedule
of the robot to ensure that all locations are observed equally
well as best as possible, i.e., in a balanced manner. Two major
objectives are to (i) ensure that a large number of events are
observedateachlocationand(ii)ensurethatthedelaybetween
two observationsof events at any given location is minimized.
Optimizing these objectives in a balanced manner is a fairly
complex, multi-objective scheduling problem.
The problem setup we study in this paper is novel, and
it is applicable to a broad set of applications concerning
persistent data collection through monitoring a set of events
1
Jingjin Yu and Deniela Rus are with the Computer Science and Artiﬁcial
Intelligence Lab, Massachusetts Institute of Technology. E-mails: {jingjin,
rus}@csail.mit.edu.
2
Jingjin Yu is also with the Mechanical Engineering Department at Boston
University.
3
Sertac Karaman is with the Department of Aeronautics and Astronautics,
Massachusetts Institute of Technology. E-mail: sertac@mit.edu.
This work was supported in part by ONR projects N00014-12-1-1000 and
N00014-09-1-1051.
(a)
¿
i,j
¸
i
¸
j
i
j
(b)
Fig. 1. (a) One of many potential applications of our persistent monitoring
formulation, in which an UAV (robot) is given the task of continuously
gathering stochastically occurring (data) events at a set of ﬁxed locations
(the surface areas under the colored cones). The sizes of the colored discs
represent the stochastic arrival rates of events at the locations. (b) Illustration
of the underlying geometric problem setting. At each point of interest, say
location (station) i, events arrive following a Poisson process with intensity
?
i
. It takes a robot ?
i,j
time to move from station i to station j, during
which no observation can be made. The associated plots roughly capture the
(exponential) distributions of event arrivals associated with the stations.
at various locations. The events of interest include natural
phenomena (e.g., volcanic eruptions and early formations of
blizzards, hailstorms, and tsunamis), biological disasters (e.g.,
early formations of epidemic diseases on animal or plant
populations), as well as military operations (e.g., terrorist
attacks).The key commoncharacteristic ofthese eventsis that
their precise time of occurrence can not be easily forecast,
although the statistics regarding how often they occur may
be available from past experience. Hence, the data-collecting
robot must wait at the location of interest to capture the event
onceitoccurs.Then,thefundamentalschedulingproblemisto
decidehow muchtime the robotshouldspendin eachlocation
to archive various objectives, such as those described above,
in a balanced way. Our main theoretical result is that this
complex multi-objective mobile sensor scheduling problem
canbereducedtoastrictlyquasi-convexoptimizationproblem
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 5758
that can be solved in polynomial time. Hence, the (unique)
globally optimal solution of this complex scheduling problem
can be computed in time that is polynomial in the number of
locations.
Broadly speaking, persistent monitoring problems appear
naturally whenever only limited resources are available for
serving a set of spatially-dispersed tasks. Motivated by a
variety of potential applications [1], [2], several authors have
studied persistent monitoringproblems [3]–[11].For example,
in [3],theauthorsconsidera certainweightedlatencymeasure
as a robot continuously traverse a graph, in which the vertices
represent the regions of interest and the edges between the
vertices are labeled with the travel time. They show that
the problem of minimizing the maximum latency across
all stations is computationally intractable, and they present
an approximation algorithm. In [5], the authors consider a
persistent monitoring problem for a group of agents in a
one-dimensional mission space. They show that this problem
can be solved by parametrically optimizing a sequence of
switching locations for the agents. The problem of generating
speed proﬁles for robots along predetermined closed paths
for keeping bounded a varying ﬁeld is addressed in [10].
The authors characterize appropriate policies for both single
and multiple robots. In [11], decentralizedadaptivecontrollers
were designed to morph the initial closed paths of robots to
focus on regions of high importance.
In contrast to all the references cited above, the problem
studied in this paper focuses on transient events, emphasizing
unknownarrival times (but knownstatistics). The event arrival
times being unknown forces the robot to wait at each station
in order to observe the events of interest.
Persistent surveillance problems are intimately linked with
coverageproblems.Coverageof a two-dimensionalregionhas
been extensively studied in robotics [12]–[14], as well as in
purely geometric settings, for example, in [15], where the
proposed algorithms compute the shortest closed routes for
continuous coverage of polygonal interiors under an inﬁnite
visibility sensing model. Coverage with limited sensing range
was also addressed later [16], [17]. If the environment to be
monitoredhas a 1-dimensionalstructure,discrete optimization
problems,suchas theTravelingSalesmanProblem,oftenarise
[3]. In most coverage problems, including those cited above,
the objective is to place sensors in order to maximize, for
example, the area that is within their sensing region. The
persistent surveillance problem we study in this paper is a
special case,wherethelimited numberofsensors donotallow
extensive coverage; hence, we resort to mobility in order to
optimize the aforementioned performance metrics.
Persistent monitoring problems are also related to (static)
sensor scheduling problems (see, e.g., [18]–[20]), which are
usually concerned with scheduling the activation times of
sensors in orderto maximizethe informationcollectedabouta
time-varyingprocess.Theproblemconsideredinthispaperin-
volves a mobile sensor that can travel to each of the locations,
wherethe additionaltime requiredtotravelbetweenstations is
non-zero. The mobile sensor scheduling literature is also rich.
For instance, in [21],the authors study the control of a robotic
vehicle in order to maximize data rate while collecting data
stochastically arriving at two locations. The problem studied
in this paper is a novel mobile sensor scheduling problem
involving several locations and a multi-objective performance
metric that includes both the data rate and the delay between
consecutive observations.
The main contributions of this paper are two-fold. First, we
proposeanovelpersistentmonitoringanddatacollectionprob-
lem, with the unique feature that the precise arrival times of
events are unknown a priori, but their statistics are available.
Modeling the arrival of events as a stochastic process allows
our formulation to encompass several practical applications,
where the precise occurrence times of the events of interest
cannotforecasteasily.Second,focusingoncyclicpolicies,we
establishthatthisfairlycomplexmulti-objectivemobilesensor
schedulingproblemadmitsagloballyoptimalsolutionthatcan
becomputedefﬁcientlyinpolynomialtime.Surprisingly,itcan
be shown that the main objective is quasi-convex on its entire
domain, which greatly simpliﬁes the computation for ﬁnding
the extremal values.
The rest of the paper is organized as follows. A precise
deﬁnition of our persistent monitoring problem is provided in
Section II. We then carry out the analysis and present our
main result in detail in Section III, followed by experimental
validationthroughsimulationin SectionIV.We concludewith
Section V.
II. PROBLEM STATEMENT
Before formulating the problem, for convenience, we list
severalfrequentlyused symbols andtheir meaningsin Table I.
When in doubt, the reader is referred to this table.
We study the problem of using a single robot to monitor
events that occur at different stations. The robot can monitor
one station at a time. It can travel from one station to another
if the two stations are topologically connected. The precise
time that an event will occur is not known to the robot a
priori. However, the robot is provided with their statistics, for
examplethe inter-arrivaltimes, for each station. The robot can
observeaneventgeneratedbyastationifandonlyifitisatthe
same station at the time of occurrence,in which case the robot
collectsvaluabledataregardingthatparticularstation.Roughly
speaking,our objectiveis to designa schedulingpolicyforthe
robot to ensure that:
• Objective.(i) maximize the number of events that is
observed at each station in a balanced way;
• Objective.(ii) minimize the delay between consecutive
observations at a particular station for all stations.
Below, this problem is formulated as a multi-objectiveopti-
mization problem. In Section III, it is shown that an important
special case, involving a chain of stations, can be reduced to
a quasi-convex program that can be solved efﬁciently. Hence,
the running time of the algorithm that solves this special case
is polynomial in the number of stations.
A more formal description of the problem is the following.
Consider a network of n stations, represented by a connected
5759
TABLE I
LIST OF FREQUENTLY USED SYMBOLS AND THEIR INTERPRETATIONS.
v
i
,k
i
Stations to be monitored
?
i
Intensity of the Poisson process at station i
?
i,j
Travel time from station i to station j
π Cyclic policy of the form ((k
1
,t
1
),...,
(k
n
,t
n
)), in which t
i
is the time spent by the
robot at station i in one policy cycle
T Total time incurred by a policy cycle
T
tr
Total travel time per policy cycle
T
obs
T ?T
tr
, total observation time per policy cycle
N
i
(π) The number of events collected at station i in
one period of the policy π
T
i
(π) The time between two consecutive event ob-
servations at station i containing travel to
other stations, for the policy π
? argmax
π
max
i
?
i
(π)
p(X) Probability density of a random variable X
Pr(e) Probability of an event e
E[X] Expected value of a random variable X
?
i
(π) E[N
i
(π)]/∑
n
j=1
E[N
j
(π)]
graph G=(V,E), where V = {v
1
,v
2
,...,v
n
} is the set of
vertices and E is the set of (directed) edges. If there exists
an edge (v
i
,v
j
)?E between vertices v
i
and v
j
, then stations
i and j are connected, meaning that the robot can travel from
station i to station j directly. The time it takes the robot to
travel from station i to station j is denoted by ?
i,j
.
Station i generates events at random time instances. More
precisely, we model the arrival of events at station i with a
Poisson process of intensity ?
i
. These statistics, that is, the
arrival processes being Poisson and their intensities being ?
i
,
are all knownto the robota priori, althoughthe precise arrival
times are not known beforehand.
A problem instance is fully characterized by the following
parameters: (i) the graph, G=(V,E), that represents the
network of stations; (ii) the travel time, ?
i,j
, from station i
and j for all i,j with (v
i
,v
j
)?E; (iii) the arrival rates of the
events, ?
i
, for each station i. Given such a problem instance,
we would like to design a routing policy for the robot to visit
each station and spend a certain amount of time, in order to
collect data through observing events so as to optimize the
objectivefunction,which we roughlydescribedabove.Precise
deﬁnitions of these objectives will follow shortly.
A cyclic policy is one that the robot visits each station in a
ﬁxed order and spends a ﬁxed amount of time at each station.
More precisely, a cyclic policy is fully characterizedby: (i) an
ordering of stations, say k
1
,k
2
,...,k
n
, where k
i
?{1,2,...,n}
and k
i
=k
j
for all i,j, and (ii) the time spent at each station,
say t
i
time units at station i. Such a cyclic policy is executed
by ﬁrst visiting station k
1
to spend t
1
time units, then visiting
station k
2
to spend t
2
time units, then visiting station k
3
to
spend t
3
time units, and so on. A cyclic policy, which we
denotebyπ,canberepresentedbytheparameterslistedabove,
as in π =

(k
1
,t
1
),(k
2
,t
2
),...,(k
n
,t
n
)

. Throughout the paper,
we consider only cyclic policies.
Given a cyclic policy π =

(k
1
,t
1
),(k
2
,t
2
),...,(k
n
,t
n
)

,we
deﬁne the aforementioned two objectives as follows. Let
N
i
(π) denote the number of events that are observed at
station i during one cycle. Deﬁne the fraction of events
observed at station i as ?
i
(π) :=E[N
i
(π)]/E[∑
n
j=1
N
j
(π)] =
E[N
i
(π)]/∑
n
j=1
E[N
j
(π)]. To formalize the ﬁrst objective, we
consider selecting a policy π that maximizes the minimum
fraction of events, where the minimum is taken across all
stations, i.e.,
max
π
min
i
?
i
(π)=max
π
min
i
E[N
i
(π)]
∑
n
j=1
E[N
j
(π)]
. (1)
This objective function maximizes the fraction of events
observed at each station.
1
It does so in a balanced manner,
maximizing the minimum ?
i
across all stations.
We formalize the second objective as follows. Suppose the
cyclic policy is run until time t
start
such that (i) at least one
event is observed at each station up until time t
start
and (ii)
the robot is at the beginning of a new cycle at time t
start
.
For each station i, deﬁne T
i
(π) as the time between the
followingtwoobservations:(i)thelasteventthatwas recorded
at stationi beforet
start
and(ii) theﬁrst eventthatis recordedat
station i after t
start
. In essence, T
i
(π) is the delay between two
consecutive observations that fall into different observation
windows, at station i. Our objective is to minimize these
delays, again in a balanced manner across all stations. Hence,
we consider choosing a policy that minimizes the maximum
delay across all stations, i.e.,
min
π
max
i
E[T
i
(π)]. (2)
In most cases, both objectives are equally important. One
would like to maximize both the fraction of observations and
minimizedelaysbetweenobservations,insomebalancedman-
ner across stations. Interestingly, the set of policies that opti-
mizetheﬁrst objectivefunctionisnotunique;infact,thereare
inﬁnitely many such cyclic policies. We compute the optimal
(cyclic) policy for the second objective function among those
policies that optimize the ﬁrst objective function. That is, we
compute the (unique) policy π
?
=argmin
π??
max
i
E[T
i
(π)],
where ?:=argmax
π
min
i
?
i
(π

). Below, we prove that ? is
an uncountablyinﬁnite set of cyclic policies andπ
?
is unique.
III. THE OPTIMAL SCHEDULING ALGORITHM
AND ITS ANALYSIS
In this section, we provide a cyclic routing policy (al-
gorithm) that solves the problem described in the previous
section. We prove that the proposed policy is optimal. First,
weshow(viaLemma1)thatforanyﬁxedtime periodT, there
1
Ideally, we would like to deﬁne the notion of expected fraction of events
observed at station i as follows: E[N
i
(π)/∑
n
j=1
N
j
(π)]. However, the random
variable N
i
(π)/∑
n
j=1
N
j
(π) is not well deﬁned, as its denominator may be
zero. Instead, we use the well-deﬁned expression E[N
i
(π)]/∑
n
j=1
E[N
j
(π)].
5760
is a unique cyclic policy π that optimizes the ﬁrst objective
(Equation (1)). However, the optimal policies for different
T’s assign the same value to Equation (1), giving rise to
a continuum of solutions for the ﬁrst objective. This issue
is resolved by our main theorem (Theorem 2), which shows
that there is a unique T that optimizes the second objective
(Equation (2)).
Throughout this section, we consider an important special
case where the locations are connected in a “closed chain”
conﬁguration. That is, we consider the network of locations
represented by the graph G=(V,E) where the vertex set is
V ={v
1
,v
2
,...,v
n
} and the edge set E is such that (v
i
,v
i+1
)?
E for all i?{1,2,...,n?1} and that (v
n
,v
1
)?E. In this case,
the locations form a closed chain, hence the robot must visit
the locations in a ﬁxed order. Our main result (Theorem 2)
applies to this important case. We conjecture an important
generalization of our result in Section V.
Letusconsidertheﬁrstobjectivefunctiononlyandmomen-
tarilyignorethesecondobjectivefunction.Then,thefollowing
lemma characterizes the set of all policies that optimize the
ﬁrst objective function, which was given by Equation (1).
Since we consider only cyclic policies, the travel time T
tr
for
the robot per cyclic period is ﬁxed:
T
tr
=
∑
i,j
?
i,j
1≤i≤n, j=(i+1) modn. (3)
Fornotationalconvenience,wedeﬁne?
i
:=1/(?
i∑
n
j=1
(1/?
j
)).
Lemma 1 Among all cyclic policies, a cyclic policy π =
((k
1
,t
1
),...,(k
n
,t
n
)) optimizes the ﬁrst objective function, i.e.,
π ?argmax
π

min
i
E[N
i
(π

)]
∑
n
j=1
E[N
j
(π

)]
if and only if
t
i
=?
i
(T ?T
tr
), (4)
where T = ∑
n
i=1
t
i
+T
tr
is a parameter (the cyclic policy’s
period). For T >T
tr
, the resulting cyclic policy optimizes the
ﬁrst objective. Moreover, such a cyclic policy π satisﬁes:
E[N
1
(π)] = E[N
2
(π)] = ··· = E[N
n
(π)]. (5)
PROOF. Since we are looking at cyclic policies, by linearity
of expectations, the value of the ﬁrst objective, as deﬁned in
Equation (1), remains the same if we only look at a single
policy cycle (versus looking at an inﬁnite time horizon). We
show that for arbitrary T > T
tr
, choosing t
i
’s according to
Equation (4) yields the same optimal value for Equation (1).
Now ﬁxing a policy π, after spending t
i
time at station i, the
robot collects E[N
i
(π)]=?
i
t
i
data points in expectation. This
yields
?
i
(π)=
E[N
i
(π)]
∑
n
j=1
E[N
j
(π)]
=
?
i
t
i
∑
n
j=1
?
j
t
j
.
It is straightforward to see that min
i
?
i
(π) is maximized if
and only if Equation (5) is satisﬁed, yielding a value of 1/n
for Equation (1). Solving the equations ?
1
t
1
=... =?
n
t
n
and
∑
n
i=1
t
i
=T ?T
tr
together then yields Equation (4). 
Lemma1has two importantimplications.Firstly,anycyclic
policy that equalizes the expected number of events observed
at each station optimizes the ﬁrst objective function given
by Equation (1). This provides us with an uncountably in-
ﬁnite set of optimal policies (optimal for the ﬁrst objective
function only), which is the second immediate implication of
the lemma. Any cyclic policy that satisﬁes Equation (4) is
optimal, independently of the value of T. Let us emphasize
that Lemma 1 is particularly important since it characterizes
the set of policies that optimize the ﬁrst objective function
givenbyEquation(1). Next,we showthat,amongthosecyclic
policiesthat optimizethe ﬁrst objectivefunction,thereexists a
unique cyclic policy that optimizes the second objective (see
Equation (2)). Moreover, this unique optimal policy can be
computed by solving a quasi-convex optimization problem,
which can be done efﬁciently in polynomial time.
Theorem 2 Let ? denote the (uncountably inﬁnite) set of
cyclic policies that maximizes the ﬁrst objective functiongiven
by Equation (1), i.e.,
? := argmax
π
min
i
?
i
(π). (6)
Then, there exists a unique cyclic policy in ? that minimizes
the second objective function given by Equation (2). This
policy is in the form given by Equation (4), i.e.,
t
?
i
=?
i
(T
?
?T
tr
) for all i, (7)
where
T
?
:=argmin
T>T
tr
max
i

2
?
i
+
(T ?t
i
)(1+e
??
i
t
i
)
1?e
??
i
t
i

, (8)
which is a quasi-convex optimization problem, i.e., the ob-
jective function is quasi-convex in T. Hence, the optimal
policy that solves the problem described in Section II can be
computed efﬁciently in polynomial time.
To prove Theorem 2, we must ﬁrst computeE[T
i
(π)]. This
computation is addressed in Lemma 3.
Lemma 3 Letπ=((k
1
,t
1
),...,(k
n
,t
n
)) be a cyclic policyand
let T =T
tr
+∑
n
i=1
t
i
be the period of the cyclic policy. Then
E[T
i
(π)]=
2
?
i
+
T ?t
i
?t
i
e
??
i
t
i
1?e
??
i
t
i
. (9)
PROOF. TocomputeE[T
i
(π)],withoutloss ofgenerality,ﬁx an
observationwindowat station i andcall it observationwindow
0, or o
0
. We further assume that o
0
contains the arrival of at
least one event.We lookat all observationgapson the right of
o
0
. Any observation gap g
j
contains the following parts, from
left to right: 1. t
left
j
, the overlap of g
j
with the observation
window on g
j
’s left end, 2. T ?t
i
, the ﬁrst observation break
(an observationbreakfor station i is the time windowbetween
two consecutive visits to station i), 3. 0 ≤ m<∞ additional
5761
policycycles (oflengthT each),and 4.t
right
j
, the overlapof g
j
withtheobservationwindowong
j
’s rightend.As anexample,
in Figure 2, the start and end of the observation gap g
j
are
marked with the two red lines, respectively. The parts t
left
j
,
the ﬁrst observationbreak T?t
i
, andt
right
j
are also as marked.
The gap g
j
further contains two additional policy cycles, i.e.,
m = 2. In this case, we say that g
j
spans m+1 = 3 policy
cycles.
i
t
T - t
t
left
j
t
right
j
T
Fig. 2. Illustration of the components of an observation gap.
To computeE[T
i
(π)], we split it into two steps: 1. compute
the probability p
m
of a gap g
j
spanning m+1 policy cycles
for any m≥0, and 2. computeE[T
i
(π)] as
E[T
i
(π)]=
∞
∑
m=0
E
m
p
m
, (10)
in whichE
m
is the expectedlength of a gapg
j
spanningm+1
policy cycles. Note that Equation (10) holds as long as the
expectations E[T
i
(π)] and E
m
are computed with the same
underlying distribution. We can computeE
m
with
E
m
=E[t
left
j
]+E[t
right
j
]+T ?t
i
+mT2E[t
left
j
]+T ?t
i
+mT.
The second equality holds becauseE[t
left
j
]=E[t
right
j
] by sym-
metry (i.e., a time reversed Poisson process is again a Poisson
process with the same arrival rate). To compute p
m
, note that
we never need to consider the left side of a gap g
j
. This is
true because as we look at an inﬁnite sequence of consecutive
gaps g
1
,...,g
j
,..., by assumption the left most observation
window (which is o
0
) overlapping with g
1
is already ﬁxed.
Once the right most observation window overlapping with g
1
is set (with certain probability), this explicitly ﬁxes the left
most observationwindowoverlappingwith g
2
and recursively,
the left most observation window overlapping g
j
. Therefore,
the probability of g
j
spanning m+1 policy cycles is
p
m
=e
?m?
i
t
i
(1?e
??
i
t
i
).
The ﬁrst term in the expression for p
m
, e
?m?
i
t
i
, is the
probabilitythatg
j
doesnotstopat0,1,...,m?1policycycles,
wherethe probabilityof noeventhappeningin eachadditional
cycle in the sequence is e
??
i
t
i
. They can be combined due to
the memoryless property of the exponential distribution. The
secondterm(1?e
??
i
t
i
)istheprobabilitythatatleastoneevent
happens in the right most observation window overlappingg
j
.
Noting that the terms 2E[t
left
j
]+T ?t
i
appear in all E
m
’s, we
can rewriteE[T
i
(π)] as
E[T
i
(π)]=2E[t
left
j
]+T ?t
i
+
∞
∑
m=1
mTe
?m?
i
t
i
(1?e
??
i
t
i
)
(11)
in which
∞
∑
m=0
mTe
?m?
i
t
i
(1?e
??
i
t
i
)=T(1?e
??
i
t
i
)
∞
∑
m=1
∞
∑
k=m
e
?k?
i
t
i
=T(1?e
??
i
t
i
)
∞
∑
m=1
e
?m?
i
t
i
1?e
??
i
t
i
=
Te
??
i
t
i
1?e
??
i
t
i
.
(12)
The computation of E[t
left
j
] is carried out as follows. By
assumption, at least one event happens during the given
observation window of length t
i
. Let the number of events
withinthist
i
timeben(theprobabilityofwhichisPr(n,?
i
t
i
)=
(?
i
t
i
)
n
e
??
i
t
i
/n!) and let ?
1
be the arrival time of the ﬁrst
event among these n events. For each n≥1, the distribution
of the n events is a uniform distribution in [0,t
i
].Wehave
Pr(?
1
>t)
0≤t≤t
i
=((t
i
?t)/(t
i
))
n
, which gives us the pdf
p(?
1
=t)
0≤t≤t
i
=
n(t
i
?t)
n?1
t
n
i
. (13)
Equation (13) gives us E[?
1
]=t
i
/(n+1). Then
E[t
left
j
]=
∞
∑
k=1
t
i
k+1
Pr(k,?
i
t
i
)
1?Pr(0,?
i
t
i
)
=
1
1?e
??
i
t
i
∞
∑
k=1
t
i
(?
i
t
i
)
k
e
??
i
t
i
(k+1)!
=
1
?
i
(1?e
??
i
t
i
)
(1?e
??
i
t
i
??
i
t
i
e
??
i
t
i
)=
1
?
i
?
t
i
e
??
i
t
i
1?e
??
i
t
i
.
(14)
Finally, plugging Equations (12) and (14) into Equation (11)
yields Equation (9). 
PROOF OF THEOREM 2. We now prove the quasi-convexity
of of E[T
i
(π)]. For notational convenience, deﬁne ?
i
:=?/?
i
.
Note that we implicitly use the fact that all functions used
in the proof are continuous. Substituting T
obs
= T ?T
tr
and
t
i
=?
i
T
obs
into the RHS of Equation (9) yields
E[T
i
(π)]=
2
?
i
+
T ?t
i
?(T ?t
i
)e
??
i
t
i
+(T ?2t
i
)e
??
i
t
i
1?e
??
i
t
i
=
2
?
i
+
T ?t
i
?t
i
e
??
i
t
i
1?e
??
i
t
i
=
2
?
i
+
T
obs
+T
tr
??
i
T
obs
??
i
T
obs
e
??
i
?
i
T
obs
1?e
??
i
?
i
T
obs
.
(15)
Noting that by scaling the unit of time, we may assume that
?
i
=1. Using this and letting x:=?
i
T
obs
gives us
E[T
i
(π)]=2+
T
tr
+(
1
?
i
?1)x?xe
?x
1?e
?x
=2+
T
tr
+(
1
?
i
?2)x
1?e
?x
+x,
(16)
in which T
tr
>0 and ?
i
?(0,1). For convenience, we let ? :=
T
tr
and ? =1/?
i
?2. Showing thatE[T
i
(π)] is quasi-convex is
equivalent to showing that
f(x):=x+(?+?x)/(1?e
?x
)
is quasi-convex for x > 0,
2
? > 0, and ? > ?1, the second
2
In the rest of the proof, the domain of x is assumed to be (0,∞).
5762
derivative of which is
f

(x)=
e
x
(?(e
x
+1)+?(e
x
(x?2)+x+2))
(?1+e
x
)
3
. (17)
Since e
x
(x?2)+x+2 is strictly positive,
3
f

(x) > 0 for
? ≥ 0. Therefore, f(x) is convex for ? ≥ 0. We are left to
show that f(x) is quasi-convex for ? ? (?1,0). We proceed
by ﬁrst establishing some properties of the function
g(x)=?(e
x
+1)+?(e
x
(x?2)+x+2) (18)
for ? > 0, and ? ? (?1,0).Wehave g(x) ?C
∞
for x ≥ 0,
g(0)=2? >0, lim
x?∞
g(x)=?∞,
g

(x)=(?+?x??)e
x
+?
and
g

(x)=(?+?x)e
x
.
Because (? +?x) is linear, monotonically decreasing and
crosses zero at most once, and e
x
is positive and strictly
increasing, g

(x) has at most a single local extrema (a
maxima) before it crosses zero. Therefore, g

(x) has at most
two zeros and must ﬁrst increase monotonically and then
decrease monotonically, implying that g(x) has at most three
zeros. Since g(0) > 0 and lim
x?∞
g(x)= ?∞ < 0, g(x) has
either one or three (but not two) zeros. For g(x) to have three
zeros, g

(x) must have two zeros. Since lim
x?∞
g

(x)= ?∞
(because ?xe
x
eventually dominates and ? < 0), we must
have g

(0) < 0. This is not possible because g

(0)=? > 0.
Therefore, g

(x) can cross zero and change sign at most
once, implying that g(x) has a single zero. That is, g(x) is
positive for small x and then remains negative after crossing
zero. Because f

(x)=(e
x
g(x))/(?1+e
x
)
3
and e
x
/(?1+e
x
)
3
is strictly positive, f

(x) behaves similarly as g(x) (i.e.,
f

(0) > 0, crosses zero only once as x increases, and stays
negativeafterthat).Thisimplies thatforeveryﬁxed? >0and
? ? (?1,0), there exists x
0
> 0 such that f(x) is convex on
x?(0,x
0
) and concave on x?(x
0
,∞). Now because f(x)?∞
for both x ? 0
+
and x ?∞, and f(1)<∞, f(x) must have
a single local minima (and therefore, a single global minima
on R
+
). To see that this is the case, as f(x) turns from
convexto concave at x=x
0
, we must have f

(x
0
)≥0 because
otherwise f

(x) < 0 for x > x
0
due to f(x)’s concavity. We
then have lim
x?∞
f(x) <∞, a contradiction. Thus, f(x) has
a single minimum on x ? (0,x
0
). Finally, to see that f(x)
is quasi-convex, we note that lim
x?∞
f

(x)= 1 +? > 0,
implying that f

(x) >0onall x ? (x
0
,∞). We then have
that f(x) is monotonically increasing on x ? (x
0
,∞). From
here, the quasi-convexity of f(x) can be easily established
following deﬁnitions. 
Interestingly, one can further show E[T
i
(π)]’s monotonic
dependencywith respect to?
i
, holdingother parameters ﬁxed.
3
To see this, let h(x)= e
x
(x?2)+x+2; then h(0)= 0, h

(0)= 0, and
h

(x)=xe
x
>0 for all x>0. Therefore, h

(x)>0 and h(x)>0 for all x>0.
Proposition 4 For ﬁxed ?, policy period T, and policy π
given by Equation (4), E[T
i
(π)] increases monotonically as
?
i
increases.
PROOF. PluggingT
obs
:=T?T
tr
and? :=1/(∑
n
i=1
(1/?
i
)) into
Equation (9) and treating it as a function of?
i
with T,T
tr
, and
? all ﬁxed, we get
f
N
(?
i
)=
2
?
i
+
T ?
?T
obs
?
i
(1+e
??T
obs
)
1?e
??T
obs
, (19)
the derivative of which is
f

N
(?
i
)=
?T
obs
e
??T
obs
+?T
obs
+2e
??T
obs
?2
?
2
i
(1?e
??T
obs
)
, (20)
which is strictly positive for all positive ?T
obs
and arbitrary
positive ?
i
, implying that f
N
(?
i
) increases monotonically
with respect to ?
i
. 
Proposition4impliesthatEquation(2)isalwaysdetermined
by the Poisson process with the largest intensity. Therefore,
we onlyneedto lookat thesingle largest?
i
whenwe optimize
the second objective.
IV. COMPUTATIONAL EXPERIMENTS
Our experimental setup is a direct adaptation of the UAV
monitoring application illustrated in Figure 1. The UAV is
tasked to ﬂy continuously along the six locations of inter-
est and hover over each location for some time to capture
stochastically occurring events at these locations. The input
consists of historical data for the event arrival rates ?
i
’s at
the event locations and the time needed for traveling between
the event locations. Table II lists ?
i
’s and ?
i,j
’s (the ground
truth) for the experiment. The time unit is hour (hr). Figure 3
illustrates the stochastic nature of the event arrivals (note that
these are standard simulations of the exponential distributions
and Poisson processes). In addition to the large range of
average arrival rates at different stations (e.g., events arrive
at station 3 ﬁve times more frequent than they do at station
1), the stochastic arrival times can vary greatly within the
same station. The UAV must balance the amount of data
collected at all stations despite the different arrival rates
while not incurringlarge delays in event observationsbetween
consecutive visits to the same location.
The two goals of our experimental effort are to (i) further
demonstrate the correctness of our theoretical developments,
and (ii) investigate the performanceof the proposed algorithm
withrespecttovariousmeasures.Fortheﬁrstgoal,wemeasure
how well our theoretical predictions hold up by comparing
simulation outcome to our analytical result side by side.
For the second, we verify that the computed optimal policy
achieves all the design expectations. We also compare it with
a non-optimal policy and contrast their performances.
The source code for our simulation software was developed
using the Java programming language, and the simulation
software itself was executed on a computer with a 1.3GHz
Intel Core i5 CPU and4GB memory.Mathematica9 was used
5763
 0
 20000
 40000
 60000
 80000
 100000
 120000
 140000
 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 5
event arrival time (hrs)
= 0.5
1.3
2.5
1.2
1.6
0.9
¸
# of events
 0
 200
 400
 600
 800
 1000
 1200
 0 10 20 30 40 50 60 70 80 90 100
# of events in 24 hours
= 0.5
1.3
2.5
1.2
1.6
0.9
¸
# of occurrences
(a) (b)
Fig. 3. (a) Histogram over the event arrival times since the last event arrival
for the Poisson processes in our experiment over a time horizon of 10000
days. The bucket size (on the x axis) is 0.1 hour. (b) Histogram over the
number of events arriving in an 24-hour window for the different Poisson
processes over 10000 runs.
for computing the optimal policy using the gradient descent
optimization procedure.
TABLE II
THE GROUND TRUTH (EVENT ARRIVAL RATES AND TRAVEL TIMES) USED
IN OUR SIMULATIONS.
Station
1 2 3 456
?
i
(1/hr) 0.5 1.3 2.5 1.2 1.6 0.9
?
i,i+1 mod6
(hrs) 0.15 0.25 0.1 0.3 0.2 0.2
A. Empirical Veriﬁcation of Theorem 2
 0
 20
 40
 60
 80
 100
 120
 140
 160
 1 10 100
T - policy period (hrs)
= 0.5, simulated
    0.5, computed
¸
expected delay (hrs)
Fig. 4. The simulated versus computed values forE[T
i
(π)]. We observe that
the mean of the simulated runs agrees very well with the value computed
directly from Equation (9) for all choices of T’s, wheres the variance grows
larger as T ?T
tr
.
In addition to the proof, we empirically check the cor-
rectness of Theorem 2 via simulations (simulation valida-
tion of Lemma 1 is omitted given its obvious correct-
ness). Our ﬁrst computational experiment validates Equa-
tion (9) by performing both simulation and direct com-
putation side by side and comparing the results, for
the aforementioned case. In simulation, for each ﬁxed
T?{1.3,1.4,1.7,2.2,3.2,6.2,11.2,21.2,51.2,101.2},we sim-
ulated the Poisson process for enough number of periods
(roughly 2?10
5
in the worst case) to gather at 2000 delays
by simulating the the policy.This gaveus 2000samples of the
randomvariableT
i
(π) fromwhich we computedthe mean and
standard deviation. Direct computation based on Equation (9)
werealsocarriedout.Toavoidclutteringthepresentation,only
? =0.5 was used (plots for other ? are similar).
The results of this simulation study are presented in Fig-
ure 4, in comparison with the optimal policy that is directly
computed using the gradient descent procedure. Notice that
the expected delay in simulation results match that of the
computed policy exactly for all choices of T’s. We also ob-
serve from the simulation study that the variance of the delay
increases as T approaches T
tr
. This should be intuitively clear,
since, as T
obs
=T ?T
tr
?0
+
, the length of each observation
window decreases when compared to T
tr
; in fact, the ratio
of the two approaches zero, which leads to the unbounded
increase in the variance of the number of events observed in
a given observation window.
 0
 20
 40
 60
 80
 100
 120
 140
 20 40 60 80 100
T - policy period (hrs)
= 0.5
1.3
2.5
1.2
1.6
0.9
¸
expected delay (hrs) 
Fig. 5. The computed E[T
i
(π)] for ?
1
,...,?
6
and T ?[1.3,101.2].
 10
 10.2
 10.4
 10.6
 10.8
 11
 11.2
 11.4
 3.5 4 4.5 5 5.5 6 6.5 7 7.5
= 0.5
1.3
2.5
1.2
1.6
0.9
¸
T - policy period (hrs)
expected delay (hrs) 
Fig. 6. The computedE[T
i
(π)] for ?
1
,...,?
6
and T ?[3.25,7.75] with ?T =
0.025 increments.
After empirically verifying that Equation (9) is accurate,
we shift our attention to the quasi-convexity of Equation (9)
and its monotonicity in ?
i
. We compute E[T
i
(π)] for all six
?
i
’s and plot the result at two different scales in Figure 5 and
6. Figure 5 shows that E[T
i
(π)] is quasi-convex for all ?
i
’s.
Figure 6, the zoomed-in version of Figure 5, further reveals
5764
thatE[T
i
(π)] depends on ?
i
monotonically for ﬁxed period T,
conﬁrming the claim of Proposition 4.
B. The Performance of the Proposed Algorithm
To compute the optimal cyclic patrolling policy’s parame-
ters,byProposition4weonlyneedtolookatE[T
i
(π)]for?
i
=
2.5.TheperiodT that minimizesEquation(9)for?
i
=2.5can
be easily computed using standard gradient descent methods.
Our computation yields T
?
= 4.59. The corresponding pol-
icy is then deﬁned by π=(1.18,0.45,0.24,0.49,0.37,0.67).
Since our theoretical results guarantee the performance of the
TABLE III
COMPARISONOF AN OPTIMAL POLICY WITH A NON-OPTIMALONE.
Station
?
i
(·) E[T
i
(·)] (hrs) ?
E[T
i
(·)]
(hrs)
ππ

ππ

ππ

1 0.17 0.06 10.1 18.3 7.5 16.0
2 0.17 0.16 10.1 8.9 7.4 6.4
3 0.16 0.31 10.3 5.9 7.7 2.9
4 0.16 0.15 10.2 9.3 7.9 6.5
5 0.17 0.20 10.2 7.6 7.6 5.0
6 0.17 0.11 10.1 11.3 7.5 8.7
patrollingpolicy,wecarriedoutasinglesimulationexperiment
incomparingtheoptimalpolicywithnon-optimalpolicies.For
our comparison, we evenly distributed T
obs
= T ?T
tr
= 3.39
among the stations and obtained an alternative policy π

that
spends 0.57 (hours) at each station per cycle. We simulated
both policy for 100000 policy periods. The simulation results
(?(·),E[T
i
(·)], and the standard deviation ofE[T
i
(·)], denoted
?
E[T
i
(·)]
) are listed in Table III. The result speaks for itself:
Under the optimal policy π, ?
i
(π)’s are uniform across all
stations. At the same time, E[T
i
(π)]’s are also very uniform
and are all about twice of the policy cycle time T
?
=4.59. On
the other hand, under policy π

, station 1 often gets neglected
with an ?
1
(π

)=0.06 and aE[T
1
(π

)]=18.3, which are both
much worse than those for the optimal policy π.
V. CONCLUSIONS
In this paper, we introduced a novel persistent monitoring
problem and data collection in which the arrivals events
at multiple stations are driven by stochastic processes. We
studied the performance of cyclic policies on two objectives:
(i) balancing the average number of events to be collected at
eachstationso thatnostationreceivesinsufﬁcientorexcessive
monitoring effort, and (ii) minimizing the maximum delay
in observing two consecutive events generated by the same
process between policy cycles. We focused on an important
special case where the locations to be visited form a closed
chain. We showed that such a problem admits a unique
cyclic policy that optimizes both objectives. Moreover, we
established that the the second and more complex objective
turned out to be quasi-convex, allowing efﬁcient computation
of the optimal policy with standard gradient descent methods.
We conjecture that these results can be applied to the general
case where the locations are connected in an arbitrary way,
rather than the closed chain conﬁguration. We conjecture that
in this general case, the optimal solution can be obtained by
ﬁrst solving a Traveling Salesman Problem (TSP), and then
computing a schedule along the optimal TSP tour using the
algorithm we propose in this paper.
REFERENCES
[1] N. Michael, E. Stump, and K. Mohta, “Persistent surveillance with a
team of mavs,” in Proceedings IEEE/RSJ International Conference on
Intelligent Robots and Systems, 2011, pp. 2708–2714.
[2] R. N. Smith, M. Schwager, S. L. Smith, B. H. Jones, D. Rus, and
G. S. Sukhatme, “Persistent ocean monitoring with underwater gliders:
Adapting sampling resolution,” Journal of Field Robotics, vol. 28, no. 5,
pp. 714–741, September-October 2011.
[3] S. Alamdari, E. Fata, and S. L. Smith, “Persistent monitoring in discrete
environments: Minimizing the maximum weighted latency between
observations,” International Journal of Robotics Research, 2012, to
appear.
[4] E. Arvelo, E. Kim, and N. C. Martins, “Memoryless control design
for persistent surveillance under safety constraints,” September 2012,
available at http://arxiv.org/abs/1209.5805.
[5] C. G. Cassandras, X. Lin, and X. Ding, “An optimal control approach
to the multi-agent persistent monitoring problem,” IEEE Transactions
on Automatic Control, vol. 58, no. 4, pp. 947–961, April 2013.
[6] A. Girard, A. Howell, and J. Hedrick, “Border patrol and surveillance
missions using multiple unmanned air vehicles,” in Proc. 43rd IEEE
Conference on Decision and Control, 2004, pp. 620–625.
[7] B. Grocholsky, J. Keller, V. Kumar, and G. Pappas, “Cooperative air and
ground surveillance,” IEEERobotics and Automation Magazine, vol. 13,
no. 3, pp. 16–25, Sep 2006.
[8] X. Lan and M. Schwager, “Planning periodic persistent monitoring
trajectories for sensing robots in gaussian random ﬁelds,” in Proc. of
the IEEE International Conference on Robotics and Automation (ICRA
13), May 2013, pp. 2407–2412.
[9] N.Nigam and I. Kroo,“Persistent surveillance using multiple unmanned
air vehicles,” in Proc. IEEE Aerospace Conference, 2008, pp. 1–14.
[10] S. L. Smith, M. Schwager, and D. Rus, “Persistent robotic tasks:
Monitoring andsweepinginchanging environments,” IEEETransactions
on Robotics, vol. 28, no. 2, pp. 410–426, April 2012.
[11] D. E. Soltero, M. Schwager, and D. Rus, “Generating informative
paths for persistent sensing in unknown environments,” in Proc. of the
International Conference on Intelligent Robots and Systems (IROS 12),
October 2012, pp. 2172–2179.
[12] H. Choset, “Coverage of known spaces: The boustrophedon cellular
decomposition,” Autonomous Robots, vol. 9, pp. 247–253, 2000.
[13] ——, “Coverage for robotics - a survey of recent results,” Annals of
Mathematics and Artiﬁcial Intelligence, vol. 31, pp. 113 – 126, 2001.
[14] Y. Gabriely and E. Rimon, “Competitive on-line coverage of grid
environments by a mobile robot,” Computational Geometry, vol. 24,
no. 3, pp. 197–224, 2003.
[15] W.-P. Chin and S. Ntafos, “Optimum watchman routes,” Information
Processing Letters, vol. 28, pp. 39–44, 1988.
[16] P. Hokayem, D. Stipanovic, and M. Spong, “On persistent coverage
control,” in Proc.46th IEEEConference on Decision and Control, 2008,
pp. 6130–6135.
[17] S. Ntafos, “Watchman routes under limited visibility,” Computational
Geometry., vol. 1, pp. 149–170, 1991.
[18] J. A. Fuemmeler and V. V. Veeravalli, “Smart sleeping policies for
energy-efﬁcient tracking in sensor networks,” Networked Sensing In-
formation and Control, 2008.
[19] Y. He and E. K. P. Chong, “Sensor scheduling for target tracking in
sensor networks,” in Proc. 43rd IEEE Conference on Decision and
Control, 2004, pp. 743–748.
[20] A. O. H. III, C. M. Kreucher, and D. Blatt, “Information theoretic
approaches to sensor management,” Foundations and Applications of
Sensor Management, 2008.
[21] J. L. Ny, M. A. Dahleh, E. Feron, and E. Frazzoli, “Continuous path
planning for a data harvesting mobile server,” in 47th IEEE Conference
on Decision and Control, 2008, pp. 1489–1494.
5765
