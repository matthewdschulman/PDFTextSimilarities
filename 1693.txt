Learning-Based Nonlinear Model Predictive Control to Improve Vision-Based
Mobile Robot Path-Tracking in Challenging Outdoor Environments
Chris J. Ostafew, Angela P. Schoellig, and Timothy D. Barfoot
Abstract— This paper presents a Learning-based Nonlinear
Model Predictive Control (LB-NMPC) algorithm for an au-
tonomous mobile robot to reduce path-tracking errors over
repeated traverses along a reference path. The LB-NMPC
algorithm uses a simple a priori vehicle model and a learned
disturbance model. Disturbances are modelled as a Gaussian
Process (GP) based on experience collected during previous
traversals as a function of system state, input and other
relevant variables. Modelling the disturbance as a GP enables
interpolation and extrapolation of learned disturbances, a key
feature of this algorithm. Localization for the controller is
provided by an on-board, vision-based mapping and navigation
system enabling operation in large-scale, GPS-denied environ-
ments. The paper presents experimental results including over
1.8 km of travel by a four-wheeled, 50 kg robot travelling
through challenging terrain (including steep, uneven hills) and
by a six-wheeled, 160 kg robot learning disturbances caused
by unmodelled dynamics at speeds ranging from 0.35 m/s to
1.0 m/s. The speed is scheduled to balance trial time, path-
tracking errors, and localization reliability based on previous
experience. The results show that the system can start from a
generic a priori vehicle model and subsequently learn to reduce
vehicle- and trajectory-speciﬁc path-tracking errors based on
experience.
I. INTRODUCTION
In many mobile robot applications, it is adequate if
not necessary, to explore and navigate the environment by
creating and maintaining a network of paths analogous to
migration routes or automobile roads [1]. The use and
reuse of paths reduces the need for repeated application of
exploratory and terrain-assessing software and also provides
an opportunity for learning behavior. Learning control al-
gorithms offer tools to acquire knowledge about the robot
dynamics and environment in situ, acausally incorporate
unknown effects, and improve performance over time. These
advantages reduce the requirement for signiﬁcant modelling
a priori [2].
In this paper, we investigate a Learning-based Nonlin-
ear Model Predictive Control (LB-NMPC) algorithm for a
nonholonomic, mobile robot within the context of an on-
board, real-time, Visual Teach and Repeat (VT&R) mapping
and navigation system [3]. NMPC is a control framework
in which the current control action is obtained by solving,
at each sampling instant, a ﬁnite-horizon optimal control
problem using the current state of the plant as the initial
state [4, 5]. We apply NMPC to a system with a pro-
cess model comprised of two components: (i) a unicycle
The authors are with the University of Toronto Institute for
Aerospace Studies, Toronto, Ontario, M3H 5T6, Canada. Email:
chris.ostafew@mail.utoronto.ca, schoellig@utias.utoronto.ca, and
tim.barfoot@utoronto.ca.
Fig. 1. The proposed learning-based, path-tracking controller compensates
for unmodelled environmental disturbances, such as the terrain slope and
wheel slip affecting our 50 kg Husky A200 robot, enabling operation in
challenging environments.
Fig. 2. The proposed algorithm learns unmodelled robot dynamics. Here
we show two trajectories of a 150 kg ROC6 robot travelling at 1.0 m/s.
The solid white line shows the desired trajectory (tire tracks), the red line
shows a trajectory with learning disabled, while the dashed blue line shows
a trajectory with learning enabled and reduced path-tracking errors.
model representing the kinematics of the robot, and (ii)
a learned disturbance model representing both unmodelled
robot dynamics and systematic environmental disturbances.
We model disturbances as a Gaussian Process (GP) [7] based
on observations gathered during previous path traversals
as a function of system state, input and other relevant
system variables. By modelling the disturbances as a GP,
the algorithm is able to interpolate and extrapolate from
previous experiences. This is a key enabling feature for
practical, large-scale applications of mobile robots that may
be required to travel at various speeds on many paths while
managing unmodelled terrain and robot dynamics.
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 4029
We also investigate a speed scheduler that automatically
increases speeds along the path based on previous tracking
performance (i.e., tracking errors and localization quality) to
achieve faster overall path completion. The scheduler bal-
ances exploration and exploitation: with the ability to learn
a multivariate disturbance model, the system must choose
between exploring states that may be beneﬁcial, in our case
driving faster, and exploiting states that recall previously
learned disturbances and therefore have lower path-tracking
errors. Effectively, the proposed speed scheduler increases
the speed where the path-tracking errors can be kept small.
The key characteristics of this paper are: (i) a path-
tracking, LB-NMPC algorithm based on a ﬁxed, a priori
known kinematic process model and a learned GP distur-
bance model, (ii) navigation based on vision only, (iii) an au-
tomated speed scheduler, which adapts speeds based on pre-
vious experience addressing the exploration vs. exploitation
trade-off, and (iv) extensive outdoor experiments including
over 1.8 km of travel by two signiﬁcantly different robots in
unmodelled terrain and at intentionally increasing velocities;
the results show the algorithm’s ability to interpolate and
extrapolate from learned experiences. To our knowledge,
this paper is the ﬁrst application of LB-NMPC capable
of interpolating and extrapolating from learned experiences
on a self-contained autonomous mobile robot travelling in
challenging outdoor environments.
II. RELATED WORK
In the literature, there are several examples of MPC
applied to mobile robots. K¨ uhne et al. [8], Klanˇ car and
ˇ
Skrjanc [9], and Xie and Fierro [10] demonstrate MPC on
robots with nonholonomic constraints operating in indoor
lab environments. All of these systems employ a simple
kinematic robot model. Peters and Iagnemma [11] present
simulation results for a ﬁxed model of wheel slip on a
car-like robot, while Burke [12] presents simulated MPC
results with an adaptive value for wheel slip on a track-
type robot. Howard et al. [13] demonstrate MPC on a large-
scale, outdoor robot navigating intricate paths. Unlike these
prior works, our LB-NMPC algorithm learns a general,
nonlinear disturbance function representing both unmodelled
environmental disturbances and robot dynamics.
LB-MPC has previously been proposed for other applica-
tions. Kocijan et al. [14] combine a GP model and NMPC for
the control of a simulated pH neutralization process. They
represent the full dynamics of the system by a GP model
trained on 400 observations of the chemical system. NMPC
is applied to control the system based on the ofﬂine-identiﬁed
GP model (i.e., no online learning). The disturbance model
in our system is constructed online, improving from trial
to trial as more observations are collected. Ko et al. [15]
use a GP-enhanced model and ofﬂine reinforcement learning
to identify open-loop control sequences for indoor blimp
maneuvers. In our system, the learned model is used by
an online NMPC algorithm in determining optimal control
actions at each control time. Nguyen-Tuong et al. [16] and
Park et al. [17] focus on achieving online operation and use
local GP (LGP) models to approximate the inverse dynamics
of 7-DoF manipulator arms and the forward dynamics of an
indoor mobile robot, respectively. In both applications, real-
time operation is achieved by partitioning training data into
regions and training an LGP model for each region. Predic-
tions are generated by weighted estimation using nearby local
models. In this paper, the GP hyperparameters are trained on
all data. However, only a local subset of the training data
is used when computing a disturbance. Aswani et al. [18]
present a general framework for a safe and robust linear
LB-MPC algorithm. Disturbance observations are collected
online and predictions are made using a Nadaraya Watson
estimator. They present simulated results from the control of
a nonlinear jet engine compression system. In this paper,
we use NMPC combined with a GP disturbance model,
and demonstrate our system operating online in challenging
environments. Lehnert and Wyeth [19] investigate Locally
Weighted Learning MPC. Initially, the system is controlled
by a simple feedback controller while the system learns the
parameters for multiple local linear models. Then the set of
linear models is incorporated into an MPC algorithm using
Receptive Field Weighted Regression. In online operation,
the set of models is updated either by adding new models
or updating existing parameters. In this paper, our NMPC
algorithm is based on a known vehicle kinematic model and
a learned general GP disturbance model. This enables con-
tinuous operation from the ﬁrst trial and the representation
of complex disturbance characteristics.
Finally, we employ a speed scheduler that addresses
the classic exploration versus exploitation trade-off, balanc-
ing speed, path-tracking errors, and localization reliability.
In practice, it is more common for the speed to be scheduled
in reaction to the detection of an obstacle [20]. However,
here we assume the desired path is obstacle-free and design
the speed scheduling to greedily maximize speed while
minimizing path-tracking errors and localization failures.
III. VISUAL TEACH AND REPEAT
Localization for the mobile robots we use in this paper
is provided by an on-board VT&R algorithm developed
by Furgale and Barfoot [3] where the sole sensor is an
on-board stereo camera. In the ﬁrst operational phase, the
teach phase, the robot is driven along the desired path
manually by an operator. Localization in this initial operation
is obtained relative to the robot’s starting position by visual
odometry (VO). In addition to the VO pipeline, path vertices
are deﬁned along the path by storing keyframes composed
of local feature descriptors and their 3D positions. During
the second operational phase, the repeat phase, the robot
re-localizes against the stored keyframes thus generating
feedback for a path-tracking controller. Re-localization is
achieved by matching feature descriptors to generate feature
tracks between the current robot view and the teach-pass
robot view. As long as sufﬁcient correct feature matches are
made, the system generates consistent localization over trials
and is able to support a learning-based control algorithm.
4030
GP-based
Disturbance Model
Nonlinear Model
Predictive Control
Mobile Robot
x
d
x u
a g(a)
Fig. 3. The controller is composed of two main components: 1) the path-
tracking NMPC controller, and 2) the GP-based Disturbance Model.
IV. MATHEMATICAL FORMULATION
A. Nonlinear Model Predictive Control
At a given sample time, the NMPC algorithm ﬁnds a
sequence of control inputs based on the current state that
optimizes the plant behaviour over a prediction horizon. The
ﬁrst control input in the optimal sequence is then applied
to the system, resulting in a new system state. The entire
process is then repeated at the next sample time for the new
system state. In traditional NMPC implementations [6], the
process model is speciﬁed a priori and remains unchanged
during operation. In this paper, we augment the process
model with a disturbance model generated from experience
in order to compensate for effects not captured by the
a priori process model, such as environmental disturbances
and unknown dynamics (Figs. 1, 2, and 3).
Consider the following nonlinear, state-space system:
x
k+1
=
a priori model
z }| {
f(x
k
; u
k
) +
unknown
z }| {
d(x
k
; v
k
; u
k
); (1)
v
k+1
= h(v
k
; u
k
)
| {z }
unknown
(2)
with system state, (x
k
; v
k
), and control input, u
k
, both at
time k. We separate the state into two parts, x
k
and v
k
, as
we wish only to affect x
k
through our path-tracking control
design. The models f(), d(), and h() are nonlinear process
models; f() is an a priori, simple vehicle model, d() is
an (unknown) general disturbance, and h() represents the
(unknown) dynamics of the system. As written, Eqs. 1 and 2
are entirely general, except that we make the assumption that
Eq. 2 does not depend on x
k
. We can think of x
k
roughly as
‘position’ and v
k
as ‘velocity’. Thus, the chosen model form
covers most robotic situations where the dynamics cascade
into the kinematics. The speciﬁc deﬁnitions for our robot
experiments are given in Sec. V-A.
By substituting v
k
= h(v
k 1
; u
k 1
) into Eq. 1, we can
write a new version of the state equation as
x
k+1
=
a priori model
z }| {
f(x
k
; u
k
) +
learned using GP
z}|{
g(a
k
) ; (3)
with
a
k
= (x
k
; v
k 1
; u
k
; u
k 1
); (4)
assumed to be observable. The disturbance, g(), now in-
cludes both unknown disturbances and unmodelled dynam-
ics; we will learn g() from experience over time and
represent it using a Gaussian process (more on this in the
next section).
As previously mentioned, the objective of the NMPC
algorithm is to ﬁnd a set of controls that optimizes the plant
behaviour over a given prediction horizon. To this end, we
deﬁne the cost function to be minimized over the next K
timesteps to be
J(u) = (x
d
  x)
T
Q(x
d
  x) + u
T
Ru; (5)
where Q is positive semi-deﬁnite, R is positive deﬁnite, u is
a sequence of control inputs,
u = (u
k
;:::; u
k+K
);
x
d
is a sequence of desired states,
x
d
= (x
d;k+1
;:::; x
d;k+K+1
);
and x is a sequence of predicted states,
x = (x
k+1
;:::; x
k+K+1
):
Since both our process model and disturbance model are
nonlinear, the minimum of J(u) must be found iteratively
using a nonlinear optimization technique. In this paper,
we use unconstrained Gauss-Newton minimization [21] to
solve the nonlinear least-squares problem. However, there
are other nonlinear optimization algorithms, such as the
constrained Gauss-Newton algorithm [6], that could be used
to incorporate constraints on the path-tracking errors and
control inputs.
Because this optimization is fairly standard, we avoid
the minutiae and provide only a high-level sketch. We
linearize around an initial guess for the optimal control input
sequence,  u, with u =  u +u. A good initial guess for  u is
the sequence of optimal inputs calculated in the previous
timestep. For the ﬁrst timestep, we use  u = 0. With  x
representing the predicted sequence of states resulting from
 u and x =  x +x, we can write a linearized equation for the
state in lifted form,
x = Hu; (6)
where H is the block-Jacobian of Eq. 3 with respect to
u; evaluting this involves computing partials of f() and
g(). In the case of f(), we have an analytical model
and in the case of g(), the derivatives are tractable so
long as an appropriate kernel function is chosen for use in
the Gaussian process model (see next section). Substituting
Eq. 6, x =  x +x, and u =  u +u into Eq. 5 results inJ()
being exactly quadratic in u. We can can easily ﬁnd the
value of u that minimizes J(), update our control input,
 u  u +u; (7)
and iterate to convergence. In accordance with NMPC, we
apply the resulting control input for one timestep and start
all over at the next timestep.
4031
B. Gaussian Processes
We model the disturbance, g(), as a GP based on past
observations given a disturbance dependency, a. The model
depends on observations of the disturbances collected during
previous trials. At timek, we use the estimated poses, ^ x
k
and
^ x
k 1
, from the VT&R system, and the control input, u
k 1
,
to solve Eq. 3 for ^ g(a
k 1
),
^ g(a
k 1
) = ^ x
k
  f(^ x
k 1
; u
k 1
): (8)
We collect an observation for all sample times in a trial
and organize the data from trial j into a set of data pairs,
D
j
=[fa
0
; ^ g(a
0
)g;:::;fa
k
; ^ g(a
k
)g;:::;fa
Nj 1
; ^ g(a
Nj 1
)g],
where N
j
is the number of timesteps it took to travel the
length of the path during trial j, and a
k
is as deﬁned in
Eq. 4. After j trials we have datasetsD
1
;:::;D
j
, that we
combine into a single database,D, withN =N
1
+ +N
j
observations. We also drop the timestep index, k, on each
datapair inD, so that when referring to a
D;i
or ^ g
D;i
, we
mean the ith pair of data in the supersetD. Note that there
is no requirement that N
j
= N
j 1
as the system simply
collects observations as they occur for the length of time
that it takes to complete a trial. Moreover, all experiences
are treated equally as observations of the underlying
unmodelled disturbance. Therefore, the system does not
require identical initial conditions, termination conditions,
or speed schedules.
In this work, we train a separate GP for each dimension in
g()2R
n
to model disturbances as the robot travels along a
path. For simplicity of discussion, we will assume for now
thatn = 1 and denote ^ g
D;i
by ^ g
D;i
. The GP model assumes
a measured disturbance originates from a process model,
^ g(a
D;i
)GP (0;k(a
D;i
; a
D;i
)); (9)
with zero mean and kernel function, k(a
D;i
; a
D;i
), to
be deﬁned. We assume that each disturbance measure-
ment is corrupted by zero-mean additive noise with vari-
ance, 
2
n
, so that ^ g
D;i
=g
D;i
+;N (0;
2
n
). Then a
modelled disturbance, g(a
k
), and the N observed distur-
bances, ^ g = (^ g
D;1
;:::; ^ g
D;N
), are jointly Gaussian,

^ g
g(a
k
)

N

0;

K k(a
k
)
T
k(a
k
) k(a
k
; a
k
)

; (10)
where
K =
2
6
6
6
4
k(a
D;1
; a
D;1
) k(a
D;1
; a
D;2
) ::: k(a
D;1
; a
D;N
)
k(a
D;2
; a
D;1
) k(a
D;2
; a
D;2
) ::: k(a
D;2
; a
D;N
)
.
.
.
.
.
.
.
.
.
.
.
.
k(a
D;N
; a
D;1
)k(a
D;N
; a
D;2
)::: k(a
D;N
; a
D;N
)
3
7
7
7
5
;
and
k(a
k
) =

k(a
k
; a
D;1
) k(a
k
; a
D;2
) ::: k(a
k
; a
D;N
)

:
In our case, we use the squared-exponential kernel func-
tion [7],
k(a
i
; a
j
) =
2
f
exp

 
1
2
(a
i
  a
j
)
T
M
 2
(a
i
  a
j
)

+
2
n

ij
;
?
k
?
k
v
k
x
d,i?1
x
d,i
x
d,i+1
x
k
y
k
Fig. 4. Deﬁnition of the robot velocities, v
k
and !
k
, and three pose
variables, x
k
, y
k
and 
k
, calculated relative to the nearest path vertex by
Euclidean distance.
where 
ij
is the Kronecker delta, that is 1 iff i = j
and 0 otherwise, and the constants M, 
f
, and 
n
are
hyperparameters. In our implementation with a
k
2 R
p
, the
constant M is a diagonal matrix, M = diag(m), m2R
p
,
representating the relevance of each component in a
k
, while
the constants
2
f
and
2
n
, represent the process variation and
measurement noise, respectively. Finally, we have that the
prediction,g(a
k
), of the disturbance at an arbitrary state, a
k
,
is also Gaussian distributed,
g(a
k
)jgN

k(a
k
)K
 1
^ g; k(a
k
; a
k
)  k(a
k
)K
 1
k(a
k
)
T

:
While we do not make use of the variance information
in our controller, in future implementations it could be used
as an indication of the uncertainty in the model and used
appropriately in deciding the resulting control command.
Finally, we include further detail on the storage and retrieval
of observations for online operation in Sec. V-C.
C. Gaussian Process Hyperparameter Selection
Having deﬁned the NMPC algorithm and the disturbance
model, g(a
k
), it remains to deﬁne the source of the hy-
perparameter selection. With the squared-exponential kernel
function and a disturbance dependency input of size p, our
GP has (2 +p)n hyperparameters to be determined. After
collecting a set of training data, we ﬁnd the optimal hyper-
parameters ofﬂine by maximizing the log marginal likelihood
using a gradient ascent algorithm, effectively maximizing the
probability of the data by adjusting the hyperparameters [7].
In order to avoid local maxima, the algorithm is repeated
many times, initialized with different initial values, and the
set of hyperparameters resulting in the greatest log marginal
likelihood is selected. After training, the hyperparameters are
held ﬁxed during online operations.
V. IMPLEMENTATION
A. Deﬁning the Process Model and Variables
In this paper, robots are modelled as unicycle-type vehicles
with ‘position’ state variables, x
k
= (x
k
; y
k
; 
k
), calculated
relative to the nearest path vertex by Euclidean distance
(Fig. 4). The robots have two control inputs, their linear and
4032
angular velocities, u
k
= (v
cmd;k
;!
cmd;k
). The commanded
linear velocity is set to the desired, scheduled speed at the
nearest path vertex, leaving only the angular velocity,!
cmd;k
,
for the NMPC algorithm to choose (i.e., we do not optimize
the commanded linear velocity).
When the time between control signal updates is deﬁned
as t, the resulting a priori process model employed by the
NMPC algorithm is
f(x
k
; u
k
) = x
k
+
2
4
t cos
k
0
t sin
k
0
0 t
3
5
u
k
; (11)
which represents a simple kinematic model for our robot;
it does not account for dynamics or environmental distur-
bances. We use the same a priori model for both robots in
our experiments, despite them being quite different in scale.
The ‘velocity’ state variables are v
k
= (v
act;k
;!
act;k
),
which represent the actual linear and rotational speeds of
the robot. These will differ from the commanded ones, u
k
,
owing to the fact that the robots we are working with have
ﬁxed rate-control loops that attempt to drive the robot at
the commanded velocity. However, the combined dynamics
of the robot and these rate controllers are not modelled.
We allow the LB-NMPC algorithm to learn these dynamics,
as well as any other systematic disturbances, based on
experience.
In order to build and query the learned model,
g(), we require all of the quantities in Eq. 4:
a
k
= (x
k
; v
k 1
; u
k
; u
k 1
). We know u
k
and u
k 1
, as
these are commanded inputs, and we obtain x
k
from
our vision-based localization system. We also require the
‘velocity’ state variables, v
k 1
= (v
act;k 1
;!
act;k 1
); we
could potentially measure these directly using a sensor, but
instead approximate them according to
v
act;k 1
=
p
(x
k
 x
k 1
)
2
+ (y
k
 y
k 1
)
2
t
;
and
!
act;k 1
=
(
k
 
k 1
)
t
:
This is preferable to using, say, wheel encoders because we
want the true speeds with respect to the ground and wheel
encoders are unable to measure slip. Because x
k
comes from
our vision-based localization system, we are able to measure
wheel slip in this way.
B. Automated Speed Scheduler
We implemented an automated speed scheduler to demon-
strate the LB-NMPC algorithm’s ability to interpolate and
extrapolate from learned experiences. For the jth trial, the
scheduled speed at the ith path vertex, v
(j)
sched;i
, is based
on variables recorded at the ith vertex during the previous
trial such as the lateral and heading path-tracking errors,
e
(j 1)
L;i
, e
(j 1)
H;i
, respectively,
"
e
(j 1)
L;i
e
(j 1)
H;i
#
=

0 1 0
0 0 1

(x
(j 1)
d;i
  x
(j 1)
i
);
the scheduled speed,v
(j 1)
sched;i
, the commanded angular veloc-
ity, !
(j 1)
cmd;i
, and the matched feature count, c
(j 1)
feature;i
. Then,
using gains for increasing and decreasing the scheduled
speed,
1
> 1,
2
< 1, respectively, and thresholds,
L
 0,

H
 0, 
v
> 0, 
!
> 0, and 
feature
 4, the scheduler
follows rules to adjust the scheduled velocity as necessary:
v
(j)
sched;i
= (12)
8
>
>
>
>
>
>
>
>
>
>
>
<
>
>
>
>
>
>
>
>
>
>
>
:

1
v
(j 1)
sched;i
if (je
(j 1)
L;i
j<
L
)^ (je
(j 1)
H;i
j<
H
)^
(jv
(j 1)
sched;i
j<
v
)^ (j!
(j 1)
cmd;i
j<
!
)^
(c
(j 1)
feature;i
>
feature
)

2
v
(j 1)
sched;i
if (je
(j 1)
L;i
j>
L
)_ (je
(j 1)
H;i
j>
H
)_
(jv
(j 1)
sched;i
j>
v
)_ (j!
(j 1)
cmd;i
j>
!
)_
(c
(j 1)
feature;i
<
feature
)
v
(j 1)
sched;i
otherwise:
For the ﬁrst trial, the scheduled speed at all vertices in the
path was set to a ﬁxed linear velocity, v
(1)
sched;i
= v
init
.
Effectively, the automated speed scheduler identiﬁes sections
of the path where the system can tolerate additional speed
and sections where it cannot, thus balancing the trade-
off between speed and path-tracking errors. The scheduler
accounts for the limits of the robot and the vision system.
C. Managing Experiences
In order to ensure the LB-NMPC algorithm was executed
in constant computation time, our implementation required
the ability to use a subset of the observed experiences when
computing a disturbance. For this purpose, as experiences
were learned, they were binned at each path vertex by
commanded velocity. When a bin was considered full, the
oldest experience in the bin was discarded. Then when
computing a disturbance, experiences were drawn from the
bins at nearby path vertices based on commanded velocity.
VI. EXPERIMENTS
A. Overview
We tested the LB-NMPC algorithm in two separate ex-
periments, including over 1.8 km of learning-enabled path-
tracking in GPS-denied environments. In the ﬁrst experiment,
we tested the algorithm’s ability to learn unmodelled envi-
ronmental disturbances, such as the terrain slope depicted in
Fig. 1. We tested on a 30-m-long path including unmodelled
slopes, sandy surfaces, and gravel surfaces using a 50 kg,
four-wheeled Husky A200 robot travelling at a desired speed
of 0.4 m/s. The test path for the ﬁrst experiment included
slope angles up to 15

, side-slope angles up to 15

, and
path curvatures up to 1 m
 1
(Fig. 5).
In the second experiment, we tested the algorithm’s ability
to interpolate and extrapolate from previous experience by
having a 150 kg, six-wheeled ROC6 robot learn to drive at a
range of scheduled speeds over 20 trials on a 60-m-long path.
The speeds were provided by an automated speed scheduler
that used path-tracking errors, control inputs, and matched
features from previous trials to determine safe speeds for the
next trial (Sec. V-B).
4033
0 5 10 15 20 25 30
?20
?10
0
10
20
Angle (deg)
Desired Path Roll and Pitch Angles
 
 
Roll Pitch
0 5 10 15 20 25 30
0
0.5
1
1.5
Curvature (m
?1
)
Distance Along Path (m)
Desired Path Curvatures
Fig. 5. Experiment 1 Conditions: The test path for the ﬁrst experiment
included slope angles up to 15
?
, side-slope angles up to 15
?
, and path
curvatures up to 1 m
?1
. At 17 m along the path, the gravel covered path
pitched forward while rolling and turning to the right.
0 5 10 15 20 25 30
?0.1
0
0.1
0.2
0.3
Lateral Errors (m)
Lateral Error vs Distance
 
 
Trial 1
Trial 20
0 5 10 15 20 25 30
?10
0
10
20
Heading Errors (deg)
Distance Along Path (m)
Heading Error vs Distance
 
 
Trial 1
Trial 20
Fig. 6. Experiment 1 Results: Lateral and error versus distance along the
path. The maximum heading and lateral errors in trial 20 occurred during
the most challenging part of the path at 17 m along the path.
5 10 15 20 25 30
?0.4
?0.3
?0.2
?0.1
0
0.1
0.2
0.3
0.4
Heading Rate Disturbance Modelling Error
Heading Disturbance (rad/s)
Distance Along Path (m)
 
 
3? Bounds
Modelling Error
Fig. 7. Experiment 1 Results: Trial 20 heading rate disturbance modelling
error versus distance along the path. The disturbance modelling error was
largely contained within the 3 bounds estimated by the GP.
Both experiments were performed in the University of
Toronto Institute for Aerospace Studies (UTIAS) MarsDome.
In both cases, the controller described in Sec. IV was
1 5 10 15 20
0
0.05
0.1
0.15
0.2
0.25
0.3
Trial Number
Lateral Error (m)
Lateral Error
 
 
Maximum
RMS
1 5 10 15 20
0
5
10
15
Trial Number
Heading Error (deg)
Heading Error
 
 
Maximum
RMS
Fig. 8. Experiment 1 Results: Lateral and heading error versus trial
number. The maximum and Root-Mean-Square (RMS) errors are reduced
signiﬁcantly within the ﬁrst few trials.
implemented and run in addition to the VT&R software on a
Lenovo W530 laptop with an Intel 2.6 Ghz Core i7 processor
with 16 GB of RAM. The camera in both experiments was
a Point Grey Bumblebee XB3 stereo camera. The resulting
real-time localization and path-tracking control signals were
generated at approximately 10 Hz. Since GPS was not
available, the improvement due to the LB-NMPC algorithm
was quantiﬁed by the localization of the VT&R algorithm.
B. Tuning Parameters
The performance of the system was adjusted using the
NMPC weighting matrices Q and R, and the speed scheduler
gains and thresholds. The weighting matrices were selected
in advance with roughly 2:1:1 ratios weighting heading
errors, position errors, and control inputs, and kept the same
for all experiments. Otherwise, the speed scheduler gains
were set to adjust the scheduled speeds by no more than
0.05 m/s between trials, while maintaining heading errors
less than 10

, lateral errors less than 15 cm, matched feature
counts greater than 30, linear speeds less than 1.0 m/s, and
angular velocities less than 1.0 rad/s.
C. Results
In the ﬁrst experiment, the robot autonomously travelled
the length of the 30-m-long path for 20 trials at a ﬁxed ve-
locity of 0.4 m/s resulting in 600 m of travel. The LB-NMPC
algorithm successfully reduced the maximum lateral and
heading errors by roughly 50% in the ﬁrst ﬁve trials, then
maintained these errors for the next 15 trials (Figs. 6 and 8),
demonstrating the system’s ability to handle unmodelled
terrain. The maximum heading and lateral errors in trial
20 occurred around 17 m along the path where the path
pitched forward, rolled to the right, and turned to the right
(Figs. 5 and 6). By trial 20, the heading rate disturbance
modelling error was largely contained within the 3 bounds
estimated by the GP (Fig. 7).
In the second experiment, the robot autonomously trav-
elled the length of a 60-m-long path for 20 trials
(Figs. 2 and 9) at a range of scheduled speeds (Fig. 10)
to demonstrate the ability of the disturbance model to inter-
polate and extrapolate from learned experiences (Fig. 12).
4034
0 10 20 30 40 50 60
?5
0
5
10
Angle (deg)
Desired Path Roll and Pitch Angles
 
 
Roll Pitch
0 10 20 30 40 50 60
0
0.1
0.2
0.3
0.4
0.5
Curvature (m
?1
)
Distance Along Path (m)
Desired Path Curvatures
Fig. 9. Experiment 2 Conditions: Slope, side-slope, and curvature versus
distance along the path. The test path for the second experiment formed a
large 60-m-long loop. In total, the ROC6 repeated the 60-m-long path in
20 trials, resulting in over 1.2 km of testing on this path.
0 10 20 30 40 50 60
0
0.2
0.4
0.6
0.8
1
Scheduled Speed
Speed (m/s)
Distance Along Path (m)
 
 
trial 1 trial 3 trial 6 trial 15 trials 16?20
Fig. 10. Experiment 2 Results: Commanded linear speed versus distance
along the path. The speed scheduler greedily increased the scheduled speed,
thus tending to expand the learned disturbance model rather than exploit it.
0 10 20 30 40 50 60
0
20
40
60
80
100
120
Matched Features
Distance Along Path (m)
Number of Matched Features
 
 
Learning Enabled
Learning Disabled
Fig. 11. Experiment 2 Results: Trial 15 VT&R matched features versus
distance along the path. In trial 15, the learning algorithm brought the
average number of matched features up from 38.33 to 55.77 features
resulting in a reduction in temporary localization failures.
For the ﬁrst 15 trials, the linear speed was incrementally
increased on a trial-by-trial basis by the speed scheduler,
demonstrating the ability of the disturbance model to ex-
trapolate disturbances from past observations (Fig. 12). The
speed scheduler determined where along the path the system
could tolerate higher speeds using experience from previous
traversals (Fig. 10). In the last ﬁve trials, the speed was ﬁxed
at 0.6 m/s, a new speed for the system, demonstrating the
1 5 10 15 20
0
0.2
0.4
Trial Number
Lateral Error (m)
Lateral Error
1 5 10 15 20
0
5
10
15
Trial Number
Heading Error (deg)
Heading Error
 
 
Learning Enabled: Max
Learning Enabled: RMS
Learning Disabled: Max
Learning Disabled: RMS
1 5 10 15 20
0
50
100
150
200
Trial time (s)
Trial Number
Travel Time Speed scheduler disabled, 
 commanded speed set to 
 0.6 m/s for trials 16 ? 20.
Fig. 12. Experiment 2 Results: In trials 1-15, the scheduled speed is
iteratively increased to test the algorithm’s ability to extrapolate from learned
data. Then in trials 16-20, the scheduled speed is ﬁxed to 0.6 m/s (Fig. 10)
to test the algorithm’s ability to interpolate from learned data.
ability of the disturbance model to interpolate disturbances
from past observations (Fig. 13). Over the course of the 20
trials, the LB-NMPC algorithm was shown to reduce the
lateral and heading errors by roughly 50% (Fig. 12) while
learning disturbances at speeds ranging from 0.35 m/s to
1.0 m/s (Fig. 10).
In total, the system had learned a model based on roughly
5000 observations (Fig. 13). Of note, the system was unable
to travel faster than 0.7 m/s at 40 m along the path due to
the path’s curvature (Fig. 9). As a result, the system was
not able to collect experience above 0.7 m/s for the section
of the path around 40 m (Figs. 13 and 14). However, when
operating with the learning disabled, the system consistently
failed to localize at higher speeds when passing through the
turns at 20, 40, and 50 m along the path (Fig. 11). On the
other hand, localization was consistent when learning was
enabled due to better path-tracking and the resulting increase
in the number of matched features.
VII. CONCLUSION
In summary, this paper presents a Learning-based Nonlin-
ear Model Predictive Control algorithm for a path-repeating,
mobile robot negotiating large-scale, GPS-denied, outdoor
environments. The disturbance is modelled as a Gaussian
Process based on observed disturbances as a function of
relevant variables such as the system state and input. Local-
ization for the controller is provided by an on-board, Visual
Teach & Repeat mapping and navigation system.
Two experiments on two signiﬁcantly different robots,
including over 1.8 km of travel through challenging GPS-
denied outdoor environments, demonstrated the system’s
ability to handle unmodelled terrain and robot dynamics, and
also to interpolate and extrapolate from learned disturbances.
In the second experiment, the system used an automated
4035
Commanded Linear Speed (m/s)
Distance Along Path (m)
Nominal Heading Rate Disturbance Model Output
 
 
0 10 20 30 40 50 60
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Heading Rate Disturbance (rad/s)
?0.35 ?0.3 ?0.25 ?0.2 ?0.15 ?0.1 ?0.05 0 0.05 0.1 0.15
Fig. 13. Experiment 2: The disturbance model maintains a database of
observations. We show the learned values for the heading rate disturbance
as a function of commanded speed and distance along the path. At 0.9 m/s,
40 m along the path (blue ellipse), there is very little data and the model is
untrustworthy (see Fig. 14).
0 10 20 30 40 50 60
?0.4
?0.3
?0.2
?0.1
0
0.1
0.2
0.3
0.4
Nominal Heading Rate Disturbance Model Output
Heading Rate Disturbance (rad/s)
Distance Along Path (m)
 
 
3? Confidence Region
Modelled Disturbance
Fig. 14. Experiment 2: Here we show the nominal values for the heading
rate disturbance at a commanded speed of 0.9 m/s. The system has no
relevant experience when travelling 0.9 m/s at 40 m along the path, therefore
the modelled disturbance is zero and 3 conﬁdence region is relatively large.
speed scheduler based on previous experience to address the
classic exploration vs. exploitation trade-off balancing speed
and path-tracking errors. The LB-NMPC approach proved to
be ﬂexible and effective at reducing path-tracking errors and
increasing the reliability of the localization system.
VIII. ACKNOWLEDGEMENTS
The authors would like to thank the Ontario Ministry of
Research and Innovation’s Early Research Award Program
for funding our research, the Canada Foundation for Inno-
vation for funding the ROC6 robot, and Clearpath Robotics
for funding the Husky A200 robot.
REFERENCES
[1] T. Barfoot, B. Stenning, P. Furgale, and C. McManus. Exploit-
ing reusable paths in mobile robotics: Beneﬁts and challenges
for long-term autonomy. In Proc. of the 9th Canadian Conf.
on Computer and Robot Vision (CRV), pages 388–395, 2012.
[2] D. Nguyen-Tuong and J. Peters. Model learning for robot
control: a survey. Cognitive Processing, 12:319–340, 2011.
[3] P. Furgale and T. Barfoot. Visual teach and repeat for long-
range rover localization. Jour. of Field Robotics, 27(5):534–
560, 2010.
[4] D. Q. Mayne, J. B. Rawlings, C. V . Rao, and P. O. M.
Scokaert. Constrained model predictive control: Stability and
optimality. Automatica, 36:789–814, 2000.
[5] M. Morari and J. H. Lee. Model predictive control: past,
present and future. Computers and Chemical Engineering, 23
(4):667–682, 1999.
[6] M. Diehl, H. J. Ferreau, and N. Haverbeke. Efﬁcient numerical
methods for nonlinear mpc and moving horizon estimation. In
Nonlinear Model Predictive Control, pages 391–417. Springer,
2009.
[7] C.E. Rasmussen and C.K.I. Williams. Gaussian processes
for machine learning, volume 1. MIT press Cambridge, MA,
2006.
[8] F. K¨ uhne, W.F. Lages, and J.M.G. Silva. Mobile robot
trajectory tracking using model predictive control. Proc. of
the Latin-American Robotics Symp., Sept. 2005.
[9] G. Klanˇ car and I.
ˇ
Skrjanc. Tracking-error model-based pre-
dictive control for mobile robots in real time. Robotics and
Autonomous Systems, 55(6):460–469, 2007.
[10] F. Xie and R. Fierro. First-state contractive model predictive
control of nonholonomic mobile robots. Proc. of the American
Control Conf., pages 3494–3499, 2008.
[11] S. Peters and K. Iagnemma. Mobile robot path tracking of
aggressive maneuvers on sloped terrain. Proc. of the Int. Conf.
on Intelligent Robots and Systems, pages 242–247, 2008.
[12] M. Burke. Path-following control of a velocity constrained
tracked vehicle incorporating adaptive slip estimation. Proc.
of the Int. Conf. on Robotics and Automation, pages 97–102,
2012.
[13] T. M. Howard, C. J. Green, and A. Kelly. Receding horizon
model-predictive control for mobile robot navigation of intri-
cate paths. Field and Service Robotics, pages 69–78, 2009.
[14] J. Kocijan, R. Murray-Smith, C.E. Rasmussen, and A. Girard.
Gaussian process model based predictive control. In Proc.
of the American Control Conf., volume 3, pages 2214–2219,
2004.
[15] J. Ko, D. Klein., D. Fox, and D. Haehnel. Gaussian processes
and reinforcement learning for identiﬁcation and control of an
autonomous blimp. In Proc. of the Int. Conf. on Robotics and
Automation, pages 742-747, 2006.
[16] D. Nguyen-Tuong, J. Peters, and M. Seeger. Local gaus-
sian process regression for real time online model learning.
Advances in Neural Information Processing Systems, pages
1193-1200, 2008.
[17] S. Park, S.K. Mustafa., and K. Shimada. Learning-based robot
control with localized sparse online gaussian process. In Proc.
of the Int. Conf. on Intelligent Robots and Systems, pages
1202-1207, 2013.
[18] A. Aswani, H. Gonzalez, S. Shankar Sastry, and C. Tomlin.
Provably safe and robust learning-based model predictive
control. Automatica, 49:1216–1226, 2013.
[19] C. Lehnert and G. Wyeth. Locally weighted learning model
predictive control for nonlinear and time varying dynamics.
Proc. of the Int. Conf. on Robotics and Automation, pages
2604–2610, 2013.
[20] L. Lapierre, R. Zapata, and P. Lepinay. Combined path-
following and obstacle avoidance control of a wheeled robot.
Int. Jour. of Robotics Research, 26(4):361–375, 2007.
[21] C. F. Gauss. M´ ethode des Moindres Carr´ es. Mallet-Bachelier,
Impreimeur-Libraire de L’
´
Ecole Polytechnique, Quai des Au-
gustins no. 55, Paris, 1855.
4036
