Space-Time Functional Gradient Optimization for Motion Planning
Arunkumar Byravan
1
, Byron Boots
1
, Siddhartha S. Srinivasa
2
and Dieter Fox
1
Abstract—Functional gradient algorithms (e.g. CHOMP)
haverecentlyshowngreatpromiseforproducinglocallyoptimal
motion for complex many degree-of-freedom robots. A key
limitation of such algorithms is the difﬁculty in incorporating
constraints and cost functions that explicitly depend on time.
We present T-CHOMP, a functional gradient algorithm that
overcomes this limitation by directly optimizing in space-time.
We outline a framework for joint space-time optimization,
derive an efﬁcient trajectory-wide update for maintaining time
monotonicity, and demonstrate the signiﬁcance of T-CHOMP
over CHOMP in several scenarios. By manipulating time, T-
CHOMP produces lower-cost trajectories leading to behavior
that is meaningfully different from CHOMP.
I. INTRODUCTION
Motion planning algorithms plan a collision-free path for
a given task, often subject to physical constraints. Recently,
trajectory optimization algorithms [1]–[8] have demonstrated
great success in a number of high-dimensional real-world
planning problems. One such state-of-the-art algorithm,
CHOMP [3], uses functional gradient optimization to bend
an initial (often infeasible) trajectory away from obstacles
while maintaining smoothness. A typical CHOMP trajectory
is illustrated in Fig.1a, where the robot HERB’s right arm
pulls back away from the countertop to avoid the red box on
its way to the goal.
Although the theory of CHOMP allows for arbitrary time
parametrization, in practice CHOMP makes a deliberate
choice. It parametrizes a trajectory as a set of waypoints
spaced equally in time (detailed in Sec. III). This has a key
consequence:
The only way to alter the timing of a trajectory is
by altering the waypoints, i.e., the conﬁgurations
of the robot.
The distinction is subtle but critical. We draw an analogy:
Imagine the trajectory as a set of photographs mounted on a
zoetrope that spun at constant speed to produce the illusion
of a movie. With CHOMP, if we wanted to speed up the
middle section of our movie, we would have to take a whole
new set of photographs.
Although any arbitrary trajectory timing can be generated,
the process is tedious. As a result, algorithms like CHOMP
are often followed by a retiming step, where the generated
path is optimized for timing. Although motion retiming
has been demonstrated to be quite successful [9]–[11], the
decoupling of path planning and timing has several known
disadvantages, including (1) it disallows the use of cost
1
Department of Computer Science & Engineering, University of
Washington(barun, bboots, fox)@cs.washington.edu
2
Robotics Institute, Carnegie Mellon Universitysiddh@cs.cmu.edu.
This work was funded in part by the National Science Foundation under
contract NSR-NRI 1227234.
(a) CHOMP trajectory
(b) T-CHOMP trajectory
Fig.1: Space-timeoptimizationgivesT-CHOMP(green)additional
freedom to manipulate time resulting in a slower, direct path above
theboxcomparedtoCHOMP(red)whichcannotreasonabouttime.
functionals that explicitly reason about time, like going
slower near obstacles, a running example in this paper, and
(2) is more prone to local minima.
Instead, we propose to add to CHOMP one additional
degree of freedom: time. This enables us to optimize the
trajectory in space-time (Sec. IV). Returning to our anal-
ogy, speeding up the middle section now merely requires
us to speed up our zoetrope, without having to take new
photographs.
As a consequence, we overcome both the above disadvan-
tages: (1) our cost functionals can explicitly reason about
time, and (2) we are able to escape more local minima.
One such scenario is illustrated in Fig.1b. By adding a cost
functionalthattradesoffspeedforobstacleavoidance,weare
able to generate a trajectory that carefully and slowly goes
over the box on its way to the goal, in contrast to Fig.1a
where the inability to reason about time forces the trajectory
to take a large detour away from the box.
Optimization in space-time poses several challenges. Key
among them is time monotonicity, i.e., preventing time from
moving backwards. To address this, we add trajectory-wide
space-timeconstraintstoenforcemonotonicity.Wederivethe
Karush-Kuhn-Tucker (KKT) ﬁrst-order necessary conditions
for the constraints and present an efﬁcient algorithm for
implementing them for a waypoint parametrization (Sec. V).
2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China
978-1-4799-3684-7/14/$31.00 ©2014 IEEE 6499
We demonstrate our new algorithm Time CHOMP (T-
CHOMP) on two scenarios: a 2D point robot (for visual
clarity) and a 7DOF robot arm attached to Marvin, a segway
platform and HERB, a bimanual mobile manipulator, in
simulated environments.
We use a speciﬁc time-based cost functional as discussed
earlier (and elaborated in Sec. VI), which slows down when
it is close to an obstacle, and contrast our results with
CHOMP. Our results show that reasoning directly in space-
time gives us better control over path and timing, resulting
in meaningfully different behavior from CHOMP. (Sec. VII).
Our paper makes the following contributions: (1) we pro-
pose a new algorithm T-CHOMP for space-time functional
gradient optimization, (2) derive an efﬁcient algorithm for
the trajectory-wide space-time time monotonicity constraint,
and (3) demonstrate results on a simulated robotic platform.
Wealsodiscussseverallimitationsofourwork(Sec.VIII).
Key among them is the structure of the cost functional.
Adding time adds extra dimensions for optimization, but
also imposes a greater burden on deﬁning the correct cost
functional.Animproperlyweightedcostfunctionalcanresult
in motion that very slowly goes through an obstacle, for
no fault of the optimizer. Learning good space-time cost
functionals is a key area of future work.
II. RELATED WORK
There has been signiﬁcant work on trajectory optimiza-
tion for motion planning [12]. Khatib [13] and Rimon
and Koditschek [14] showed the use of artiﬁcial potential
functions in navigation planning. Quinlan and Khatib [1]
introduced the theory of elastic bands for planning collision
free paths in space, bending the band away from collision
while maintaining shape. Ratliff et al. [2], [3] extended these
techniques to use functional gradient optimization to plan
collision free paths, leading to the algorithm CHOMP.
Kalakrishnan et al. [4] adapted the optimization to use
stochastic gradient descent with the path integral framework
[15]. Schulman et al. [6] used convex relaxations and se-
quential quadratic programming to compute paths that are
out of collision. Park et al. [5] suggested an incremental
replanning algorithm to generate low cost paths in dynamic
environments. These methods neglect to optimize the timing
of the trajectory, and are usually followed by a retiming step.
Motion retiming for pre-planned robot trajectories with
constraints is a well developed ﬁeld. Bobrow et al. [9]
proposed a method for computing minimum-time optimal
controls for a pre-planned path subject to torque limitations.
Shiller et al. [10] and Canny et al. [16] extended this to in-
clude obstacles and other non-linear constraints. Hollerbach
[11] proposed to dynamically rescale the velocity proﬁle to
make trajectories feasible for execution on robots. All these
methods handle path planning and timing in isolation.
Optimal control techniques [17] have looked at the prob-
lem of trajectory optimization with velocity as a part of
the state. Differential Dynamic Programming [18] methods
used a locally quadratic approximation of the dynamics
and cost to solve the optimal control problem. Similar to
DDP, iLQG [7] used quadratic cost approximations and
handled non-linear control costs. Toussaint et al. [19] used
approximate inference to improve over iLQG. LQGMP [8]
is similar and additionally handled uncertainty in state and
motion. In contrast to these methods, we choose a different
parametrization by adding time directly to our state. This
results in a lower dimensional state representation compared
to having velocities in-state while allowing the ﬂexibility to
directly manipulate time. Rawlik et al. [20] used a similar
approach with approximate inference for joint optimization
of movement and duration in an optimal control framework.
Witkin [21] introduced space-time constraints for gen-
erating physically realistic motion in character animation.
This paradigm has been used extensively in the animation
literature for transferring motion between characters [22],
physics based motion transformation [23], and interactive
simulation and editing of motion [24], [25]. These methods
jointly optimize over space-time using physically grounded
cost functions and constraints. In practice, these methods are
used in conjunction with human demonstrations to guide the
search and have not been applied to robot motion planning.
Witkin and Popovic [26] timewarped motions using C-
splines while preserving the structure of the original motion.
McCann et al. [27] used physics-based constraints to retime
pre-plannedmotionsequencesforcharacteranimation.These
techniques affect timing while keeping the motion intact.
Work in Human Robot interaction has focused on using
timing to enable better interaction [28], [29]. Researchers
have looked at how human motion and gestures vary in
timing and shape to help convey intentions better. For
example, Gielniak and Thomaz studied the importance of
spatiotemporal correspondences in generating human-like
motion [30]. Whitaker [31] discussed the signiﬁcance of
timing in altering perception of people towards actions,
Jeannerod [32] showed that simple reaching and grasping
tasks tend to have a fast approach phase and a slow phase
forgraspingsuccessfully,andBecchioetal.[33]showedthat
velocity proﬁles change based on the task being performed
in isolation or in a social setting. These studies provide
further motivation for extending functional gradient planners
to reason about time.
III. CHOMP PRELIMINARIES
CHOMP [3] is a functional gradient optimization algo-
rithm (Fig.3a) that minimizes a cost functional to produce
smooth collision-free trajectories. CHOMP represents a tra-
jectory ? :[0,1]!Q as a smooth function mapping time
? 2 [0,1] to robot conﬁgurations ? (? )2Q in the robot’s
conﬁguration space.
Functionals are functions of functions. CHOMP considers
objective functionals U :? !R that map each path ? 2 ? to a real number. Here,? is a Hilbert space of trajectories.
The objective functional is a combination of two com-
ponents: a smoothness term that measures the shape of the
trajectory, and an obstacle term that measures its proximity
to obstacles:
U[? ]=F
obs
[? ]+  F
smooth
[? ] (1)
6500
For example, CHOMP uses the integral over squared path
tangent norms as the smoothness cost:
F
smooth
[? ]=
1
2
Z
1
0
 
 
 
 
d
d? ? (? )
 
 
 
 
2
d? (2)
The other term in the objective, F
obs
, encourages
collision-free trajectories by penalizing points close to ob-
stacles. Let c : R
3
! R be a scalar potential deﬁned on
the workspace of the robot (Fig.3a). CHOMP, for example,
deﬁnes a c that increases with proximity to the the nearest
obstacle. LetB? R
3
denote the set of points on the exterior
of the robot. Let x :Q?B! R
3
represent the forward
kinematics of the robot, mapping robot conﬁgurations to 3D
positions. With this, CHOMP deﬁnes the obstacle cost as:
F
obs
[? ]=
Z
1
0
Z
B
c(x(? (? ),u))
 
 
 
 
d
d? x(? (? ),u)
 
 
 
 
du d? (3)
This is the arc-length parametrized line integral (note the
scaling by the norm of workspace velocity) of the robot’s
body points through the workspace cost ﬁeld.
CHOMP then iteratively minimizes the objective func-
tional U over the space of trajectories by minimizing a
regularized ﬁrst order Taylor expansion of the objective
functional around the current path ? i
:
? i+1 = argmin
? U[? i]+
¯
rU [? i]
T
(?   ? i)+
? 2
k?   ? ik
2
A
(4)
where the regularization is with respect to an admissible
norm A in ? and ? is a step size parameter. Taking the
gradient of (4) and setting it to zero gives the update rule:
? i+1 = ? i  1
? A
  1
¯
rU [? i] (5)
where
¯
rU [? i
] is the functional gradient of the cost func-
tional.
IV. OPTIMIZING IN SPACE-TIME
We outline the framework for jointly optimizing in Space-
Time using functional gradient descent. Like CHOMP, we
consider position trajectories ? :[0,1]!Q as smooth
functions mapping ? 2 [0,1] to robot conﬁgurations. For-
mally, we refer to ? as pseudo time; it mimics time, but is
ﬁxed during the optimization. We think of ? as a stepping
parameter that montotonically increases as we traverse the
trajectory; it is 0 at the start and 1 at the goal. With this
notation, we introduce a time trajectory t:[0,1]!R
+
as
smooth function mapping ? 2 [0,1] to time t(? )2 R
+
. In
the waypoint parametrization, t is a vector of time points,
t(? ) is the time at which the robot is in conﬁguration ? (? ).
It is important to note that ? and t are independent of each
other, and are related only through their dependence on ? .
We consider objective functionals U :[? ,?] !R that map
a pair of path ? 2 ? and timing t 2 ? to a real number.
Here, ? is a Hilbert space of all possible time trajectories.
Similar to CHOMP, the objective functional is made up of
smoothness and obstacle terms.
A. Smoothness functional
The smoothness functional F
smooth
measures the shape
of the position trajectory ? and time trajectory t. We use the
integral over squared tangent norms of ? and t:
F
smooth
[?,t ]=
1
2
Z
1
0
 
 
 
 
 
d
d? ? (? )
 
 
 
 
2
+   
 
 
 
d
d? t(? )
 
 
 
 
2
!
d? (6)
where   trades off time and position smoothness. F
smooth
does not enforce coupling between the path ? and its timing
t; if the obstacle cost is zero, the resulting objective treats
the trajectories independently. MinimizingF
smooth
moves ? towards a straight line and leads t to have equal spacing.
The smoothness functional implicitly constrains the speed
kx
0
k/t
0
, but it can be modiﬁed to directly minimize this.
1
B. Obstacle functional
The obstacle functionalF
obs
measures proximity to obsta-
clesandencodesinteractionbetweenthepath? anditstiming
t. We consider a general functional f :[? ,? ,? 0
,? 0
]! R
and deﬁne the obstacle functional:
F
obs
[?,t ]=
Z
1
0
Z
B
f(?,t,? 0
,t
0
) du d? (7)
which is the line integral of the robot’s body points through
f. The CHOMP obstacle functional (3) is a special case
of this general cost functional where f maps the trajectory
through forward kinematics to measure a position-dependent
workspace potential scaled by the workspace velocity.
C. Functional gradients
We compute the functional gradient of the objective func-
tional by applying the Euler-Lagrange equations [34] for
the path ? and timing t. The functional gradients of the
smoothness functional are straightforward:
¯
rF
? smooth
[?,t ]=  ? 00
(? );
¯
rF
t
smooth
[?,t ]=   t
00
(? ) (8)
where
¯
rU
? and
¯
rU
t
are the functional gradients with
respect to ? and t respectively. The obstacle functional is
more general and its functional gradient is the functional
gradient of f with respect to ? and t. We have:
¯
rF
? obs
[?,t ]=
Z
B

@f
@?
  d
d? @f
@?
0
 
du (9)
¯
rF
t
obs
[?,t ]=
Z
B

@f
@t
  d
d? @f
@t
0
 
du (10)
For the CHOMP objective,
@f
@t
=0 and
@f
@t
0
=0; it has
no time gradient. Fig.2 visualizes the gradients for a single
iteration in a 2D environment with a circular obstacle. The
smoothness gradients (red arrows) push ? towards a straight
line trajectory (Fig.2a) and t towards equal spacing (Fig.2b).
D. Gradient Descent
At every iteration of the optimization, we minimize a
regularized ﬁrst order taylor expansion of our functional U
about the current trajectories (? i
,t
i
) :
(? i+1,ti+1) = argmin
?,t
U[? i,ti]+
¯
rU
? [? i,ti]
T
(?   ? i)
+
¯
rU
t
[? i,ti]
T
(t  ti)+
? 2
k?   ? ik
2
A
+
? 0
2
kt  tik
2
B
(11)
where B is an allowable metric on ? . Computing the
gradient of this expression with respect to ? andt and setting
1
()
0
refers to
d
d? 6501
(a) Gradients for position (? ) (b) Gradients for time (t)
Fig. 2: Smoothness (red) and obstacle (blue) gradients for a
velocity scaled obstacle functional (18). Black circle is the obstacle.
themtozero,wearriveattheupdaterulesforthetrajectories.
The update for ? is the same as (5) while for t it is:
ti+1 =ti  1
? 0
B
  1
¯
r U
t
[? i,ti] (12)
V. CONSTRAINTS
The optimization problem in (11) is unconstrained in
positionandtime.Weimposeboundconstraintsonthepath? to ensure that the robot stays within its joint limits. These are
linear inequality constraints for which a closed form update
rule can be derived in a manner similar to [35]. We impose
monotonicity constraints on the time trajectory t to ensure
that the optimization does not move time backwards.
To derive the update rule for the constraints, we explicitly
assume a waypoint parametrization for the path ? and its
timing t. t is now a sequence of n+1 waypoints t =
[T
1
,T
2
,T
3
,...T
n+1
] with T
0
=0 and T
n+1
= T
goal
,
the total duration of the motion. In this paper, we consider a
ﬁxed, pre-speciﬁed duration for the robot’s motion; T
goal
2 R
+
is constant throughout our optimization. Similarly, the
start and end points of the path ? are assumed ﬁxed.
A. Time monotonicity
We formulate the monotonicity constraint on t as a set of
linear inequality constraints:
  t=(T
j
  T
j  1
)  ?; 8 j=1,2,...n+1 (13)
where ? 2 R
+
. While ? =0 is enough to ensure mono-
tonicity, in practice this can result in inﬁnite velocities and
numerical instabilities. By choosing ? 2 R
+
we implicitly
constrain the maximum velocity subject to smoothness. To
ensuremonotonicityissatisﬁedthroughoutt,wefreetheend
pointT
n+1
;elsewehavemoreconstraintsthanvariables.We
rewrite the constraints as:
  T
j
(Xt+y)  ? =)    T
j
(Xt+y)+? 0 (14)
where X is a (n + 1)? (n + 1) ﬁnite-difference matrix
[X(j,j)=1,X(j,j  1) =  1; 8 j],y isa(n+1)? 1vector
to take care of the start point [y(1) =  T
0
,y(2,..,n+1) =
0]and  j
isa (n+1)? 1indicatorvectorwiththejthelement
equal to 1 and 0 otherwise.
B. Fixed time duration
Previously we assumed a ﬁxed duration for our trajec-
tories, but we had to free the end point T
n+1
to ensure
monotonicity. To counter this, we add a linear equality
constraint on the end point:
T
n+1
= T
goal
=)   T
n+1
t  T
goal
=0 (15)
Algorithm 1 Computing W,z,v for constraints on t
S =S1[ S2 ; m =|S| .S1 := (n+1)
W 2 R
m? m
; z,v2 R
m? 1
for x=1:m do
j =S(x)
if j2 S1 then . Fixed duration (FD) constraint
z(x):=   v(x)= ? 0
 
  T
n+1
ti  T
goal
 
    T
n+1
B
  1
¯
rU
t
else . Monotonicity (TM) constraint
z(x):=  ? j
v(x)= ? 0
?
  T
j
(Xti +y)  ?
?
    T
j
XB
  1
¯
rU
t
for y=1:m do
k =S(y)
if x=1 and y=1 then . FD term
W(x,y)=
 
B
  1
 
n+1,n+1
else if x=1 andy> 1 then . Cross terms
W(x,y)=
 
B
  1
X
T
 
n+1,j
else ifx> 1 and y=1 then . Cross terms
W(x,y)=
 
XB
  1
 
j,n+1
else . TM terms
W(x,y)=
 
XB
  1
X
T
 
j,k
C. Lagrangian
Taking the constraints into the optimization, we have the
Lagrangian:
L[?,t ]=U[? i,ti]+
?
¯
rU
?T
?
(?   ? i)+
? 2
k?   ? ik
2
A
+
?
¯
rU
tT
?
(t  ti)+
? 0
2
kt  tik
2
B
  n+1
X
j=1
? j
h
  T
j
(Xt+y)  ?
i
+  ?
  T
n+1
t  T
goal
?
(16)
where ? j
’s and   are KKT multipliers and functional gra-
dients
¯
rU
? ,
¯
rU
t
are evaluated at current estimates (? i
,t
i
).
D. Time trajectory update
TakingthegradientoftheLagrangianwithrespecttotand
setting it to zero, we get the ﬁrst order optimality condition:
t =ti  1
? 0
B
  1
"
¯
rU
t
  n+1
X
j=1
? j
?
X
T
  j
?
+   n+1
#
(17)
The monotonicity constraints are inequality constraints and
are either active or inactive, and the linear ﬁxed duration
constraint is always active. In a general case, the ﬁxed dura-
tion constraint is active at the goal   6= 0; S
1
:= (n+1) and
there is some set S
2
? [1,2,...,n+1] of active monotonicity
constraints ? j
6= 0;8 j 2 S
2
. To solve for the unknown
scalars ? j
,  we can substitute the optimality condition (17)
in the KKT complementarity conditions for the constraints
   
  T
n+1
t  T
goal
 
=0; ? j
 
  T
j
(Xt+y)  ?
 
= 0;8 j 2 S
2
. This results in |S
1
[ S
2
| simultaneous equations in the
unknowns, which we write in the form of a matrix vector
equation:
Wz = v =) z = W
†
v
where z is a vector of unknown KKT multipliers. Due to
space constraints, we do not detail the derivation of this
structure, but Algorithm (1) gives a procedure to compute
the KKT multipliers for a general case. Substituting these
into (17) gives the updated time trajectory t
i+1
.
6502
E. What does the update do?
For a speciﬁc active constraint j the expression for v in
Algorithm 1 is made up of two terms, the magnitude of
the current violation at j scaled by the step size ? 0
and a
scaled version of the gradient at j. The matrix W measures
correlation between all active constraints and is dependent
on the metric B and the constraint matrix X. The algorithm
takes the gradient and violation, scales it through the inverse
correlation matrix and smoothly updates the trajectory. At j,
it cancels out the gradient and corrects the violation. Away
fromj itscalestheupdatebasedonthemetricB.Thematrix
W is invertible for the current set of time constraints, but in
a general case this may not be true. Using the pseudo-inverse
amounts to projecting on a lower dimensional set of linearly
independent constraints. Throughout the derivation, we did
not make any explicit assumptions on the structure of X; the
update is thus valid for any linear inequality constraint on t.
In fact, joint limit constraints on ? can be formulated in this
way and the resulting W is an invertible submatrix of A
  1
.
To compute the constrained update, we need X,B
  1
and
W. X and B
  1
can be pre-computed while W needs to
be computed at each iteration. In the worst case, we can
have active monotonicity constraints on all the n+1 points,
leading W to have size (n + 2)? (n + 2). So, the added
complexityoftheconstrainedupdateoverCHOMPisO(n
3
).
VI. VELOCITY SCALING
Withaframeworkinplaceforspace-timeoptimization,we
proceed to choose a speciﬁc obstacle functional to evaluate
the performance of our algorithm. We consider an obstacle
functional of the form f :[? ,? 0
,? 0
]!R :
F
obs
=
Z
1
0
Z
B
c(x)
kx
0
k
t
0
du d? (18)
where the obstacle potential c from [3] is scaled by the norm
of workspace velocity. We compute the functional gradient
of this obstacle cost function:
¯
rF
? obs
=
Z
B
J
T
kx
0
k
t
0

?
I  ˆ x
0
ˆ x
0T
?
r c  ck +c
x
0
kx
0
k
2
t
00
t
0
 
(19)
¯
rF
t
obs
=
Z
B
kx
0
k
(t
0
)
2

x
0T
r c+c
x
0T
x
00
kx
0
k
2
  2c
t
00
t
0
 
du (20)
where k = kx
0
k
  2
 
I  ˆ x
0
ˆ x
0T
 
x
00
is the curvature vector.
The obstacle functional scales the position-dependent poten-
tial c by the norm of the workspace velocity and it naturally
encourages the trajectory to have lesser velocity and cost.
Fig.2 shows the obstacle gradients (blue) for a single
obstacle environment. The gradients push ? away from the
obstacle (Fig.2a) and try to make the trajectory slower near
obstacles by spreading the time points apart (Fig.2b).
A. What can T-CHOMP do differently?
For a given objective functional, CHOMP modiﬁes the
path ? to minimize cost. T-CHOMP extends functional
gradientplannerstooptimizeoverspace-time,meaningitcan
modify both the path ? and its timing t (or either). With this
in mind, we can broadly group the behavior of T-CHOMP
into the following three classes:
1) T-CHOMP encodes interaction between the path ? and
its timing t through the obstacle functional (7). When
the algorithm successfully minimizes this functional (or
in its absence), ? and t become independent, reducing
T-CHOMP to CHOMP. In the context of our current
obstacle functional, if the path escapes the obstacle’s
inﬂuence, T-CHOMP starts to behave like CHOMP
2) When there is interaction between ? and t, the cross
terms in the functional gradients (19), (20) encourage
T-CHOMP to jointly optimize ? and t. When the path
? reaches a local minima, T-CHOMP can reduce cost
by modifying the timing t (subject to smoothness and
monotonicity constraints). For the velocity scaled ob-
jective, when T-CHOMP is unable to escape obstacles,
it can lower the robot’s velocity proﬁle near obstacles
3) Finally,incaseswhereT-CHOMPfreelyoptimizesboth
? and t, the optimization can fall into different basins
of attraction than CHOMP resulting in meaningfully
different paths ? and timing t. (Fig.1a) is a good
example where the velocity scaled objective causes T-
CHOMP to take a slower, more direct route to the goal.
Obviously, there could be a host of in-between cases, but
to highlight our differences to CHOMP, these serve as good
representatives.
VII. EXPERIMENTS
We present simulation experiments from T-CHOMP and
highlight our results by comparing to CHOMP. In all experi-
ments, we use the velocity scaled obstacle functional (18) for
T-CHOMP and the arc-length parametrized functional (3) for
CHOMP. We use the same workspace cost potential c and
smoothness cost functional F
smooth
(2) as CHOMP [3] and
choose the metrics A and B to measure total acceleration in
? and t respectively. We test the following hypotheses:
H
1
. T-CHOMP with velocity scaling manipulates time to
meaningfully alter the velocity proﬁles of trajectories
in comparison with CHOMP
H
2
. T-CHOMP with velocity scaling leads to different
basins of attraction resulting in different trajectories in
comparison with CHOMP
which correspond to the second and third cases discussed in
Sec. VI-A. We do not discuss the case without obstacles as
it is evident that T-CHOMP directly reduces to CHOMP.
We test two scenarios in simulation: (1) a 2D point robot
with planar obstacles, and (2) a 7DOF BarrettWAM attached
to Marvin and HERB in realistic kitchen setups. We use the
following plots to aid explanation:
1) Rendered workspace trajectories x(? ) returned by T-
CHOMP and CHOMP
2) Robot’s speed kx
0
k/t
0
at each trajectory point as a
function of the distance to the closest obstacle
3) T-CHOMP timing t as a function of CHOMP’s timing
? (equally spaced in 2D, parabolically retimed in 7D)
A. 2D Point Robot
We tested the algorithms on several 2D obstacle avoidance
tasks with randomly generated start and end points and
6503
(a) Optimized paths (b) Distance to obstacle vs Speed (c) Time comparison
Fig. 3: 2D point robot: Although the paths are nearly identical, retiming signiﬁcantly reduces cost.
(a) Optimized paths (b) Distance to obstacle vs Speed (c) Time comparison
Fig. 4: 2D point robot: T-CHOMP (green) escapes CHOMP’s (red) local minimum and produces a different lower-cost trajectory.
circular obstacles. The duration of motion was ﬁxed at 1
second and the algorithms were initialized with equally
spaced points in time and straight line paths in space.
We used the following default parameters: n = 99,? =
0.005,? = ? 0
=
1
500
,  =   =1 and ran until convergence.
Our resulting trajectories fell primarily into two classes.
The ﬁrst, illustrated in Fig.3, is where both paths (green
for T-CHOMP and red for CHOMP in Fig.3a) are nearly
identical, but T-CHOMP achieves lower cost by retiming. By
manipulating timing, T-CHOMP slows down near obstacles,
lowering cost. This is evident in Fig.3b where CHOMP (red)
shows no interesting structure, but there is signiﬁcant corre-
lation between speed and obstacle distance for T-CHOMP.
At points closer to the obstacle, the speed is less, but farther
away it increases dramatically until it saturates at a distance
of around 0.2 m which is exactly the obstacle tolerance for
this experiment. The fact that the speed saturates means that
the time difference for those points is? ?. Fig.3c shows the
comparison of time trajectories between the algorithms with
T-CHOMP on the y-axis. Near the middle, T-CHOMP slows
down signiﬁcantly as it is near obstacles, then speeds up at
the end when it is outside the obstacle’s inﬂuence. This is
exactly what we hypothesized (H
1
): even if the path is stuck,
T-CHOMP can modify timing to reduce cost.
The second class, illustrated in Fig.4, is where the ﬁnal
paths of the algorithms are different (Fig.4a). CHOMP gets
stuck in the local minima between obstacles and returns a
high cost path while T-CHOMP ﬁnds a signiﬁcantly lower-
cost path away from the obstacles, just as hypothesized in
H
2
. Once out of the obstacles’ inﬂuence, the obstacle func-
tionalreachesanearglobalminimumandthealgorithmstarts
to aggressively reduce the smoothness objective, pushing t
towards equal spacing. This is in line with Fig.4c which
shows minimal re-timing. This is exactly what we expected
Parameters CHOMP objective T-CHOMP objective
Default 1.7±1.223.6±1.8
n
obs
=1   0.6±0.33.3±0.9
n
obs
=5 0.4±1.331.2±1.3
T
goal
=2.0 s   0.8±0.46.1±0.4
T
goal
=0.75 s 1.1±1.732.0±2.1
?=0.01 s 1.4±0.84.7±0.8
?=0.001 s   3.4±5.620.7±6.4
TABLE I: Cost improvement for T-CHOMP over CHOMP from
100 2D tests, measured as percentage of CHOMP trajectory cost.
Positive value implies T-CHOMP has lower cost. All tests use
default parameters (Sec. VII-A) with n
obs
=3. Error metric is
Standard Error.
the algorithm to do (Sec. VI-A); when the path is able to
escape obstacles, we tend more towards CHOMP. This also
explains the lack of structure in Fig.4b.
Table I shows the percentage cost improvement of T-
CHOMP over CHOMP on 100 random 2D scenarios with
varying parameters. With the default parameters, T-CHOMP
signiﬁcantly outperforms CHOMP when compared under the
T-CHOMP objective. This is in line withH
1
, and shows that
T-CHOMP reduces cost even when stuck in local optima of
the path. Predominantly, the T-CHOMP path ? tends to be
similar to CHOMP and there is variation in t. But in around
5% of our tests, we found that T-CHOMP escapes CHOMP’s
local optima (H
2
), leading to paths with signiﬁcantly lower
costs. This is reﬂected in the results: T-CHOMP also per-
forms better than CHOMP under the CHOMP objective.
B. 7D Robot Manipulator
We implemented T-CHOMP in the OpenRAVE [36] sim-
ulation environment as an add-on to the CHOMP implemen-
tation from [3] and evaluated the algorithms with Marvin
and HERB in a kitchen environment. In all experiments,
the algorithms were initialized with straight line paths in
conﬁguration space. CHOMP was initialized with equally
spaced points from 0 to 1 second and its output retimed by
6504
Fig. 7: End-effector paths for the task in Fig.5, initialized to a
longer duration (? 10s). T-CHOMP (green) takes a completely
different path from CHOMP (red).
OpenRAVE’s parabolic retimer to be within velocity and ac-
celerationlimits. T-CHOMPwas initialized withthe duration
of this retimed trajectory, with equally spaced points. Default
parameters from Sec. VII-A were used.
We set up two types of reaching tasks for the robots in
the kitchen environment: (1) Fig.5 where Marvin’s arm starts
off at a conﬁguration above the kitchen counter and moves
towards a bottle inside the microwave on its lower left and
(2) Fig.6 where HERB’s right arm tries to get around a box
placed on the countertop. Just like in the 2D case, our results
fell primarily into two classes.
The ﬁrst class, illustrated in Fig.5a, is where the optimized
paths are nearly identical. The distance-speed plot in Fig.5b
is very similar to Fig.3b, T-CHOMP slows the robot near
obstacles and speeds it up away from them. This is also
reﬂected in Fig.5c, T-CHOMP makes the robot slower until
it leaves the counter ( 0.3 s), then speeds it up ( 0.5 s) till it
gets near the microwave after which it slows until the goal.
The second class, illustrated in Fig.6, is where the two
trajectories are different. CHOMP follows the gradient of
the obstacle potential to move away from the box resulting
in a trajectory that makes a wide berth of the obstacle. T-
CHOMP on the other hand is attracted to the optima above
the box. By manipulating timing and reducing the velocity
near the box, T-CHOMP lowers the cost of the path, making
it desirable to move above the box rather than avoiding it
altogether. This results in completely different end-effector
paths as witnessed in Fig.6a. A look at Fig.6b reveals a
similarity to the 2D example in Fig.4: there is little structure
and the trajectory has lower speed throughout. Fig.6c shows
the expected slowdown in timing near the middle.
Fig.7 provides further proof for our hypotheses. Given a
longer duration for the motion (? 5x previous), T-CHOMP
manipulates timing to reach a different local minima that
takes a direct route to the microwave. This behavior high-
lights an interesting property of our algorithm: We get a
different path and timing for every new duration. We believe
this to be an interesting feature of our algorithm that can be
exploited to better optimize the objective. These scenarios
show that our hypotheses are valid in higher dimensions.
Joint space-time optimization allows T-CHOMP to directly
exploit timing, resulting in meaningfully different behavior.
The attached video elaborates these results further.
VIII. DISCUSSION
We introduced T-CHOMP, a novel motion planner that
extends functional gradient optimization to space-time. We
showed that T-CHOMP with a velocity scaled objective
functional results in meaningful changes to trajectories in
comparison with CHOMP. While the method is general, the
implementationissensitivetoparameters,especiallythetotal
duration (T
goal
) and monotonicity constraint (?).
Increasing T
goal
affords the algorithm more ﬂexibility in
modifying timing but also reduces speed throughout the
trajectory, effectively reducing cost. While this can result
in different local optima (Fig.7), this can also result in risky
behavior where the algorithm thinks that it has low cost even
near obstacles. Table I shows results from 2D scenarios that
highlightthisissue:doublingthedurationreducesT-CHOMP
performance signiﬁcantly. On the other hand, reducing the
duration far too much can result in numerical instabilities. In
general, the total duration has to be determined while taking
into account the length of the motion, the robot’s velocity
limits and the number of points on the trajectory. A rule of
thumb can be twice the time taken to travel the straight line
trajectory at maximum velocity.
A loose monotonicity constraint (smaller ?) allows for
more freedom in manipulating timing, but can lead to poor
time smoothness, large increases in acceleration and numer-
ical instabilities. Too tight a constraint stiﬂes the ﬂexibility
and reduces performance, as can be seen from the results in
Table I. Critical to choosing a good ? are the robot’s velocity
limits;?canbelargerthanthetimetotraversetwosuccessive
waypointsofthestraightlinetrajectoryatmaximumvelocity.
Many of our issues with local optima and parameter
sensitivity are due to a ﬁxed motion duration which restricts
the solution space the optimizer can choose from. We be-
lieve that key to addressing these issues is the ability to
afford the optimizer freedom to choose the total duration.
T-CHOMP does not have explicit velocity constraints, rather
it implicitly constrains velocity through smoothness priors
andmonotonicity.Webelievethataddingvelocityconstraints
directlyinto theoptimization isthe correctway torestrictthe
search space. Combined with variable duration optimization,
we see T-CHOMP as generating valid controls for the task
at hand, subject to the robot’s physical constraints.
T-CHOMP can represent more general context dependent
costfunctionalsthatdependbothonpositionandtime.While
this offers more freedom, it is hard for an end user to specify
the correct functional to match a task. We are interested
in exploring the use of Inverse Optimal Control techniques
[37] to learn these cost functions from demonstrations.
Time dependency in the cost functional should allow us to
naturally handle dynamic obstacles in the environment and
is another interesting direction for future work.
REFERENCES
[1] S. Quinlan and O. Khatib, “Elastic bands: Connecting path planning
and control,” in IEEE-RA. IEEE, 1993, pp. 802–807.
[2] N. Ratliff, M. Zucker, J. A. Bagnell, and S. Srinivasa, “Chomp:
Gradient optimization techniques for efﬁcient motion planning,” in
IEEE ICRA. IEEE, 2009, pp. 489–494.
6505
(a) Optimized End-effector paths (b) Distance to obstacle vs Speed (c) Time comparison
Fig. 5: Marvin robot: Although paths are nearly identical, retiming signiﬁcantly reduces cost.
(a) Optimized End-effector paths (b) Distance to obstacle vs Speed (c) Time comparison
Fig. 6: HERB robot: T-CHOMP (green) escapes CHOMP’s (red) local minimum and produces a different lower-cost trajectory.
[3] M. Zucker, N. Ratliff, A. Dragan, M. Pivtoraiko, M. Klingensmith,
C. M. Dellin, J. A. Bagnell, and S. Srinivasa, “Chomp: Covariant
hamiltonian optimization for motion planning,” 2013.
[4] M. Kalakrishnan, S. Chitta, E. Theodorou, P. Pastor, and S. Schaal,
“Stomp: Stochastic trajectory optimization for motion planning,” in
IEEE ICRA. IEEE, 2011, pp. 4569–4574.
[5] C. Park, J. Pan, and D. Manocha, “Itomp: Incremental trajectory
optimization for real-time replanning in dynamic environments.” in
ICAPS, 2012.
[6] J. Schulman, A. Lee, I. Awwal, H. Bradlow, and P. Abbeel, “Find-
ing locally optimal, collision-free trajectories with sequential convex
optimization,” RSS, 2013.
[7] E. Todorov and W. Li, “A generalized iterative LQG method for
locally-optimal feedback control of constrained nonlinear stochastic
systems,” in ACC. IEEE, 2005, pp. 300–306.
[8] J. Van Den Berg, P. Abbeel, and K. Goldberg, “LQG-MP: Optimized
path planning for robots with motion uncertainty and imperfect state
information,” IJRR, vol. 30, no. 7, pp. 895–913, 2011.
[9] J. E. Bobrow, S. Dubowsky, and J. Gibson, “Time-optimal control of
robotic manipulators along speciﬁed paths,” IJRR, vol. 4, no. 3, pp.
3–17, 1985.
[10] Z. Shiller and S. Dubowsky, “On computing the global time-optimal
motions of robotic manipulators in the presence of obstacles,” IEEE-
RA, vol. 7, no. 6, pp. 785–797, 1991.
[11] J. M. Hollerbach, “Dynamic scaling of manipulator trajectories,” in
ACC. IEEE, 1983, pp. 752–756.
[12] J. T. Betts, “Survey of numerical methods for trajectory optimization,”
J.ofguidance,control,anddynamics,vol.21,no.2,pp.193–207,1998.
[13] O. Khatib, “Real-time obstacle avoidance for manipulators and mobile
robots,” IJRR, vol. 5, no. 1, pp. 90–98, 1986.
[14] E. Rimon and D. E. Koditschek, “Exact robot navigation using
artiﬁcial potential functions,” IEEE-RA, vol. 8, no. 5, pp. 501–518,
1992.
[15] E. Theodorou, J. Buchli, and S. Schaal, “Reinforcement learning of
motor skills in high dimensions: A path integral approach,” in IEEE
ICRA. IEEE, 2010, pp. 2397–2403.
[16] J. Canny, J. Reif, B. Donald, and P. Xavier, “On the complexity of
kinodynamic planning,” in Foundations of Computer Science, 1988.,
29th Annual Symposium on. IEEE, 1988, pp. 306–316.
[17] R. F. Stengel, Optimal control and estimation. Dover publns., 1986.
[18] D. Jacobson and D. Mayne, “Differential dynamic programming,”
1970.
[19] M. Toussaint, “Robot trajectory optimization using approximate infer-
ence,” in ICML. ACM, 2009, pp. 1049–1056.
[20] K. Rawlik, M. Toussaint, and S. Vijayakumar, “An approximate
inference approach to temporal optimization in optimal control.” in
NIPS, 2010.
[21] A. Witkin and M. Kass, “Spacetime constraints,” in ACM SIGGRAPH,
vol. 22, no. 4. ACM, 1988, pp. 159–168.
[22] M. Gleicher, “Retargetting motion to new characters,” in ACM SIG-
GRAPH. ACM, 1998, pp. 33–42.
[23] Z. Popovi´ c and A. Witkin, “Physically based motion transformation,”
in ACM SIGGRAPH, 1999, pp. 11–20.
[24] M. F. Cohen, “Interactive spacetime control for animation,” in ACM
SIGGRAPH, vol. 26, no. 2. ACM, 1992, pp. 293–302.
[25] J. Popovi´ c, S. M. Seitz, M. Erdmann, Z. Popovi´ c, and A. Witkin, “In-
teractivemanipulationofrigidbodysimulations,”inACMSIGGRAPH,
2000, pp. 209–217.
[26] A. Witkin and Z. Popovic, “Motion warping,” in ACM SIGGRAPH.
ACM, 1995, pp. 105–108.
[27] J. McCann, N. S. Pollard, and S. Srinivasa, “Physics-based motion
retiming,”inACMSIGGRAPH/EurographicsSCA,2006,pp.205–214.
[28] M. Huber, M. Rickert, A. Knoll, T. Brandt, and S. Glasauer, “Human-
robot interaction in handing-over tasks,” in IEEE RO-MAN. IEEE,
2008, pp. 107–112.
[29] M. Cakmak, S. S. Srinivasa, M. K. Lee, J. Forlizzi, and S. Kiesler,
“Human preferences for robot-human hand-over conﬁgurations,” in
IEEE/RSJ IROS. IEEE, 2011, pp. 1986–1993.
[30] M. J. Gielniak and A. L. Thomaz, “Spatiotemporal correspondence as
a metric for human-like robot motion,” in ACM/IEEE HRI, 2011.
[31] H. Whitaker and J. Halas, Timing for animation. Taylor & Francis
US, 2002.
[32] M. Jeannerod, “The timing of natural prehension movements.” Journal
of motor behavior, 1984.
[33] C.Becchio,L.Sartori,andU.Castiello,“Towardyouthesocialsideof
actions,” Current Directions in Psychological Science, vol. 19, no. 3,
pp. 183–188, 2010.
[34] I. M. Gelfand and S. V. Fomin, Calculus of variations. Courier Dover
Publications, 2000.
[35] A. D. Dragan, N. D. Ratliff, and S. S. Srinivasa, “Manipulation
planning with goal sets using constrained trajectory optimization,” in
IEEE ICRA. IEEE, 2011, pp. 4582–4588.
[36] R. Diankov and J. Kuffner, “Openrave: A planning architecture for
autonomous robotics,” Robotics Institute, Pittsburgh, PA, Tech. Rep.
CMU-RI-TR-08-34, p. 79, 2008.
[37] B. D. Ziebart, A. L. Maas, J. A. Bagnell, and A. K. Dey, “Maximum
entropy inverse reinforcement learning.” in AAAI, 2008, pp. 1433–
1438.
6506
